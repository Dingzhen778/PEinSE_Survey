2212.08221v1,SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval,http://arxiv.org/abs/2212.08221v1,"Pre-trained giant code models (PCMs) start coming into the developers' dailypractices. Understanding what types of and how much software knowledge ispacked into PCMs is the foundation for incorporating PCMs into softwareengineering (SE) tasks and fully releasing their potential. In this work, weconduct the first systematic study on the SE factual knowledge in thestate-of-the-art PCM CoPilot, focusing on APIs' Fully Qualified Names (FQNs),the fundamental knowledge for effective code analysis, search and reuse. Drivenby FQNs' data distribution properties, we design a novel lightweight in-contextlearning on Copilot for FQN inference, which does not require code compilationas traditional methods or gradient update by recent FQN prompt-tuning. Wesystematically experiment with five in-context-learning design factors toidentify the best in-context learning configuration that developers can adoptin practice. With this best configuration, we investigate the effects of amountof example prompts and FQN data properties on Copilot's FQN inferencecapability. Our results confirm that Copilot stores diverse FQN knowledge andcan be applied for the FQN inference due to its high inference accuracy andnon-reliance on code analysis. Based on our experience interacting withCopilot, we discuss various opportunities to improve human-CoPilot interactionin the FQN inference task.",Qing Huang,2022/12/16,2022/12/16
2401.12412v1,Program Decomposition and Translation with Static Analysis,http://arxiv.org/abs/2401.12412v1,"The rising popularity of Large Language Models (LLMs) has motivated exploringtheir use in code-related tasks. Code LLMs with more than millions ofparameters are trained on a massive amount of code in different ProgrammingLanguages (PLs). Such models are used for automating various SoftwareEngineering (SE) tasks using prompt engineering. However, given the very largesize of industry-scale project files, a major issue of these LLMs is theirlimited context window size, motivating the question of ""Can these LLMs processvery large files and can we effectively perform prompt engineering?"". Codetranslation aims to convert source code from one PL to another. In this work,we assess the effect of method-level program decomposition on context window ofLLMs and investigate how this approach can enable translation of very largefiles which originally could not be done due to out-of-context issue. Ourobservations from 20 well-known java projects and approximately 60K methodssuggest that method-level program decomposition significantly improves thelimited context window problem of LLMs by 99.5%. Furthermore, our empiricalanalysis indicate that with method-level decomposition, each input fragment onaverage only consumes 5% of the context window, leaving more context space forprompt engineering and the output. Finally, we investigate the effectiveness ofa Call Graph (CG) approach for translating very large files when doingmethod-level program decomposition.",Ali Reza Ibrahimzada,2024/1/22,2024/1/22
2303.13534v2,Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering,http://arxiv.org/abs/2303.13534v2,"We are witnessing a novel era of creativity where anyone can create digitalcontent via prompt-based learning (known as prompt engineering). This paperdelves into prompt engineering as a novel creative skill for creating AI artwith text-to-image generation. In a pilot study, we find that many crowdsourcedparticipants have knowledge about art which could be used for writing effectiveprompts. In three subsequent studies, we explore whether crowdsourcedparticipants can put this knowledge into practice. We examine if participantscan 1) discern prompt quality, 2) write prompts, and 3) refine prompts. We findthat participants could evaluate prompt quality and crafted descriptiveprompts, but they lacked style-specific vocabulary necessary for effectiveprompting. This is in line with our hypothesis that prompt engineering is a newtype of skill that is non-intuitive and must first be acquired (e.g., throughmeans of practice and learning) before it can be used. Our studies deepen ourunderstanding of prompt engineering and chart future research directions. Weoffer nine guidelines for conducting research on text-to-image generation andprompt engineering with paid crowds. We conclude by envisioning four potentialfutures for prompt engineering.",Jonas Oppenlaender,2023/3/13,2023/12/3
2308.12415v1,Benchmarking Causal Study to Interpret Large Language Models for Source Code,http://arxiv.org/abs/2308.12415v1,"One of the most common solutions adopted by software researchers to addresscode generation is by training Large Language Models (LLMs) on massive amountsof source code. Although a number of studies have shown that LLMs have beeneffectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu),previous research has largely overlooked the role of Causal Inference as afundamental component of the interpretability of LLMs' performance. Existingbenchmarks and datasets are meant to highlight the difference between theexpected and the generated outcome, but do not take into account confoundingvariables (e.g., lines of code, prompt size) that equally influence theaccuracy metrics. The fact remains that, when dealing with generative softwaretasks by LLMs, no benchmark is available to tell researchers how to quantifyneither the causal effect of SE-based treatments nor the correlation ofconfounders to the model's performance. In an effort to bring statistical rigorto the evaluation of LLMs, this paper introduces a benchmarking strategy namedGaleras comprised of curated testbeds for three SE tasks (i.e., codecompletion, code summarization, and commit generation) to help aid theinterpretation of LLMs' performance. We illustrate the insights of ourbenchmarking strategy by conducting a case study on the performance of ChatGPTunder distinct prompt engineering methods. The results of the case studydemonstrate the positive causal influence of prompt semantics on ChatGPT'sgenerative performance by an average treatment effect of $\approx 3\%$.Moreover, it was found that confounders such as prompt size are highlycorrelated with accuracy metrics ($\approx 0.412\%$). The end result of ourcase study is to showcase causal inference evaluations, in practice, to reduceconfounding bias. By reducing the bias, we offer an interpretable solution forthe accuracy metric under analysis.",Daniel Rodriguez-Cardenas,2023/8/23,2023/8/23
2310.08879v1,A Critical Review of Large Language Model on Software Engineering: An Example from ChatGPT and Automated Program Repair,http://arxiv.org/abs/2310.08879v1,"Large Language Models (LLMs) have been gaining increasing attention anddemonstrated promising performance across a variety of Software Engineering(SE) tasks, such as Automated Program Repair (APR), code summarization, andcode completion. For example, ChatGPT, the latest black-box LLM, has beeninvestigated by numerous recent research studies and has shown impressiveperformance in various tasks. However, there exists a potential risk of dataleakage since these LLMs are usually close-sourced with unknown specifictraining details, e.g., pre-training datasets.  In this paper, we seek to review the bug-fixing capabilities of ChatGPT on aclean APR benchmark with different research objectives. We first introduce{\benchmark}, a new benchmark with buggy and the corresponding fixed programsfrom competitive programming problems starting from 2023, after the trainingcutoff point of ChatGPT. The results on {\benchmark} show that ChatGPT is ableto fix 109 out of 151 buggy programs using the basic prompt within 35independent rounds, outperforming state-of-the-art LLMs CodeT5 and PLBART by27.5\% and 62.4\% prediction accuracy. We also investigate the impact of threetypes of prompts, i.e., problem description, error feedback, and buglocalization, leading to additional 34 fixed bugs. Besides, we provideadditional discussion from the interactive nature of ChatGPT to illustrate thecapacity of a dialog-based repair workflow with 9 additional fixed bugs.Inspired by the findings, we further pinpoint various challenges andopportunities for advanced SE study equipped with such LLMs (e.g.,~ChatGPT) inthe near future. More importantly, our work calls for more research on thereevaluation of the achievements obtained by existing black-box LLMs acrossvarious SE tasks, not limited to ChatGPT on APR.",Quanjun Zhang,2023/10/13,2023/10/13
2311.05661v1,Prompt Engineering a Prompt Engineer,http://arxiv.org/abs/2311.05661v1,"Prompt engineering is a challenging yet crucial task for optimizing theperformance of large language models (LLMs). It requires complex reasoning toexamine the model's errors, hypothesize what is missing or misleading in thecurrent prompt, and communicate the task with clarity. While recent worksindicate that LLMs can be meta-prompted to perform automatic promptengineering, their potentials may not be fully untapped due to the lack ofsufficient guidance to elicit complex reasoning capabilities in LLMs in themeta-prompt. In this work, we investigate the problem of ""prompt engineering aprompt engineer"" -- constructing a meta-prompt that more effectively guidesLLMs to perform automatic prompt engineering. We introduce and analyze keycomponents, such as a step-by-step reasoning template and contextspecification, which lead to improved performance. In addition, inspired bycommon optimization concepts such as batch size, step size and momentum, weintroduce their verbalized counterparts to the meta-prompt and investigatetheir effects. Our final method, named PE2, finds a prompt that outperforms""let's think step by step"" by 6.3% on the MultiArith dataset and 3.1% on theGSM8K dataset. To demonstrate its versatility, we apply PE2 to the InstructionInduction benchmark, a suite of counterfactual tasks, and a lengthy, real-worldindustrial prompt. In these settings, PE2 achieves strong performance andoutperforms prior automatic prompt engineering baselines. Further, we show thatPE2 makes meaningful and targeted prompt edits, amends erroneous or incompleteprompts, and presents non-trivial counterfactual reasoning abilities.",Qinyuan Ye,2023/11/9,2023/11/9
2304.11060v2,SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model,http://arxiv.org/abs/2304.11060v2,"We present SkillGPT, a tool for skill extraction and standardization (SES)from free-style job descriptions and user profiles with an open-source LargeLanguage Model (LLM) as backbone. Most previous methods for similar taskseither need supervision or rely on heavy data-preprocessing and featureengineering. Directly prompting the latest conversational LLM for standardskills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizesa LLM to perform its tasks in steps via summarization and vector similaritysearch, to balance speed with precision. The backbone LLM of SkillGPT is basedon Llama, free for academic use and thus useful for exploratory research andprototype development. Hence, our cost-free SkillGPT gives users theconvenience of conversational SES, efficiently and reliably.",Nan Li,2023/4/17,2023/10/18
2311.09773v1,To be or not to be? an exploration of continuously controllable prompt engineering,http://arxiv.org/abs/2311.09773v1,"As the use of large language models becomes more widespread, techniques likeparameter-efficient fine-tuning and other methods for controlled generation aregaining traction for customizing models and managing their outputs. However,the challenge of precisely controlling how prompts influence these models is anarea ripe for further investigation. In response, we introduce ControlPE(Continuously Controllable Prompt Engineering). ControlPE enables fineradjustments to prompt effects, complementing existing prompt engineering, andeffectively controls continuous targets. This approach harnesses the power ofLoRA (Low-Rank Adaptation) to create an effect akin to prompt weighting,enabling fine-tuned adjustments to the impact of prompts. Our methodologyinvolves generating specialized datasets for prompt distillation, incorporatingthese prompts into the LoRA model, and carefully adjusting LoRA merging weightto regulate the influence of prompts. This provides a dynamic and adaptabletool for prompt control. Through our experiments, we have validated thepracticality and efficacy of ControlPE. It proves to be a promising solutionfor control a variety of prompts, ranging from generating short responsesprompts, refusal prompts to chain-of-thought prompts.",Yuhan Sun,2023/11/16,2023/11/16
2310.14735v2,Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review,http://arxiv.org/abs/2310.14735v2,"This paper delves into the pivotal role of prompt engineering in unleashingthe capabilities of Large Language Models (LLMs). Prompt engineering is theprocess of structuring input text for LLMs and is a technique integral tooptimizing the efficacy of LLMs. This survey elucidates foundational principlesof prompt engineering, such as role-prompting, one-shot, and few-shotprompting, as well as more advanced methodologies such as the chain-of-thoughtand tree-of-thoughts prompting. The paper sheds light on how externalassistance in the form of plugins can assist in this task, and reduce machinehallucination by retrieving external knowledge. We subsequently delineateprospective directions in prompt engineering research, emphasizing the need fora deeper understanding of structures and the role of agents in ArtificialIntelligence-Generated Content (AIGC) tools. We discuss how to assess theefficacy of prompt methods from different perspectives and using differentmethods. Finally, we gather information about the application of promptengineering in such fields as education and programming, showing itstransformative potential. This comprehensive survey aims to serve as a friendlyguide for anyone venturing through the big world of LLMs and promptengineering.",Banghao Chen,2023/10/23,2023/10/27
2310.10508v1,Prompt Engineering or Fine Tuning: An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks,http://arxiv.org/abs/2310.10508v1,"In this paper, we investigate the effectiveness of state-of-the-art LLM,i.e., GPT-4, with three different prompting engineering techniques (i.e., basicprompting, in-context learning, and task-specific prompting) against 18fine-tuned LLMs on three typical ASE tasks, i.e., code generation, codesummarization, and code translation. Our quantitative analysis of theseprompting strategies suggests that prompt engineering GPT-4 cannot necessarilyand significantly outperform fine-tuning smaller/older LLMs in all three tasks.For comment generation, GPT-4 with the best prompting strategy (i.e.,task-specific prompt) had outperformed the first-ranked fine-tuned model by8.33% points on average in BLEU. However, for code generation, the first-rankedfine-tuned model outperforms GPT-4 with best prompting by 16.61% and 28.3%points, on average in BLEU. For code translation, GPT-4 and fine-tunedbaselines tie as they outperform each other on different translation tasks. Toexplore the impact of different prompting strategies, we conducted a user studywith 27 graduate students and 10 industry practitioners. From our qualitativeanalysis, we find that the GPT-4 with conversational prompts (i.e., when ahuman provides feedback and instructions back and forth with a model to achievebest results) showed drastic improvement compared to GPT-4 with automaticprompting strategies. Moreover, we observe that participants tend to requestimprovements, add more context, or give specific instructions as conversationalprompts, which goes beyond typical and generic prompting strategies. Our studysuggests that, at its current state, GPT-4 with conversational prompting hasgreat potential for ASE tasks, but fully automated prompt engineering with nohuman in the loop requires more study and improvement.",Jiho Shin,2023/10/11,2023/10/11
1805.04825v1,Deep Learning in Software Engineering,http://arxiv.org/abs/1805.04825v1,"Recent years, deep learning is increasingly prevalent in the field ofSoftware Engineering (SE). However, many open issues still remain to beinvestigated. How do researchers integrate deep learning into SE problems?Which SE phases are facilitated by deep learning? Do practitioners benefit fromdeep learning? The answers help practitioners and researchers develop practicaldeep learning models for SE tasks. To answer these questions, we conduct abibliography analysis on 98 research papers in SE that use deep learningtechniques. We find that 41 SE tasks in all SE phases have been facilitated bydeep learning integrated solutions. In which, 84.7% papers only use standarddeep learning models and their variants to solve SE problems. Thepracticability becomes a concern in utilizing deep learning techniques. How toimprove the effectiveness, efficiency, understandability, and testability ofdeep learning based solutions may attract more SE researchers in the future.",Xiaochen Li,2018/5/13,2018/5/13
2308.11628v1,Prompt Engineering For Students of Medicine and Their Teachers,http://arxiv.org/abs/2308.11628v1,"""Prompt Engineering for Students of Medicine and Their Teachers"" brings theprinciples of prompt engineering for large language models such as ChatGPT andGoogle Bard to medical education. This book contains a comprehensive guide toprompt engineering to help both teachers and students improve education in themedical field. Just as prompt engineering is critical in getting goodinformation out of an AI, it is also critical to get students to think andunderstand more deeply. The principles of prompt engineering that we havelearned from AI systems have the potential to simultaneously revolutionizelearning in the healthcare field. The book analyzes from multiple angles theanatomy of a good prompt for both AI models and students. The different typesof prompts are examined, showing how each style has unique characteristics andapplications. The principles of prompt engineering, applied properly, aredemonstrated to be effective in teaching across the diverse fields of anatomy,physiology, pathology, pharmacology, and clinical skills. Just like ChatGPT andsimilar large language AI models, students need clear and detailed prompting inorder for them to fully understand a topic. Using identical principles, aprompt that gets good information from an AI will also cause a student to thinkmore deeply and accurately. The process of prompt engineering facilitates thisprocess. Because each chapter contains multiple examples and key takeaways, itis a practical guide for implementing prompt engineering in the learningprocess. It provides a hands-on approach to ensure readers can immediatelyapply the concepts they learn",Thomas F. Heston,2023/8/8,2023/8/8
2211.09425v1,Machine Learning for Software Engineering: A Tertiary Study,http://arxiv.org/abs/2211.09425v1,"Machine learning (ML) techniques increase the effectiveness of softwareengineering (SE) lifecycle activities. We systematically collected,quality-assessed, summarized, and categorized 83 reviews in ML for SE publishedbetween 2009-2022, covering 6,117 primary studies. The SE areas most tackledwith ML are software quality and testing, while human-centered areas appearmore challenging for ML. We propose a number of ML for SE research challengesand actions including: conducting further empirical validation and industrialstudies on ML; reconsidering deficient SE methods; documenting and automatingdata collection and pipeline processes; reexamining how industrialpractitioners distribute their proprietary data; and implementing incrementalML approaches.",Zoe Kotti,2022/11/17,2022/11/17
1812.01791v1,A Formal Method for Mapping Software Engineering Practices to Essence,http://arxiv.org/abs/1812.01791v1,Essence Framework EF aims at addressing the core problems of softwareengineering SE and its practices,Murat Pasa Uysal,2018/12/4,2018/12/4
2310.07088v1,Diversity of Thought Improves Reasoning Abilities of Large Language Models,http://arxiv.org/abs/2310.07088v1,"Large language models (LLMs) are documented to struggle in settings thatrequire complex reasoning. Nevertheless, instructing the model to break downthe problem into smaller reasoning steps (Wei et al., 2022), or ensemblingvarious generations through modifying decoding steps (Wang et al., 2023) boostsperformance. Current methods assume that the input prompt is fixed and expectthe decoding strategies to introduce the diversity needed for ensembling. Inthis work, we relax this assumption and discuss how one can create and leveragevariations of the input prompt as a means to diversity of thought to improvemodel performance. We propose a method that automatically improves promptdiversity by soliciting feedback from the LLM to ideate approaches that fit forthe problem. We then ensemble the diverse prompts in our method DIV-SE (DIVersereasoning path Self-Ensemble) across multiple inference calls. We also proposea cost-effective alternative where diverse prompts are used within a singleinference call; we call this IDIV-SE (In-call DIVerse reasoning pathSelf-Ensemble). Under a fixed generation budget, DIV-SE and IDIV-SE outperformthe previously discussed baselines using both GPT-3.5 and GPT-4 on severalreasoning benchmarks, without modifying the decoding process. Additionally,DIV-SE advances state-of-the-art performance on recent planning benchmarks(Valmeekam et al., 2023), exceeding the highest previously reported accuracy byat least 29.6 percentage points on the most challenging 4/5 Blocksworld task.Our results shed light on how to enforce prompt diversity toward LLM reasoningand thereby improve the pareto frontier of the accuracy-cost trade-off.",Ranjita Naik,2023/10/11,2023/10/11
2308.15161v1,TASEP: A Collaborative Social Engineering Tabletop Role-Playing Game to Prevent Successful Social Engineering Attacks,http://arxiv.org/abs/2308.15161v1,"Data breaches resulting from targeted attacks against organizations, e.g., byadvanced persistent threat groups, often involve social engineering (SE) as theinitial attack vector before malicious software is used, e.g., for persistence,lateral movement, and data exfiltration. While technical security controls,such as the automated detection of phishing emails, can contribute tomitigating SE risks, raising awareness for SE attacks through education andmotivation of personnel is an important building block to increasing anorganization's resilience. To facilitate hands-on SE awareness training as onecomponent of broader SE awareness campaigns, we created a SE tabletop gamecalled Tabletop As Social Engineering Prevention (TASEP) in two editions for(a) small and medium enterprises and (b) large corporations, respectively. Itsgame design is inspired by Dungeons & Dragons role-playing games andfacilitates LEGO models of the in-game target organizations. Participantsswitch roles by playing a group of SE penetration testers and conducting asecurity audit guided by the game master. We evaluated the created game withdifferent student groups, achieving highly immersive and flexible training,resulting in an entertaining way of learning about SE and raising awareness.",Lukas Hafner,2023/8/29,2023/8/29
2312.15223v1,A Survey on Large Language Models for Software Engineering,http://arxiv.org/abs/2312.15223v1,"Software Engineering (SE) is the systematic design, development, andmaintenance of software applications, underpinning the digital infrastructureof our modern mainworld. Very recently, the SE community has seen a rapidlyincreasing number of techniques employing Large Language Models (LLMs) toautomate a broad range of SE tasks. Nevertheless, existing information of theapplications, effects, and possible limitations of LLMs within SE is still notwell-studied.  In this paper, we provide a systematic survey to summarize the currentstate-of-the-art research in the LLM-based SE community. We summarize 30representative LLMs of Source Code across three model architectures, 15pre-training objectives across four categories, and 16 downstream tasks acrossfive categories. We then present a detailed summarization of the recent SEstudies for which LLMs are commonly utilized, including 155 studies for 43specific code-related tasks across four crucial phases within the SE workflow.Besides, we summarize existing attempts to empirically evaluate LLMs in SE,such as benchmarks, empirical studies, and exploration of SE education. We alsodiscuss several critical aspects of optimization and applications of LLMs inSE, such as security attacks, model tuning, and model compression. Finally, wehighlight several challenges and potential opportunities on applying LLMs forfuture SE studies, such as exploring domain LLMs and constructing cleanevaluation datasets. Overall, our work can help researchers gain acomprehensive understanding about the achievements of the existing LLM-based SEstudies and promote the practical application of these techniques. Ourartifacts are publicly available and will continuously updated at the livingrepository: \url{https://github.com/iSEngLab/AwesomeLLM4SE}.",Quanjun Zhang,2023/12/23,2023/12/23
2311.03359v1,Prompted Software Engineering in the Era of AI Models,http://arxiv.org/abs/2311.03359v1,"This paper introduces prompted software engineering (PSE), which integratesprompt engineering to build effective prompts for language-based AI models, toenhance the software development process. PSE enables the use of AI models insoftware development to produce high-quality software with fewer resources,automating tedious tasks and allowing developers to focus on more innovativeaspects. However, effective prompts are necessary to guide software developmentin generating accurate, relevant, and useful responses, while mitigating risksof misleading outputs. This paper describes how productive prompts should bebuilt throughout the software development cycle.",Dae-Kyoo Kim,2023/9/7,2023/9/7
1909.10751v1,Landscaping Systematic Mapping Studies in Software Engineering: A Tertiary Study,http://arxiv.org/abs/1909.10751v1,"Context: A number of Systematic Mapping Studies (SMSs) that cover SoftwareEngineering (SE) are reported in literature. Tertiary studies synthesize thesecondary studies to provide a holistic view of an area. Objectives: Wesynthesize SMSs in SE to provide insights into existing SE areas and toinvestigate the trends and quality of SMSs. Methodology: We use SystematicLiterature Review protocol to analyze and map the SMSs in SE, till August 2017,to SE Body of Knowledge (SWEBOK). Results: We analyze 210 SMSs and results showthat: (1) Software design and construction are most active areas in SE; (2)Some areas lack SMSs, including mathematical foundations, softwareconfiguration management, and SE tools; (3) The quality of SMSs is improvingwith time; (4) SMSs in journals have higher quality than SMSs in conferencesand are cited more often; (5) Low quality in SMSs can be attributed to a lackof quality assessment in SMSs and not reporting information about the primarystudies. Conclusion: There is a potential for more SMSs in some SE areas. Anumber of SMSs do not provide the required information for an SMS, which leadsto a low quality score.",Muhammad Uzair khan,2019/9/24,2019/9/24
2302.00042v1,Diversity Awareness in Software Engineering Participant Research,http://arxiv.org/abs/2302.00042v1,"Diversity and inclusion are necessary prerequisites for shaping technologicalinnovation that benefits society as a whole. A common indicator of diversityconsideration is the representation of different social groups among softwareengineering (SE) researchers, developers, and students. However, this does notnecessarily entail that diversity is considered in the SE research itself.  In our study, we examine how diversity is embedded in SE research,particularly research that involves participant studies. To this end, we haveselected 79 research papers containing 105 participant studies spanning threeyears of ICSE technical tracks. Using a content analytical approach, weidentified how SE researchers report the various diversity categories of theirstudy participants and investigated: 1) the extent to which participants aredescribed, 2) what diversity categories are commonly reported, and 3) thefunction diversity serves in the SE studies.  We identified 12 different diversity categories reported in SE participantstudies. Our results demonstrate that even though most SE studies report on thediversity of participants, SE research often emphasizes professional diversitydata, such as occupation and work experience, over social diversity data, suchas gender or location of the participants. Furthermore, our results show thatparticipant diversity is seldom analyzed or reflected upon when SE researchersdiscuss their study results, outcome or limitations. To help researchersself-assess their study diversity awareness, we propose a diversity awarenessmodel and guidelines that SE researchers can apply to their research. With thisstudy, we hope to shed light on a new approach to tackling the diversity andinclusion crisis in the SE field.",Riya Dutta,2023/1/31,2023/1/31
1503.02803v2,A Monte Carlo Study of the Relationship between the Time Structures of Prompt Gammas and in vivo Radiation Dose in Proton Therapy,http://arxiv.org/abs/1503.02803v2,"For the in vivo range verification in proton therapy, it has been tried tomeasure the spatial distribution of the prompt gammas generated by theproton-induced interactions with the close relationship with the proton dosedistribution. However, the high energy of the prompt gammas and backgroundgammas are still problematic in measuring the distribution. In this study, wesuggested a new method determining the in vivo range by utilizing the timestructure of the prompt gammas formed with the rotation of a range modulationwheel (RMW) in the passive scattering proton therapy. To validate the MonteCarlo code simulating the proton beam nozzle, axial percent depth doses (PDDs)were compared with the measured PDDs with the varying beam range of 4.73-24.01cm. And the relationship between the proton dose rate and the time structure ofthe prompt gammas was assessed and compared in the water phantom. The resultsof the PDD showed accurate agreement within the relative errors of 1.1% in thedistal range and 2.9% in the modulation width. Average dose difference in themodulation was assessed as less than 1.3% by comparing with the measurement.The time structure of prompt gammas was well-matched within 0.39 ms with theproton dose rate, and this could enable the accurate prediction of the in vivorange.",Wook-Geun Shin,2015/3/10,2015/3/12
2303.03628v1,CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification,http://arxiv.org/abs/2303.03628v1,"Chain-of-thought (CoT) prompting enables large language models (LLMs) tosolve complex reasoning tasks by generating an explanation before the finalprediction. Despite it's promising ability, a critical downside of CoTprompting is that the performance is greatly affected by the factuality of thegenerated explanation. To improve the correctness of the explanations,fine-tuning language models with explanation data is needed. However, thereexists only a few datasets that can be used for such approaches, and no datacollection tool for building them. Thus, we introduce CoTEVer, a tool-kit forannotating the factual correctness of generated explanations and collectingrevision data of wrong explanations. Furthermore, we suggest several use caseswhere the data collected with CoTEVer can be utilized for enhancing thefaithfulness of explanations. Our toolkit is publicly available athttps://github.com/SeungoneKim/CoTEVer.",Seungone Kim,2023/3/7,2023/3/7
1903.01092v1,Zero-Shot Task Transfer,http://arxiv.org/abs/1903.01092v1,"In this work, we present a novel meta-learning algorithm, i.e. TTNet, thatregresses model parameters for novel tasks for which no ground truth isavailable (zero-shot tasks). In order to adapt to novel zero-shot tasks, ourmeta-learner learns from the model parameters of known tasks (with groundtruth) and the correlation of known tasks to zero-shot tasks. Such intuitionfinds its foothold in cognitive science, where a subject (human baby) can adaptto a novel-concept (depth understanding) by correlating it with old concepts(hand movement or self-motion), without receiving explicit supervision. Weevaluated our model on the Taskonomy dataset, with four tasks as zero-shot:surface-normal, room layout, depth, and camera pose estimation. These taskswere chosen based on the data acquisition complexity and the complexityassociated with the learning process using a deep network. Our proposedmethodology out-performs state-of-the-art models (which use ground truth)oneach of our zero-shot tasks, showing promise on zero-shot task transfer. Wealso conducted extensive experiments to study the various choices of ourmethodology, as well as showed how the proposed method can also be used intransfer learning. To the best of our knowledge, this is the firstsuch efforton zero-shot learning in the task space.",Arghya Pal,2019/3/4,2019/3/4
1102.0472v1,Discoveries enabled by Multi-wavelength Afterglow Observations of Gamma-Ray Bursts,http://arxiv.org/abs/1102.0472v1,"A review is given on the various aspects of gamma-ray burst afterglowobservations, and the inferences derived from the data. After a short historyof optical transient search and the BeppoSAX discoveries, the main topicsincluded are prompt multiwavelength emission, dark bursts, spectral lines lineand continuum variability, the early light curve behaviour, jet breaks, X-rayflares, late afterglow features, polarization, and orphan afterglows.",J. Greiner,2011/2/2,2011/2/2
2401.09566v2,Aligning Large Language Models with Counterfactual DPO,http://arxiv.org/abs/2401.09566v2,"Advancements in large language models (LLMs) have demonstrated remarkablecapabilities across a diverse range of applications. These models excel ingenerating text completions that are contextually coherent and cover anextensive array of subjects. However, the vast datasets required for theirtraining make aligning response styles during the pretraining and instructiontuning phases challenging. Consequently, an additional alignment phase istypically employed, wherein the model is further trained with human preferencedata to better align its outputs with human expectations. While this processdoesn't introduce new capabilities per se, it does accentuate generation stylesinnate to the model. This paper explores the utilization of counterfactualprompting within the framework of Direct Preference Optimization (DPO) to alignthe model's style without relying on human intervention. We demonstrate thatthis method effectively instils desirable behaviour, mitigates undesirableones, and encourages the model to disregard inappropriate instructions. Ourfindings suggest that counterfactual prompting with DPO presents a low-resourceway to fine-tune LLMs to meet the demands for responsible and ethically alignedAI systems.",Bradley Butcher,2024/1/17,2024/1/19
2304.02827v1,DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model,http://arxiv.org/abs/2304.02827v1,"The increasing demand for high-quality 3D content creation has motivated thedevelopment of automated methods for creating 3D object models from a singleimage and/or from a text prompt. However, the reconstructed 3D objects usingstate-of-the-art image-to-3D methods still exhibit low correspondence to thegiven image and low multi-view consistency. Recent state-of-the-art text-to-3Dmethods are also limited, yielding 3D samples with low diversity per promptwith long synthesis time. To address these challenges, we propose DITTO-NeRF, anovel pipeline to generate a high-quality 3D NeRF model from a text prompt or asingle image. Our DITTO-NeRF consists of constructing high-quality partial 3Dobject for limited in-boundary (IB) angles using the given or text-generated 2Dimage from the frontal view and then iteratively reconstructing the remaining3D NeRF using inpainting latent diffusion model. We propose progressive 3Dobject reconstruction schemes in terms of scales (low to high resolution),angles (IB angles initially to outer-boundary (OB) later), and masks (object tobackground boundary) in our DITTO-NeRF so that high-quality information on IBcan be propagated into OB. Our DITTO-NeRF outperforms state-of-the-art methodsin terms of fidelity and diversity qualitatively and quantitatively with muchfaster training times than prior arts on image/text-to-3D such as DreamFusion,and NeuralLift-360.",Hoigi Seo,2023/4/6,2023/4/6
1912.05761v1,Results of the MAJORANA DEMONSTRATOR's Search for Double-Beta Decay of $^{76}$Ge to Excited States of $^{76}$Se,http://arxiv.org/abs/1912.05761v1,"The MAJORANA DEMONSTRATOR is searching for double-beta decay of $^{76}$Ge toexcited states (E.S.) in $^{76}$Se using a modular array of high purityGermanium detectors. $^{76}$Ge can decay into three E.S.s of $^{76}$Se. TheE.S. decays have a clear event signature consisting of a $\beta\beta$-decaywith the prompt emission of one or two $\gamma$-rays, resulting in with highprobability in a multi-site event. The granularity of the DEMONSTRATOR detectorarray enables powerful discrimination of this event signature from backgrounds.Using 21.3 kg-y of isotopic exposure, the DEMONSTRATOR has set world leadinglimits for each E.S. decay, with 90% CL lower half-life limits in the range of$(0.56-2.1)\cdot10^{24}$ y. In particular, for the $2\nu$ transition to thefirst $0^+$ E.S. of $^{76}$Se, a lower half-life limit of $0.68\cdot10^{24}$ at90% CL was achieved.",I. S. Guinn,2019/12/12,2019/12/12
0912.1760v2,Exchange interactions and Curie temperatures in Cr-based alloys in Zinc Blende structure: volume- and composition-dependence from first-principles calculations,http://arxiv.org/abs/0912.1760v2,"We present calculations of the exchange interactions and Curie temperaturesin Cr-based pnictides and chalcogenides of the form CrX with X=As, Sb, S, Seand Te, and the mixed alloys CrAs$_{50}$X$_{50}$ with X=Sb, S, Se, and Te. Thecalculations are performed for Zinc Blende (ZB) structure for 12 values of thelattice parameter between 5.44 and 6.62 \AA, appropriate for some typical II-VIand III-V semiconducting substrates. Electronic structure is calculated via thelinear muffin-tin-orbitals (LMTO) method in the atomic sphere approximation(ASA), using empty spheres to optimize ASA-related errors. Whenever necessary,the results have been verified using the full-potential version of the method,FP-LMTO. The disorder effect in the As-sublattice for CrAs$_{50}$X$_{50}$(X=Sb, S, Se, Te) alloys is taken into account via the coherent potentialapproximation (CPA). Exchange interactions are calculated using the linearresponse method for the ferromagnetic (FM) reference states of the alloys, aswell as the disordered local moments (DLM) states. These results are then usedto estimate the Curie temperature from the low and high temperature side of theferromagnetic/paramagnetic transition. Estimates of the Curie temperature areprovided, based on the mean field and the more accurate random phaseapproximations. Dominant antiferromagnetic exchange interactions for some lowvalues of the lattice parameter for the FM reference states in CrS, CrSe andCrTe prompted us to look for antiferromagnetic (AFM) configurations for thesesystems with energies lower than the corresponding FM and DLM values. Resultsfor a limited number of such AFM calculations are discussed, identifying theAFM[111] state as a likely candidate for the ground state for these cases.",S. K. Bose,2009/12/9,2010/2/5
mtrl-th/9602001v1,"The Structure, Dynamics and Electronic Structure of Liquid Ag-Se Alloys Investigated by Ab Initio Simulation",http://arxiv.org/abs/mtrl-th/9602001v1,"Ab initio molecular-dynamics simulations have been used to investigate thestructure, dynamics and electronic properties of the liquid alloy Ag(1-x)Se(x)at 1350 K and at the three compositions x=0.33, 0.42 and 0.65. The calculationsare based on density-functional theory in the local density approximation andon the pseudopotential plane-wave method. The reliability of the simulations isconfirmed by detailed comparisons with very recent neutron diffraction resultsfor the partial structure factors and radial distribution functions (RDF) ofthe stoichiometric liquid Ag2Se. The simulations show a dramatic change of theSe-Se RDF with increasing Se content. This change is due to the formation of Seclusters bound by covalent bonds, the Se-Se bond length being almost the sameas in pure c-Se and l-Se. The clusters are predominantly chain-like, but forhigher x a large fraction of 3-fold coordinated Se atoms is also found. It isshown that the equilibrium fractions of Se present as isolated atoms and inclusters can be understood on a simple charge-balance model based on an ionicinterpretation. The Ag and Se diffusion coefficients both increase with Secontent, in spite of the Se clustering. An analysis of the Se-Se bond dynamicsreveals surprisingly short bond lifetimes of less than 1 ps. The changes in thedensity of states with composition arise directly from the formation of Se-Secovalent bonds. Results for the electronic conductivity obtained using theKubo-Greenwood approximation are in adequate agreement with experiment forl-Ag2Se, but not for the high Se contents. Possible reasons for this arediscussed.",F. Kirchhoff,1996/2/7,1996/2/7
2310.14946v1,Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model,http://arxiv.org/abs/2310.14946v1,"We present a novel approach to multilingual audio-visual speech recognitiontasks by introducing a single model on a multilingual dataset. Motivated by ahuman cognitive system where humans can intuitively distinguish differentlanguages without any conscious effort or guidance, we propose a model that cancapture which language is given as an input speech by distinguishing theinherent similarities and differences between languages. To do so, we design aprompt fine-tuning technique into the largely pre-trained audio-visualrepresentation model so that the network can recognize the language class aswell as the speech with the corresponding language. Our work contributes todeveloping robust and efficient multilingual audio-visual speech recognitionsystems, reducing the need for language-specific models.",Joanna Hong,2023/10/23,2023/10/23
2008.06014v4,The Majorana Demonstrator's Search for Double-Beta Decay of $^{76}$Ge to Excited States of $^{76}$Se,http://arxiv.org/abs/2008.06014v4,"The Majorana Demonstrator is a neutrinoless double-beta decay searchconsisting of a low-background modular array of high-purity germaniumdetectors, $\sim2/3$ of which are enriched to 88\% in $^{76}$Ge. The experimentis also searching for double-beta decay of $^{76}$Ge to excited states (e.s.)in $^{76}$Se. $^{76}$Ge can decay into three daughter states of $^{76}$Se, withclear event signatures consisting of a $\beta\beta$-decay followed by theprompt emission of one or two $\gamma$-rays. This results with high probabilityin multi-detector coincidences. The granularity of the Demonstrator detectorarray enables powerful discrimination of this event signature from backgrounds.Using 41.9~kg-y of isotopic exposure, the Demonstrator has set world leadinglimits for each e.s.\ decay of $^{76}$Ge, with 90\% CL lower half-life limitsin the range of $(0.75-4.0)\times10^{24}$~y. In particular, for the $2\nu$transition to the first $0^+$ e.s.\ of $^{76}$Se, a lower half-life limit of$7.5\times10^{23}$~y at 90\% CL was achieved.",I. J. Arnquist,2020/8/13,2021/2/24
1611.10036v3,Cu-In Halide Perovskite solar absorbers,http://arxiv.org/abs/1611.10036v3,"The long-term chemical instability and the presence of toxic Pb in otherwisestellar solar absorber APbX$_{3}$ have hindered their large-scalecommercialization. Previously explored ways to achieve Pb-free halideperovskites involved replacing Pb$^{2+}$ with other similar M$^{2+}$ cations inns$^2$ electron configuration, e.g., Sn$^{2+}$ or by Bi$^{3+}$ (plus Ag$^+$),but unfortunately this showed either poor stability (M = Sn) or weaklyabsorbing oversized indirect gaps (M = Bi), prompting concerns that perhapsstability and good optoelectronic properties might be contraindicated. Herein,we exploit the electronic structure underpinning of classic Cu[In,Ga]Se$_{2}$(CIGS) chalcopyrite solar absorbers to design Pb-free halide perovskites bytransmuting 2Pb to the pair [B$^{IB}$ + C$^{III}$]. The resulting group ofdouble perovskites with formula A$_2$BCX$_6$ (A = K, Rb, Cs; B = Cu, Ag; C =Ga, In; X = Cl, Br, I) benefits from the ionic, yet narrow-gap character ofhalide perovskites, and at the same time borrows the advantage of the strongand rapidly rising Cu(d)/Se(p) $\rightarrow$ Ga/In(s/p)valence-to-conduction-band absorption spectra known from CIGS. This constitutesa new group of CuIn-based Halide Perovskite (CIHP). Our first-principlescalculations guided by such design principles indicate that the CIHPs class hasmembers with clear thermodynamic stability, showing rather strong direct-gapoptical transitions, and manifesting a wide-range of tunable gap values (fromzero to about 2.5 eV) and combination of light electron and heavy-light holeeffective masses. Materials screening of candidate CHIPs then identifies thebest-of-class Rb$_2$[CuIn]Cl$_6$, Rb$_2$[AgIn]Br$_6$ and Cs$_2$[AgIn]Br$_6$,having direct band gaps of 1.36, 1.46 and 1.50 eV, and a theoreticalspectroscopic limited maximal efficiency comparable to chalcopyrites andCH$_3$NH$_3$PbI$_3$.",Xin-Gang Zhao,2016/11/30,2017/5/15
2103.06419v3,SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography,http://arxiv.org/abs/2103.06419v3,"Background and objective: In this paper, a modified U-Net based framework ispresented, which leverages techniques from Squeeze-and-Excitation (SE) block,Atrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate androbust liver CT segmentation, and the effectiveness of the proposed method wastested on two public datasets LiTS17 and SLiver07.  Methods: A new network architecture called SAR-U-Net was designed. Firstly,the SE block is introduced to adaptively extract image features after eachconvolution in the U-Net encoder, while suppressing irrelevant regions, andhighlighting features of specific segmentation task; Secondly, ASPP wasemployed to replace the transition layer and the output layer, and acquiremulti-scale image information via different receptive fields. Thirdly, toalleviate the degradation problem, the traditional convolution block wasreplaced with the residual block and thus prompt the network to gain accuracyfrom considerably increased depth.  Results: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD andMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with otherclosely related 2D-based models, the proposed method achieved the highestaccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,ASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Comparedwith other closely related models, the proposed method achieved the highestsegmentation accuracy except for the RVD.  Conclusion: The proposed model enables a great improvement on the accuracycompared to 2D-based models, and its robustness in circumvent challengingproblems, such as small liver regions, discontinuous liver regions, and fuzzyliver boundaries, is also well demonstrated and validated.",Jinke Wang,2021/3/11,2021/7/17
2212.01012v1,Injecting Spatial Information for Monaural Speech Enhancement via Knowledge Distillation,http://arxiv.org/abs/2212.01012v1,"Monaural speech enhancement (SE) provides a versatile and cost-effectiveapproach to SE tasks by utilizing recordings from a single microphone. However,the monaural SE lags performance behind multi-channel SE as the monaural SEmethods are unable to extract spatial information from one-channel recordings,which greatly limits their application scenarios. To address this issue, weinject spatial information into the monaural SE model and propose a knowledgedistillation strategy to enable the monaural SE model to learn binaural speechfeatures from the binaural SE model, which makes monaural SE model possible toreconstruct higher intelligibility and quality enhanced speeches under lowsignal-to-noise ratio (SNR) conditions. Extensive experiments show that ourproposed monaural SE model by injecting spatial information via knowledgedistillation achieves favorable performance against other monaural SE modelswith fewer parameters.",Xinmeng Xu,2022/12/2,2022/12/2
2306.02342v1,Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image Restoration,http://arxiv.org/abs/2306.02342v1,"We propose an image restoration algorithm that can control the perceptualquality and/or the mean square error (MSE) of any pre-trained model, tradingone over the other at test time. Our algorithm is few-shot: Given about a dozenimages restored by the model, it can significantly improve the perceptualquality and/or the MSE of the model for newly restored images without furthertraining. Our approach is motivated by a recent theoretical result that linksbetween the minimum MSE (MMSE) predictor and the predictor that minimizes theMSE under a perfect perceptual quality constraint. Specifically, it has beenshown that the latter can be obtained by optimally transporting the output ofthe former, such that its distribution matches the source data. Thus, toimprove the perceptual quality of a predictor that was originally trained tominimize MSE, we approximate the optimal transport by a linear transformationin the latent space of a variational auto-encoder, which we compute inclosed-form using empirical means and covariances. Going beyond the theory, wefind that applying the same procedure on models that were initially trained toachieve high perceptual quality, typically improves their perceptual qualityeven further. And by interpolating the results with the original output of themodel, we can improve their MSE on the expense of perceptual quality. Weillustrate our method on a variety of degradations applied to general contentimages of arbitrary dimensions.",Theo Adrai,2023/6/4,2023/6/4
2208.04548v2,Inconsistencies in the Definition and Annotation of Student Engagement in Virtual Learning Datasets: A Critical Review,http://arxiv.org/abs/2208.04548v2,"Background: Student engagement (SE) in virtual learning can have a majorimpact on meeting learning objectives and program dropout risks. DevelopingArtificial Intelligence (AI) models for automatic SE measurement requiresannotated datasets. However, existing SE datasets suffer from inconsistentdefinitions and annotation protocols mostly unaligned with the definition of SEin educational psychology. This issue could be misleading in developinggeneralizable AI models and make it hard to compare the performance of thesemodels developed on different datasets. The objective of this critical reviewwas to explore the existing SE datasets and highlight inconsistencies in termsof differing engagement definitions and annotation protocols. Methods: Severalacademic databases were searched for publications introducing new SE datasets.The datasets containing students' single- or multi-modal data in online oroffline computer-based virtual learning sessions were included. The definitionand annotation of SE in the existing datasets were analyzed based on ourdefined seven dimensions of engagement annotation: sources, data modalities,timing, temporal resolution, level of abstraction, combination, andquantification. Results: Thirty SE measurement datasets met the inclusioncriteria. The reviewed SE datasets used very diverse and inconsistentdefinitions and annotation protocols. Unexpectedly, very few of the revieweddatasets used existing psychometrically validated scales in their definition ofSE. Discussion: The inconsistent definition and annotation of SE areproblematic for research on developing comparable AI models for automatic SEmeasurement. Some of the existing SE definitions and protocols in settingsother than virtual learning that have the potential to be used in virtuallearning are introduced.",Shehroz S. Khan,2022/8/9,2023/1/16
2011.04454v3,A Syntactic Approach to Studying Strongly Equivalent Logic Programs,http://arxiv.org/abs/2011.04454v3,"In the field of Answer Set Programming (ASP), two logic programs are stronglyequivalent if they are ordinarily equivalent under any extensions. Thisproperty provides a theoretical foundation for studying many aspects of logicprograms such as program simplification and transformation etc. Therefore,strong equivalence has been investigated extensively for ASP and its extensionssuch as LPMLN. In this paper, we present a syntactic approach to studying thestrong equivalence of logic programs, which provides several interestingresults and would help us understand the strong equivalence from a newperspective. Firstly, we present the notions of independent sets and five kindsof syntactic transformations (S-* transformations) for logic programs. And weinvestigate the strong equivalence (SE) and non-strong equivalence (NSE)preserving properties of the S-* transformations in the contexts of ASP andLPMLN. Secondly, based on the properties of the S-* transformations, we presenta fully automatic algorithm to discover syntactic conditions that preservestrong equivalences (SE-conditions) of ASP and LPMLN programs. To discover theSE-conditions efficiently, we present four kinds of approaches to improve thealgorithm. Thirdly, we present a preliminary method to simplify the discoveredSE-conditions and report the simplified SE-conditions of several kinds of LPMLNprograms. After that, we present a discussion on the discovered SE-conditionsand some existing problems. Finally, we present a comparison betweenSE-conditions discovering approaches in this paper and in the related work.",Zhizheng Zhang,2020/11/9,2021/12/6
2305.06599v3,Structured Chain-of-Thought Prompting for Code Generation,http://arxiv.org/abs/2305.06599v3,"Large Language Models (LLMs) (e.g., ChatGPT) have shown impressiveperformance in code generation. LLMs take prompts as inputs, andChain-of-Thought (CoT) prompting is the state-of-the-art prompting technique.CoT prompting asks LLMs first to generate CoTs (i.e., intermediate naturallanguage reasoning steps) and then output the code. However, CoT prompting isdesigned for natural language generation and has low accuracy in codegeneration.  In this paper, we propose Structured CoTs (SCoTs) and present a novelprompting technique for code generation, named SCoT prompting. Our motivationis source code contains rich structural information and any code can becomposed of three program structures (i.e., sequence, branch, and loopstructures). Intuitively, structured intermediate reasoning steps make forstructured source code. Thus, we ask LLMs to use program structures to buildCoTs, obtaining SCoTs. Then, LLMs generate the final code based on SCoTs.Compared to CoT prompting, SCoT prompting explicitly constrains LLMs to thinkabout how to solve requirements from the view of source code and further theperformance of LLMs in code generation. We apply SCoT prompting to two LLMs(i.e., ChatGPT and Codex) and evaluate it on three benchmarks (i.e., HumanEval,MBPP, and MBCPP). (1) SCoT prompting outperforms the state-of-the-art baseline- CoT prompting by up to 13.79% in Pass@1. (2) Human evaluation shows humandevelopers prefer programs from SCoT prompting. (3) SCoT prompting is robust toexamples and achieves substantial improvements.",Jia Li,2023/5/11,2023/9/7
1906.07970v1,Fast Nonconvex SDP Solvers for Large-scale Power System State Estimation,http://arxiv.org/abs/1906.07970v1,"Fast power system state estimation (SE) solution is of paramount importancefor achieving real-time decision making in power grid operations. Semidefiniteprogramming (SDP) reformulation has been shown effective to obtain the globaloptimum for the nonlinear SE problem, while suffering from high computationalcomplexity. Thus, we leverage the recent advances in nonconvex SDP approachthat allows for the simple first-order gradient-descent (GD) updates. Using thepower system model, we can verify that the SE objective function enjoys niceproperties (strongly convex, smoothness) which in turn guarantee a linearconvergence rate of the proposed GD-based SE method. To further accelerate theconvergence speed, we consider the accelerated gradient descent (AGD)extension, as well as their robust versions under outlier data and a hybridGD-based SE approach with additional synchrophasor measurements. Numericaltests on the IEEE 118-bus, 300-bus and the synthetic ACTIVSg2000-bus systemshave demonstrated that FGD-SE and AGD-SE, can approach the near-optimalperformance of the SDP-SE solution at significantly improved computationalefficiency, especially so for AGD-SE.",Yu Lan,2019/6/19,2019/6/19
2208.03631v1,An Enclave-based TEE for SE-in-SoC in RISC-V Industry,http://arxiv.org/abs/2208.03631v1,"Secure Element (SE) in SoC sees an increasing adoption in industry. Manyapplications in IoT devices are bound to the SE because it provides strongcryptographic functions and physical protection. Though SE-in-SoC providesstrong proven isolation for software programs, it also brings more designcomplexity and higher cost to PCB board building. More, SE-in-SoC may stillhave security concerns, such as malware installation and user impersonation. Inthis work, we employ TEE, a hardware-backed security technique, for protectingSE-in-SoC and RISCV. In particular, we construct various enclaves for isolatingapplications and manipulating the SE, with the inherently-secure primitivesprovided by RISC-V. Using hardware and software co-design, the solution ensurestrusted execution and secure communication among applications. The security ofSE is further protected by enforcing the SE to be controlled by a trustedenclave and making the RISC-V core resilient to side-channel attacks.",Xuanle Ren,2022/8/7,2022/8/7
2208.07912v2,FOLD-SE: An Efficient Rule-based Machine Learning Algorithm with Scalable Explainability,http://arxiv.org/abs/2208.07912v2,"We present FOLD-SE, an efficient, explainable machine learning algorithm forclassification tasks given tabular data containing numerical and categoricalvalues. FOLD-SE generates a set of default rules-essentially a stratifiednormal logic program-as an (explainable) trained model. Explainability providedby FOLD-SE is scalable, meaning that regardless of the size of the dataset, thenumber of learned rules and learned literals stay quite small while goodaccuracy in classification is maintained. A model with smaller number of rulesand literals is easier to understand for human beings. FOLD-SE is competitivewith state-of-the-art machine learning algorithms such as XGBoost andMulti-Layer Perceptrons (MLP) wrt accuracy of prediction. However, unlikeXGBoost and MLP, the FOLD-SE algorithm is explainable. The FOLD-SE algorithmbuilds upon our earlier work on developing the explainable FOLD-R++ machinelearning algorithm for binary classification and inherits all of its positivefeatures. Thus, pre-processing of the dataset, using techniques such as one-hotencoding, is not needed. Like FOLD-R++, FOLD-SE uses prefix sum to speed upcomputations resulting in FOLD-SE being an order of magnitude faster thanXGBoost and MLP in execution speed. The FOLD-SE algorithm outperforms FOLD-R++as well as other rule-learning algorithms such as RIPPER in efficiency,performance and scalability, especially for large datasets. A major reason forscalable explainability of FOLD-SE is the use of a literal selection heuristicsbased on Gini Impurity, as opposed to Information Gain used in FOLD-R++. Amulti-category classification version of FOLD-SE is also presented.",Huaduo Wang,2022/8/16,2023/1/10
2105.08838v1,Machine-Learned Molecular Surface and Its Application to Implicit Solvent Simulation,http://arxiv.org/abs/2105.08838v1,"Implicit solvent models, such as Poisson-Boltzmann models, play importantroles in computational studies of biomolecules. A vital step in almost allimplicit solvent models is to determine the solvent-solute interface, and thesolvent excluded surface (SES) is the most widely used interface definition inthese models. However, classical algorithms used for computing SES aregeometry-based, thus neither suitable for parallel implementations norconvenient for obtaining surface derivatives. To address the limitations, weexplored a machine learning strategy to obtain a level-set formulation for theSES. The training process was conducted in three steps, eventually leading to amodel with over 95% agreement with the classical SES. Visualization of testedmolecular surfaces shows that the machine-learned SES overlaps with theclassical SES on almost all situations. We also implemented the machine-learnedSES into the Amber/PBSA program to study its performance on reaction fieldenergy calculation. The analysis shows that the two sets of reaction fieldenergies are highly consistent with 1% deviation on average. Given itslevel-set formulation, we expect the machine-learned SES to be applied inmolecular simulations that require either surface derivatives or highefficiency on parallel computing platforms.",Haixin Wei,2021/5/18,2021/5/18
2305.18170v2,Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning,http://arxiv.org/abs/2305.18170v2,"Chain-of-thought (CoT) prompting with large language models has proveneffective in numerous natural language processing tasks, but designing promptsthat generalize well to diverse problem types can be challenging, especially inthe context of math word problem (MWP) solving. Additionally, it is common tohave a large amount of training data that have a better diversity coverage butCoT annotations are not available, which limits the use of supervised learningtechniques. To address these issues, we investigate two approaches to leveragethe training data in a few-shot prompting scenario: dynamic program promptingand program distillation. Our approach is largely inspired by Gao et al.,(2022), where they proposed to replace the CoT with the programs as theintermediate reasoning step. Such a prompting strategy allows us to accuratelyverify the answer correctness through program execution in MWP solving. Ourdynamic program prompting involves annotating the training data by samplingcorrect programs from a large language model, while program distillationinvolves adapting a smaller model to the program-annotated training data. Ourexperiments on three standard MWP datasets demonstrate the effectiveness ofthese approaches, yielding significant improvements over previous baselines forprompting and fine-tuning. Our results suggest that leveraging a large amountof training data can improve the generalization ability of prompts and boostthe performance of fine-tuned small models in MWP solving.",Zhanming Jie,2023/5/29,2023/6/9
2311.05943v1,Prompt Problems: A New Programming Exercise for the Generative AI Era,http://arxiv.org/abs/2311.05943v1,"Large Language Models (LLMs) are revolutionizing the field of computingeducation with their powerful code-generating capabilities. Traditionalpedagogical practices have focused on code writing tasks, but there is now ashift in importance towards code reading, comprehension and evaluation ofLLM-generated code. Alongside this shift, an important new skill is emerging --the ability to solve programming tasks by constructing good prompts forcode-generating models. In this work we introduce a new type of programmingexercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems aredesigned to help students learn how to write effective prompts for AI codegenerators. A student solves a Prompt Problem by crafting a natural languageprompt which, when provided as input to an LLM, outputs code that successfullysolves a specified programming task. We also present a new web-based toolcalled Promptly which hosts a repository of Prompt Problems and supports theautomated evaluation of prompt-generated code. We deploy Promptly for the firsttime in one CS1 and one CS2 course and describe our experiences, which includestudent perceptions of this new type of activity and their interactions withthe tool. We find that students are enthusiastic about Prompt Problems, andappreciate how the problems engage their computational thinking skills andexpose them to new programming constructs. We discuss ideas for the futuredevelopment of new variations of Prompt Problems, and the need to carefullystudy their integration into classroom practice.",Paul Denny,2023/11/10,2023/11/10
2001.11645v2,Linear Programming Contractor for Interval Distribution State Estimation Using RDM Arithmetic,http://arxiv.org/abs/2001.11645v2,"State estimation (SE) of distribution networks heavily relies on pseudomeasurements that introduce significant errors, since real-time measurementsare insufficient. Interval SE models are regularly used, where true values ofsystem states are supposed to be within the estimated ranges. However,conventional interval SE algorithms cannot consider the correlations of sameinterval variables in different terms of constraints, which results in overlyconservative estimation results. In this paper, we propose a Linear Programming(LP) Contractor algorithm that uses a relative distance measure (RDM) intervaloperation to solve this problem. In the proposed model, measurement errors areassumed to be bounded into given sets, thus converting the state variables toRDM variables. In this case, the SE model is a non-convex model, and thesolution credibility cannot be guaranteed. Therefore, each nonlinearmeasurement equation in the model is transformed into dual inequality linearequations using the mean value theorem. The SE model is finally reformulated asa linear programming contractor that iteratively narrows the upper and lowerbounds of the system state variables. Numerical tests on IEEE three-phasedistribution networks show that the proposed method outperforms theconventional interval-constrained propagation, modified Krawczyk-operator andoptimization based interval SE methods.",VietCuong Ngo,2020/1/31,2020/3/27
2102.07350v1,Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm,http://arxiv.org/abs/2102.07350v1,"Prevailing methods for mapping large generative language models to supervisedtasks may fail to sufficiently probe models' novel capabilities. Using GPT-3 asa case study, we show that 0-shot prompts can significantly outperform few-shotprompts. We suggest that the function of few-shot examples in these cases isbetter described as locating an already learned task rather than meta-learning.This analysis motivates rethinking the role of prompts in controlling andevaluating powerful language models. In this work, we discuss methods of promptprogramming, emphasizing the usefulness of considering prompts through the lensof natural language. We explore techniques for exploiting the capacity ofnarratives and cultural anchors to encode nuanced intentions and techniques forencouraging deconstruction of a problem into components before producing averdict. Informed by this more encompassing theory of prompt programming, wealso introduce the idea of a metaprompt that seeds the model to generate itsown natural language prompts for a range of tasks. Finally, we discuss howthese more general methods of interacting with language models can beincorporated into existing and future benchmarks and practical applications.",Laria Reynolds,2021/2/15,2021/2/15
1503.00829v2,Polyhedral aspects of score equivalence in Bayesian network structure learning,http://arxiv.org/abs/1503.00829v2,"This paper deals with faces and facets of the family-variable polytope andthe characteristic-imset polytope, which are special polytopes used in integerlinear programming approaches to statistically learn Bayesian networkstructure. A common form of linear objectives to be maximized in this arealeads to the concept of score equivalence (SE), both for linear objectives andfor faces of the family-variable polytope. We characterize the linear space ofSE objectives and establish a one-to-one correspondence between SE faces of thefamily-variable polytope, the faces of the characteristic-imset polytope, andstandardized supermodular functions. The characterization of SE facets in termsof extremality of the corresponding supermodular function gives an elegantmethod to verify whether an inequality is SE-facet-defining for thefamily-variable polytope. We also show that when maximizing an SE objective onecan eliminate linear constraints of the family-variable polytope thatcorrespond to non-SE facets. However, we show that solely considering SE facetsis not enough as a counter-example shows; one has to consider the linearinequality constraints that correspond to facets of the characteristic-imsetpolytope despite the fact that they may not define facets in thefamily-variable mode.",James Cussens,2015/3/3,2015/4/10
2310.13896v3,GPTutor: an open-source AI pair programming tool alternative to Copilot,http://arxiv.org/abs/2310.13896v3,"This paper presents the latest progress of GPTutor: a ChatGPT-poweredprogramming tool extension in Visual Studio Code. The emergence of LargeLanguage Models (LLMs) has improved software development efficiency, but theirperformance can be hindered by training data limitations and prompt designissues. Existing LLM development tools often operate as black boxes, with usersunable to view the prompts used and unable to improve performance by correctingprompts when errors occur. To address the aforementioned issues, GPTutor wasintroduced as an open-source AI pair programming tool, offering an alternativeto Copilot. GPTutor empowers users to customize prompts for various programminglanguages and scenarios, with support for 120+ human languages and 50+programming languages. Users can fine-tune prompts to correct the errors fromLLM for precision and efficient code generation. At the end of the paper, weunderscore GPTutor's potential through examples, including demonstrating itsproficiency in interpreting and generating Sui-Move, a newly introduced smartcontract language, using prompt engineering.",Eason Chen,2023/10/21,2023/10/25
2205.13675v1,Reinforcement Learning Approach for Mapping Applications to Dataflow-Based Coarse-Grained Reconfigurable Array,http://arxiv.org/abs/2205.13675v1,"The Streaming Engine (SE) is a Coarse-Grained Reconfigurable Array whichprovides programming flexibility and high-performance with energy efficiency.An application program to be executed on the SE is represented as a combinationof Synchronous Data Flow (SDF) graphs, where every instruction is representedas a node. Each node needs to be mapped to the right slot and array in the SEto ensure the correct execution of the program. This creates an optimizationproblem with a vast and sparse search space for which finding a mappingmanually is impractical because it requires expertise and knowledge of the SEmicro-architecture. In this work we propose a Reinforcement Learning frameworkwith Global Graph Attention (GGA) module and output masking of invalidplacements to find and optimize instruction schedules. We use Proximal PolicyOptimization in order to train a model which places operations into the SEtiles based on a reward function that models the SE device and its constraints.The GGA module consists of a graph neural network and an attention module. Thegraph neural network creates embeddings of the SDFs and the attention block isused to model sequential operation placement. We show results on how certainworkloads are mapped to the SE and the factors affecting mapping quality. Wefind that the addition of GGA, on average, finds 10% better instructionschedules in terms of total clock cycles taken and masking improves rewardobtained by 20%.",Andre Xian Ming Chang,2022/5/26,2022/5/26
2306.04556v1,StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code,http://arxiv.org/abs/2306.04556v1,"Code LLMs are being rapidly deployed and there is evidence that they can makeprofessional programmers more productive. Current benchmarks for codegeneration measure whether models generate correct programs given an expertprompt. In this paper, we present a new benchmark containing multiple promptsper problem, written by a specific population of non-expert prompters:beginning programmers. StudentEval contains 1,749 prompts for 48 problems,written by 80 students who have only completed one semester of Pythonprogramming. Our students wrote these prompts while working interactively witha Code LLM, and we observed very mixed success rates. We use StudentEval toevaluate 5 Code LLMs and find that StudentEval is a better discriminator ofmodel performance than existing benchmarks. We analyze the prompts and findsignificant variation in students' prompting techniques. We also find thatnondeterministic LLM sampling could mislead students into thinking that theirprompts are more (or less) effective than they actually are, which hasimplications for how to teach with Code LLMs.",Hannah McLean Babe,2023/6/7,2023/6/7
2401.04651v1,Learning to Prompt Segment Anything Models,http://arxiv.org/abs/2401.04651v1,"Segment Anything Models (SAMs) like SEEM and SAM have demonstrated greatpotential in learning to segment anything. The core design of SAMs lies withPromptable Segmentation, which takes a handcrafted prompt as input and returnsthe expected segmentation mask. SAMs work with two types of prompts includingspatial prompts (e.g., points) and semantic prompts (e.g., texts), which worktogether to prompt SAMs to segment anything on downstream datasets. Despite theimportant role of prompts, how to acquire suitable prompts for SAMs is largelyunder-explored. In this work, we examine the architecture of SAMs and identifytwo challenges for learning effective prompts for SAMs. To this end, we proposespatial-semantic prompt learning (SSPrompt) that learns effective semantic andspatial prompts for better SAMs. Specifically, SSPrompt introduces spatialprompt learning and semantic prompt learning, which optimize spatial promptsand semantic prompts directly over the embedding space and selectively leveragethe knowledge encoded in pre-trained prompt encoders. Extensive experimentsshow that SSPrompt achieves superior image segmentation performanceconsistently across multiple widely adopted datasets.",Jiaxing Huang,2024/1/9,2024/1/9
2210.10841v1,Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models,http://arxiv.org/abs/2210.10841v1,"Prompt learning is a new learning paradigm which reformulates downstreamtasks as similar pretraining tasks on pretrained models by leveraging textualprompts. Recent works have demonstrated that prompt learning is particularlyuseful for few-shot learning, where there is limited training data. Dependingon the granularity of prompts, those methods can be roughly divided intotask-level prompting and instance-level prompting. Task-level prompting methodslearn one universal prompt for all input samples, which is efficient butineffective to capture subtle differences among different classes.Instance-level prompting methods learn a specific prompt for each input, thougheffective but inefficient. In this work, we develop a novel prototype-basedprompt learning method to overcome the above limitations. In particular, wefocus on few-shot image recognition tasks on pretrained vision-language models(PVLMs) and develop a method of prompting through prototype (PTP), where wedefine $K$ image prototypes and $K$ prompt prototypes. In PTP, the imageprototype represents a centroid of a certain image cluster in the latent spaceand a prompt prototype is defined as a soft prompt in the continuous space. Thesimilarity between a query image and an image prototype determines how muchthis prediction relies on the corresponding prompt prototype. Hence, in PTP,similar images will utilize similar prompting ways. Through extensiveexperiments on seven real-world benchmarks, we show that PTP is an effectivemethod to leverage the latent knowledge and adaptive to various PVLMs.Moreover, through detailed analysis, we discuss pros and cons for promptlearning and parameter-efficient fine-tuning under the context of few-shotlearning.",Yue Zhang,2022/10/19,2022/10/19
2008.01441v1,Prompt Agnostic Essay Scorer: A Domain Generalization Approach to Cross-prompt Automated Essay Scoring,http://arxiv.org/abs/2008.01441v1,"Cross-prompt automated essay scoring (AES) requires the system to use nontarget-prompt essays to award scores to a target-prompt essay. Since obtaininga large quantity of pre-graded essays to a particular prompt is often difficultand unrealistic, the task of cross-prompt AES is vital for the development ofreal-world AES systems, yet it remains an under-explored area of research.Models designed for prompt-specific AES rely heavily on prompt-specificknowledge and perform poorly in the cross-prompt setting, whereas currentapproaches to cross-prompt AES either require a certain quantity of labelledtarget-prompt essays or require a large quantity of unlabelled target-promptessays to perform transfer learning in a multi-step manner. To address theseissues, we introduce Prompt Agnostic Essay Scorer (PAES) for cross-prompt AES.Our method requires no access to labelled or unlabelled target-prompt dataduring training and is a single-stage approach. PAES is easy to apply inpractice and achieves state-of-the-art performance on the Automated StudentAssessment Prize (ASAP) dataset.",Robert Ridley,2020/8/4,2020/8/4
2305.15689v2,Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts,http://arxiv.org/abs/2305.15689v2,"Recent studies have demonstrated that natural-language prompts can help toleverage the knowledge learned by pre-trained language models for the binarysentence-level sentiment classification task. Specifically, these methodsutilize few-shot learning settings to fine-tune the sentiment classificationmodel using manual or automatically generated prompts. However, the performanceof these methods is sensitive to the perturbations of the utilized prompts.Furthermore, these methods depend on a few labeled instances for automaticprompt generation and prompt ranking. This study aims to find high-qualityprompts for the given task in a zero-shot setting. Given a base prompt, ourproposed approach automatically generates multiple prompts similar to the baseprompt employing positional, reasoning, and paraphrasing techniques and thenranks the prompts using a novel metric. We empirically demonstrate that thetop-ranked prompts are high-quality and significantly outperform the baseprompt and the prompts generated using few-shot learning for the binarysentence-level sentiment classification task.",Mohna Chakraborty,2023/5/25,2023/7/1
2310.16730v1,MultiPrompter: Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning,http://arxiv.org/abs/2310.16730v1,"Recently, there has been an increasing interest in automated promptoptimization based on reinforcement learning (RL). This approach offersimportant advantages, such as generating interpretable prompts and beingcompatible with black-box foundation models. However, the substantial promptspace size poses challenges for RL-based methods, often leading to suboptimalpolicy convergence. This paper introduces MultiPrompter, a new framework thatviews prompt optimization as a cooperative game between prompters which taketurns composing a prompt together. Our cooperative prompt optimizationeffectively reduces the problem size and helps prompters learn optimal prompts.We test our method on the text-to-image task and show its ability to generatehigher-quality images than baselines.",Dong-Ki Kim,2023/10/25,2023/10/25
2312.06562v1,On Meta-Prompting,http://arxiv.org/abs/2312.06562v1,"Certain statistical models are capable of interpreting input strings asinstructions, or prompts, and carry out tasks based on them. Many approaches toprompting and pre-training these models involve the automated generation ofthese prompts. We call these approaches meta-prompting, or prompting to obtainprompts. We propose a theoretical framework based on category theory togeneralize and describe them. This framework is flexible enough to account forLLM stochasticity; and allows us to obtain formal results around taskagnosticity and equivalence of various meta-prompting approaches. We experimentwith meta-prompting in two active areas of model research: creativity andideation. We find that user preference favors (p < 0.01) the prompts generatedunder meta-prompting, as well as their corresponding outputs, over a series ofhardcoded baseline prompts that include the original task prompt. Using ourframework, we argue that meta-prompting is more effective than basic promptingat generating desirable outputs.",Adrian de Wynter,2023/12/11,2023/12/11
2210.16489v1,STPrompt: Semantic-guided and Task-driven prompts for Effective Few-shot Classification,http://arxiv.org/abs/2210.16489v1,"The effectiveness of prompt learning has been demonstrated in differentpre-trained language models. By formulating suitable template and choosingrepresentative label mapping, prompt learning can be used as an efficientknowledge probe. However, finding suitable prompt in existing methods requiresmultiple experimental attempts or appropriate vector initialization onformulating suitable template and choosing representative label mapping, whichit is more common in few-shot learning tasks. Motivating by PLM workingprocess, we try to construct the prompt from task semantic perspective and thuspropose the STPrompt -Semantic-guided and Task-driven Prompt model.Specifically, two novel prompts generated from the semantic dependency tree(Dep-prompt) and task-specific metadata description (Meta-prompt), are firstlyconstructed in a prompt augmented pool, and the proposed model wouldautomatically select a suitable semantic prompt to motivating the promptlearning process. Our results show that the proposed model achieves thestate-of-the-art performance in five different datasets of few-shot textclassification tasks, which prove that more semantic and significant promptscould assume as a better knowledge proving tool.",Jinta Weng,2022/10/29,2022/10/29
2111.05703v1,OSSEM: one-shot speaker adaptive speech enhancement using meta learning,http://arxiv.org/abs/2111.05703v1,"Although deep learning (DL) has achieved notable progress in speechenhancement (SE), further research is still required for a DL-based SE systemto adapt effectively and efficiently to particular speakers. In this study, wepropose a novel meta-learning-based speaker-adaptive SE approach (called OSSEM)that aims to achieve SE model adaptation in a one-shot manner. OSSEM consistsof a modified transformer SE network and a speaker-specific masking (SSM)network. In practice, the SSM network takes an enrolled speaker embeddingextracted using ECAPA-TDNN to adjust the input noisy feature through masking.To evaluate OSSEM, we designed a modified Voice Bank-DEMAND dataset, in whichone utterance from the testing set was used for model adaptation, and theremaining utterances were used for testing the performance. Moreover, we setrestrictions allowing the enhancement process to be conducted in real time, andthus designed OSSEM to be a causal SE system. Experimental results first showthat OSSEM can effectively adapt a pretrained SE model to a particular speakerwith only one utterance, thus yielding improved SE results. Meanwhile, OSSEMexhibits a competitive performance compared to state-of-the-art causal SEsystems.",Cheng Yu,2021/11/10,2021/11/10
2210.02390v3,Bayesian Prompt Learning for Image-Language Model Generalization,http://arxiv.org/abs/2210.02390v3,"Foundational image-language models have generated considerable interest dueto their efficient adaptation to downstream tasks by prompt learning. Promptlearning treats part of the language model input as trainable while freezingthe rest, and optimizes an Empirical Risk Minimization objective. However,Empirical Risk Minimization is known to suffer from distributional shifts whichhurt generalizability to prompts unseen during training. By leveraging theregularization ability of Bayesian methods, we frame prompt learning from theBayesian perspective and formulate it as a variational inference problem. Ourapproach regularizes the prompt space, reduces overfitting to the seen promptsand improves the prompt generalization on unseen prompts. Our framework isimplemented by modeling the input prompt space in a probabilistic manner, as ana priori distribution which makes our proposal compatible with prompt learningapproaches that are unconditional or conditional on the image. We demonstrateempirically on 15 benchmarks that Bayesian prompt learning provides anappropriate coverage of the prompt space, prevents learning spurious features,and exploits transferable invariant features. This results in bettergeneralization of unseen prompts, even across different datasets and domains.Code available at: https://github.com/saic-fi/Bayesian-Prompt-Learning",Mohammad Mahdi Derakhshani,2022/10/5,2023/8/20
2305.12437v2,PLAR: Prompt Learning for Action Recognition,http://arxiv.org/abs/2305.12437v2,"We present a new general learning approach, Prompt Learning for ActionRecognition (PLAR), which leverages the strengths of prompt learning to guidethe learning process. Our approach is designed to predict the action label byhelping the models focus on the descriptions or instructions associated withactions in the input videos. Our formulation uses various prompts, includinglearnable prompts, auxiliary visual information, and large vision models toimprove the recognition performance. In particular, we design a learnableprompt method that learns to dynamically generate prompts from a pool of promptexperts under different inputs. By sharing the same objective with the task,our proposed PLAR can optimize prompts that guide the model's predictions whileexplicitly learning input-invariant (prompt experts pool) and input-specific(data-dependent) prompt knowledge. We evaluate our approach on datasetsconsisting of both ground camera videos and aerial videos, and scenes withsingle-agent and multi-agent actions. In practice, we observe a 3.17-10.2%accuracy improvement on the aerial multi-agent dataset Okutamam and a 1.0-3.6%improvement on the ground camera single-agent dataset Something Something V2.We plan to release our code on the WWW.",Xijun Wang,2023/5/21,2023/11/15
2301.07069v2,Prompting Large Language Model for Machine Translation: A Case Study,http://arxiv.org/abs/2301.07069v2,"Research on prompting has shown excellent performance with little or even nosupervised training across many tasks. However, prompting for machinetranslation is still under-explored in the literature. We fill this gap byoffering a systematic study on prompting strategies for translation, examiningvarious factors for prompt template and demonstration example selection. Wefurther explore the use of monolingual data and the feasibility ofcross-lingual, cross-domain, and sentence-to-document transfer learning inprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as thetestbed show that 1) the number and the quality of prompt examples matter,where using suboptimal examples degenerates translation; 2) several features ofprompt examples, such as semantic similarity, show significant Spearmancorrelation with their prompting performance; yet, none of the correlations arestrong enough; 3) using pseudo parallel prompt examples constructed frommonolingual data via zero-shot prompting could improve translation; and 4)improved performance is achievable by transferring knowledge from promptexamples selected in other settings. We finally provide an analysis on themodel outputs and discuss several problems that prompting still suffers from.",Biao Zhang,2023/1/17,2023/1/18
2304.06502v2,Variations of Squeeze and Excitation networks,http://arxiv.org/abs/2304.06502v2,Convolutional neural networks learns spatial features and are heavilyinterlinked within kernels. The SE module have broken the traditional route ofneural networks passing the entire result to next layer. Instead SE only passesimportant features to be learned with its squeeze and excitation (SE) module.We propose variations of the SE module which improvises the process of squeezeand excitation and enhances the performance. The proposed squeezing or excitingthe layer makes it possible for having a smooth transition of layer weights.These proposed variations also retain the characteristics of SE module. Theexperimented results are carried out on residual networks and the results aretabulated.,Mahendran NV,2023/4/11,2023/7/3
2202.02790v1,Learning Synthetic Environments and Reward Networks for Reinforcement Learning,http://arxiv.org/abs/2202.02790v1,"We introduce Synthetic Environments (SEs) and Reward Networks (RNs),represented by neural networks, as proxy environment models for trainingReinforcement Learning (RL) agents. We show that an agent, after being trainedexclusively on the SE, is able to solve the corresponding real environment.While an SE acts as a full proxy to a real environment by learning about itsstate dynamics and rewards, an RN is a partial proxy that learns to augment orreplace rewards. We use bi-level optimization to evolve SEs and RNs: the innerloop trains the RL agent, and the outer loop trains the parameters of the SE /RN via an evolution strategy. We evaluate our proposed new concept on a broadrange of RL algorithms and classic control environments. In a one-to-onecomparison, learning an SE proxy requires more interactions with the realenvironment than training agents only on the real environment. However, oncesuch an SE has been learned, we do not need any interactions with the realenvironment to train new agents. Moreover, the learned SE proxies allow us totrain agents with fewer interactions while maintaining the original taskperformance. Our empirical results suggest that SEs achieve this result bylearning informed representations that bias the agents towards relevant states.Moreover, we find that these proxies are robust against hyperparametervariation and can also transfer to unseen agents.",Fabio Ferreira,2022/2/6,2022/2/6
2204.03895v2,SoundBeam: Target sound extraction conditioned on sound-class labels and enrollment clues for increased performance and continuous learning,http://arxiv.org/abs/2204.03895v2,"In many situations, we would like to hear desired sound events (SEs) whilebeing able to ignore interference. Target sound extraction (TSE) tackles thisproblem by estimating the audio signal of the sounds of target SE classes in amixture of sounds while suppressing all other sounds. We can achieve this witha neural network that extracts the target SEs by conditioning it on cluesrepresenting the target SE classes. Two types of clues have been proposed,i.e., target SE class labels and enrollment audio samples (or audio queries),which are pre-recorded audio samples of sounds from the target SE classes.Systems based on SE class labels can directly optimize embedding vectorsrepresenting the SE classes, resulting in high extraction performance. However,extending these systems to extract new SE classes not encountered duringtraining is not easy. Enrollment-based approaches extract SEs by finding soundsin the mixtures that share similar characteristics to the enrollment audiosamples. These approaches do not explicitly rely on SE class definitions andcan thus handle new SE classes. In this paper, we introduce a TSE framework,SoundBeam, that combines the advantages of both approaches. We also perform anextensive evaluation of the different TSE schemes using synthesized and realmixtures, which shows the potential of SoundBeam.",Marc Delcroix,2022/4/8,2022/11/2
2304.04873v1,SocioEconomicMag Meets a Platform for SES-Diverse College Students: A Case Study,http://arxiv.org/abs/2304.04873v1,"Emerging research shows that individual differences in how people usetechnology sometimes cluster by socioeconomic status (SES) and that whentechnology is not socioeconomically inclusive, low-SES individuals may abandonit. To understand how to improve technology's SES-inclusivity, we present amulti-phase case study on SocioEconomicMag (SESMag), an emerging inspectionmethod for socio+economic inclusivity. In our 16-month case study, a softwareteam developing a learning management platform used SESMag to evaluate and thento improve their platform's SES-inclusivity. The results showed that (1) thepractitioners identified SES-inclusivity bugs in 76% of the features theyevaluated; (2) these inclusivity bugs actually arise among low-SES collegestudents; and (3) the SESMag process pointed ways towards fixing these bugs.Finally, (4) a user study with SES-diverse college students showed that theplatform's SES-inclusivity eradicated 45-54% of the bugs; for some types ofbugs, the bug instance eradication rate was 80% or higher.",Puja Agarwal,2023/4/10,2023/4/10
2203.07933v2,Threat Detection for General Social Engineering Attack Using Machine Learning Techniques,http://arxiv.org/abs/2203.07933v2,"This paper explores the threat detection for general Social Engineering (SE)attack using Machine Learning (ML) techniques, rather than focusing on orlimited to a specific SE attack type, e.g. email phishing. Firstly, this paperprocesses and obtains more SE threat data from the previous Knowledge Graph(KG), and then extracts different threat features and generates new datasetscorresponding with three different feature combinations. Finally, 9 types of MLmodels are created and trained using the three datasets, respectively, andtheir performance are compared and analyzed with 27 threat detectors and 270times of experiments. The experimental results and analyses show that: 1) theML techniques are feasible in detecting general SE attacks and some ML modelsare quite effective; ML-based SE threat detection is complementary withKG-based approaches; 2) the generated datasets are usable and the SE domainontology proposed in previous work can dissect SE attacks and deliver the SEthreat features, allowing it to be used as a data model for future research.Besides, more conclusions and analyses about the characteristics of differentML detectors and the datasets are discussed.",Zuoguang Wang,2022/3/15,2022/3/17
2008.05515v1,Synergy between Machine/Deep Learning and Software Engineering: How Far Are We?,http://arxiv.org/abs/2008.05515v1,"Since 2009, the deep learning revolution, which was triggered by theintroduction of ImageNet, has stimulated the synergy between Machine Learning(ML)/Deep Learning (DL) and Software Engineering (SE). Meanwhile, criticalreviews have emerged that suggest that ML/DL should be used cautiously. Toimprove the quality (especially the applicability and generalizability) ofML/DL-related SE studies, and to stimulate and enhance future collaborationsbetween SE/AI researchers and industry practitioners, we conducted a 10-yearSystematic Literature Review (SLR) on 906 ML/DL-related SE papers publishedbetween 2009 and 2018. Our trend analysis demonstrated the mutual impacts thatML/DL and SE have had on each other. At the same time, however, we alsoobserved a paucity of replicable and reproducible ML/DL-related SE studies andidentified five factors that influence their replicability and reproducibility.To improve the applicability and generalizability of research results, weanalyzed what ingredients in a study would facilitate an understanding of why aML/DL technique was selected for a specific SE problem. In addition, weidentified the unique trends of impacts of DL models on SE tasks, as well asfive unique challenges that needed to be met in order to better leverage DL toimprove the productivity of SE tasks. Finally, we outlined a road-map that webelieve can facilitate the transfer of ML/DL-based SE research results intoreal-world industry practices.",Simin Wang,2020/8/12,2020/8/12
2101.09721v3,Learning Synthetic Environments for Reinforcement Learning with Evolution Strategies,http://arxiv.org/abs/2101.09721v3,"This work explores learning agent-agnostic synthetic environments (SEs) forReinforcement Learning. SEs act as a proxy for target environments and allowagents to be trained more efficiently than when directly trained on the targetenvironment. We formulate this as a bi-level optimization problem and representan SE as a neural network. By using Natural Evolution Strategies and apopulation of SE parameter vectors, we train agents in the inner loop onevolving SEs while in the outer loop we use the performance on the target taskas a score for meta-updating the SE population. We show empirically that ourmethod is capable of learning SEs for two discrete-action-space tasks(CartPole-v0 and Acrobot-v1) that allow us to train agents more robustly andwith up to 60% fewer steps. Not only do we show in experiments with 4000evaluations that the SEs are robust against hyperparameter changes such as thelearning rate, batch sizes and network sizes, we also show that SEs trainedwith DDQN agents transfer in limited ways to a discrete-action-space version ofTD3 and very well to Dueling DDQN.",Fabio Ferreira,2021/1/24,2021/2/8
1909.11909v3,Multichannel Speech Enhancement by Raw Waveform-mapping using Fully Convolutional Networks,http://arxiv.org/abs/1909.11909v3,"In recent years, waveform-mapping-based speech enhancement (SE) methods havegarnered significant attention. These methods generally use a deep learningmodel to directly process and reconstruct speech waveforms. Because both theinput and output are in waveform format, the waveform-mapping-based SE methodscan overcome the distortion caused by imperfect phase estimation, which may beencountered in spectral-mapping-based SE systems. So far, mostwaveform-mapping-based SE methods have focused on single-channel tasks. In thispaper, we propose a novel fully convolutional network (FCN) with Sinc anddilated convolutional layers (termed SDFCN) for multichannel SE that operatesin the time domain. We also propose an extended version of SDFCN, called theresidual SDFCN (termed rSDFCN). The proposed methods are evaluated on twomultichannel SE tasks, namely the dual-channel inner-ear microphones SE taskand the distributed microphones SE task. The experimental results confirm theoutstanding denoising capability of the proposed SE systems on both tasks andthe benefits of using the residual architecture on the overall SE performance.",Chang-Le Liu,2019/9/26,2020/2/24
2210.08210v2,Providing Error Detection for Deep Learning Image Classifiers Using Self-Explainability,http://arxiv.org/abs/2210.08210v2,"This paper proposes a self-explainable Deep Learning (SE-DL) system for animage classification problem that performs self-error detection. The self-errordetection is key to improving the DL system's safe operation, especially insafety-critical applications such as automotive systems. A SE-DL system outputsboth the class prediction and an explanation for that prediction, whichprovides insight into how the system makes its predictions for humans.Additionally, we leverage the explanation of the proposed SE-DL system todetect potential class prediction errors of the system. The proposed SE-DLsystem uses a set of concepts to generate the explanation. The concepts arehuman-understandable lower-level image features in each input image relevant tothe higher-level class of that image. We present a concept selectionmethodology for scoring all concepts and selecting a subset of them based ontheir contribution to the error detection performance of the proposed SE-DLsystem. Finally, we present different error detection schemes using theproposed SE-DL system to compare them against an error detection scheme withoutany SE-DL system.",Mohammad Mahdi Karimi,2022/10/15,2022/10/31
2112.09060v1,Towards Robust Real-time Audio-Visual Speech Enhancement,http://arxiv.org/abs/2112.09060v1,"The human brain contextually exploits heterogeneous sensory information toefficiently perform cognitive tasks including vision and hearing. For example,during the cocktail party situation, the human auditory cortex contextuallyintegrates audio-visual (AV) cues in order to better perceive speech. Recentstudies have shown that AV speech enhancement (SE) models can significantlyimprove speech quality and intelligibility in very low signal to noise ratio(SNR) environments as compared to audio-only SE models. However, despitesignificant research in the area of AV SE, development of real-time processingmodels with low latency remains a formidable technical challenge. In thispaper, we present a novel framework for low latency speaker-independent AV SEthat can generalise on a range of visual and acoustic noises. In particular, agenerative adversarial networks (GAN) is proposed to address the practicalissue of visual imperfections in AV SE. In addition, we propose a deep neuralnetwork based real-time AV SE model that takes into account the cleaned visualspeech output from GAN to deliver more robust SE. The proposed framework isevaluated on synthetic and real noisy AV corpora using objective speech qualityand intelligibility metrics and subjective listing tests. Comparativesimulation results show that our real time AV SE framework outperformsstate-of-the-art SE approaches, including recent DNN based SE models.",Mandar Gogate,2021/12/16,2021/12/16
2102.13419v2,Iterative SE(3)-Transformers,http://arxiv.org/abs/2102.13419v2,"When manipulating three-dimensional data, it is possible to ensure thatrotational and translational symmetries are respected by applying so-calledSE(3)-equivariant models. Protein structure prediction is a prominent exampleof a task which displays these symmetries. Recent work in this area hassuccessfully made use of an SE(3)-equivariant model, applying an iterativeSE(3)-equivariant attention mechanism. Motivated by this application, weimplement an iterative version of the SE(3)-Transformer, an SE(3)-equivariantattention-based model for graph data. We address the additional complicationswhich arise when applying the SE(3)-Transformer in an iterative fashion,compare the iterative and single-pass versions on a toy problem, and considerwhy an iterative model may be beneficial in some problem settings. We make thecode for our implementation available to the community.",Fabian B. Fuchs,2021/2/26,2021/3/16
1611.03227v1,Feature Selection with the R Package MXM: Discovering Statistically-Equivalent Feature Subsets,http://arxiv.org/abs/1611.03227v1,"The statistically equivalent signature (SES) algorithm is a method forfeature selection inspired by the principles of constrained-based learning ofBayesian Networks. Most of the currently available feature-selection methodsreturn only a single subset of features, supposedly the one with the highestpredictive power. We argue that in several domains multiple subsets can achieveclose to maximal predictive accuracy, and that arbitrarily providing only onehas several drawbacks. The SES method attempts to identify multiple, predictivefeature subsets whose performances are statistically equivalent. Under thatrespect SES subsumes and extends previous feature selection algorithms, likethe max-min parent children algorithm. SES is implemented in an homonymfunction included in the R package MXM, standing for mens ex machina, meaning'mind from the machine' in Latin. The MXM implementation of SES handles severaldata-analysis tasks, namely classification, regression and survival analysis.In this paper we present the SES algorithm, its implementation, and provideexamples of use of the SES function in R. Furthermore, we analyze threepublicly available data sets to illustrate the equivalence of the signaturesretrieved by SES and to contrast SES against the state-of-the-art featureselection method LASSO. Our results provide initial evidence that the twomethods perform comparably well in terms of predictive accuracy and thatmultiple, equally predictive signatures are actually present in real worlddata.",Vincenzo Lagani,2016/11/10,2016/11/10
2004.05748v1,Chemical Migration and Dipole Formation at van der Waals Interfaces between Magnetic Transition Metal Chalcogenides and Topological Insulators,http://arxiv.org/abs/2004.05748v1,"Metal and magnetic overlayers alter the surface of the topological insulator(TI) bismuth selenide (Bi$_2$Se$_3$) through proximity effects but also bychanging the composition and chemical structure of the Bi$_2$Se$_3$sub-surface. The interface between Bi$_2$Se$_3$ and Mn metal or manganeseselenide was explored using x-ray photoelectron spectroscopy (XPS) revealingchemical and electronic changes at the interface. Depositing Mn metal onBi$_2$Se$_3$ without an external source of Se shows unexpected bonding withinthe Mn layer due to Mn-Se bonding as Se diffuses out of the Bi$_2$Se$_3$ layerinto the growing Mn film. The Se out-diffusion is further evidenced by changesin Bi core levels within the Bi$_2$Se$_3$ layers indicating primarily Bi-Bibonding over Bi-Se bonding. No out-diffusion of Se occurred when excess Se issupplied with Mn, indicating the importance of supplying enough chalcogen atomswith deposited metals. However, Bi$_2$Se$_3$ core level photoelectronsexhibited a rigid chemical shift toward higher binding energy after depositinga monolayer of MnSe$_{2-x}$, indicating a dipole within the overlayer.Stoichiometry calculations indicated that the monolayer forms MnSepreferentially over the transition metal dichalcogenide (TMD) phase MnSe$_2$,providing a consistent picture of the dipole formation in which a plane of Seanions sits above Mn cations. This study shows that chemical diffusion anddipole formation are important for Mn-Bi$_2$Se$_3$ andMnSe$_{2-x}$-Bi$_2$Se$_3$ and should be considered carefully for TMD/TIinterfaces more generally.",Brenton A. Noesges,2020/4/13,2020/4/13
2301.10347v2,GePA*SE: Generalized Edge-Based Parallel A* for Slow Evaluations,http://arxiv.org/abs/2301.10347v2,"Parallel search algorithms have been shown to improve planning speed byharnessing the multithreading capability of modern processors. One suchalgorithm PA*SE achieves this by parallelizing state expansions, whereasanother algorithm ePA*SE achieves this by effectively parallelizing edgeevaluations. ePA*SE targets domains in which the action space comprises actionswith expensive but similar evaluation times. However, in a number of roboticsdomains, the action space is heterogenous in the computational effort requiredto evaluate the cost of an action and its outcome. Motivated by this, weintroduce GePA*SE: Generalized Edge-based Parallel A* for Slow Evaluations,which generalizes the key ideas of PA*SE and ePA*SE i.e. parallelization ofstate expansions and edge evaluations respectively. This extends itsapplicability to domains that have actions requiring varying computationaleffort to evaluate them. The open-source code for GePA*SE along with thebaselines is available here: https://github.com/shohinm/parallel_search",Shohin Mukherjee,2023/1/24,2023/3/10
2305.10734v1,Diffusion-Based Speech Enhancement with Joint Generative and Predictive Decoders,http://arxiv.org/abs/2305.10734v1,"Diffusion-based speech enhancement (SE) has been investigated recently, butits decoding is very time-consuming. One solution is to initialize the decodingprocess with the enhanced feature estimated by a predictive SE system. However,this two-stage method ignores the complementarity between predictive anddiffusion SE. In this paper, we propose a unified system that integrates thesetwo SE modules. The system encodes both generative and predictive information,and then applies both generative and predictive decoders, whose outputs arefused. Specifically, the two SE modules are fused in the first and finaldiffusion steps: the first step fusion initializes the diffusion process withthe predictive SE for improving the convergence, and the final step fusioncombines the two complementary SE outputs to improve the SE performance.Experiments on the Voice-Bank dataset show that the diffusion score estimationcan benefit from the predictive information and speed up the decoding.",Hao Shi,2023/5/18,2023/5/18
2210.17287v3,Diffiner: A Versatile Diffusion-based Generative Refiner for Speech Enhancement,http://arxiv.org/abs/2210.17287v3,"Although deep neural network (DNN)-based speech enhancement (SE) methodsoutperform the previous non-DNN-based ones, they often degrade the perceptualquality of generated outputs. To tackle this problem, we introduce a DNN-basedgenerative refiner, Diffiner, aiming to improve perceptual speech qualitypre-processed by an SE method. We train a diffusion-based generative model byutilizing a dataset consisting of clean speech only. Then, our refinereffectively mixes clean parts newly generated via denoising diffusionrestoration into the degraded and distorted parts caused by a preceding SEmethod, resulting in refined speech. Once our refiner is trained on a set ofclean speech, it can be applied to various SE methods without additionaltraining specialized for each SE module. Therefore, our refiner can be aversatile post-processing module w.r.t. SE methods and has high potential interms of modularity. Experimental results show that our method improvedperceptual speech quality regardless of the preceding SE methods used.",Ryosuke Sawata,2022/10/27,2023/8/30
1310.8342v1,On the Optimum Energy Efficiency for Flat-fading Channels with Rate-dependent Circuit Power,http://arxiv.org/abs/1310.8342v1,"This paper investigates the optimum energy efficiency (EE) and thecorresponding spectral efficiency (SE) for a communication link operating overa flat-fading channel. The EE is evaluated by the total energy consumption fortransmitting per message bit. Three channel cases are considered, namely staticchannel with channel state information available at transmitter (CSIT),fast-varying (FV) channel with channel distribution information available attransmitter (CDIT), and FV channel with CSIT. A general circuit power model isconsidered. For all the three channel cases, the tradeoff between the EE and SEis studied. It is shown that the EE improves strictly as the SE increases from0 to the optimum SE, and then strictly degrades as the SE increases beyond theoptimum SE. The impact of {\kappa}, {\rho} and other system parameters on theoptimum EE and corresponding SE is investigated to obtain insight.Some of theimportant and interesting results for all the channel cases include: (1) when{\kappa} increases the SE corresponding to the optimum EE should keep unchangedif {\phi}(R) = R, but reduced if {\phi}(R) is strictly convex of R; (2) whenthe rate-independent circuit power {\rho} increases, the SE corresponding tothe optimum EE has to be increased. A polynomial-complexity algorithm isdeveloped with the bisection method to find the optimum SE. The insight iscorroborated and the optimum EE for the three cases are compared by simulationresults.",Tao Wang,2013/10/30,2013/10/30
1801.02855v1,Chemical order in Ge-Ga-Sb-Se glasses,http://arxiv.org/abs/1801.02855v1,"The short range order in Ge$_{30}$Ga$_{5}$Sb$_{10}$Se$_{55}$ andGe$_{21}$Ga$_{5}$Sb$_{10}$Se$_{64}$ glasses was investigated by X-ray (XRD) andneutron diffraction (ND) as well as extended X-ray absorption fine structure(EXAFS) measurements at the Ge, Ga, Sb and Se K-edges. Large scale structuralmodels were obtained by fitting simultaneously the experimental data sets byreverse Monte Carlo (RMC) simulation technique. It was found that Ge, Sb and Seatoms follow the Mott-rule and have 4, 3 and 2 nearest neighbors, respectively.The average coordination number of the Ga atoms was around 4. The structure ofthese glasses can be described by the chemically ordered network model: theGe-Se, Ga-Se and Sb-Se bonds are the most prominent while Ge-Ge and Ge-Sb bondsare formed only in Se-poor compositions. Models generated by RMC contained somelong distances (0.3-0.4 {\AA} higher than the usual covalent bond lengths)between Ge-Se and/or Ge-Ge pairs. Dedicated simulation runs confirm theexistence of these bonds.",Ildik Pethes,2018/1/9,2018/1/9
quant-ph/0502034v3,Spin equation and its solutions,http://arxiv.org/abs/quant-ph/0502034v3,"The aim of the present article is to study in detail the so-called spinequation (SE) and present both the methods of generating new solution and a newset of exact solutions. We recall that the SE with a real external field can betreated as a reduction of the Pauli equation to the (0+1)-dimensional case.Two-level systems can be described by an SE with a particular form of theexternal field. In this article, we also consider associated equations that areequivalent or (in one way or another) related to the SE. We describe thegeneral solution of the SE and solve the inverse problem for this equation. Weconstruct the evolution operator for the SE and consider methods of generatingnew sets of exact solutions. Finally, we find a new set of exact solutions ofthe SE.",V. G. Bagrov,2005/2/4,2005/11/18
1912.13099v1,Generic Constructions and Semidualizing Modules,http://arxiv.org/abs/1912.13099v1,We investigate some general machinery for describing semidualizing modulesover generic constructions like ladder determinantal rings with coefficients ina normal domain. We also pose and investigate natural localization questionsthat arise in the process.,Sean K. Sather-Wagstaff,2019/12/30,2019/12/30
1207.0267v1,Quantum oscillations in topological superconductor candidate Cu$_{0.25}$Bi$_2$Se$_3$,http://arxiv.org/abs/1207.0267v1,"Quantum oscillations are generally studied to resolve the electronicstructure of topological insulators. In Cu$_{0.25}$Bi$_2$Se$_3$, the primecandidate of topological superconductors, quantum oscillations are still notobserved in magnetotransport measurement. However, using torque magnetometry,quantum oscillations (the de Hass - van Alphen effect) were observed inCu$_{0.25}$Bi$_2$Se$_3$ . The doping of Cu in Bi$_2$Se$_3$ increases thecarrier density and the effective mass without increasing the scattering rateor decreasing the mean free path. In addition, the Fermi velocity remains thesame in Cu$_{0.25}$Bi$_2$Se$_3$ as that in Bi$_2$Se$_3$. Our results imply thatthe insertion of Cu does not change the band structure of Bi$_2$Se$_3$.",Ben J. Lawson,2012/7/2,2012/7/2
2111.01862v1,Secondary Electron Count Imaging in SEM,http://arxiv.org/abs/2111.01862v1,"Scanning electron microscopy (SEM) is a versatile technique used to imagesamples at the nanoscale. Conventional imaging by this technique relies onfinding the average intensity of the signal generated on a detector bysecondary electrons (SEs) emitted from the sample and is subject to noise dueto variations in the voltage signal from the detector. This noise can result indegradation of the SEM image quality for a given imaging dose. SE countimaging, which uses the direct count of SEs detected from the sample instead ofthe average signal intensity, would overcome this limitation and lead toimprovement in SEM image quality. In this paper, we implement an SE countimaging scheme by synchronously outcoupling the detector and beam scan signalsfrom the microscope and using custom code to count detected SEs. We demonstratea ~30% increase in the image signal-to-noise-ratio due to SE counting comparedto conventional imaging. The only external hardware requirement for thisimaging scheme is an oscilloscope fast enough to accurately sample the detectorsignal for SE counting, making the scheme easily implementable on any SEM.",Akshay Agarwal,2021/11/2,2021/11/2
1112.1730v1,Quality-Of-Service Provisioning in Decentralized Networks: A Satisfaction Equilibrium Approach,http://arxiv.org/abs/1112.1730v1,"This paper introduces a particular game formulation and its correspondingnotion of equilibrium, namely the satisfaction form (SF) and the satisfactionequilibrium (SE). A game in SF models the case where players are uniquelyinterested in the satisfaction of some individual performance constraints,instead of individual performance optimization. Under this formulation, thenotion of equilibrium corresponds to the situation where all players cansimultaneously satisfy their individual constraints. The notion of SE, modelsthe problem of QoS provisioning in decentralized self-configuring networks.Here, radio devices are satisfied if they are able to provide the requestedQoS. Within this framework, the concept of SE is formalized for both pure andmixed strategies considering finite sets of players and actions. In both cases,sufficient conditions for the existence and uniqueness of the SE are presented.When multiple SE exist, we introduce the idea of effort or cost of satisfactionand we propose a refinement of the SE, namely the efficient SE (ESE). At theESE, all players adopt the action which requires the lowest effort forsatisfaction. A learning method that allows radio devices to achieve a SE inpure strategies in finite time and requiring only one-bit feedback is alsopresented. Finally, a power control game in the interference channel is used tohighlight the advantages of modeling QoS problems following the notion of SErather than other equilibrium concepts, e.g., generalized Nash equilibrium.",Samir M. Perlaza,2011/12/7,2011/12/7
1801.00929v1,Discovery of highly spin-polarized conducting surface states in the strong spin-orbit coupling semiconductor Sb$_2$Se$_3$,http://arxiv.org/abs/1801.00929v1,"Majority of the A$_2$B$_3$ type chalcogenide systems with strong spin-orbitcoupling, like Bi$_2$Se$_3$, Bi$_2$Te$_3$ and Sb$_2$Te$_3$ etc., aretopological insulators. One important exception is Sb$_2$Se$_3$, where atopological non-trivial phase was argued to be possible under ambientconditions, but such a phase could be detected to exist only under pressure. Inthis Letter, we show that like Bi$_2$Se$_3$, Sb$_2$Se$_3$, displays generationof highly spin-polarized current under mesoscopic superconducting pointcontacts as measured by point contact Andreev reflection spectroscopy. Inaddition, we observe a large negative and anisotropic magnetoresistance inSb$_2$Se$_3$, when the field is rotated in the basal plane. However, unlike inBi$_2$Se$_3$, in case of Sb$_2$Se$_3$ a prominent quasiparticle interference(QPI) pattern around the defects could be obtained in STM conductance imaging.Thus, our experiments indicate that Sb$_2$Se$_3$ is a regular band insulatorunder ambient conditions, but due to it's high spin-orbit coupling, non-trivialspin-texture exists on the surface and the system could be on the verge of atopological insulator phase.",Shekhar Das,2018/1/3,2018/1/3
2310.04915v1,On Accelerating Diffusion-based Molecular Conformation Generation in SE(3)-invariant Space,http://arxiv.org/abs/2310.04915v1,"Diffusion-based generative models in SE(3)-invariant space have demonstratedpromising performance in molecular conformation generation, but typicallyrequire solving stochastic differential equations (SDEs) with thousands ofupdate steps. Till now, it remains unclear how to effectively accelerate thisprocedure explicitly in SE(3)-invariant space, which greatly hinders its wideapplication in the real world. In this paper, we systematically study thediffusion mechanism in SE(3)-invariant space via the lens of approximate errorsinduced by existing methods. Thereby, we develop more precise approximate inSE(3) in the context of projected differential equations. Theoretical analysisis further provided as well as empirical proof relating hyper-parameters withsuch errors. Altogether, we propose a novel acceleration scheme for generatingmolecular conformations in SE(3)-invariant space. Experimentally, our schemecan generate high-quality conformations with 50x--100x speedup compared toexisting methods.",Zihan Zhou,2023/10/7,2023/10/7
2309.01212v1,NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement,http://arxiv.org/abs/2309.01212v1,"The goal of speech enhancement (SE) is to eliminate the backgroundinterference from the noisy speech signal. Generative models such as diffusionmodels (DM) have been applied to the task of SE because of bettergeneralization in unseen noisy scenes. Technical routes for the DM-based SEmethods can be summarized into three types: task-adapted diffusion processformulation, generator-plus-conditioner (GPC) structures and the multi-stageframeworks. We focus on the first two approaches, which are constructed underthe GPC architecture and use the task-adapted diffusion process to better dealwith the real noise. However, the performance of these SE models is limited bythe following issues: (a) Non-Gaussian noise estimation in the task-adapteddiffusion process. (b) Conditional domain bias caused by the weak conditionerdesign in the GPC structure. (c) Large amount of residual noise caused byunreasonable interpolation operations during inference. To solve the aboveproblems, we propose a noise-aware diffusion-based SE model (NADiffuSE) toboost the SE performance, where the noise representation is extracted from thenoisy speech signal and introduced as a global conditional information forestimating the non-Gaussian components. Furthermore, the anchor-based inferencealgorithm is employed to achieve a compromise between the speech distortion andnoise residual. In order to mitigate the performance degradation caused by theconditional domain bias in the GPC framework, we investigate three modelvariants, all of which can be viewed as multi-stage SE based on thepreprocessing networks for Mel spectrograms. Experimental results show thatNADiffuSE outperforms other DM-based SE models under the GPC infrastructure.Audio samples are available at: https://square-of-w.github.io/NADiffuSE-demo/.",Wen Wang,2023/9/3,2023/9/3
1105.5054v1,Special features of the relation between Fisher Information and Schrdinger eigenvalue equation,http://arxiv.org/abs/1105.5054v1,"It is well known that a suggestive relation exists that links Schr\""odinger'sequation (SE) to the information-optimizing principle based on Fisher'sinformation measure (FIM). The connection entails the existence of a Legendretransform structure underlying the SE. Here we show that appeal to thisstructure leads to a first order differential equation for the SE's eigenvaluesthat, in certain cases, can be used to obtain the eigenvalues withoutexplicitly solving SE. Complying with the above mentioned equation constitutesa necessary condition to be satisfied by an energy eigenvalue.  We show that the general solution is unique.",S. P. Flego,2011/5/25,2011/5/25
2209.03764v1,Deep Multi-Scale Representation Learning with Attention for Automatic Modulation Classification,http://arxiv.org/abs/2209.03764v1,"Currently, deep learning methods with stacking small size convolutionalfilters are widely used for automatic modulation classification (AMC). In thisreport, we find some experienced improvements by using large kernel size forconvolutional deep convolution neural network based AMC, which is moreefficient in extracting multi-scale features of the raw signal I/Q sequencedata. Also, Squeeze-and-Excitation (SE) mechanisms can significantly help AMCnetworks to focus on the more important features of the signal. As a result, wepropose a multi-scale feature network with large kernel size and SE mechanism(SE-MSFN) in this paper. SE-MSFN achieves state-of-the-art classificationperformance on the public well-known RADIOML 2018.01A dataset, with averageclassification accuracy of 64.50%, surpassing CLDNN by 1.42%, maximumclassification accuracy of 98.5%, and an average classification accuracy of85.53% in the lower SNR range 0dB to 10dB, surpassing CLDNN by 2.85%. Inaddition, we also verified that ensemble learning can help further improveclassification performance. We hope this report can provide some references fordevelopers and researchers in practical scenes.",Xiaowei Wu,2022/8/31,2022/8/31
2209.10491v1,Unifying Classification Schemes for Software Engineering Meta-Research,http://arxiv.org/abs/2209.10491v1,"Background: Classifications in meta-research enable researchers to cope withan increasing body of scientific knowledge. They provide a framework for, e.g.,distinguishing methods, reports, reproducibility, and evaluation in a knowledgefield as well as a common terminology. Both eases sharing, understanding andevolution of knowledge. In software engineering (SE), there are severalclassifications that describe the nature of SE research. Regarding theconsolidation of the large body of classified knowledge in SE research, agenerally applicable classification scheme is crucial. Moreover, thecommonalities and differences among different classification schemes haverarely been studied. Due to the fact that classifications are documentedtextual, it is hard to catalog, reuse, and compare them. To the best of ourknowledge, there is no research work so far that addresses documentation andsystematic investigation of classifications in SE meta-research. Objective: Weaim to construct a unified, generally applicable classification scheme for SEmeta-research by collecting and documenting existing classification schemes andunifying their classes and categories. Method: Our execution plan is dividedinto three phases: construction, validation, and evaluation phase. For theconstruction phase, we perform a literature review to identify, collect, andanalyze a set of established SE research classifications. In the validationphase, we analyze individual categories and classes of included papers. We usequantitative metrics from literature to conduct and assess the unificationprocess to build a generally applicable classification scheme for SE research.Lastly, we investigate the applicability of the unified scheme. Therefore, weperform a workshop session followed by user studies w.r.t. investigations aboutreliability, correctness, and ease of use.",Angelika Kaplan,2022/9/21,2022/9/21
2312.10297v2,Shedding Light on Software Engineering-specific Metaphors and Idioms,http://arxiv.org/abs/2312.10297v2,"Use of figurative language, such as metaphors and idioms, is common in ourdaily-life communications, and it can also be found in Software Engineering(SE) channels, such as comments on GitHub. Automatically interpretingfigurative language is a challenging task, even with modern Large LanguageModels (LLMs), as it often involves subtle nuances. This is particularly truein the SE domain, where figurative language is frequently used to conveytechnical concepts, often bearing developer affect (e.g., `spaghetti code').Surprisingly, there is a lack of studies on how figurative language in SEcommunications impacts the performance of automatic tools that focus onunderstanding developer communications, e.g., bug prioritization, incivilitydetection. Furthermore, it is an open question to what extent state-of-the-artLLMs interpret figurative expressions in domain-specific communication such assoftware engineering. To address this gap, we study the prevalence and impactof figurative language in SE communication channels. This study contributes tounderstanding the role of figurative language in SE, the potential of LLMs ininterpreting them, and its impact on automated SE communication analysis. Ourresults demonstrate the effectiveness of fine-tuning LLMs with figurativelanguage in SE and its potential impact on automated tasks that involve affect.We found that, among three state-of-the-art LLMs, the best improved fine-tunedversions have an average improvement of 6.66% on a GitHub emotionclassification dataset, 7.07% on a GitHub incivility classification dataset,and 3.71% on a Bugzilla bug report prioritization dataset.",Mia Mohammad Imran,2023/12/16,2023/12/23
2311.16595v1,D4AM: A General Denoising Framework for Downstream Acoustic Models,http://arxiv.org/abs/2311.16595v1,"The performance of acoustic models degrades notably in noisy environments.Speech enhancement (SE) can be used as a front-end strategy to aid automaticspeech recognition (ASR) systems. However, existing training objectives of SEmethods are not fully effective at integrating speech-text and noisy-cleanpaired data for training toward unseen ASR systems. In this study, we propose ageneral denoising framework, D4AM, for various downstream acoustic models. Ourframework fine-tunes the SE model with the backward gradient according to aspecific acoustic model and the corresponding classification objective. Inaddition, our method aims to consider the regression objective as an auxiliaryloss to make the SE model generalize to other unseen acoustic models. Tojointly train an SE unit with regression and classification objectives, D4AMuses an adjustment scheme to directly estimate suitable weighting coefficientsrather than undergoing a grid search process with additional training costs.The adjustment scheme consists of two parts: gradient calibration andregression objective weighting. The experimental results show that D4AM canconsistently and effectively provide improvements to various unseen acousticmodels and outperforms other combination setups. Specifically, when evaluatedon the Google ASR API with real noisy data completely unseen during SEtraining, D4AM achieves a relative WER reduction of 24.65% compared with thedirect feeding of noisy input. To our knowledge, this is the first work thatdeploys an effective combination scheme of regression (denoising) andclassification (ASR) objectives to derive a general pre-processor applicable tovarious unseen ASR systems. Our code is available athttps://github.com/ChangLee0903/D4AM.",Chi-Chang Lee,2023/11/28,2023/11/28
2212.10372v1,Se-ResNet+SVM model: an effective method of searching for hot subdwarfs from LAMOST,http://arxiv.org/abs/2212.10372v1,"In this paper, we apply the feature-integration idea to fuse the abstractfeatures extracted by Se-ResNet with experience features into hybrid featuresand input the hybrid features to the Support Vector Machine (SVM) to classifyHot subdwarfs. Based on this idea, we construct a Se-ResNet+SVM model,including a binary classification model and a four-class classification model.The four-class classification model can further screen the hot subdwarfcandidates obtained by the binary classification model. The F1 values derivedby the binary and the four-class classification model on the test set are96.17% and 95.64%, respectively. Then, we use the binary classification modelto classify 333,534 nonFGK type spectra in the low-resolution spectra of LAMOSTDR8 and obtain a catalog of 3,266 hot subdwarf candidates, of which 1223 arenewly-determined. Subsequently, the four-class classification model furtherfiltered the 3,266 candidates, 409 and 296 are newly-determined respectivelywhen the thresholds were set at 0.5 and 0.9. Through manual inspection, Thetrue number of hot subdwarfs in the three newly-determined canditates are 176,63, and 41, the corresponding precision of the classification model in thethree cases are 67.94%, 84.88%, and 87.60%, respectively. Finally, we train aSe-ResNet regression model with MAE values of 1212.65 K for Teff, 0.32 dex forlog g and 0.24 for [He/H], and predict the atmospheric parameters of these 176hot subdwarf stars. This provides a certain amount of samples to help forfuture studies of hot subdwarfs.",Cheng Zhongding,2022/12/20,2022/12/20
2110.05598v1,GCN-SE: Attention as Explainability for Node Classification in Dynamic Graphs,http://arxiv.org/abs/2110.05598v1,"Graph Convolutional Networks (GCNs) are a popular method from graphrepresentation learning that have proved effective for tasks like nodeclassification tasks. Although typical GCN models focus on classifying nodeswithin a static graph, several recent variants propose node classification indynamic graphs whose topologies and node attributes change over time, e.g.,social networks with dynamic relationships, or literature citation networkswith changing co-authorships. These works, however, do not fully address thechallenge of flexibly assigning different importance to snapshots of the graphat different times, which depending on the graph dynamics may have more or lesspredictive power on the labels. We address this challenge by proposing a newmethod, GCN-SE, that attaches a set of learnable attention weights to graphsnapshots at different times, inspired by Squeeze and Excitation Net (SE-Net).We show that GCN-SE outperforms previously proposed node classification methodson a variety of graph datasets. To verify the effectiveness of the attentionweight in determining the importance of different graph snapshots, we adaptperturbation-based methods from the field of explainable machine learning tographical settings and evaluate the correlation between the attention weightslearned by GCN-SE and the importance of different snapshots over time. Theseexperiments demonstrate that GCN-SE can in fact identify different snapshots'predictive power for dynamic node classification.",Yucai Fan,2021/10/11,2021/10/11
2306.07557v2,Ethical Aspects of ChatGPT in Software Engineering Research,http://arxiv.org/abs/2306.07557v2,"ChatGPT can improve Software Engineering (SE) research practices by offeringefficient, accessible information analysis and synthesis based on naturallanguage interactions. However, ChatGPT could bring ethical challenges,encompassing plagiarism, privacy, data security, and the risk of generatingbiased or potentially detrimental data. This research aims to fill the givengap by elaborating on the key elements: motivators, demotivators, and ethicalprinciples of using ChatGPT in SE research. To achieve this objective, weconducted a literature survey, identified the mentioned elements, and presentedtheir relationships by developing a taxonomy. Further, the identifiedliterature-based elements (motivators, demotivators, and ethical principles)were empirically evaluated by conducting a comprehensive questionnaire-basedsurvey involving SE researchers. Additionally, we employed InterpretiveStructure Modeling (ISM) approach to analyze the relationships between theethical principles of using ChatGPT in SE research and develop a level baseddecision model. We further conducted a Cross-Impact Matrix MultiplicationApplied to Classification (MICMAC) analysis to create a cluster-based decisionmodel. These models aim to help SE researchers devise effective strategies forethically integrating ChatGPT into SE research by following the identifiedprinciples through adopting the motivators and addressing the demotivators. Thefindings of this study will establish a benchmark for incorporating ChatGPTservices in SE research with an emphasis on ethical considerations.",Muhammad Azeem Akbar,2023/6/13,2023/8/13
2306.14407v1,Homomorphic Encryption: An Analysis of its Applications in Searchable Encryption,http://arxiv.org/abs/2306.14407v1,"The widespread adoption of cloud infrastructures has revolutionised datastorage and access. However, it has also raised concerns regarding the privacyof sensitive data stored in the cloud. To address these concerns, encryptiontechniques have been widely used. However, traditional encryption schemes limitthe efficient search and retrieval of encrypted data. To tackle this challenge,innovative approaches have emerged, such as the utilisation of HomomorphicEncryption (HE) in Searchable Encryption (SE) schemes. This paper provides acomprehensive analysis of the advancements in HE-based privacy-preservingtechniques, focusing on their application in SE. The main contributions of thiswork include the identification and classification of existing SE schemes thatutilize HE, a comprehensive analysis of the types of HE used in SE, anexamination of how HE shapes the search process structure and enablesadditional functionalities, and the identification of promising directions forfuture research in HE-based SE. The findings reveal the increasing usage of HEin SE schemes, particularly Partially Homomorphic Encryption. The analysis alsohighlights the prevalence of index-based SE schemes using HE, the support forranked search and multi-keyword queries, and the need for further explorationin functionalities such as verifiability and the ability to authorise andrevoke users. Future research directions include exploring the usage of otherencryption schemes alongside HE, addressing omissions in functionalities likefuzzy keyword search, and leveraging recent advancements in Fully HomomorphicEncryption schemes.",Ivone Amorim,2023/6/26,2023/6/26
1806.05298v1,Apuntes de Redes Neuronales Artificiales,http://arxiv.org/abs/1806.05298v1,"These handouts are designed for people who is just starting involved with thetopic artificial neural networks. We show how it works a single artificialneuron (McCulloch & Pitt model), mathematically and graphically. We do explainthe delta rule, a learning algorithm to find the neuron weights. We alsopresent some examples in MATLAB/Octave. There are examples for classificationtask for lineal and non-lineal problems. At the end, we present an artificialneural network, a feed-forward neural network along its learning algorithmbackpropagation.  -----  Estos apuntes est\'an dise\~nados para personas que por primera vez seintroducen en el tema de las redes neuronales artificiales. Se muestra elfuncionamiento b\'asico de una neurona, matem\'aticamente y gr\'aficamente. Seexplica la Regla Delta, algoritmo deaprendizaje para encontrar los pesos de unaneurona. Tambi\'en se muestran ejemplos en MATLAB/Octave. Hay ejemplos paraproblemas de clasificaci\'on, para problemas lineales y no-lineales. En laparte final se muestra la arquitectura de red neuronal artificial conocida comobackpropagation.",J. C. Cuevas-Tello,2018/6/13,2018/6/13
2305.13547v3,Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks,http://arxiv.org/abs/2305.13547v3,"Text classification tasks often encounter few shot scenarios with limitedlabeled data, and addressing data scarcity is crucial. Data augmentation withmixup has shown to be effective on various text classification tasks. However,most of the mixup methods do not consider the varying degree of learningdifficulty in different stages of training and generate new samples with onehot labels, resulting in the model over confidence. In this paper, we propose aself evolution learning (SE) based mixup approach for data augmentation in textclassification, which can generate more adaptive and model friendly pesudosamples for the model training. SE focuses on the variation of the model'slearning ability. To alleviate the model confidence, we introduce a novelinstance specific label smoothing approach, which linearly interpolates themodel's output and one hot labels of the original samples to generate new softfor label mixing up. Through experimental analysis, in addition to improvingclassification accuracy, we demonstrate that SE also enhances the model'sgeneralize ability.",Haoqi Zheng,2023/5/22,2023/11/27
2208.05573v1,Data Augmentation for Improving Emotion Recognition in Software Engineering Communication,http://arxiv.org/abs/2208.05573v1,"Emotions (e.g., Joy, Anger) are prevalent in daily software engineering (SE)activities, and are known to be significant indicators of work productivity(e.g., bug fixing efficiency). Recent studies have shown that directly applyinggeneral purpose emotion classification tools to SE corpora is not effective.Even within the SE domain, tool performance degrades significantly when trainedon one communication channel and evaluated on another (e.g, StackOverflow vs.GitHub comments). Retraining a tool with channel-specific data takessignificant effort since manually annotating large datasets of ground truthdata is expensive.  In this paper, we address this data scarcity problem by automaticallycreating new training data using a data augmentation technique. Based on ananalysis of the types of errors made by popular SE-specific emotion recognitiontools, we specifically target our data augmentation strategy in order toimprove the performance of emotion recognition. Our results show an averageimprovement of 9.3% in micro F1-Score for three existing emotion classificationtools (ESEM-E, EMTk, SEntiMoji) when trained with our best augmentationstrategy.",Mia Mohammad Imran,2022/8/10,2022/8/10
2311.00408v1,AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification,http://arxiv.org/abs/2311.00408v1,"Recent work has found that few-shot sentence classification based onpre-trained Sentence Encoders (SEs) is efficient, robust, and effective. Inthis work, we investigate strategies for domain-specialization in the contextof few-shot sentence classification with SEs. We first establish thatunsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained LanguageModel (PLM) (i.e., not an SE) substantially improves the accuracy of few-shotsentence classification by up to 8.4 points. However, applying DAPT on SEs, onthe one hand, disrupts the effects of their (general-domain) Sentence EmbeddingPre-Training (SEPT). On the other hand, applying general-domain SEPT on top ofa domain-adapted base PLM (i.e., after DAPT) is effective but inefficient,since the computationally expensive SEPT needs to be executed on top of aDAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouplesSEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can beinserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent'seffectiveness in extensive experiments on 17 different few-shot sentenceclassification datasets. AdaSent matches or surpasses the performance of fullSEPT on DAPT-ed PLM, while substantially reducing the training costs. The codefor AdaSent is available.",Yongxin Huang,2023/11/1,2023/11/1
2305.06701v2,Extending Audio Masked Autoencoders Toward Audio Restoration,http://arxiv.org/abs/2305.06701v2,"Audio classification and restoration are among major downstream tasks inaudio signal processing. However, restoration derives less of a benefit frompretrained models compared to the overwhelming success of pretrained models inclassification tasks. Due to such unbalanced benefits, there has been risinginterest in how to improve the performance of pretrained models for restorationtasks, e.g., speech enhancement (SE). Previous works have shown that thefeatures extracted by pretrained audio encoders are effective for SE tasks, butthese speech-specialized encoder-only models usually require extra decoders tobecome compatible with SE, and involve complicated pretraining procedures orcomplex data augmentation. Therefore, in pursuit of a universal audio model,the audio masked autoencoder (MAE) whose backbone is the autoencoder of VisionTransformers (ViT-AE), is extended from audio classification to SE, arepresentative restoration task with well-established evaluation standards.ViT-AE learns to restore masked audio signal via a mel-to-mel mapping duringpretraining, which is similar to restoration tasks like SE. We proposevariations of ViT-AE for a better SE performance, where the mel-to-melvariations yield high scores in non-intrusive metrics and the STFT-orientedvariation is effective at intrusive metrics such as PESQ. Different variationscan be used in accordance with the scenarios. Comprehensive evaluations revealthat MAE pretraining is beneficial to SE tasks and help the ViT-AE to bettergeneralize to out-of-domain distortions. We further found that large-scalenoisy data of general audio sources, rather than clean speech, is sufficientlyeffective for pretraining.",Zhi Zhong,2023/5/11,2023/8/17
1701.06028v4,Identifying time scales for violation/preservation of Stokes-Einstein relation in supercooled water,http://arxiv.org/abs/1701.06028v4,"The violation of Stokes--Einstein (SE) relation $D\sim (\eta/T)^{-1}$ betweenthe shear viscosity $\eta$ and the translational diffusion constant $D$ attemperature $T$ is of great importance for characterizing anomalous dynamics ofsupercooled water. Determining which time scales play key roles in the SEviolation remains elusive without the measurement of $\eta$. Here we providecomprehensive simulation results of the dynamic properties involving $\eta$ and$D$ in TIP4P/2005 supercooled water. This enabled the thorough identificationof the appropriate time scales for SE relation $D\eta/T$. In particular, it isdemonstrated that the temperature dependence of various time scales associatedwith structural relaxation, hydrogen bond breakage, stress relaxation, anddynamic heterogeneities can be definitely classified into only two classes.That is, we propose the generalized SE relations that exhibit ""violation"" or""preservation"". The classification depends on the examined time scales that arecoupled or decoupled with the diffusion. On the basis of the classification, weexplain the physical origins of the violation in terms of the increase in theplateau modulus and the nonexponentiality of stress relaxation. This impliesthat the mechanism of SE violation is attributed to the attained solidity uponsupercooling, which is in accord with the growth of non-Gaussianity andspatially heterogeneous dynamics.",Takeshi Kawasaki,2017/1/21,2017/8/1
2008.09264v5,CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile Application,http://arxiv.org/abs/2008.09264v5,"This study presents a deep learning-based speech signal-processing mobileapplication known as CITISEN. The CITISEN provides three functions: speechenhancement (SE), model adaptation (MA), and background noise conversion (BNC),allowing CITISEN to be used as a platform for utilizing and evaluating SEmodels and flexibly extend the models to address various noise environments andusers. For SE, a pretrained SE model downloaded from the cloud server is usedto effectively reduce noise components from instant or saved recordingsprovided by users. For encountering unseen noise or speaker environments, theMA function is applied to promote CITISEN. A few audio samples recording on anoisy environment are uploaded and used to adapt the pretrained SE model on theserver. Finally, for BNC, CITISEN first removes the background noises throughan SE model and then mixes the processed speech with new background noise. Thenovel BNC function can evaluate SE performance under specific conditions, coverpeople's tracks, and provide entertainment. The experimental results confirmedthe effectiveness of SE, MA, and BNC functions. Compared with the noisy speechsignals, the enhanced speech signals achieved about 6\% and 33\% ofimprovements, respectively, in terms of short-time objective intelligibility(STOI) and perceptual evaluation of speech quality (PESQ). With MA, the STOIand PESQ could be further improved by approximately 6\% and 11\%, respectively.Finally, the BNC experiment results indicated that the speech signals convertedfrom noisy and silent backgrounds have a close scene identification accuracyand similar embeddings in an acoustic scene classification model. Therefore,the proposed BNC can effectively convert the background noise of a speechsignal and be a data augmentation method when clean speech signals areunavailable.",Yu-Wen Chen,2020/8/21,2022/4/25
2106.02245v2,Towards offensive language detection and reduction in four Software Engineering communities,http://arxiv.org/abs/2106.02245v2,"Software Engineering (SE) communities such as Stack Overflow have becomeunwelcoming, particularly through members' use of offensive language. Researchhas shown that offensive language drives users away from active engagementwithin these platforms. This work aims to explore this issue more broadly byinvestigating the nature of offensive language in comments posted by users infour prominent SE platforms - GitHub, Gitter, Slack and Stack Overflow (SO). Itproposes an approach to detect and classify offensive language in SEcommunities by adopting natural language processing and deep learningtechniques. Further, a Conflict Reduction System (CRS), which identifiesoffence and then suggests what changes could be made to minimize offence hasbeen proposed. Beyond showing the prevalence of offensive language in over 1million comments from four different communities which ranges from 0.07% to0.43%, our results show promise in successful detection and classification ofsuch language. The CRS system has the potential to drastically reduce manualmoderation efforts to detect and reduce offence in SE communities.",Jithin Cheriyan,2021/6/4,2021/6/12
2206.13279v2,Differential invariants for SE(2)-equivariant networks,http://arxiv.org/abs/2206.13279v2,"Symmetry is present in many tasks in computer vision, where the same class ofobjects can appear transformed, e.g. rotated due to different cameraorientations, or scaled due to perspective. The knowledge of such symmetries indata coupled with equivariance of neural networks can improve theirgeneralization to new samples. Differential invariants are equivariantoperators computed from the partial derivatives of a function. In this paper weuse differential invariants to define equivariant operators that form thelayers of an equivariant neural network. Specifically, we derive invariants ofthe Special Euclidean Group SE(2), composed of rotations and translations, andapply them to construct a SE(2)-equivariant network, called SE(2) DifferentialInvariants Network (SE2DINNet). The network is subsequently tested inclassification tasks which require a degree of equivariance or invariance torotations. The results compare positively with the state-of-the-art, eventhough the proposed SE2DINNet has far less parameters than the compared models.",Mateus Sangalli,2022/6/27,2022/7/22
2306.05083v2,Revealing the Blind Spot of Sentence Encoder Evaluation by HEROS,http://arxiv.org/abs/2306.05083v2,"Existing sentence textual similarity benchmark datasets only use a singlenumber to summarize how similar the sentence encoder's decision is to humans'.However, it is unclear what kind of sentence pairs a sentence encoder (SE)would consider similar. Moreover, existing SE benchmarks mainly considersentence pairs with low lexical overlap, so it is unclear how the SEs behavewhen two sentences have high lexical overlap. We introduce a high-quality SEdiagnostic dataset, HEROS. HEROS is constructed by transforming an originalsentence into a new sentence based on certain rules to form a \textit{minimalpair}, and the minimal pair has high lexical overlaps. The rules includereplacing a word with a synonym, an antonym, a typo, a random word, andconverting the original sentence into its negation. Different rules yielddifferent subsets of HEROS. By systematically comparing the performance of over60 supervised and unsupervised SEs on HEROS, we reveal that most unsupervisedsentence encoders are insensitive to negation. We find the datasets used totrain the SE are the main determinants of what kind of sentence pairs an SEconsiders similar. We also show that even if two SEs have similar performanceon STS benchmarks, they can have very different behavior on HEROS. Our resultreveals the blind spot of traditional STS benchmarks when evaluating SEs.",Cheng-Han Chiang,2023/6/8,2023/6/13
2011.14597v1,A Survey on Deep Learning for Software Engineering,http://arxiv.org/abs/2011.14597v1,"In 2006, Geoffrey Hinton proposed the concept of training ''Deep NeuralNetworks (DNNs)'' and an improved model training method to break the bottleneckof neural network development. More recently, the introduction of AlphaGo in2016 demonstrated the powerful learning ability of deep learning and itsenormous potential. Deep learning has been increasingly used to developstate-of-the-art software engineering (SE) research tools due to its ability toboost performance for various SE tasks. There are many factors, e.g., deeplearning model selection, internal structure differences, and modeloptimization techniques, that may have an impact on the performance of DNNsapplied in SE. Few works to date focus on summarizing, classifying, andanalyzing the application of deep learning techniques in SE. To fill this gap,we performed a survey to analyse the relevant studies published since 2006. Wefirst provide an example to illustrate how deep learning techniques are used inSE. We then summarize and classify different deep learning techniques used inSE. We analyzed key optimization technologies used in these deep learningmodels, and finally describe a range of key research topics using DNNs in SE.Based on our findings, we present a set of current challenges remaining to beinvestigated and outline a proposed research road map highlighting keyopportunities for future work.",Yanming Yang,2020/11/30,2020/11/30
2211.10623v1,Do Pre-trained Language Models Indeed Understand Software Engineering Tasks?,http://arxiv.org/abs/2211.10623v1,"Artificial intelligence (AI) for software engineering (SE) tasks has recentlyachieved promising performance. In this paper, we investigate to what extentthe pre-trained language model truly understands those SE tasks such as codesearch, code summarization, etc. We conduct a comprehensive empirical study ona board set of AI for SE (AI4SE) tasks by feeding them with variant inputs: 1)with various masking rates and 2) with sufficient input subset method. Then,the trained models are evaluated on different SE tasks, including code search,code summarization, and duplicate bug report detection. Our experimentalresults show that pre-trained language models are insensitive to the giveninput, thus they achieve similar performance in these three SE tasks. We referto this phenomenon as overinterpretation, where a model confidently makes adecision without salient features, or where a model finds some irrelevantrelationships between the final decision and the dataset. Our studyinvestigates two approaches to mitigate the overinterpretation phenomenon:whole word mask strategy and ensembling. To the best of our knowledge, we arethe first to reveal this overinterpretation phenomenon to the AI4SE community,which is an important reminder for researchers to design the input for themodels and calls for necessary future work in understanding and implementingAI4SE tasks.",Yao Li,2022/11/19,2022/11/19
1909.11436v3,Software Engineering Meets Deep Learning: A Mapping Study,http://arxiv.org/abs/1909.11436v3,"Deep Learning (DL) is being used nowadays in many traditional SoftwareEngineering (SE) problems and tasks. However, since the renaissance of DLtechniques is still very recent, we lack works that summarize and condense themost recent and relevant research conducted at the intersection of DL and SE.Therefore, in this paper, we describe the first results of a mapping studycovering 81 papers about DL & SE. Our results confirm that DL is gainingmomentum among SE researchers over the years and that the top-3 researchproblems tackled by the analyzed papers are documentation, defect prediction,and testing.",Fabio Ferreira,2019/9/25,2020/12/4
2108.12411v1,Towards a Methodology for Participant Selection in Software Engineering Experiments. A Vision of the Future,http://arxiv.org/abs/2108.12411v1,"Background. Software Engineering (SE) researchers extensively performexperiments with human subjects. Well-defined samples are required to ensureexternal validity. Samples are selected \textit{purposely} or by\textit{convenience}, limiting the generalizability of results. Objective. Weaim to depict the current status of participants selection in empirical SE,identifying the main threats and how they are mitigated. We draft a robustapproach to participants' selection. Method. We reviewed existing participants'selection guidelines in SE, and performed a preliminary literature review tofind out how participants' selection is conducted in SE in practice. % and 3)we summarized the main issues identified. Results. We outline a new selectionmethodology, by 1) defining the characteristics of the desired population, 2)locating possible sources of sampling available for researchers, and 3)identifying and reducing the ""distance"" between the selected sample and itscorresponding population. Conclusion. We propose a roadmap to develop andempirically validate the selection methodology.",Valentina Lenarduzzi,2021/8/27,2021/8/27
2304.14597v3,AI Safety Subproblems for Software Engineering Researchers,http://arxiv.org/abs/2304.14597v3,"In this 4-page manuscript we discuss the problem of long-term AI Safety froma Software Engineering (SE) research viewpoint. We briefly summarize long-termAI Safety, and the challenge of avoiding harms from AI as systems meet orexceed human capabilities, including software engineering capabilities (andapproach AGI / ""HLMI""). We perform a quantified literature review suggestingthat AI Safety discussions are not common at SE venues. We make conjecturesabout how software might change with rising capabilities, and categorize""subproblems"" which fit into traditional SE areas, proposing how work onsimilar problems might improve the future of AI and SE.",David Gros,2023/4/28,2023/8/31
2312.08055v2,Breaking the Silence: the Threats of Using LLMs in Software Engineering,http://arxiv.org/abs/2312.08055v2,"Large Language Models (LLMs) have gained considerable traction within theSoftware Engineering (SE) community, impacting various SE tasks from codecompletion to test generation, from program repair to code summarization.Despite their promise, researchers must still be careful as numerous intricatefactors can influence the outcomes of experiments involving LLMs. This paperinitiates an open discussion on potential threats to the validity of LLM-basedresearch including issues such as closed-source models, possible data leakagebetween LLM training data and research evaluation, and the reproducibility ofLLM-based findings. In response, this paper proposes a set of guidelinestailored for SE researchers and Language Model (LM) providers to mitigate theseconcerns. The implications of the guidelines are illustrated using existinggood practices followed by LLM providers and a practical example for SEresearchers in the context of test case generation.",June Sallou,2023/12/13,2024/1/8
2012.07919v3,A Software Engineering Perspective on Engineering Machine Learning Systems: State of the Art and Challenges,http://arxiv.org/abs/2012.07919v3,"Context: Advancements in machine learning (ML) lead to a shift from thetraditional view of software development, where algorithms are hard-coded byhumans, to ML systems materialized through learning from data. Therefore, weneed to revisit our ways of developing software systems and consider theparticularities required by these new types of systems. Objective: The purposeof this study is to systematically identify, analyze, summarize, and synthesizethe current state of software engineering (SE) research for engineering MLsystems. Method: I performed a systematic literature review (SLR). Isystematically selected a pool of 141 studies from SE venues and then conducteda quantitative and qualitative analysis using the data extracted from thesestudies. Results: The non-deterministic nature of ML systems complicates all SEaspects of engineering ML systems. Despite increasing interest from 2018onwards, the results reveal that none of the SE aspects have a mature set oftools and techniques. Testing is by far the most popular area amongresearchers. Even for testing ML systems, engineers have only some toolprototypes and solution proposals with weak experimental proof. Many of thechallenges of ML systems engineering were identified through surveys andinterviews. Researchers should conduct experiments and case studies, ideally inindustrial environments, to further understand these challenges and proposesolutions. Conclusion: The results may benefit (1) practitioners in foreseeingthe challenges of ML systems engineering; (2) researchers and academicians inidentifying potential research questions; and (3) educators in designing orupdating SE courses to cover ML systems engineering.",Grkem Giray,2020/12/14,2021/6/15
1606.01012v1,"Synthesis, phase stability, structural and physical properties of 11-type iron chalcogenides",http://arxiv.org/abs/1606.01012v1,"This article reviews recent experimental investigations on two binaryFe-chalcogenides: FeSe and Fe$_{1+y}$Te. The main focus is on synthesis, singlecrystal growth, chemical composition, as well as on the effect of excess ironon structural, magnetic, and transport properties of these materials. Thestructurally simplest Fe-based superconductor Fe$_{1+x}$Se with a criticaltemperature $T_c \approx$ 8.5 K undergoes a tetragonal to orthorhombic phasetransition at a temperature $T_s \approx$ 87 K. No long-range magnetic order isobserved down to the lowest measured temperature in Fe$_{1+x}$Se. On the otherhand, isostructural Fe$_{1+y}$Te displays a complex interplay of magnetic andstructural phase transitions in dependence on the tuning parameter such asexcess amount of Fe or pressure, but it becomes a superconductor only when Teis substituted by a sufficient amount of Se. We summarize experimental evidencefor different competing interactions and discuss related open questions.",Sahana Rler,2016/6/3,2016/6/3
1709.05017v1,Recent Advances in Fog Radio Access Networks: Performance Analysis and Radio Resource Allocation,http://arxiv.org/abs/1709.05017v1,"As a promising paradigm for the fifth generation wireless communication (5G)system, the fog radio access network (F-RAN) has been proposed as an advancedsocially-aware mobile networking architecture to provide high spectralefficiency (SE) while maintaining high energy efficiency (EE) and low latency.Recent advents are advocated to the performance analysis and radio resourceallocation, both of which are fundamental issues to make F-RANs successfullyrollout. This article comprehensively summarizes the recent advances of theperformance analysis and radio resource allocation in F-RANs. Particularly, theadvanced edge cache and adaptive model selection schemes are presented toimprove SE and EE under maintaining a low latency level. The radio resourceallocation strategies to optimize SE and EE in F-RANs are respectivelyproposed. A few open issues in terms of the F-RAN based 5G architecture and thesocial-awareness technique are identified as well.",Mugen Peng,2017/9/15,2017/9/15
1908.08518v3,Aspects of AdS$_2$ classification in M-theory: Solutions with mesonic and baryonic charges,http://arxiv.org/abs/1908.08518v3,"We construct necessary and sufficient geometric conditions for a class ofAdS$_2$ solutions of M-theory with, at least, minimal supersymmetry to exist.We generalize previous results in the literature for ${\cal N}=(2,0)$supersymmetry in AdS$_2$ to ${\cal N}=(1,0)$. When the solution can be locallydescribed as AdS$_2\times \Sigma_g \times \,$SE$_7$ with $\Sigma_g$ a Riemannsurface of genus $g$ and SE$_7$ a seven-dimensional Sasaki-Einstein manifold,we clarify and unify various solutions present in the literature. In the caseof SE$_7=Q^{1,1,1}$ we find a new solution with baryonic and mesonic chargesturned on simultaneously.",Junho Hong,2019/8/22,2019/12/5
1609.07302v1,Building accurate HAV exploiting User Profiling and Sentiment Analysis,http://arxiv.org/abs/1609.07302v1,"Social Engineering (SE) is one of the most dangerous aspect an attacker canuse against a given entity (private citizen, industry, government, ...). Inorder to perform SE attacks, it is necessary to collect as much information aspossible about the target (or victim(s)). The aim of this paper is to reportthe details of an activity which took to the development of an automatic toolthat extracts, categorizes and summarizes the target interests, thus possibleweaknesses with respect to specific topics. Data is collected from the user'sactivity on social networks, parsed and analyzed using text mining techniques.The main contribution of the proposed tool consists in delivering some reportsthat allow the citizen, institutions as well as private bodies the screening oftheir exposure to SE attacks, with a strong awareness potential that will bereflected in a decrease of the risks and a good opportunity to save money.",Alan Ferrari,2016/9/23,2016/9/23
1904.04530v1,Toward Spectral and Energy Efficient 5G Networks Using Relayed OFDM with Index Modulation,http://arxiv.org/abs/1904.04530v1,"Next generation wireless networks are expected to provide much higher datathroughput and reliable connections for a far larger number of wireless servicesubscribers and machine-type nodes, which result in increasingly stringentrequirements of spectral efficiency (SE) and energy efficiency (EE). Orthogonalfrequency-division multiplexing with index modulation (OFDM-IM) stands out as apromising solution to satisfy the SE requirement with a reasonable increase insystem complexity. However, the EE of OFDM-IM is still required to be enhanced.Moreover, diversity gain is hardly harvested in OFDM-IM systems, which hindersfurther reliability enhancement. In this regard, relay assisted OFDM-IM, as apromising joint paradigm to achieve both high SE and EE, was proposed and hasbeen studied since last year. The objectives of this article are to summarizethe recent achievements of this joint paradigm, articulate its pros and cons,and reveal the corresponding challenges and future work.",Shuping Dang,2019/4/9,2019/4/9
2108.09529v1,Term Interrelations and Trends in Software Engineering,http://arxiv.org/abs/2108.09529v1,"The Software Engineering (SE) community is prolific, making it challengingfor experts to keep up with the flood of new papers and for neophytes to enterthe field. Therefore, we posit that the community may benefit from a toolextracting terms and their interrelations from the SE community's text corpusand showing terms' trends. In this paper, we build a prototyping tool using theword embedding technique. We train the embeddings on the SE Body of Knowledgehandbook and 15,233 research papers' titles and abstracts. We also create testcases necessary for validation of the training of the embeddings. We providerepresentative examples showing that the embeddings may aid in summarizingterms and uncovering trends in the knowledge base.",Janusan Baskararajah,2021/8/21,2021/8/21
2302.00167v1,Materia cuntica y dinmica por mediciones,http://arxiv.org/abs/2302.00167v1,"This article discusses some details of the course on ""Quantum matter andmeasurement induced dynamics"" given in the Summer School of Physics XXIX atUNAM in 2022. The notes describe useful concepts to study the dynamics inducedby photon losses, the method for simulation (quantum trajectories) issummarized and details of models in optical lattices and high-Q cavities aregiven. The notes are in Spanish.  En este art\'iculo se discuten algunos detalles del curso sobre ""Materiacu\'antica y din\'amica inducida por medici\'on"" de la escuela de verano deF\'isica XXIX (2022) en la UNAM. Las notas describen conceptos \'utiles paraestudiar la din\'amica emergente por efectos de medici\'on de fotones, seresume el m\'etodo para simulaci\'on (trayectorias cu\'anticas) y se dandetalles de modelos de materia cu\'antica y cavidades de alta reflectancia.",Santiago F. Caballero-Benitez,2023/2/1,2023/2/1
2111.02523v1,Adding Safety Rules to Surgeon-Authored VR Training,http://arxiv.org/abs/2111.02523v1,"Introduction: Safety criteria in surgical VR training are typicallyhard-coded and informally summarized. The Virtual Reality (VR) content creationinterface, TIPS-author, for the Toolkit for Illustration of Procedures inSurgery (TIPS) allows surgeon-educators (SEs) to create laparoscopicVR-training modules with force feedback. TIPS-author initializes anatomy shapeand physical properties selected by the SE accessing a cloud data base ofphysics-enabled pieces of anatomy. Methods: A new addition to TIPS-author aresafety rules that are set by the SE and are automatically monitored duringsimulation. Errors are recorded as visual snapshots for feedback to thetrainee. This paper reports on the implementation and opportunistic evaluationof the snap-shot mechanism as a trainee feedback mechanism. TIPS was fieldtested at two surgical conferences, one before and one after adding thesnapshot feature. Results: While other ratings of TIPS remained unchanged foran overall Likert scale score of 5.24 out of 7 (7 equals very useful), therating of the statement `The TIPS interface helps learners understand the forcenecessary to explore the anatomy' improved from 5.04 to 5.35 out of 7 after thesnapshot mechanism was added. Conclusions: The ratings indicate the viabilityof the TIPS open-source2 E-authored surgical training units. PresentingSE-determined procedural missteps via the snapshot mechanism at the end of thetraining increases acceptance",Ruiliang Gao,2021/11/3,2021/11/3
2307.08540v1,Utilization of Pre-trained Language Model for Adapter-based Knowledge Transfer in Software Engineering,http://arxiv.org/abs/2307.08540v1,"Software Engineering (SE) Pre-trained Language Models (PLMs), such asCodeBERT, are pre-trained on large code corpora, and their learned knowledgehas shown success in transferring into downstream tasks (e.g., code clonedetection) through fine-tuning the PLMs. In Natural Language Processing (NLP),an alternative in transferring the knowledge of PLMs is explored through theuse of adapter, a compact and parameter efficient module that is inserted intoa PLM. Although the use of adapters has shown promising results in manyNLP-based downstream tasks, their application and exploration in SE-baseddownstream tasks are limited.  Here, we study the knowledge transfer using adapters on multiple downstreamtasks including cloze test, code clone detection, and code summarization. Theseadapters are trained on code corpora and are inserted into a PLM that ispre-trained on English corpora or code corpora. We called these PLMs as NL-PLMand C-PLM, respectively. We observed an improvement in results using NL-PLMover a PLM that does not have adapters, and this suggested that adapters cantransfer and utilize useful knowledge from NL-PLM to SE tasks. The results aresometimes on par with or exceed the results of C-PLM; while being moreefficient in terms of the number of parameters and training time.Interestingly, adapters inserted into a C-PLM generally yield better resultsthan a traditional fine-tuned C-PLM. Our results open new directions to buildmore compact models for SE tasks.",Iman Saberi,2023/7/17,2023/7/17
1804.03393v3,Roto-Translation Covariant Convolutional Networks for Medical Image Analysis,http://arxiv.org/abs/1804.03393v3,"We propose a framework for rotation and translation covariant deep learningusing $SE(2)$ group convolutions. The group product of the special Euclideanmotion group $SE(2)$ describes how a concatenation of two roto-translationsresults in a net roto-translation. We encode this geometric structure intoconvolutional neural networks (CNNs) via $SE(2)$ group convolutional layers,which fit into the standard 2D CNN framework, and which allow to genericallydeal with rotated input samples without the need for data augmentation.  We introduce three layers: a lifting layer which lifts a 2D (vector valued)image to an $SE(2)$-image, i.e., 3D (vector valued) data whose domain is$SE(2)$; a group convolution layer from and to an $SE(2)$-image; and aprojection layer from an $SE(2)$-image to a 2D image. The lifting and groupconvolution layers are $SE(2)$ covariant (the output roto-translates with theinput). The final projection layer, a maximum intensity projection overrotations, makes the full CNN rotation invariant.  We show with three different problems in histopathology, retinal imaging, andelectron microscopy that with the proposed group CNNs, state-of-the-artperformance can be achieved, without the need for data augmentation by rotationand with increased performance compared to standard CNNs that do rely onaugmentation.",Erik J Bekkers,2018/4/10,2018/6/11
1806.10546v2,Non-Abelian Fourier Series on $\mathbb{Z}^2\backslash SE(2)$,http://arxiv.org/abs/1806.10546v2,"This paper discusses computational structure of coefficients of non-AbelianFourier series on the right coset space $\mathbb{Z}^2\backslash SE(2)$expressed in the trigonometric basis, where $SE(2)$ is the group of handednesspreserving Euclidean isometries of the plane and $\mathbb{Z}^2$ denotes thediscrete subgroup of translations of the orthogonal (square) lattice in$\mathbb{R}^2$. Assume that $\mu$ is the finite $SE(2)$-invariant measure onthe right coset space $\mathbb{Z}^2\backslash SE(2)$, normalized with respectto Weil's formula. We present a constructive computational characterizationincluding discrete sampling of non-Abelian Fourier matrix elements on $SE(2)$for coefficients of $\mu$-square integrable functions on$\mathbb{Z}^2\backslash SE(2)$ with respect to the concrete trigonometricbasis. The paper is concluded with discussion of the method for non-AbelianFourier coefficients of convolutions on $\mathbb{Z}^2\backslash SE(2)$.",Arash Ghaani Farashahi,2018/6/27,2023/11/27
1707.02811v2,Nilpotent Approximations of Sub-Riemannian Distances for Fast Perceptual Grouping of Blood Vessels in 2D and 3D,http://arxiv.org/abs/1707.02811v2,"We propose an efficient approach for the grouping of local orientations(points on vessels) via nilpotent approximations of sub-Riemannian distances inthe 2D and 3D roto-translation groups $SE(2)$ and $SE(3)$. In our distanceapproximations we consider homogeneous norms on nilpotent groups that locallyapproximate $SE(n)$, and which are obtained via the exponential and logarithmicmap on $SE(n)$. In a qualitative validation we show that the norms provideaccurate approximations of the true sub-Riemannian distances, and we discusstheir relations to the fundamental solution of the sub-Laplacian on $SE(n)$.The quantitative experiments further confirm the accuracy of theapproximations. Quantitative results are obtained by evaluating perceptualgrouping performance of retinal blood vessels in 2D images and curves inchallenging 3D synthetic volumes. The results show that 1) sub-Riemanniangeometry is essential in achieving top performance and 2) that grouping via thefast analytic approximations performs almost equally, or better, thandata-adaptive fast marching approaches on $\mathbb{R}^n$ and $SE(n)$.",Erik J. Bekkers,2017/7/10,2017/11/8
cond-mat/0605170v1,Fractional Stokes-Einstein and Debye-Stokes-Einstein relations in a network forming liquid,http://arxiv.org/abs/cond-mat/0605170v1,"We study the breakdown of the Stokes-Einstein (SE) and Debye-Stokes-Einstein(DSE) relations for translational and rotational motion in a prototypical modelof a network-forming liquid, the ST2 model of water. We find that the emergenceof ``fractional'' SE and DSE relations at low temperature is ubiquitous in thissystem, with exponents that vary little over a range of distinct physicalregimes. We also show that the same fractional SE relation is obeyed by bothmobile and immobile dynamical heterogeneities of the liquid.",Stephen R. Becker,2006/5/7,2006/5/7
1506.08765v1,Spectral Motion Synchronization in SE(3),http://arxiv.org/abs/1506.08765v1,"This paper addresses the problem of motion synchronization (or averaging) anddescribes a simple, closed-form solution based on a spectral decomposition,which does not consider rotation and translation separately but works straightin SE(3), the manifold of rigid motions. Besides its theoretical interest,being the first closed form solution in SE(3), experimental results show thatit compares favourably with the state of the art both in terms of precision andspeed.",Federica Arrigoni,2015/6/29,2015/6/29
1805.00897v2,On the Design of Hybrid Pose and Velocity-bias Observers on Lie Group SE(3),http://arxiv.org/abs/1805.00897v2,"This paper deals with the design of globally exponentially stable invariantobservers on the Special Euclidian group SE(3). First, we propose a generichybrid observer scheme (depending on a generic potential function) evolving on$SE(3)\times \mathbb{R}^6$ for pose (orientation and position) andvelocity-bias estimation. Thereafter, the proposed observer is formulatedexplicitly in terms of inertial vectors and landmark measurements.Interestingly, the proposed observer leads to a decoupled rotational errordynamics from the translational dynamics, which is an interesting feature inpractical applications with noisy measurements and disturbances.",Miaomiao Wang,2018/5/2,2018/11/13
0704.0123v1,Nonlinear Dynamics of the Phonon Stimulated Emission in Microwave Solid-State Resonator of the Nonautonomous Phaser Generator,http://arxiv.org/abs/0704.0123v1,"The microwave phonon stimulated emission (SE) has been experimentally andnumerically investigated in a nonautonomous microwave acoustic quantumgenerator, called also microwave phonon laser or phaser (see previous worksarXiv:cond-mat/0303188 ; arXiv:cond-mat/0402640 ; arXiv:nlin.CG/0703050)Phenomena of branching and long-time refractority (absence of the reaction onthe external pulses) for deterministic chaotic and regular processes of SE wereobserved in experiments with various levels of electromagnetic pumping. At thepumping level growth, the clearly depined increasing of the number ofcoexisting SE states has been observed both in real physical experiments and incomputer simulations. This confirms the analytical estimations of the branchingdensity in the phase space. The nature of the refractority of SE pulses isclosely connected with the pointed branching and reflects the crises of strangeattractors, i.e. their collisions with unstable periodic components of thehigher branches of SE states in the nonautonomous microwave phonon laser.",D. N. Makovetskii,2007/4/2,2007/4/2
2001.02020v3,Violation of Stokes-Einstein and Stokes-Einstein-Debye relations in polymers at the gas-supercooled liquid coexistence,http://arxiv.org/abs/2001.02020v3,"Molecular dynamics simulations are performed on a system of model linearpolymers to look at the violations of Stokes-Einstein (SE) andStokes-Einstein-Debye (SED) relations near the mode coupling theory transitiontemperature $T_c$ at three (one higher and two lower) densities. At lowtemperatures, both lower density systems show stable gas-supercooled-liquidcoexistence whereas the higher density system is homogeneous. We show thatmonomer density relaxation exhibits SE violation for all three densities,whereas molecular density relaxation shows a weak violation of the SE relationnear $T_c$ in both lower density systems. This study identifies disparity inmonomer mobility and observation of jumplike motion in the typical monomertrajectories resulting in the SE violations. In addition to the SE violation, aweak SED violation is observed in the gas-supercooled-liquid coexisting domainsof the lower densities. Both lower density systems also show a decoupling oftranslational and rotational dynamics in this polymer system.",Jalim Singh,2020/1/7,2020/11/9
2006.10503v3,SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,http://arxiv.org/abs/2006.10503v3,"We introduce the SE(3)-Transformer, a variant of the self-attention modulefor 3D point clouds and graphs, which is equivariant under continuous 3Droto-translations. Equivariance is important to ensure stable and predictableperformance in the presence of nuisance transformations of the data input. Apositive corollary of equivariance is increased weight-tying within the model.The SE(3)-Transformer leverages the benefits of self-attention to operate onlarge point clouds and graphs with varying number of points, while guaranteeingSE(3)-equivariance for robustness. We evaluate our model on a toy N-bodyparticle simulation dataset, showcasing the robustness of the predictions underrotations of the input. We further achieve competitive performance on tworeal-world datasets, ScanObjectNN and QM9. In all cases, our model outperformsa strong, non-equivariant attention baseline and an equivariant model withoutattention.",Fabian B. Fuchs,2020/6/18,2020/11/24
0705.4475v1,Dynamical heterogeneities and the breakdown of the Stokes-Einstein and Stokes-Einstein-Debye relations in simulated water,http://arxiv.org/abs/0705.4475v1,"We study the Stokes-Einstein (SE) and the Stokes-Einstein-Debye (SED)relations using molecular dynamics simulations of the extended simple pointcharge model of water. We find that both the SE and SED relations break down atlow temperature. To explore the relationship between these breakdowns anddynamical heterogeneities (DH), we also calculate the SE and SED relations forsubsets of the 7% ``fastest'' and 7% ``slowest'' molecules. We find that the SEand SED relations break down in both subsets, and that the breakdowns occur onall scales of mobility. Thus these breakdowns appear to be generalizedphenomena, in contrast with the view where only the most mobile molecules arethe origin of the breakdown of the SE and SED relations, embedded in aninactive background where these relations hold. At low temperature, the SE andSED relations in both subsets of molecules are replaced with ``fractional'' SEand SED relations, $D_t\sim(\tau/T)^{-\xi_t}$ and $D_r\sim(\tau/T)^{-\xi_r}$where $\xi_t\approx0.84<1$ and $\xi_r\approx0.75<1$. We also find that there isa decoupling between rotational and translational motion, and that thisdecoupling occurs in both fastest and slowest subsets of molecules. We alsofind that when the decoupling increases, upon cooling, the probability of amolecule being classified as both translationally and rotationally fastest alsoincreases. To study the effect of time scale for SE and SED breakdown anddecoupling, we introduce a time-dependent version of the SE and SED relations,and a time-dependent function that measures the extent of decoupling. Ourresults suggest that both the decoupling and SE and SED breakdowns areoriginated at the time scale corresponding to the end of the cage regime, whendiffusion starts. This is also the time scale when the DH are more relevant.",Marco G. Mazza,2007/5/30,2007/5/30
2312.02512v1,AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation,http://arxiv.org/abs/2312.02512v1,"This paper proposes a novel direct Audio-Visual Speech to Audio-Visual SpeechTranslation (AV2AV) framework, where the input and output of the system aremultimodal (i.e., audio and visual speech). With the proposed AV2AV, two keyadvantages can be brought: 1) We can perform real-like conversations withindividuals worldwide in a virtual meeting by utilizing our own primarylanguages. In contrast to Speech-to-Speech Translation (A2A), which solelytranslates between audio modalities, the proposed AV2AV directly translatesbetween audio-visual speech. This capability enhances the dialogue experienceby presenting synchronized lip movements along with the translated speech. 2)We can improve the robustness of the spoken language translation system. Byemploying the complementary information of audio-visual speech, the system caneffectively translate spoken language even in the presence of acoustic noise,showcasing robust performance. To mitigate the problem of the absence of aparallel AV2AV translation dataset, we propose to train our spoken languagetranslation system with the audio-only dataset of A2A. This is done by learningunified audio-visual speech representations through self-supervised learning inadvance to train the translation system. Moreover, we propose an AV-Rendererthat can generate raw audio and video in parallel. It is designed withzero-shot speaker modeling, thus the speaker in source audio-visual speech canbe maintained at the target translated audio-visual speech. The effectivenessof AV2AV is evaluated with extensive experiments in a many-to-many languagetranslation setting. The demo page is available onhttps://choijeongsoo.github.io/av2av.",Jeongsoo Choi,2023/12/5,2023/12/5
2212.14871v2,Equivariant Light Field Convolution and Transformer,http://arxiv.org/abs/2212.14871v2,"3D reconstruction and novel view rendering can greatly benefit from geometricpriors when the input views are not sufficient in terms of coverage andinter-view baselines. Deep learning of geometric priors from 2D images oftenrequires each image to be represented in a $2D$ canonical frame and the priorto be learned in a given or learned $3D$ canonical frame. In this paper, givenonly the relative poses of the cameras, we show how to learn priors frommultiple views equivariant to coordinate frame transformations by proposing an$SE(3)$-equivariant convolution and transformer in the space of rays in 3D.This enables the creation of a light field that remains equivariant to thechoice of coordinate frame. The light field as defined in our work, refers bothto the radiance field and the feature field defined on the ray space. We modelthe ray space, the domain of the light field, as a homogeneous space of $SE(3)$and introduce the $SE(3)$-equivariant convolution in ray space. Depending onthe output domain of the convolution, we present convolution-based$SE(3)$-equivariant maps from ray space to ray space and to $\mathbb{R}^3$. Ourmathematical framework allows us to go beyond convolution to$SE(3)$-equivariant attention in the ray space. We demonstrate how to tailorand adapt the equivariant convolution and transformer in the tasks ofequivariant neural rendering and $3D$ reconstruction from multiple views. Wedemonstrate $SE(3)$-equivariance by obtaining robust results in roto-translateddatasets without performing transformation augmentation.",Yinshuang Xu,2022/12/30,2023/6/7
1901.03011v3,Classification of mobile- and immobile-molecule timescales for the Stokes-Einstein and Stokes-Einstein-Debye relations in supercooled water,http://arxiv.org/abs/1901.03011v3,"Molecular dynamics simulations have been performed on TIP4P/2005 supercooledwater to investigate the molecular diffusion and shear viscosity at varioustimescales and assess the Stokes-Einstein (SE) and Stokes-Einstein-Debye (SED)relations. For this purpose, we calculated various time correlation functions,such as the mean-squared displacement, stress relaxation function, densitycorrelation function, hydrogen-bond correlation function, rotationalcorrelation function of molecular orientation, non-Gaussian parameter, andfour-point correlation function. Our study of the SE and SED relationsindicates that the transport coefficients and timescales obtained using thesetime correlation functions may be classified into two distinct classes: thosegoverned by either mobile or immobile molecules, due to dynamicalheterogeneity. In particular, we show that the stress relaxation time,hydrogen-bond lifetime, and large-angle rotational relaxation time are coupledwith translational diffusion, and are characterized by mobile molecules. Incontrast, the structural $\alpha$-relaxation time, small-angle rotationalrelaxation time, and characteristic timescales of four-point correlationfunctions are decoupled with translational diffusion, and are governed byimmobile molecules. This decoupling results in a violation of the SE relation.These results indicate that the identification of timescales that appropriatelycharacterize transport coefficients, such as translational diffusion constantand shear viscosity, provides a deep insight into the violation of the SE andSED relations in glass-forming liquids.",Takeshi Kawasaki,2019/1/10,2019/8/9
0805.3583v3,New Mechanics of Traumatic Brain Injury,http://arxiv.org/abs/0805.3583v3,"The prediction and prevention of traumatic brain injury is a very importantaspect of preventive medical science. This paper proposes a new coupledloading-rate hypothesis for the traumatic brain injury (TBI), which states thatthe main cause of the TBI is an external Euclidean jolt, or SE(3)-jolt, animpulsive loading that strikes the head in several coupled degrees-of-freedomsimultaneously. To show this, based on the previously defined covariant forcelaw, we formulate the coupled Newton-Euler dynamics of brain's micro-motionswithin the cerebrospinal fluid and derive from it the coupled SE(3)-joltdynamics. The SE(3)-jolt is a cause of the TBI in two forms of brain's rapiddiscontinuous deformations: translational dislocations and rotationaldisclinations. Brain's dislocations and disclinations, caused by theSE(3)-jolt, are described using the Cosserat multipolar viscoelastic continuumbrain model.  Keywords: Traumatic brain injuries, coupled loading-rate hypothesis,Euclidean jolt, coupled Newton-Euler dynamics, brain's dislocations anddisclinations",Vladimir G. Ivancevic,2008/5/23,2008/11/18
1307.4599v2,The role of SE(d)-reduction for swimming in Stokes and Navier-Stokes fluids,http://arxiv.org/abs/1307.4599v2,"Steady swimming appears both periodic and stable. These characteristics arethe very definition of limit cycles, and so we ask ""Can we view swimming as alimit cycle?"" In this paper we will not be able to answer this question infull. However, we shall find that reduction by SE(d)-symmetry brings us closer.Upon performing reduction by symmetry, we will find a stable fixed point whichcorresponds to a motionless body in stagnant water. We will then speculate onthe existence of periodic orbits which are ""approximately"" limit cycles in thereduced system. When we lift these periodic orbits from the reduced phasespace, we obtain dynamically robust relatively periodic orbits wherein eachperiod is related to the previous by an SE(d)-phase. Clearly, an SE(d) phaseconsisting of nonzero translation and identity rotation means directionalswimming, while non-trivial rotations correspond to turning with a constantturning radius.",Henry O. Jacobs,2013/7/17,2013/10/26
1605.02031v2,Extended Kalman Filter on SE(3) for Geometric Control of a Quadrotor UAV,http://arxiv.org/abs/1605.02031v2,"An extended Kalman filter (EKF) is developed on the special Euclidean group,SE(3) for geometric control of a quadrotor UAV. It is obtained by performing anextensive linearization on SE(3) to estimate the state of the quadrotor fromnoisy measurements. Proposed estimator considers all the coupling effectsbetween rotational and translational dynamics, and it is developed in acoordinate-free fashion. The desirable features of the proposed EKF areillustrated by numerical examples and experimental results for severalscenarios. The proposed estimation scheme on SE(3) has been unprecedented andthese results can be particularly useful for aggressive maneuvers in GPS deniedenvironments or in situations where parts of onboard sensors fail.",Farhad A. Goodarzi,2016/5/6,2016/5/9
2201.00802v1,Learning Small Molecule Energies and Interatomic Forces with an Equivariant Transformer on the ANI-1x Dataset,http://arxiv.org/abs/2201.00802v1,"Accurate predictions of interatomic energies and forces are essential forhigh quality molecular dynamic simulations (MD). Machine learning algorithmscan be used to overcome limitations of classical MD by predicting ab initioquality energies and forces. SE(3)-equivariant neural network allow reasoningover spatial relationships and exploiting the rotational and translationalsymmetries. One such algorithm is the SE(3)-Transformer, which we adapt for theANI-1x dataset. Our early experimental results indicate through ablationstudies that deeper networks - with additional SE(3)-Transformer layers - couldreach necessary accuracies to allow effective integration with MD. However,faster implementations of the SE(3)-Transformer will be required, such as therecently published accelerated version by Milesi.",Bryce Hedelius,2022/1/3,2022/1/3
2306.13960v2,Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis,http://arxiv.org/abs/2306.13960v2,"Regular group convolutional neural networks (G-CNNs) have been shown toincrease model performance and improve equivariance to different geometricalsymmetries. This work addresses the problem of SE(3), i.e., roto-translationequivariance, on volumetric data. Volumetric image data is prevalent in manymedical settings. Motivated by the recent work on separable group convolutions,we devise a SE(3) group convolution kernel separated into a continuous SO(3)(rotation) kernel and a spatial kernel. We approximate equivariance to thecontinuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernelis parameterized via RBF interpolation on similarly uniform grids. Wedemonstrate the advantages of our approach in volumetric medical imageanalysis. Our SE(3) equivariant models consistently outperform CNNs and regulardiscrete G-CNNs on challenging medical classification tasks and showsignificantly improved generalization capabilities. Our approach achieves up toa 16.5% gain in accuracy over regular CNNs.",Thijs P. Kuipers,2023/6/24,2023/7/20
2306.16261v1,SE-PQA: Personalized Community Question Answering,http://arxiv.org/abs/2306.16261v1,"Personalization in Information Retrieval is a topic studied for a long time.Nevertheless, there is still a lack of high-quality, real-world datasets toconduct large-scale experiments and evaluate models for personalized search.This paper contributes to filling this gap by introducing SE-PQA (StackExchange- Personalized Question Answering), a new curated resource to design andevaluate personalized models related to the task of community QuestionAnswering (cQA). The contributed dataset includes more than 1 million queriesand 2 million answers, annotated with a rich set of features modeling thesocial interactions among the users of a popular cQA platform. We describe thecharacteristics of SE-PQA and detail the features associated with questions andanswers. We also provide reproducible baseline methods for the cQA task basedon the resource, including deep learning models and personalization approaches.The results of the preliminary experiments conducted show the appropriatenessof SE-PQA to train effective cQA models; they also show that personalizationremarkably improves the effectiveness of all the methods tested. Furthermore,we show the benefits in terms of robustness and generalization of combiningdata from multiple communities for personalization purposes.",Pranav Kasela,2023/6/28,2023/6/28
2303.00964v2,A deep learning-based approach for identifying unresolved questions on Stack Exchange Q&A communities through graph-based communication modelling,http://arxiv.org/abs/2303.00964v2,"In recent years, online question-answering (Q&A) platforms, such as StackExchange (SE), have become increasingly popular as a source of information andknowledge sharing. Despite the vast amount of information available on theseplatforms, many questions remain unresolved. In this work, we aim to addressthis issue by proposing a novel approach to identify unresolved questions in SEQ&A communities. Our approach utilises the graph structure of communicationformed around a question by users to model the communication networksurrounding it. We employ a property graph model and graph neural networks(GNNs), which can effectively capture both the structure of communication andthe content of messages exchanged among users. By leveraging the power of graphrepresentation and GNNs, our approach can effectively identify unresolvedquestions in SE communities. Experimental results on the complete historicaldata from three distinct Q&A communities demonstrate the superiority of ourproposed approach over baseline methods that only consider the content ofquestions. Finally, our work represents a first but important step towardsbetter understanding the factors that can affect questions becoming andremaining unresolved in SE communities.",Hassan Abedi Firouzjaei,2023/3/2,2023/8/1
2305.00233v2,Towards machine learning guided by best practices,http://arxiv.org/abs/2305.00233v2,"Nowadays, machine learning (ML) is being used in software systems withmultiple application fields, from medicine to software engineering (SE). On theone hand, the popularity of ML in the industry can be seen in the statisticsshowing its growth and adoption. On the other hand, its popularity can also beseen in research, particularly in SE, where not only have multiple studies beenpublished in SE conferences and journals but also in the multiple workshops andco-located conferences in software engineering conferences. At the same time,researchers and practitioners have shown that machine learning has someparticular challenges and pitfalls. In particular, research has shown thatML-enabled systems have a different development process than traditional SE,which also describes some of the challenges of ML applications. In order tomitigate some of the identified challenges and pitfalls, white and grayliterature has proposed a set of recommendations based on their own experiencesand focused on their domain (e.g., biomechanics), but for the best of ourknowledge, there is no guideline focused on the SE community. This thesis aimsto reduce this gap by answering research questions that help to understand thepractices used and discussed by practitioners and researchers in the SEcommunity by analyzing possible sources of practices such as question andanswer communities and also previous research studies to present a set ofpractices with an SE perspective.",Anamaria Mojica-Hanke,2023/4/29,2023/5/6
2203.17166v1,On the Evaluation of NLP-based Models for Software Engineering,http://arxiv.org/abs/2203.17166v1,"NLP-based models have been increasingly incorporated to address SE problems.These models are either employed in the SE domain with little to no change, orthey are greatly tailored to source code and its unique characteristics. Manyof these approaches are considered to be outperforming or complementingexisting solutions. However, an important question arises here: ""Are thesemodels evaluated fairly and consistently in the SE community?"". To answer thisquestion, we reviewed how NLP-based models for SE problems are being evaluatedby researchers. The findings indicate that currently there is no consistent andwidely-accepted protocol for the evaluation of these models. While differentaspects of the same task are being assessed in different studies, metrics aredefined based on custom choices, rather than a system, and finally, answers arecollected and interpreted case by case. Consequently, there is a dire need toprovide a methodological way of evaluating NLP-based models to have aconsistent assessment and preserve the possibility of fair and efficientcomparison.",Maliheh Izadi,2022/3/31,2022/3/31
2308.10620v4,Large Language Models for Software Engineering: A Systematic Literature Review,http://arxiv.org/abs/2308.10620v4,"Large Language Models (LLMs) have significantly impacted numerous domains,including Software Engineering (SE). Many recent publications have exploredLLMs applied to various SE tasks. Nevertheless, a comprehensive understandingof the application, effects, and possible limitations of LLMs on SE is still inits early stages. To bridge this gap, we conducted a systematic literaturereview on LLM4SE, with a particular focus on understanding how LLMs can beexploited to optimize processes and outcomes. We collect and analyze 229research papers from 2017 to 2023 to answer four key research questions (RQs).In RQ1, we categorize different LLMs that have been employed in SE tasks,characterizing their distinctive features and uses. In RQ2, we analyze themethods used in data collection, preprocessing, and application highlightingthe role of well-curated datasets for successful LLM for SE implementation. RQ3investigates the strategies employed to optimize and evaluate the performanceof LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs haveshown success to date, illustrating their practical contributions to the field.From the answers to these RQs, we discuss the current state-of-the-art andtrends, identifying gaps in existing research, and flagging promising areas forfuture study.",Xinyi Hou,2023/8/21,2023/9/12
2003.06887v1,How to Improve AI Tools (by Adding in SE Knowledge): Experiments with the TimeLIME Defect Reduction Tool,http://arxiv.org/abs/2003.06887v1,"AI algorithms are being used with increased frequency in SE research andpractice. Such algorithms are usually commissioned and certified using datafrom outside the SE domain. Can we assume that such algorithms can be used''off-the-shelf'' (i.e. with no modifications)? To say that another way, arethere special features of SE problems that suggest a different and better wayto use AI tools?  To answer these questions, this paper reports experiments with TimeLIME, avariant of the LIME explanation algorithm from KDD'16. LIME can offerrecommendations on how to change static code attributes in order to reduce thenumber of defects in the next software release. That version of LIME used aninternal weighting tool to decide what attributes to include/exclude in thoserecommendations. TimeLIME improves on that weighting scheme using the followingSE knowledge: software comes in releases; an implausible change to software issomething that has never been changed in prior releases; so it is better to useplausible changes, i.e. changes with some precedent in the prior releases. Byrestricting recommendations to just the frequently changed attributes, TimeLIMEcan produce (a)~dramatically better explanations of what causes defects and(b)~much better recommendations on how to fix buggy code.  Apart from these specific results about defect reduction and TimeLIME, themore general point of this paper is that our community should be more carefulabout using off-the-shelf AI tools, without first applying SE knowledge. Asshown here, it may not be a complex matter to apply that knowledge. Further,once that SE knowledge is applied, this can result in dramatically bettersystems.",Kewen Peng,2020/3/15,2020/3/15
2204.03366v2,Impact of Software Engineering Research in Practice: A Patent and Author Survey Analysis,http://arxiv.org/abs/2204.03366v2,"Existing work on the practical impact of software engineering (SE) researchexamines industrial relevance rather than adoption of study results, hence thequestion of how results have been practically applied remains open. To answerthis and investigate the outcomes of impactful research, we performed aquantitative and qualitative analysis of 4,354 SE patents citing 1,690 SEpapers published in four leading SE venues between 1975-2017. Moreover, weconducted a survey on 475 authors of 593 top-cited and awarded publications,achieving 26% response rate. Overall, researchers have equipped practitionerswith various tools, processes, and methods, and improved many existingproducts. SE practice values knowledge-seeking research and is impacted bydiverse cross-disciplinary SE areas. Practitioner-oriented publication venuesappear more impactful than researcher-oriented ones, while industry-relatedtracks in conferences could enhance their impact. Some research works did notreach a wide footprint due to limited funding resources or unfavorablecost-benefit trade-off of the proposed solutions. The need for higher SEresearch funding could be corroborated through a dedicated empirical study. Ingeneral, the assessment of impact is subject to its definition. Therefore,academia and industry could jointly agree on a formal description to set acommon ground for subsequent research on the topic.",Zoe Kotti,2022/4/7,2022/9/22
2206.03474v1,A COVID-19 Search Engine (CO-SE) with Transformer-based Architecture,http://arxiv.org/abs/2206.03474v1,"Coronavirus disease (COVID-19) is an infectious disease, which is caused bythe SARS-CoV-2 virus. Due to the growing literature on COVID-19, it is hard toget precise, up-to-date information about the virus. Practitioners, front-lineworkers, and researchers require expert-specific methods to stay current onscientific knowledge and research findings. However, there are a lot ofresearch papers being written on the subject, which makes it hard to keep upwith the most recent research. This problem motivates us to propose the designof the COVID-19 Search Engine (CO-SE), which is an algorithmic system thatfinds relevant documents for each query (asked by a user) and answers complexquestions by searching a large corpus of publications. The CO-SE has aretriever component trained on the TF-IDF vectorizer that retrieves therelevant documents from the system. It also consists of a reader component thatconsists of a Transformer-based model, which is used to read the paragraphs andfind the answers related to the query from the retrieved documents. Theproposed model has outperformed previous models, obtaining an exact match ratioscore of 71.45% and a semantic answer similarity score of 78.55%. It alsooutperforms other benchmark datasets, demonstrating the generalizability of theproposed approach.",Shaina Raza,2022/6/7,2022/6/7
2004.14171v1,SE-KGE: A Location-Aware Knowledge Graph Embedding Model for Geographic Question Answering and Spatial Semantic Lifting,http://arxiv.org/abs/2004.14171v1,"Learning knowledge graph (KG) embeddings is an emerging technique for avariety of downstream tasks such as summarization, link prediction, informationretrieval, and question answering. However, most existing KG embedding modelsneglect space and, therefore, do not perform well when applied to (geo)spatialdata and tasks. For those models that consider space, most of them primarilyrely on some notions of distance. These models suffer from higher computationalcomplexity during training while still losing information beyond the relativedistance between entities. In this work, we propose a location-aware KGembedding model called SE-KGE. It directly encodes spatial information such aspoint coordinates or bounding boxes of geographic entities into the KGembedding space. The resulting model is capable of handling different types ofspatial reasoning. We also construct a geographic knowledge graph as well as aset of geographic query-answer pairs called DBGeo to evaluate the performanceof SE-KGE in comparison to multiple baselines. Evaluation results show thatSE-KGE outperforms these baselines on the DBGeo dataset for geographic logicquery answering task. This demonstrates the effectiveness of ourspatially-explicit model and the importance of considering the scale ofdifferent geographic entities. Finally, we introduce a novel downstream taskcalled spatial semantic lifting which links an arbitrary location in the studyarea to entities in the KG via some relations. Evaluation on DBGeo shows thatour model outperforms the baseline by a substantial margin.",Gengchen Mai,2020/4/25,2020/4/25
2108.01591v1,The application of artificial intelligence in software engineering: a review challenging conventional wisdom,http://arxiv.org/abs/2108.01591v1,"The field of artificial intelligence (AI) is witnessing a recent upsurge inresearch, tools development, and deployment of applications. Multiple softwarecompanies are shifting their focus to developing intelligent systems; and manyothers are deploying AI paradigms to their existing processes. In parallel, theacademic research community is injecting AI paradigms to provide solutions totraditional engineering problems. Similarly, AI has evidently been proveduseful to software engineering (SE). When one observes the SE phases(requirements, design, development, testing, release, and maintenance), itbecomes clear that multiple AI paradigms (such as neural networks, machinelearning, knowledge-based systems, natural language processing) could beapplied to improve the process and eliminate many of the major challenges thatthe SE field has been facing. This survey chapter is a review of the mostcommonplace methods of AI applied to SE. The review covers methods betweenyears 1975-2017, for the requirements phase, 46 major AI-driven methods arefound, 19 for design, 15 for development, 68 for testing, and 15 for releaseand maintenance. Furthermore, the purpose of this chapter is threefold;firstly, to answer the following questions: is there sufficient intelligence inthe SE lifecycle? What does applying AI to SE entail? Secondly, to measure,formulize, and evaluate the overlap of SE phases and AI disciplines. Lastly,this chapter aims to provide serious questions to challenging the currentconventional wisdom (i.e., status quo) of the state-of-the-art, craft a callfor action, and to redefine the path forward.",Feras A. Batarseh,2021/8/3,2021/8/3
1809.04344v1,"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA",http://arxiv.org/abs/1809.04344v1,"We introduce MASSES, a simple evaluation metric for the task of VisualQuestion Answering (VQA). In its standard form, the VQA task is operationalizedas follows: Given an image and an open-ended question in natural language,systems are required to provide a suitable answer. Currently, model performanceis evaluated by means of a somehow simplistic metric: If the predicted answeris chosen by at least 3 human annotators out of 10, then it is 100% correct.Though intuitively valuable, this metric has some important limitations. First,it ignores whether the predicted answer is the one selected by the Majority(MA) of annotators. Second, it does not account for the quantitativeSubjectivity (S) of the answers in the sample (and dataset). Third, informationabout the Semantic Similarity (SES) of the responses is completely neglected.Based on such limitations, we propose a multi-component metric that accountsfor all these issues. We show that our metric is effective in providing a morefine-grained evaluation both on the quantitative and qualitative level.",Shailza Jolly,2018/9/12,2018/9/12
2108.08139v2,Towards Mapping Control Theory and Software Engineering Properties using Specification Patterns,http://arxiv.org/abs/2108.08139v2,"A traditional approach to realize self-adaptation in software engineering(SE) is by means of feedback loops. The goals of the system can be specified asformal properties that are verified against models of the system. On the otherhand, control theory (CT) provides a well-established foundation for designingfeedback loop systems and providing guarantees for essential properties, suchas stability, settling time, and steady state error. Currently, it is an openquestion whether and how traditional SE approaches to self-adaptation considerproperties from CT. Answering this question is challenging given the principledifferences in representing properties in both fields. In this paper, we take afirst step to answer this question. We follow a bottom up approach where wespecify a control design (in Simulink) for a case inspired by Scuderia Ferrari(F1) and provide evidence for stability and safety. The design is thentransferred into code (in C) that is further optimized. Next, we defineproperties that enable verifying whether the control properties still hold atcode level. Then, we consolidate the solution by mapping the properties in bothworlds using specification patterns as common language and we verify thecorrectness of this mapping. The mapping offers a reusable artifact to solvesimilar problems. Finally, we outline opportunities for future work,particularly to refine and extend the mapping and investigate how it canimprove the engineering of self-adaptive systems for both SE and CT engineers.",Ricardo Caldas,2021/8/18,2022/5/23
2306.00758v2,LiT-4-RSVQA: Lightweight Transformer-based Visual Question Answering in Remote Sensing,http://arxiv.org/abs/2306.00758v2,"Visual question answering (VQA) methods in remote sensing (RS) aim to answernatural language questions with respect to an RS image. Most of the existingmethods require a large amount of computational resources, which limits theirapplication in operational scenarios in RS. To address this issue, in thispaper we present an effective lightweight transformer-based VQA in RS(LiT-4-RSVQA) architecture for efficient and accurate VQA in RS. Ourarchitecture consists of: i) a lightweight text encoder module; ii) alightweight image encoder module; iii) a fusion module; and iv) aclassification module. The experimental results obtained on a VQA benchmarkdataset demonstrate that our proposed LiT-4-RSVQA architecture providesaccurate VQA results while significantly reducing the computationalrequirements on the executing hardware. Our code is publicly available athttps://git.tu-berlin.de/rsim/lit4rsvqa.",Leonard Hackel,2023/6/1,2023/6/2
1804.10657v1,"Can You Explain That, Better? Comprehensible Text Analytics for SE Applications",http://arxiv.org/abs/1804.10657v1,"Text mining methods are used for a wide range of Software Engineering (SE)tasks. The biggest challenge of text mining is high dimensional data, i.e., acorpus of documents can contain $10^4$ to $10^6$ unique words. To address thiscomplexity, some very convoluted text mining methods have been applied. Is thatcomplexity necessary? Are there simpler ways to quickly generate models thatperform as well as the more convoluted methods and also be human-readable?  To answer these questions, we explore a combination of LDA (Latent DirichletAllocation) and FFTs (Fast and Frugal Trees) to classify NASA software bugreports from six different projects. Designed using principles frompsychological science, FFTs return very small models that arehuman-comprehensible. When compared to the commonly used text mining method anda recent state-of-the-art-system (search-based SE method that automaticallytune the control parameters of LDA), these FFT models are very small (a binarytree of depth $d = 4$ that references only 4 topics) and hence easy tounderstand. They were also faster to generate and produced similar or betterseverity predictions.  Hence we can conclude that, at least for datasets explored here, convolutedtext mining models can be deprecated in favor of simpler method such asLDA+FFTs. At the very least, we recommend LDA+FFTs (a) when humans need toread, understand, and audit a model or (b) as an initial baseline method forthe SE researchers exploring text artifacts from software projects.",Amritanshu Agrawal,2018/4/27,2018/4/27
1801.09109v1,Spectral and Energy Efficient Wireless Powered IoT Networks: NOMA or TDMA?,http://arxiv.org/abs/1801.09109v1,"Wireless powered communication networks (WPCNs), where multipleenergy-limited devices first harvest energy in the downlink and then transmitinformation in the uplink, have been envisioned as a promising solution for thefuture Internet-of-Things (IoT). Meanwhile, non-orthogonal multiple access(NOMA) has been proposed to improve the system spectral efficiency (SE) of thefifth-generation (5G) networks by allowing concurrent transmissions of multipleusers in the same spectrum. As such, NOMA has been recently considered for theuplink of WPCNs based IoT networks with a massive number of devices. However,simultaneous transmissions in NOMA may also incur more transmit energyconsumption as well as circuit energy consumption in practice which is criticalfor energy constrained IoT devices. As a result, compared to orthogonalmultiple access schemes such as time-division multiple access (TDMA), whetherthe SE can be improved and/or the total energy consumption can be reduced withNOMA in such a scenario still remains unknown. To answer this question, wefirst derive the optimal time allocations for maximizing the SE of a TDMA-basedWPCN (T-WPCN) and a NOMA-based WPCN (N-WPCN), respectively. Subsequently, weanalyze the total energy consumption as well as the maximum SE achieved bythese two networks. Surprisingly, it is found that N-WPCN not only consumesmore energy, but also is less spectral efficient than T-WPCN. Simulationresults verify our theoretical findings and unveil the fundamental performancebottleneck, i.e., ""worst user bottleneck problem"", in multiuser NOMA systems.",Qingqing Wu,2018/1/27,2018/1/27
2312.15614v1,A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Software Engineering Tasks,http://arxiv.org/abs/2312.15614v1,"Pre-trained models (PTMs) have achieved great success in various SoftwareEngineering (SE) downstream tasks following the ``pre-train then fine-tune''paradigm. As fully fine-tuning all parameters of PTMs can be computationallyexpensive, a widely used solution is parameter-efficient fine-tuning (PEFT),which freezes PTMs while introducing extra parameters. Though work has beendone to test PEFT methods in the SE field, a comprehensive evaluation is stilllacking. This paper aims to fill in this gap by evaluating the effectiveness offive PEFT methods on eight PTMs and four SE downstream tasks. For differenttasks and PEFT methods, we seek answers to the following research questions: 1)Is it more effective to use PTMs trained specifically on source code, or is itsufficient to use PTMs trained on natural language text? 2) What is the impactof varying model sizes? 3) How does the model architecture affect theperformance? Besides effectiveness, we also discuss the efficiency of PEFTmethods, concerning the costs of required training time and GPU resourceconsumption. We hope that our findings can provide a deeper understanding ofPEFT methods on various PTMs and SE downstream tasks. All the codes and dataare available at \url{https://github.com/zwtnju/PEFT.git}.",Wentao Zou,2023/12/25,2023/12/25
2311.05111v1,Vector Approximate Survey Propagation for Model-Mismatched Estimation (Or: How to Achieve Kabashima's 1RSB Prediction),http://arxiv.org/abs/2311.05111v1,"For approximate inference in high-dimensional generalized linear models(GLMs), the performance of an estimator may significantly degrade when mismatchexists between the postulated model and the ground truth. In mismatched GLMswith rotation-invariant measurement matrices, Kabashima et al. proved vectorapproximate message passing (VAMP) computes exactly the optimal estimator ifthe replica symmetry (RS) ansatz is valid, but it becomes inappropriate if RSbreaking (RSB) appears. Although the one-step RSB (1RSB) saddle point equationswere given for the optimal estimator, the question remains: how to achieve the1RSB prediction? This paper answers the question by proposing a new algorithm,vector approximate survey propagation (VASP). VASP derives from a reformulationof Kabashima's extremum conditions, which later links the theoretical equationsto survey propagation in vector form and finally the algorithm. VASP has acomplexity as low as VAMP, while embracing VAMP as a special case. The SEderived for VASP can capture precisely the per-iteration behavior of thesimulated algorithm, and the SE's fixed point equations perfectly matchKabashima's 1RSB prediction, which indicates VASP can achieve the optimalperformance even in a model-mismatched setting with 1RSB. Simulation resultsconfirm VASP outperforms many state-of-the-art algorithms.",Qun Chen,2023/11/9,2023/11/9
2211.16093v1,Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,http://arxiv.org/abs/2211.16093v1,"Question answering (QA) models are shown to be insensitive to largeperturbations to inputs; that is, they make correct and confident predictionseven when given largely perturbed inputs from which humans can not correctlyderive answers. In addition, QA models fail to generalize to other domains andadversarial test sets, while humans maintain high accuracy. Based on theseobservations, we assume that QA models do not use intended features necessaryfor human reading but rely on spurious features, causing the lack ofgeneralization ability. Therefore, we attempt to answer the question: If theoverconfident predictions of QA models for various types of perturbations arepenalized, will the out-of-distribution (OOD) generalization be improved? Toprevent models from making confident predictions on perturbed inputs, we firstfollow existing studies and maximize the entropy of the output probability forperturbed inputs. However, we find that QA models trained to be sensitive to acertain perturbation type are often insensitive to unseen types ofperturbations. Thus, we simultaneously maximize the entropy for the fourperturbation types (i.e., word- and sentence-level shuffling and deletion) tofurther close the gap between models and humans. Contrary to our expectations,although models become sensitive to the four types of perturbations, we findthat the OOD generalization is not improved. Moreover, the OOD generalizationis sometimes degraded after entropy maximization. Making unconfidentpredictions on largely perturbed inputs per se may be beneficial to gaininghuman trust. However, our negative results suggest that researchers should payattention to the side effect of entropy maximization.",Kazutoshi Shinoda,2022/11/29,2022/11/29
2009.09331v1,A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions,http://arxiv.org/abs/2009.09331v1,"Automated filtering of toxic conversations may help an Open-source software(OSS) community to maintain healthy interactions among the projectparticipants. Although, several general purpose tools exist to identify toxiccontents, those may incorrectly flag some words commonly used in the SoftwareEngineering (SE) context as toxic (e.g., 'junk', 'kill', and 'dump') and viceversa. To encounter this challenge, an SE specific tool has been proposed bythe CMU Strudel Lab (referred as the `STRUDEL' hereinafter) by combining theoutput of the Perspective API with the output from a customized version of theStanford's Politeness detector tool. However, since STRUDEL's evaluation wasvery limited with only 654 SE text, its practical applicability is unclear.Therefore, this study aims to empirically evaluate the Strudel tool as well asfour state-of-the-art general purpose toxicity detectors on a large scale SEdataset. On this goal, we empirically developed a rubric to manually labeltoxic SE interactions. Using this rubric, we manually labeled a dataset of6,533 code review comments and 4,140 Gitter messages. The results of ouranalyses suggest significant degradation of all tools' performances on ourdatasets. Those degradations were significantly higher on our dataset of formalSE communication such as code review than on our dataset of informalcommunication such as Gitter messages. Two of the models from our study showedsignificant performance improvements during 10-fold cross validations after weretrained those on our SE datasets. Based on our manual investigations of theincorrectly classified text, we have identified several recommendations fordeveloping an SE specific toxicity detector.",Jaydeb Sarker,2020/9/20,2020/9/20
2211.13817v3,Psychometric Instruments in Software Engineering Research on Personality: Status Quo After Fifty Years,http://arxiv.org/abs/2211.13817v3,"Context: Although software development is a human activity, SoftwareEngineering (SE) research has focused mostly on processes and tools, makinghuman factors underrepresented. This kind of research may be improved usingknowledge from human-focused disciplines. An example of missed opportunities ishow SE employs psychometric instruments. Objective: Provide an overview ofpsychometric instruments in SE research regarding personality and providerecommendations for adopting them. Method: We conducted a systematic mapping tobuild an overview of instruments used within SE for assessing personality andreviewed their use from a multidisciplinary perspective of SE and socialscience. Results: We contribute with a secondary study covering fifty years ofresearch (1970 to 2020). One of the most adopted instruments (MBTI) facescriticism within social sciences, and we identified discrepancies between itsapplication and existing recommendations. We emphasize that several instrumentsrefer to the Five-Factor Model, which despite its relevance in social sciences,has no specific advice for its application within SE. We discuss general advicefor its proper application. Conclusion: The findings show that the adoption ofpsychometric instruments regarding personality in SE needs to be improved,ideally with the support of social science researchers. We believe that thereview presented in this study can help to understand limitations and to evolvein this direction.",Danilo Almeida Felipe,2022/11/24,2023/5/5
1709.00944v5,Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks,http://arxiv.org/abs/1709.00944v5,"Speech enhancement (SE) aims to reduce noise in speech signals. Most SEtechniques focus only on addressing audio information. In this work, inspiredby multimodal learning, which utilizes data from different modalities, and therecent success of convolutional neural networks (CNNs) in SE, we propose anaudio-visual deep CNNs (AVDCNN) SE model, which incorporates audio and visualstreams into a unified network model. We also propose a multi-task learningframework for reconstructing audio and visual signals at the output layer.Precisely speaking, the proposed AVDCNN model is structured as an audio-visualencoder-decoder network, in which audio and visual data are first processedusing individual CNNs, and then fused into a joint network to generate enhancedspeech (the primary task) and reconstructed images (the secondary task) at theoutput layer. The model is trained in an end-to-end manner, and parameters arejointly learned through back-propagation. We evaluate enhanced speech usingfive instrumental criteria. Results show that the AVDCNN model yields a notablysuperior performance compared with an audio-only CNN-based SE model and twoconventional SE approaches, confirming the effectiveness of integrating visualinformation into the SE process. In addition, the AVDCNN model also outperformsan existing audio-visual SE model, confirming its capability of effectivelycombining audio and visual information in SE.",Jen-Cheng Hou,2017/9/1,2022/4/18
1812.03866v1,Systems Enginnering applied to spectroscopy of the ELTs: The Conceptual Design phase of GMACS,http://arxiv.org/abs/1812.03866v1,"An important tool for the development of the next generation of extremelylarge telescopes (ELTs) is the Systems Engineering (SE). GMACS is thefirst-generation multi-object spectrograph working at visible wavelengths forthe Giant Magellan Telescope (GMT). The aim is to discuss the application of SEin ground-based astronomy for multi-object spectrographs. For this, it ispresented the SE of the GMACS spectrograph, currently on its Conceptual Designphase. SE provide means to assist the management of complex projects, and inthe case of GMACS, to ensure its success when in operation, maximizing thescientific potential of GMT.",D. M. Faes,2018/12/7,2018/12/7
2101.08655v2,Q4EDA: A Novel Strategy for Textual Information Retrieval Based on User Interactions with Visual Representations of Time Series,http://arxiv.org/abs/2101.08655v2,"Knowing how to construct text-based Search Queries (SQs) for use in SearchEngines (SEs) such as Google or Wikipedia has become a fundamental skill.Though much data are available through such SEs, most structured datasets liveoutside their scope. Visualization tools aid in this limitation, but no suchtools come close to the sheer amount of information available throughgeneral-purpose SEs. To fill this gap, this paper presents Q4EDA, a novelframework that converts users' visual selection queries executed on top of timeseries visual representations, providing valid and stable SQs to be used ingeneral-purpose SEs and suggestions of related information. The usefulness ofQ4EDA is presented and validated by users through an application linking aGapminder's line-chart replica with a SE populated with Wikipedia documents,showing how Q4EDA supports and enhances exploratory analysis of United Nationsworld indicators. Despite some limitations, Q4EDA is unique in its proposal andrepresents a real advance towards providing solutions for querying textualinformation based on user interactions with visual representations.",Leonardo Christino,2021/1/19,2022/8/2
2205.13293v1,Joint Training of Speech Enhancement and Self-supervised Model for Noise-robust ASR,http://arxiv.org/abs/2205.13293v1,"Speech enhancement (SE) is usually required as a front end to improve thespeech quality in noisy environments, while the enhanced speech might not beoptimal for automatic speech recognition (ASR) systems due to speechdistortion. On the other hand, it was shown that self-supervised pre-trainingenables the utilization of a large amount of unlabeled noisy data, which israther beneficial for the noise robustness of ASR. However, the potential ofthe (optimal) integration of SE and self-supervised pre-training still remainsunclear. In order to find an appropriate combination and reduce the impact ofspeech distortion caused by SE, in this paper we therefore propose a jointpre-training approach for the SE module and the self-supervised model. First,in the pre-training phase the original noisy waveform or the waveform obtainedby SE is fed into the self-supervised model to learn the contextualrepresentation, where the quantified clean speech acts as the target. Second,we propose a dual-attention fusion method to fuse the features of noisy andenhanced speeches, which can compensate the information loss caused byseparately using individual modules. Due to the flexible exploitation ofclean/noisy/enhanced branches, the proposed method turns out to be ageneralization of some existing noise-robust ASR models, e.g., enhancedwav2vec2.0. Finally, experimental results on both synthetic and real noisydatasets show that the proposed joint training approach can improve the ASRperformance under various noisy settings, leading to a stronger noiserobustness.",Qiu-Shi Zhu,2022/5/26,2022/5/26
2206.02731v1,Robust and Fast Data-Driven Power System State Estimator Using Graph Neural Networks,http://arxiv.org/abs/2206.02731v1,"The power system state estimation (SE) algorithm estimates the complex busvoltages based on the available set of measurements. Because phasor measurementunits (PMUs) are becoming more widely employed in transmission power systems, afast SE solver capable of exploiting PMUs' high sample rates is required. Toaccomplish this, we present a method for training a model based on graph neuralnetworks (GNNs) to learn estimates from PMU voltage and current measurements,which, once it is trained, has a linear computational complexity with respectto the number of nodes in the power system. We propose an original GNNimplementation over the power system's factor graph to simplify theincorporation of various types and numbers of measurements both on power systembuses and branches. Furthermore, we augment the factor graph to improve therobustness of GNN predictions. Training and test examples were generated byrandomly sampling sets of power system measurements and annotated with theexact solutions of linear SE with PMUs. The numerical results demonstrate thatthe GNN model provides an accurate approximation of the SE solutions.Additionally, errors caused by PMU malfunctions or the communication failuresthat make the SE problem unobservable have a local effect and do notdeteriorate the results in the rest of the power system.",Ognjen Kundacina,2022/6/6,2022/6/6
hep-ph/9503208v3,CALCULATION OF THE D AND B MESON LIFETIMES AND THE UNITARITY TRIANGLE PARAMETERS,http://arxiv.org/abs/hep-ph/9503208v3,"Using the expansions of the heavy meson decay widths in the heavy quark massand QCD sum rules for estimates of corresponding matrix elements,\, wecalculate the $D^{\pm,o,s}$ and $B^{\pm,o,s}$ meson lifetimes. The results forD mesons are in a reasonable agreement with the data,\, while it is predicted:$[\Gamma (B_d)-\Gamma (B^\pm)]/\Gamma_B\se 4\%\,$ (and the lifetime differenceof the $B_d$ and $B_s$ mesons is even smaller);\,$[\Gamma(B_s^{short})-\Gamma(B_s^{long})]/{\ov \Gamma}(B_s)\se 8\%\,.$ The roleof the weak annihilation and Pauli interference contributions to the lifetimedifferences is described in detail. In the course of self-consistentcalculations the values of many parameters crucial for calculations withcharmed and beauty mesons are found. In particular,\, the quark pole massesare: $M_c\se 1.65\,GeV,\,\, M_b\se 5.04\,GeV\,,$ and the decay constants are:$f_D(M_c)\se 165\,MeV\,,\,\,f_B(M_b)\se 120\,MeV\,$. It is also shown that thenonfactorizable corrections to the $B-{\bar B}$ mixing are large,\,$B_B(M_b)\se (1-18\%)\,.$ The values of the unitarity triangle parameters arefound which are consistent with these results and the data available (exceptfor the NA31 result for the $\epsilon ^{\prime}/\epsilon$ which is too large):$|V_{cb}|\se 4.2\cdot 10^{-2}\,,\, |V_{td}|\se 1.3\cdot 10^{-2}\,,\,|V_{ub}/V_{cb}|\se 0.10\,,\, \{\,A\se 0.86\,,\,\,\rho \se -0.40\,,\,\, \eta \se0.20\,\}.$",V. Chernyak,1995/3/2,1995/3/28
1907.02202v1,SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering,http://arxiv.org/abs/1907.02202v1,"Sentiment analysis has various application scenarios in software engineering(SE), such as detecting developers' emotions in commit messages and identifyingtheir opinions on Q&A forums. However, commonly used out-of-the-box sentimentanalysis tools cannot obtain reliable results on SE tasks and themisunderstanding of technical jargon is demonstrated to be the main reason.Then, researchers have to utilize labeled SE-related texts to customizesentiment analysis for SE tasks via a variety of algorithms. However, thescarce labeled data can cover only very limited expressions and thus cannotguarantee the analysis quality. To address such a problem, we turn to theeasily available emoji usage data for help. More specifically, we employemotional emojis as noisy labels of sentiments and propose a representationlearning approach that uses both Tweets and GitHub posts containing emojis tolearn sentiment-aware representations for SE-related texts. These emoji-labeledposts can not only supply the technical jargon, but also incorporate moregeneral sentiment patterns shared across domains. They as well as labeled dataare used to learn the final sentiment classifier. Compared to the existingsentiment analysis methods used in SE, the proposed approach can achievesignificant improvement on representative benchmark datasets. By furthercontrast experiments, we find that the Tweets make a key contribution to thepower of our approach. This finding informs future research not to unilaterallypursue the domain-specific resource, but try to transform knowledge from theopen domain through ubiquitous signals such as emojis.",Zhenpeng Chen,2019/7/4,2019/7/4
2109.07434v1,Discriminative and Generative Transformer-based Models For Situation Entity Classification,http://arxiv.org/abs/2109.07434v1,"We re-examine the situation entity (SE) classification task with varyingamounts of available training data. We exploit a Transformer-based variationalautoencoder to encode sentences into a lower dimensional latent space, which isused to generate the text and learn a SE classifier. Test set and cross-genreevaluations show that when training data is plentiful, the proposed model canimprove over the previous discriminative state-of-the-art models. Our approachperforms disproportionately better with smaller amounts of training data, butwhen faced with extremely small sets (4 instances per label), generative RNNmethods outperform transformers. Our work provides guidance for future effortson SE and semantic prediction tasks, and low-label training regimes.",Mehdi Rezaee,2021/9/15,2021/9/15
1803.11466v1,Generating Functional Analysis of Iterative Sparse Signal Recovery Algorithms with Divergence-Free Estimators,http://arxiv.org/abs/1803.11466v1,"Approximate message passing (AMP) is an effective iterative sparse recoveryalgorithm for linear system models. Its performance is characterized by thestate evolution (SE) which is a simple scalar recursion. However, depending ona measurement matrix ensemble, AMP may face a convergence problem. To avoidthis problem, orthogonal AMP (OAMP), which uses de-correlation linearestimation and divergence-free non-linear estimation, was proposed by Ma andPing. They also provide the SE analysis for OAMP. In their SE analysis, thefollowing two assumptions were made: (i) The estimated vector of thede-correlation linear estimator consists of i.i.d. zero-mean Gaussian entriesindependent of the vector to be estimated and (ii) the estimated vector of thedivergence-free non-linear estimator consists of i.i.d. entries independent ofthe measurement matrix and the noise vector. In this paper, we derive a simplescalar recursion to characterize iterative sparse recovery algorithms withdivergence-free estimators without such assumptions of independence of messagesby using the generating functional analysis (GFA), which allows us to study thedynamics by an exact way in the large system limit.",Kazushi Mimura,2018/3/28,2018/3/28
1808.02911v1,A Case Study on the Impact of Similarity Measure on Information Retrieval based Software Engineering Tasks,http://arxiv.org/abs/1808.02911v1,"Information Retrieval (IR) plays a pivotal role in diverse SoftwareEngineering (SE) tasks, e.g., bug localization and triaging, code retrieval,requirements analysis, etc. The choice of similarity measure is the corecomponent of an IR technique. The performance of any IR method criticallydepends on selecting an appropriate similarity measure for the givenapplication domain. Since different SE tasks operate on different documenttypes like bug reports, software descriptions, source code, etc. that oftencontain non-standard domain-specific vocabulary, it is essential to understandwhich similarity measures work best for different SE documents.  This paper presents two case studies on the effect of different similaritymeasure on various SE documents w.r.t. two tasks: (i) project recommendation:finding similar GitHub projects and (ii) bug localization: retrieving buggysource file(s) correspond to a bug report. These tasks contain a diversecombination of textual (i.e. description, readme) and code (i.e. source code,API, import package) artifacts. We observe that the performance of IR modelsvaries when applied to different artifact types. We find that, in general, thecontext-aware models achieve better performance on textual artifacts. Incontrast, simple keyword-based bag-of-words models perform better on codeartifacts. On the other hand, the probabilistic ranking model BM25 performsbetter on a mixture of text and code artifacts.  We further investigate how such an informed choice of similarity measureimpacts the performance of SE tools. In particular, we analyze two previouslyproposed tools for project recommendation and bug localization tasks, whichleverage diverse software artifacts, and observe that an informed choice ofsimilarity measure indeed leads to improved performance of the existing SEtools.",Md Masudur Rahman,2018/8/8,2018/8/8
2311.18654v1,Detailed Human-Centric Text Description-Driven Large Scene Synthesis,http://arxiv.org/abs/2311.18654v1,"Text-driven large scene image synthesis has made significant progress withdiffusion models, but controlling it is challenging. While using additionalspatial controls with corresponding texts has improved the controllability oflarge scene synthesis, it is still challenging to faithfully reflect detailedtext descriptions without user-provided controls. Here, we proposeDetText2Scene, a novel text-driven large-scale image synthesis with highfaithfulness, controllability, and naturalness in a global context for thedetailed human-centric text description. Our DetText2Scene consists of 1)hierarchical keypoint-box layout generation from the detailed description byleveraging large language model (LLM), 2) view-wise conditioned joint diffusionprocess to synthesize a large scene from the given detailed text withLLM-generated grounded keypoint-box layout and 3) pixel perturbation-basedpyramidal interpolation to progressively refine the large scene for globalcoherence. Our DetText2Scene significantly outperforms prior arts intext-to-large scene synthesis qualitatively and quantitatively, demonstratingstrong faithfulness with detailed descriptions, superior controllability, andexcellent naturalness in a global context.",Gwanghyun Kim,2023/11/30,2023/11/30
2103.13154v1,Exploiting the Unique Expression for Improved Sentiment Analysis in Software Engineering Text,http://arxiv.org/abs/2103.13154v1,"Sentiment analysis on software engineering (SE) texts has been widely used inthe SE research, such as evaluating app reviews or analyzing developerssentiments in commit messages. To better support the use of automated sentimentanalysis for SE tasks, researchers built an SE-domain-specified sentimentdictionary to further improve the accuracy of the results. Unfortunately,recent work reported that current mainstream tools for sentiment analysis stillcannot provide reliable results when analyzing the sentiments in SE texts. Wesuggest that the reason for this situation is because the way of expressingsentiments in SE texts is largely different from the way in social network ormovie comments. In this paper, we propose to improve sentiment analysis in SEtexts by using sentence structures, a different perspective from building adomain dictionary. Specifically, we use sentence structures to first identifywhether the author is expressing her sentiment in a given clause of an SE text,and to further adjust the calculation of sentiments which are confirmed in theclause. An empirical evaluation based on four different datasets shows that ourapproach can outperform two dictionary-based baseline approaches, and is moregeneralizable compared to a learning-based baseline approach.",Kexin Sun,2021/3/24,2021/3/24
1708.09719v1,Lightweight Efficient Multi-keyword Ranked Search over Encrypted Cloud Data using Dual Word Embeddings,http://arxiv.org/abs/1708.09719v1,"Cloud computing is emerging as a revolutionary computing paradigm whichpro-vides a flexible and economic strategy for data management and resourcesharing. Security and privacy become major concerns in the cloud scenario, forwhich Searchable Encryption (SE) technology is proposed to support efficientretrieval of encrypted data. However, the absence of lightweight ranked searchis still a typical shortage in existing SE schemes. In this paper, we propose aLightweight Efficient Multi-keyword Ranked Search over Encrypted Cloud Datausing Dual Word Embeddings (LRSE) scheme that supports top-k retrieval in theknown background model. For the first time, we formulate the privacy issue anddesign goals for lightweight ranked search in SE. We employ word embeddingtrained on the whole English Wikipedia using word2vec to replace the generaldictionary, afterwards we make use of Dual Embedding Space Model (DESM) tosubstitute traditional Vector Space Model (VSM), based on which we achieve thegoal of lightweight ranked search with higher precision and solve thechallenging prob-lems caused by updating the traditional dictionary in existingSE schemes. In LRSE, we employ an improved secure kNN scheme to guaranteesufficient pri-vacy protection. Our security analysis shows that LRSE satisfiesour formulated privacy requirements and extensive experiments performed onreal-world datasets demonstrate that LRSE indeed accords with our proposeddesign goals.",Ruihui Zhao,2017/5/22,2017/5/22
2305.14045v2,The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning,http://arxiv.org/abs/2305.14045v2,"Language models (LMs) with less than 100B parameters are known to performpoorly on chain-of-thought (CoT) reasoning in contrast to large LMs whensolving unseen tasks. In this work, we aim to equip smaller LMs with thestep-by-step reasoning capability by instruction tuning with CoT rationales. Inorder to achieve this goal, we first introduce a new instruction-tuning datasetcalled the CoT Collection, which augments the existing Flan Collection(including only 9 CoT tasks) with additional 1.84 million rationales across1,060 tasks. We show that CoT fine-tuning Flan-T5 (3B & 11B) with CoTCollection enables smaller LMs to have better CoT capabilities on unseen tasks.On the BIG-Bench-Hard (BBH) benchmark, we report an average improvement of+4.34% (Flan-T5 3B) and +2.60% (Flan-T5 11B), in terms of zero-shot taskaccuracy. Furthermore, we show that instruction tuning with CoT Collectionallows LMs to possess stronger few-shot learning capabilities on 4domain-specific tasks, resulting in an improvement of +2.24% (Flan-T5 3B) and+2.37% (Flan-T5 11B), even outperforming ChatGPT utilizing demonstrations untilthe max length by a +13.98% margin. Our code, the CoT Collection data, andmodel checkpoints are publicly available.",Seungone Kim,2023/5/23,2023/10/14
2207.00837v1,UTD-Yolov5: A Real-time Underwater Targets Detection Method based on Attention Improved YOLOv5,http://arxiv.org/abs/2207.00837v1,"As the treasure house of nature, the ocean contains abundant resources. Butthe coral reefs, which are crucial to the sustainable development of marinelife, are facing a huge crisis because of the existence of COTS and otherorganisms. The protection of society through manual labor is limited andinefficient. The unpredictable nature of the marine environment also makesmanual operations risky. The use of robots for underwater operations has becomea trend. However, the underwater image acquisition has defects such as weaklight, low resolution, and many interferences, while the existing targetdetection algorithms are not effective. Based on this, we propose an underwatertarget detection algorithm based on Attention Improved YOLOv5, calledUTD-Yolov5. It can quickly and efficiently detect COTS, which in turn providesa prerequisite for complex underwater operations. We adjusted the originalnetwork architecture of YOLOv5 in multiple stages, including: replacing theoriginal Backbone with a two-stage cascaded CSP (CSP2); introducing the visualchannel attention mechanism module SE; designing random anchor box similaritycalculation method etc. These operations enable UTD-Yolov5 to detect moreflexibly and capture features more accurately. In order to make the networkmore efficient, we also propose optimization methods such as WBF and iterativerefinement mechanism. This paper conducts a lot of experiments based on theCSIRO dataset [1]. The results show that the average accuracy of our UTD-Yolov5reaches 78.54%, which is a great improvement compared to the baseline.",Jingyao Wang,2022/7/2,2022/7/2
2309.16621v1,Stress Testing Chain-of-Thought Prompting for Large Language Models,http://arxiv.org/abs/2309.16621v1,"This report examines the effectiveness of Chain-of-Thought (CoT) prompting inimproving the multi-step reasoning abilities of large language models (LLMs).Inspired by previous studies \cite{Min2022RethinkingWork}, we analyze theimpact of three types of CoT prompt perturbations, namely CoT order, CoTvalues, and CoT operators on the performance of GPT-3 on various tasks. Ourfindings show that incorrect CoT prompting leads to poor performance onaccuracy metrics. Correct values in the CoT is crucial for predicting correctanswers. Moreover, incorrect demonstrations, where the CoT operators or the CoTorder are wrong, do not affect the performance as drastically when compared tothe value based perturbations. This research deepens our understanding of CoTprompting and opens some new questions regarding the capability of LLMs tolearn reasoning in context.",Aayush Mishra,2023/9/28,2023/9/28
1204.2079v1,"A Theoretical and Empirical Evaluation of Software Component Search Engines, Semantic Search Engines and Google Search Engine in the Context of COTS-Based Development",http://arxiv.org/abs/1204.2079v1,"COTS-based development is a component reuse approach promising to reducecosts and risks, and ensure higher quality. The growing availability of COTScomponents on the Web has concretized the possibility of achieving theseobjectives. In this multitude, a recurrent problem is the identification of theCOTS components that best satisfy the user requirements. Finding an adequateCOTS component implies searching among heterogeneous descriptions of thecomponents within a broad search space. Thus, the use of search engines isrequired to make more efficient the COTS components identification. In thispaper, we investigate, theoretically and empirically, the COTS component searchperformance of eight software component search engines, nine semantic searchengines and a conventional search engine (Google). Our empirical evaluation isconducted with respect to precision and normalized recall. We defined tenqueries for the assessed search engines. These queries were carefully selectedto evaluate the capability of each search engine for handling COTS componentidentification.",Nacim Yanes,2012/4/10,2012/4/10
2212.10001v2,Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,http://arxiv.org/abs/2212.10001v2,"Chain-of-Thought (CoT) prompting can dramatically improve the multi-stepreasoning abilities of large language models (LLMs). CoT explicitly encouragesthe LLM to generate intermediate rationales for solving a problem, by providinga series of reasoning steps in the demonstrations. Despite its success, thereis still little understanding of what makes CoT prompting effective and whichaspects of the demonstrated reasoning steps contribute to its performance. Inthis paper, we show that CoT reasoning is possible even with invaliddemonstrations - prompting with invalid reasoning steps can achieve over 80-90%of the performance obtained using CoT under various metrics, while stillgenerating coherent lines of reasoning during inference. Further experimentsshow that other aspects of the rationales, such as being relevant to the queryand correctly ordering the reasoning steps, are much more important foreffective CoT reasoning. Overall, these findings both deepen our understandingof CoT prompting, and open up new questions regarding LLMs' capability to learnto reason in context.",Boshi Wang,2022/12/20,2023/6/1
2309.11054v2,Design of Chain-of-Thought in Math Problem Solving,http://arxiv.org/abs/2309.11054v2,"Chain-of-Thought (CoT) plays a crucial role in reasoning for math problemsolving. We conduct a comprehensive examination of methods for designing CoT,comparing conventional natural language CoT with various program CoTs,including the self-describing program, the comment-describing program, and thenon-describing program. Furthermore, we investigate the impact of programminglanguage on program CoTs, comparing Python and Wolfram Language. Throughextensive experiments on GSM8K, MATHQA, and SVAMP, we find that program CoTsoften have superior effectiveness in math problem solving. Notably, the bestperforming combination with 30B parameters beats GPT-3.5-turbo by a significantmargin. The results show that self-describing program offers greater diversityand thus can generally achieve higher performance. We also find that Python isa better choice of language than Wolfram for program CoTs. The experimentalresults provide a valuable guideline for future CoT designs that take intoaccount both programming language and coding style for further advancements.Our datasets and code are publicly available.",Zhanming Jie,2023/9/20,2023/9/30
2310.06692v2,Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models,http://arxiv.org/abs/2310.06692v2,"Large language models (LLMs) have unveiled remarkable reasoning capabilitiesby exploiting chain-of-thought (CoT) prompting, which generates intermediatereasoning chains to serve as the rationale for deriving the answer. However,current CoT methods either simply employ general prompts such as Let's thinkstep by step, or heavily rely on handcrafted task-specific demonstrations toattain preferable performances, thereby engendering an inescapable gap betweenperformance and generalization. To bridge this gap, we propose Meta-CoT, ageneralizable CoT prompting method in mixed-task scenarios where the type ofinput questions is unknown. Meta-CoT firstly categorizes the scenario based onthe input question and subsequently constructs diverse demonstrations from thecorresponding data pool in an automatic pattern. Meta-CoT simultaneously enjoysremarkable performances on ten public benchmark reasoning tasks and superiorgeneralization capabilities. Notably, Meta-CoT achieves the state-of-the-artresult on SVAMP (93.7%) without any additional program-aided methods. Ourfurther experiments on five out-of-distribution datasets verify the stabilityand generality of Meta-CoT.",Anni Zou,2023/10/10,2023/10/11
2310.19750v1,Chain-of-Thought Embeddings for Stance Detection on Social Media,http://arxiv.org/abs/2310.19750v1,"Stance detection on social media is challenging for Large Language Models(LLMs), as emerging slang and colloquial language in online conversations oftencontain deeply implicit stance labels. Chain-of-Thought (COT) prompting hasrecently been shown to improve performance on stance detection tasks --alleviating some of these issues. However, COT prompting still struggles withimplicit stance identification. This challenge arises because many samples areinitially challenging to comprehend before a model becomes familiar with theslang and evolving knowledge related to different topics, all of which need tobe acquired through the training data. In this study, we address this problemby introducing COT Embeddings which improve COT performance on stance detectiontasks by embedding COT reasonings and integrating them into a traditionalRoBERTa-based stance detection pipeline. Our analysis demonstrates that 1) textencoders can leverage COT reasonings with minor errors or hallucinations thatwould otherwise distort the COT output label. 2) Text encoders can overlookmisleading COT reasoning when a sample's prediction heavily depends ondomain-specific patterns. Our model achieves SOTA performance on multiplestance detection datasets collected from social media.",Joseph Gatto,2023/10/30,2023/10/30
2305.18869v2,Dissecting Chain-of-Thought: Compositionality through In-Context Filtering and Learning,http://arxiv.org/abs/2305.18869v2,"Chain-of-thought (CoT) is a method that enables language models to handlecomplex reasoning tasks by decomposing them into simpler steps. Despite itssuccess, the underlying mechanics of CoT are not yet fully understood. In anattempt to shed light on this, our study investigates the impact of CoT on theability of transformers to in-context learn a simple to study, yet generalfamily of compositional functions: multi-layer perceptrons (MLPs). In thissetting, we find that the success of CoT can be attributed to breaking downin-context learning of a compositional function into two distinct phases:focusing on and filtering data related to each step of the composition andin-context learning the single-step composition function. Through bothexperimental and theoretical evidence, we demonstrate how CoT significantlyreduces the sample complexity of in-context learning (ICL) and facilitates thelearning of complex functions that non-CoT methods struggle with. Furthermore,we illustrate how transformers can transition from vanilla in-context learningto mastering a compositional function with CoT by simply incorporatingadditional layers that perform the necessary data-filtering for CoT via theattention mechanism. In addition to these test-time benefits, we show CoT helpsaccelerate pretraining by learning shortcuts to represent complex functions andfiltering plays an important role in this process. These findings collectivelyprovide insights into the mechanics of CoT, inviting further investigation ofits role in complex reasoning tasks.",Yingcong Li,2023/5/30,2023/11/8
2308.13259v2,Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering,http://arxiv.org/abs/2308.13259v2,"Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shownimpressive reasoning ability in various downstream tasks. Even so, sufferingfrom hallucinations and the inability to access external knowledge, LLMs oftencome with incorrect or unfaithful intermediate reasoning steps, especially inthe context of answering knowledge-intensive tasks such as KBQA. To alleviatethis issue, we propose a framework called Knowledge-Driven Chain-of-Thought(KD-CoT) to verify and modify reasoning traces in CoT via interaction withexternal knowledge, and thus overcome the hallucinations and error propagation.Concretely, we formulate the CoT rationale process of LLMs into a structuredmulti-round QA format. In each round, LLMs interact with a QA system thatretrieves external knowledge and produce faithful reasoning traces based onretrieved precise answers. The structured CoT reasoning of LLMs is facilitatedby our developed KBQA CoT collection, which serves as in-context learningdemonstrations and can also be utilized as feedback augmentation to train arobust retriever. Extensive experiments on WebQSP and ComplexWebQuestiondatasets demonstrate the effectiveness of proposed KD-CoT in task-solvingreasoning generation, which outperforms the vanilla CoT ICL with an absolutesuccess rate of 8.0% and 5.1%. Furthermore, our proposed feedback-augmentedretriever outperforms the state-of-the-art baselines for retrieving knowledge,achieving significant improvement in Hit and recall performance. Our code anddata are released on https://github.com/AdelWang/KD-CoT/tree/main.",Keheng Wang,2023/8/25,2023/10/28
2401.12863v1,KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning,http://arxiv.org/abs/2401.12863v1,"Large Language Models (LLMs) have demonstrated impressive performance innatural language processing tasks by leveraging chain of thought (CoT) thatenables step-by-step thinking. Extending LLMs with multimodal capabilities isthe recent interest, but incurs computational cost and requires substantialhardware resources. To address these challenges, we propose KAM-CoT a frameworkthat integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalitiesfor a comprehensive understanding of multimodal tasks. KAM-CoT adopts atwo-stage training process with KG grounding to generate effective rationalesand answers. By incorporating external knowledge from KGs during reasoning, themodel gains a deeper contextual understanding reducing hallucinations andenhancing the quality of answers. This knowledge-augmented CoT reasoningempowers the model to handle questions requiring external context, providingmore informed answers. Experimental findings show KAM-CoT outperforms thestate-of-the-art methods. On the ScienceQA dataset, we achieve an averageaccuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by10%. Remarkably, KAM-CoT achieves these results with only 280M trainableparameters at a time, demonstrating its cost-efficiency and effectiveness.",Debjyoti Mondal,2024/1/23,2024/1/23
2302.12822v1,Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data,http://arxiv.org/abs/2302.12822v1,"Chain-of-thought prompting (CoT) advances the reasoning abilities of largelanguage models (LLMs) and achieves superior performance in arithmetic,commonsense, and symbolic reasoning tasks. However, most CoT studies rely oncarefully designed human-annotated rational chains to prompt the languagemodel, which poses challenges for real-world applications where labeledtraining data is available without human-annotated rational chains. Thiscreates barriers to applications of CoT prompting to these general tasks. Thispaper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation andSelection with Chain-of-Thought), that can bypass human engineering of CoTs byautomatically augmenting rational chains from a small labeled dataset, and thenpruning low-quality chains to construct a candidate pool of machine-generatedrationale chains based on the labels. Finally, it selects the optimalcombination of several rationale chains from the pool for CoT prompting byemploying a variance-reduced policy gradient strategy to estimate thesignificance of each example in a black-box language model. Automate-CoTenables a quick adaptation of the CoT technique to different tasks.Experimental results demonstrate the effectiveness of our method, wherestate-of-the-art results are achieved on arithmetic reasoning (+2.7\%),commonsense reasoning (+3.4\%), symbolic reasoning (+3.2\%), and non-reasoningtasks (+2.5\%). Our code will be available athttps://github.com/shizhediao/automate-cot.",KaShun Shum,2023/2/24,2023/2/24
2307.13702v1,Measuring Faithfulness in Chain-of-Thought Reasoning,http://arxiv.org/abs/2307.13702v1,"Large language models (LLMs) perform better when they produce step-by-step,""Chain-of-Thought"" (CoT) reasoning before answering a question, but it isunclear if the stated reasoning is a faithful explanation of the model's actualreasoning (i.e., its process for answering the question). We investigatehypotheses for how CoT reasoning may be unfaithful, by examining how the modelpredictions change when we intervene on the CoT (e.g., by adding mistakes orparaphrasing it). Models show large variation across tasks in how strongly theycondition on the CoT when predicting their answer, sometimes relying heavily onthe CoT and other times primarily ignoring it. CoT's performance boost does notseem to come from CoT's added test-time compute alone or from informationencoded via the particular phrasing of the CoT. As models become larger andmore capable, they produce less faithful reasoning on most tasks we study.Overall, our results suggest that CoT can be faithful if the circumstances suchas the model size and task are carefully chosen.",Tamera Lanham,2023/7/17,2023/7/17
2305.16896v1,MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,http://arxiv.org/abs/2305.16896v1,"Large language models (LLMs) have achieved impressive performance on variousreasoning tasks. To further improve the performance, we propose MultiTool-CoT,a novel framework that leverages chain-of-thought (CoT) prompting toincorporate multiple external tools, such as a calculator and a knowledgeretriever, during the reasoning process. We apply MultiTool-CoT to the Task 2dataset of NumGLUE, which requires both numerical reasoning and domain-specificknowledge. The experiments show that our method significantly outperformsstrong baselines and achieves state-of-the-art performance.",Tatsuro Inaba,2023/5/26,2023/5/26
2307.08922v1,Large Language Models Perform Diagnostic Reasoning,http://arxiv.org/abs/2307.08922v1,"We explore the extension of chain-of-thought (CoT) prompting to medicalreasoning for the task of automatic diagnosis. Motivated by doctors' underlyingreasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empiricalresults demonstrate that by simply prompting large language models trained onlyon general text corpus with two DR-CoT exemplars, the diagnostic accuracyimproves by 15% comparing to standard prompting. Moreover, the gap reaches apronounced 18% in out-domain settings. Our findings suggest expert-knowledgereasoning in large language models can be elicited through proper promptings.",Cheng-Kuang Wu,2023/7/18,2023/7/18
2212.00193v2,Distilling Reasoning Capabilities into Smaller Language Models,http://arxiv.org/abs/2212.00193v2,"Step-by-step reasoning approaches like chain of thought (CoT) have proved tobe very effective in inducing reasoning capabilities in large language models.However, the success of the CoT approach is fundamentally tied to the modelsize, and billion parameter-scale models are often needed to get CoT to work.In this paper, we propose a knowledge distillation approach that leverages thestep-by-step CoT reasoning capabilities of larger models and distills theseabilities into smaller models.  In this work, we propose an alternative reasoning scheme, Socratic CoT, thatlearns a decomposition of the original problem into a sequence of subproblemsand uses it to guide the intermediate reasoning steps. We use Socratic CoT totrain a combination of two small distilled models: a problem decomposer and asubproblem solver. In practice, given a new problem, the two distilled modelswork in sync to decompose and solve complex problems. On multiple reasoningdatasets (GSM8K, StrategyQA, and SVAMP), our proposed distillation strategiesboosts the performance of smaller models over 70% compared to the baselines.Finally, we investigate when Socratic CoT is an effective alternative to CoT,demonstrating cases where a much smaller model (GPT-2 large) can outperform a10X larger model (GPT-3 6B). Our code is available here:https://github.com/kumar-shridhar/Distiiling-LM",Kumar Shridhar,2022/12/1,2023/5/18
2305.04388v2,Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,http://arxiv.org/abs/2305.04388v2,"Large Language Models (LLMs) can achieve strong performance on many tasks byproducing step-by-step reasoning before giving a final output, often referredto as chain-of-thought reasoning (CoT). It is tempting to interpret these CoTexplanations as the LLM's process for solving a task. This level oftransparency into LLMs' predictions would yield significant safety benefits.However, we find that CoT explanations can systematically misrepresent the truereason for a model's prediction. We demonstrate that CoT explanations can beheavily influenced by adding biasing features to model inputs--e.g., byreordering the multiple-choice options in a few-shot prompt to make the answeralways ""(A)""--which models systematically fail to mention in theirexplanations. When we bias models toward incorrect answers, they frequentlygenerate CoT explanations rationalizing those answers. This causes accuracy todrop by as much as 36% on a suite of 13 tasks from BIG-Bench Hard, when testingwith GPT-3.5 from OpenAI and Claude 1.0 from Anthropic. On a social-bias task,model explanations justify giving answers in line with stereotypes withoutmentioning the influence of these social biases. Our findings indicate that CoTexplanations can be plausible yet misleading, which risks increasing our trustin LLMs without guaranteeing their safety. Building more transparent andexplainable systems will require either improving CoT faithfulness throughtargeted efforts or abandoning CoT in favor of alternative methods.",Miles Turpin,2023/5/7,2023/12/9
2312.08901v2,Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning,http://arxiv.org/abs/2312.08901v2,"Large language models (LLMs) have shown impressive capabilities in varioustasks, yet they still struggle with math reasoning. Despite efforts to optimizeChain-of-Thoughts (CoT) prompts and fine-tune LLMs, the potential of few-shotlearning remains unexplored. In this work, we propose CoT-Influx, a novelapproach pushing the boundaries of few-shot CoT learning to improve LLM mathreasoning capabilities. CoT-Influx addresses the challenges of the selection ofuseful examples and limited number of examples due to restricted context windowlength. Inspired by our observation that natural language inputs contain manyredundancy, we propose a coarse-to-fine pruner as a plug-and-play module forLLMs, which first identifies as many crucial CoT examples as possible and thenfurther prunes unimportant tokens within the context window. To train thepruner, we collect a math reasoning dataset with diverse difficulty and steps,introduce a reward to measure both the input's effectiveness for math reasoningand token length constraints, and propose a novel training approach withreinforcement learning. As a result, CoT-Influx significantly outperforms CoTand few-shot prompting baselines across various LLMs (LLaMA2-7B, 13B, 70B) and5 mathematical datasets, achieving up to 4.55% absolute improvements.Remarkably, without any fine-tuning, LLaMA2-70B with CoT-Influx surpassesGPT-3.5 and a wide range of larger LLMs (PaLM, Minerva, etc.) on the GSM8K.",Xijie Huang,2023/12/14,2023/12/26
2209.13770v1,Unusual electric polarization behavior in elemental quasi-2D allotropes of selenium,http://arxiv.org/abs/2209.13770v1,"We investigate tunable electric polarization and electronic structure ofquasi-two-dimensional (quasi-2D) allotropes of selenium, which are formed fromtheir constituent one-dimensional (1D) structures through an inter-chaininteraction facilitated by the multi-valence nature of Se. Our em ab initiocalculations reveal that different quasi-2D Se allotropes display differenttypes of electric polarization, including ferroelectric (FE) polarizationnormal to the chain direction in alpha and delta allotropes, non-collinearferrielectric (FiE) polarization along the chain axis in tau-Se, andanti-ferroelectric (AFE) polarization in eta-Se. The magnitude and direction ofthe polarization can be changed by a previously unexplored rotation of theconstituent chains. In that case, an in-plane polarization direction may changeto out-of-plane in alpha-Se and delta-Se, flip its direction, and evendisappear in tau-Se. Also, the band gap may be reduced and changed fromindirect to direct by rotating the constituent chains about their axes in thesequasi-2D Se allotropes.",Dan Liu,2022/9/28,2022/9/28
2306.14050v1,"Symbolic Chain-of-Thought Distillation: Small Models Can Also ""Think"" Step-by-Step",http://arxiv.org/abs/2306.14050v1,"Chain-of-thought prompting (e.g., ""Let's think step-by-step"") primes largelanguage models to verbalize rationalization for their predictions. Whilechain-of-thought can lead to dramatic performance gains, benefits appear toemerge only for sufficiently large models (beyond 50B parameters). We show thatorders-of-magnitude smaller models (125M -- 1.3B parameters) can still benefitfrom chain-of-thought prompting. To achieve this, we introduce SymbolicChain-of-Thought Distillation (SCoTD), a method to train a smaller studentmodel on rationalizations sampled from a significantly larger teacher model.Experiments across several commonsense benchmarks show that: 1) SCoTD enhancesthe performance of the student model in both supervised and few-shot settings,and especially for challenge sets; 2) sampling many reasoning chains perinstance from the teacher is paramount; and 3) after distillation, studentchain-of-thoughts are judged by humans as comparable to the teacher, despiteorders of magnitude fewer parameters. We test several hypotheses regarding whatproperties of chain-of-thought samples are important, e.g., diversity vs.teacher likelihood vs. open-endedness. We release our corpus ofchain-of-thought samples and code.",Liunian Harold Li,2023/6/24,2023/6/24
2311.09277v1,Contrastive Chain-of-Thought Prompting,http://arxiv.org/abs/2311.09277v1,"Despite the success of chain of thought in enhancing language modelreasoning, the underlying process remains less well understood. Althoughlogically sound reasoning appears inherently crucial for chain of thought,prior studies surprisingly reveal minimal impact when using invaliddemonstrations instead. Furthermore, the conventional chain of thought does notinform language models on what mistakes to avoid, which potentially leads tomore errors. Hence, inspired by how humans can learn from both positive andnegative examples, we propose contrastive chain of thought to enhance languagemodel reasoning. Compared to the conventional chain of thought, our approachprovides both valid and invalid reasoning demonstrations, to guide the model toreason step-by-step while reducing reasoning mistakes. To improvegeneralization, we introduce an automatic method to construct contrastivedemonstrations. Our experiments on reasoning benchmarks demonstrate thatcontrastive chain of thought can serve as a general enhancement ofchain-of-thought prompting.",Yew Ken Chia,2023/11/15,2023/11/15
2304.06266v2,Effect of Graphene Interface on Potassiation in a Graphene- Selenium Heterostructure Cathode for Potassium-ion Batteries,http://arxiv.org/abs/2304.06266v2,"Selenium (Se) cathodes are an exciting emerging high energy density storagesystem for Potassium ion batteries(KIB), where potassiation reactions are lessunderstood. Here, we present an atomic-level investigation of KxSe cathodeenclosed in hexagonal lattices of carbon(C) characteristic of multilayeredgraphene matrix and multiwalled carbon nanotubes (MW-CNTs). Microstructuralchanges directed by graphene substrate in KxSe cathode are contrasted withgraphene-free cathode. Graphene's binding affinity for long-chain polyselenides(Se-Se-Se = -2.82 eV and Se-Se = -2.646 eV) and ability to induce reactivitybetween Se and K are investigated. Furthermore, intercalation voltage forgraphene enclosed KxSe cathode reaction intermediates are calculated with K2Seas the final discharged product. Our results indicate a single-step reactionnear a voltage of 1.55 V between K and Se cathode. Our findings suggest thatoperating at higher voltages (~2V) could result in the formation of reactionintermediates where intercalation/deintercalation of K could be a challenge,and therefore cause irreversible capacity losses in the battery. Primary issuesare the high binding energy of long-chain polyselenides with graphene thatdiscourage K storage and Se-Se bond dissociation at low K concentrations. Acomparison with graphene-free cathode highlights the substantial changes a vander Waals (vdW) graphene interface can bring in atomic-structure andelectrochemistry of the KxSe cathode.",Vidushi Sharma,2023/4/13,2023/7/31
1601.00603v1,Anion-Anion Bonding and the Topology in Ternary Iridium Seleno-Stannides,http://arxiv.org/abs/1601.00603v1,"The synthesis and physical properties of two new and one known Ir-Sn-Secompound are reported. Their crystal structures are elucidated withtransmission electron microscopy and powder X-ray diffraction. IrSn0.45Se1.55is a pyrite phase which consists of tilted corner-sharing IrX6 octahedra withrandomly distributed (Sn-Se)4- and (Se-Se)2- dimers. Ir2Sn3Se3 is a trigonallydistorted skutterudite that consists of cooperatively tilted corner-sharingIrSn3Se3 octahedra with ordered (Sn-Se)24- tetramers. Ir2SnSe5 is a layered,distorted \b{eta}-MnO2 (pyrolusite) structure consisting of a double IrSe6octrahedral row, corner-sharing in the a direction and edge-sharing in the bdirection. This distorted pyrolusite contains (Se-Se)2- dimers, Se2- anions,and each double row is ""capped"" with a (Sn-Se)n polymeric chain. Resistivity,specific heat, and magnetization measurements show that all three haveinsulating and diamagnetic behavior, indicative of low spin 5d6 Ir3+.Electronic structure calculations on Ir2Sn3Se3 show a single, spherical,non-spin-orbit split valence band, and suggest that Ir2Sn3Se3 is topologicallynon-trivial under tensile strain, due to inversion of Ir-d and Se-p states.",Benjamin A. Trump,2016/1/4,2016/1/4
2201.11903v6,Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,http://arxiv.org/abs/2201.11903v6,"We explore how generating a chain of thought -- a series of intermediatereasoning steps -- significantly improves the ability of large language modelsto perform complex reasoning. In particular, we show how such reasoningabilities emerge naturally in sufficiently large language models via a simplemethod called chain of thought prompting, where a few chain of thoughtdemonstrations are provided as exemplars in prompting. Experiments on threelarge language models show that chain of thought prompting improves performanceon a range of arithmetic, commonsense, and symbolic reasoning tasks. Theempirical gains can be striking. For instance, prompting a 540B-parameterlanguage model with just eight chain of thought exemplars achieves state of theart accuracy on the GSM8K benchmark of math word problems, surpassing evenfinetuned GPT-3 with a verifier.",Jason Wei,2022/1/28,2023/1/10
2311.01460v1,Implicit Chain of Thought Reasoning via Knowledge Distillation,http://arxiv.org/abs/2311.01460v1,"To augment language models with the ability to reason, researchers usuallyprompt or finetune them to produce chain of thought reasoning steps beforeproducing the final answer. However, although people use natural language toreason effectively, it may be that LMs could reason more effectively with someintermediate computation that is not in natural language. In this work, weexplore an alternative reasoning approach: instead of explicitly producing thechain of thought reasoning steps, we use the language model's internal hiddenstates to perform implicit reasoning. The implicit reasoning steps aredistilled from a teacher model trained on explicit chain-of-thought reasoning,and instead of doing reasoning ""horizontally"" by producing intermediate wordsone-by-one, we distill it such that the reasoning happens ""vertically"" amongthe hidden states in different layers. We conduct experiments on a multi-digitmultiplication task and a grade school math problem dataset and find that thisapproach enables solving tasks previously not solvable without explicitchain-of-thought, at a speed comparable to no chain-of-thought.",Yuntian Deng,2023/11/2,2023/11/2
cond-mat/0401556v1,Photo-induced volume changes in selenium. Tight-binding molecular dynamics study,http://arxiv.org/abs/cond-mat/0401556v1,Tight-binding molecular dynamics simulations of photo-excitations in small Seclusters (isolated Se$_8$ ring and helical Se chain) and glassy Se networks(containing 162 atoms) were carried out in order to analyse the photo inducedinstability inside the amorphous selenium. In the cluster systems after takingan electron from the highest occupied molecular orbital to the lowestunoccupied molecular orbital a bond breaking occurs. In the glassy networksphotoinduced volume expansion was observed and at the same time the number ofcoordination defects changed significantly due to illumination.,J. Hegedus,2004/1/27,2004/1/27
2305.16582v1,"Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models",http://arxiv.org/abs/2305.16582v1,"With the widespread use of large language models (LLMs) in NLP tasks,researchers have discovered the potential of Chain-of-thought (CoT) to assistLLMs in accomplishing complex reasoning tasks by generating intermediate steps.However, human thought processes are often non-linear, rather than simplysequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT)reasoning, which models human thought processes not only as a chain but also asa graph. By representing thought units as nodes and connections between them asedges, our approach captures the non-sequential nature of human thinking andallows for a more realistic modeling of thought processes. Similar toMultimodal-CoT, we modeled GoT reasoning as a two-stage framework, generatingrationales first and then producing the final answer. Specifically, we employan additional graph-of-thoughts encoder for GoT representation learning andfuse the GoT representation with the original input representation through agated fusion mechanism. We implement a GoT reasoning model on the T5pre-trained model and evaluate its performance on a text-only reasoning task(GSM8K) and a multimodal reasoning task (ScienceQA). Our model achievessignificant improvement over the strong CoT baseline with 3.41% and 5.08% onthe GSM8K test set with T5-base and T5-large architectures, respectively.Additionally, our model boosts accuracy from 84.91% to 91.54% using the T5-basemodel and from 91.68% to 92.77% using the T5-large model over thestate-of-the-art Multimodal-CoT on the ScienceQA test set. Experiments haveshown that GoT achieves comparable results to Multimodal-CoT(large) with over700M parameters, despite having fewer than 250M backbone model parameters,demonstrating the effectiveness of GoT.",Yao Yao,2023/5/26,2023/5/26
2112.02482v2,Non-Trivial Oblique Spin Equilibria of Super-Earths in Multi-planetary Systems,http://arxiv.org/abs/2112.02482v2,"Many Sun-like stars are observed to host close-in super-Earths (SEs) as partof a multi-planetary system. In such a system, the spin of the SE evolves dueto spin-orbit resonances and tidal dissipation. In the absence of tides, theplanet's obliquity can evolve chaotically to large values. However, forclose-in SEs, tidal dissipation is significant and suppresses the chaos,instead driving the spin into various steady states. We find that theattracting steady states of the SE's spin are more numerous than previouslythought, due to the discovery of a new class of ""mixed-mode"" high-obliquityequilibria. These new equilibria arise due to subharmonic responses of theparametrically-driven planetary spin, an unusual phenomenon that arises innonlinear systems. Many SEs should therefore have significant obliquities, withpotentially large impacts on the physical conditions of their surfaces andatmospheres.",Yubo Su,2021/12/5,2022/10/17
2309.11749v1,Zigzag chain order of LiVSe$_2$ developing away from the vanadium trimer phase transition boundary,http://arxiv.org/abs/2309.11749v1,"The phenomenon of self-assembly of constituent elements to form molecules atlow temperatures appears ubiquitously in transition metal compounds withorbital degrees of freedom. Recent progress in local structure studies usingsynchrotron radiation x-rays is shifting the interest in structural studies insuch molecule-forming systems from the low-temperature ordered phase to theshort-range order that appears like a precursor at high temperatures. In thisstudy, we discuss both experimentally and theoretically the relationshipbetween the trimer structure that appears in the layered LiV$X_2$ ($X$ = O, S,Se) system with a two-dimensional triangular lattice of vanadium and the zigzagchain-like local structure that appears near the phase transition boundarywhere molecular formation occurs. The vanadium trimerization that persistentlyappears in both low-temperature phases of LiVO$_2$ and LiVS$_2$ disappears inLiVSe$_2$, and a regular triangular lattice is thought to be realized inLiVSe$_2$, but this study reveals that the zigzag chain local distortionappears with a finite correlation length. This zigzag chain state localdistortions are similar to the motif of local distortions in thehigh-temperature phase of LiVS$_2$, indicating that the local distortions arepersistent away from the trimer phase transition boundary. On the other hand,it is concluded that the zigzag chain order appearing in LiVSe$_2$ is morestable than that in LiVS$_2$ in terms of the temperature variation of atomicdisplacement and correlation length. The zigzag chain order is considered to becompetitive with the trimer order appearing in the LiV$X_2$ system. In thispaper, we discuss the similarities and differences between the parameters thatstabilize these electronic phases and the local distortions that appear inother molecular formation systems.",K. Kojima,2023/9/21,2023/9/21
1605.03553v1,Increasing cognitive-emotional flexibility with meditation and hypnosis: The cognitive neuroscience of de-automatization,http://arxiv.org/abs/1605.03553v1,"Meditation and hypnosis both aim to facilitate cognitive-emotionalflexibility, i.e., the ""de-automatization"" of thought and behavior. However,little research or theory has addressed how internal thought patterns mightchange after such interventions, even though alterations in the internal flowof consciousness may precede externally observable changes in behavior. Thischapter outlines three mechanisms by which meditation or hypnosis might alteror reduce automatic associations and elaborations of spontaneous thought: by anoverall reduction of the chaining of thoughts into an associative stream; byde-automatizing and diversifying the content of thought chains (i.e.,increasing thought flexibility or variety); and, finally, by re-automatizingchains of thought along desired or valued paths (i.e., forming new, voluntarilychosen mental habits). The authors discuss behavioral and cognitiveneuroscientific evidence demonstrating the influence of hypnosis and meditationon internal cognition and highlight the putative neurobiological basis, as wellas potential benefits, of these forms of de-automatization.",Kieran C. R. Fox,2016/5/11,2016/5/11
2304.09364v3,Optoelectronic manifestation of orbital angular momentum driven by chiral hopping in helical Se chains,http://arxiv.org/abs/2304.09364v3,"Chiral materials have garnered significant attention in the field ofcondensed matter physics. Nevertheless, the magnetic moment induced by thechiral spatial motion of electrons in helical materials, such as elemental Teand Se, remains inadequately understood. In this work, we investigate thedevelopment of quantum angular momentum enforced by chirality using static andtime-dependent density functional theory calculations for an elemental Sechain. Our findings reveal the emergence of an unconventional orbital texturedriven by the chiral geometry, giving rise to a non-vanishing current-inducedorbital moment. By incorporating spin-orbit coupling, we demonstrate that acurrent-induced spin accumulation arises in the chiral chain, whichfundamentally differs from the conventional Edelstein effect. Furthermore, wedemonstrate the optoelectronic detection of the orbital angular momentum in thechiral Se chain, providing a conceptually novel alternative to the interbandBerry curvature, which is ill-defined in low dimensions.",Bumseop Kim,2023/4/19,2023/10/4
quant-ph/0611258v1,Generando entrelazamiento en cadenas XY - (Generating entanglement in XY chains),http://arxiv.org/abs/quant-ph/0611258v1,"Se estudia en este trabajo la capacidad de generar entrelazamiento de unacadena de espines con acoplamiento de Heisenberg XY y un campo magneticouniforme a partir de un estado inicial en el que los espines estancompletamente alineados. Se encuentra que la capacidad de generar estadosentrelazados no muestra un comportamiento monotono con el campo presentando, encambio, plateaus y resonancias. Tambien se muestra que, a pesar de que laanisotropia es necesaria para que se generen estados entrelazados, una mayoranisotropia no implica necesariamente mejores condiciones para generarentrelazamiento que sirva para usarse en una computadora cuantica. Inclusive,se observa que, se genera una cantidad finita de entrelazamiento en el limitede pequena anisotropia.  (The maximum entanglement reached by an initially fully aligned stateevolving in a XY Heisenberg spin chain placed in a uniform transverse magneticfield is studied. It is shown that the capacity to create entangled states(both of one qubit with the rest of the chain and pairwise between two adjacentqubits) is not a monotonous function of the magnetic field: it presentsplateaus and resonances. It is also shown that, though anisotropy in theinteraction is necessary for entanglement generation, the best conditions forgenerating entanglement that may be suitable for use in quantum computation isnot that of biggest anisotropy. Moreover finite amounts of entanglement aregenerated in the small anisotropy limit.)",C. T. Schmiegelow,2006/11/27,2006/11/27
2004.05848v1,"Topological magnetic line defects in Fe(Te,Se) high-temperature superconductors",http://arxiv.org/abs/2004.05848v1,"Magnetic impurity chains on top of conventional superconductors are promisingplatforms to realize Majorana modes. Iron-based high-temperaturesuperconductors are known in the vicinity of magnetic states due to the strongHund's coupling in iron atoms. Here we propose that the line defects withmissing Te/Se anions in Fe(Se,Te) superconductors provide the realization ofintrinsic antiferromagnetic(AFM) chains with Rashba spin-orbit coupling.Against conventional wisdom, Majorana zero modes (MZMs) can be robustlygenerated at these AFM chain ends. These results can consistently explain therecent experimental observation of zero-energy end states in line defects ofmonolayer Fe(Te,Se)/SrTiO$_3$ by scanning tunneling microscopy (STM)measurements. Our research not only demonstrates an unprecedented interplayamong native line defect, emergent magnetism and topological superconductivitybut also explores a high-temperature platform for Majorana fermions.",Xianxin Wu,2020/4/13,2020/4/13
0807.2958v1,Negative Compressibility of Single Selenium Chain Confined in Zeolite Pore,http://arxiv.org/abs/0807.2958v1,"Pressure induced structural and electronic transitions of Se helical chainsconfined inside nano-channels are studied. Raman scattering and opticalabsorption experiments show strong evidence of band gap reduction under highpressure. Ab initio calculations reveal that under hydrostatic compression, theSe chains should elongate and the change in morphology leads to a softening ofphonons and narrowing of band gaps, and these signatures are observed inexperiments. Our investigation demonstrates a negative compressibility in onedimension.",Wei Ren,2008/7/18,2008/7/18
1305.3959v1,Spectral Efficiency and Energy Efficiency of OFDM Systems: Impact of Power Amplifiers and Countermeasures,http://arxiv.org/abs/1305.3959v1,"In wireless communication systems, the nonlinear effect and inefficiency ofpower amplifier (PA) have posed practical challenges for system designs toachieve high spectral efficiency (SE) and energy efficiency (EE). In thispaper, we analyze the impact of PA on the SE-EE tradeoff of orthogonalfrequency division multiplex (OFDM) systems. An ideal PA that is always linearand incurs no additional power consumption can be shown to yield a decreasingconvex function in the SE-EE tradeoff. In contrast, we show that a practical PAhas an SE-EE tradeoff that has a turning point and decreases sharply after itsmaximum EE point. In other words, the Pareto-optimal tradeoff boundary of theSE-EE curve is very narrow. A wide range of SE-EE tradeoff, however, is desiredfor future wireless communications that have dynamic demand depending on thetraffic loads, channel conditions, and system applications, e.g.,high-SE-with-low-EE for rate-limited systems and high-EE-with-low-SE forenergy-limited systems. For the SE-EE tradeoff improvement, we propose a PAswitching (PAS) technique. In a PAS transmitter, one or more PAs are switchedon intermittently to maximize the EE and deliver an overall required SE. As aconsequence, a high EE over a wide range SE can be achieved, which is verifiedby numerical evaluations: with 15% SE reduction for low SE demand, the PASbetween a low power PA and a high power PA can improve EE by 323%, while asingle high power PA transmitter improves EE by only 68%.",Jingon Joung,2013/5/17,2013/5/17
1803.00703v1,Structures and Physical Properties of CsV$_2$Se$_{2-x}$O and V$_2$Se$_2$O,http://arxiv.org/abs/1803.00703v1,"By using solid-state reactions, we successfully synthesize new oxyselenidesCsV$_2$Se$_{2-x}$O (x = 0, 0.5). These compounds containing V$_2$O planarlayers with a square lattice crystallize in the CeCr$_2$Si$_2$C structure withthe space group of $P4/mmm$. Another new compound V$_2$Se$_2$O whichcrystallizes in space group $I4/mmm$ is fabricated by topochemicaldeintercalation of cesium from CsV$_2$Se$_2$O powder with iodine intetrahydrofuran(THF). Resistivity measurements show a semiconducting behaviorfor CsV$_2$Se$_2$O, while a metallic behavior for CsV$_2$Se$_{1.5}$O, and aninsulating feature for V$_2$Se$_2$O. A charge- or spin-density wave-likeanomaly has been observed at 168 K for CsV$_2$Se$_2$O and 150 K forCsV$_2$Se$_{1.5}$O, respectively. And these anomalies are also confirmed by themagnetic susceptibility measurements. The resistivity in V$_2$Se$_2$O exhibitsan anomalous log(1/$T$) temperature dependence, which is similar to the case inparent phase or very underdoped cuprates indicating the involvement of strongcorrelation. Magnetic susceptibility measurements show that the magnetic momentper V-site in V$_2$Se$_2$O is much larger than that of CsV$_2$Se$_{2-x}$O,which again suggests the correlation induced localization effect in the former.",Hai Lin,2018/3/2,2018/3/2
1310.1983v1,Bulk Superconductivity in Fe$_{1+y}$Te$_{1-x}$Se$_{x}$ Induced by Annealing in Se and S Vapor,http://arxiv.org/abs/1310.1983v1,"We reported that bulk superconductivity in Fe$_{1+y}$Te$_{1-x}$Se$_{x}$ canbe induced by annealing in Se and S vapor. The well-annealed samples show alarge critical current density, emph{J}$_c$ $\sim$ 2 - 4 $\times$ 10$^5$A/cm$^2$. Combined with our previous reports about O$_2$ and Te annealingeffects, we proved that bulk superconductivity can be successfully induced inFe$_{1+y}$Te$_{1-x}$Se$_{x}$ by annealing in atmosphere of all chalcogens, suchas O, S, Se and Te.",Yue Sun,2013/10/8,2013/10/8
2106.04317v1,Equations of state of new boron-rich selenides B$_6$Se and B$_{12}$Se,http://arxiv.org/abs/2106.04317v1,"Two novel of boron-rich selenides, orthorhombic B$_6$Se and rhombohedralB$_{12}$Se, have been recently synthesized at high pressure - high temperatureconditions. Room-temperature compressibilities of these phases were studied ina diamond anvil cell using synchrotron powder X-ray diffraction. A fit ofexperimental p-V data by third-order Birch-Murnaghan equation of state yieldedthe bulk moduli of 155(2) GPa for B$_{12}$Se and 144(3) GPa for B$_6$Se. Nopressure-induced phase transitions have been observed in the studied pressurerange, i.e., up to 35 GPa.",Kirill A. Cherednichenko,2021/6/8,2021/6/8
2203.01369v3,ePA*SE: Edge-based Parallel A* for Slow Evaluations,http://arxiv.org/abs/2203.01369v3,"Parallel search algorithms harness the multithreading capability of modernprocessors to achieve faster planning. One such algorithm is PA*SE (Parallel A*for Slow Expansions), which parallelizes state expansions to achieve fasterplanning in domains where state expansions are slow. In this work, we proposeePA*SE (Edge-based Parallel A* for Slow Evaluations) that improves on PA*SE byparallelizing edge evaluations instead of state expansions. This makes ePA*SEmore efficient in domains where edge evaluations are expensive and need varyingamounts of computational effort, which is often the case in robotics. On thetheoretical front, we show that ePA*SE provides rigorous optimality guarantees.In addition, ePA*SE can be trivially extended to handle an inflation weight onthe heuristic resulting in a bounded suboptimal algorithm w-ePA*SE (WeightedePA*SE) that trades off optimality for faster planning. On the experimentalfront, we validate the proposed algorithm in two different planning domains: 1)motion planning for 3D humanoid navigation and 2) task and motion planning fora dual-arm robotic assembly task. We show that ePA*SE can be significantly moreefficient than PA*SE and other alternatives. The open-source code for ePA*SEalong with the baselines is available here:https://github.com/shohinm/parallel_search",Shohin Mukherjee,2022/3/2,2023/1/10
2211.00843v1,"Weak antilocalization induced by Se substitution in layered BiCh$_2$-based (Ch = S, Se) superconductors LaO$_{1-x}$F$_x$BiS$_{2-y}$Se$_y$",http://arxiv.org/abs/2211.00843v1,"We report transport properties for layered BiCh2-based (Ch = S, Se)superconductors LaO1-xFxBiS2-ySey (x = 0.2, 0.5, y = 0-1.05) and theobservation of weak antilocalization (WAL). Electrical resistivity and Hallcoefficients for the Se-poor samples increase with decreasing temperature. Theincrease becomes less pronounced with increasing Se concentration indicating aloss of insulating behavior. Interestingly, the moderately Se-substitutedsamples exhibit metallic behavior in the high-temperature region and a weakincrease in the resistivity in the low-temperature regions, which indicates theexistence of carrier localization. The heavily Se-substituted compounds showmetallic behavior in the entire-temperature region. Sign changes of the Hallcoefficients are observed for the x = 0.2 samples, which possibly is related toa charge-density wave (CDW). Magnetoresistance measurements indicate that WALis realized in the heavily Se-substituted systems. The WAL behavior is weakenedby the changes in F and Se concentrations. A crossover state of the WAL and WLemerges around the moderately F-doped and Se-free LaO0.8F0.2BiS2. The change ofthe resistivity behavior by the F and Se substitution clearly correlates to thedifference of the magnetoconductance. Moreover, the localization regions of theWAL-WL crossover and weak WAL states are possibly associated with the CDW. Wepropose that the BiCh2-based system is a good platform for studyingrelationship between WAL, superconductivity, and electronic ordering becausethose states are tunable by element substitutions with bulk single crystals.",Kazuhisa Hoshi,2022/11/2,2022/11/2
2208.14025v1,"Superconducting four-fold Fe(Te,Se) film on six-fold magnetic MnTe via hybrid symmetry epitaxy",http://arxiv.org/abs/2208.14025v1,"Epitaxial Fe(Te,Se) thin films have been grown on various substrates butnever been realized on magnetic layers. Here we report the epitaxial growth offour-fold Fe(Te,Se) film on a six-fold antiferromagnetic insulator, MnTe. TheFe(Te,Se)/MnTe heterostructure shows a clear superconducting transition ataround 11 K and the critical magnetic field measurement suggests the origin ofthe superconductivity to be bulk-like. Structural characterizations suggestthat the uniaxial lattice match between Fe(Te,Se) and MnTe allows a hybridsymmetry epitaxy mode, which was recently discovered between Fe(Te,Se) andBi2Te3. Furthermore, Te/Fe flux ratio during deposition of the Fe(Te,Se) layeris found to be critical for its superconductivity. Now that superconductingFe(Te,Se) can be grown on two related hexagonal platforms, Bi2Te3 and MnTe,this result opens a new possibility of combining topological superconductivityof Fe(Te,Se) with the rich physics in the intrinsic magnetic topologicalmaterials (MnTe)n(Bi2Te3)m family.",Xiong Yao,2022/8/30,2022/8/30
2307.02723v1,Selenium / Tellurium Two-Dimensional Structures: from Isovalent Se Dopants in Te to Atomically Thin Se Films,http://arxiv.org/abs/2307.02723v1,"Two-dimensional (2D) elemental semiconductors have great potential for deviceapplications, but their performance is limited by the lack of efficient dopingmethods. Here, combining molecular beam epitaxy, scanning tunnelingmicroscopy/spectroscopy, X-ray photoelectron spectroscopy, and densityfunctional theory calculations, we investigate the evolution of the structuraland electronic properties of 2D selenium/tellurium films with increased Sedosages on graphene/6H-SiC(0001) substrates. We found that Se atoms formisovalent dopants by replacing surface Te atoms, which introduces efficientelectron doping and lowers the work function of Te films. With the Se dosageincreasing, two types of elemental 2D crystalline Se structures, trigonal Seand Se8 molecular assembly films, are obtained on ultrathin Te films, which aredistinct from the amorphous Se acquired by depositing Se directly ongraphene/6H-SiC(0001). Our results shed light on tuning the electronicproperties of 2D elemental semiconductors by isovalent doping and constructingheterostructures of isovalent 2D elemental materials.",Guangyao Miao,2023/7/6,2023/7/6
1403.4979v1,Intra Cluster Light properties in the CLASH-VLT cluster MACS J1206.2-0847,http://arxiv.org/abs/1403.4979v1,"We aim at constraining the assembly history of clusters by studying the intracluster light (ICL) properties, estimating its contribution to the fraction ofbaryons in stars, f*, and understanding possible systematics/bias usingdifferent ICL detection techniques. We developed an automated method, GALtoICL,based on the software GALAPAGOS to obtain a refined version of typical BCG+ICLmaps. We applied this method to our test case MACS J1206.2-0847, a massivecluster located at z=0.44, that is part of the CLASH sample. Using deepmulti-band SUBARU images, we extracted the surface brightness (SB) profile ofthe BCG+ICL and we studied the ICL morphology, color, and contribution to f*out to R500. We repeated the same analysis using a different definition of theICL, SBlimit method, i.e. a SB cut-off level, to compare the results. The mostpeculiar feature of the ICL in MACS1206 is its asymmetric radial distribution,with an excess in the SE direction and extending towards the 2nd brightestcluster galaxy which is a Post Starburst galaxy. This suggests an interactionbetween the BCG and this galaxy that dates back to t <= 1.5 Gyr. The BCG+ICLstellar content is 8% of M_(*,500) and the (de-) projected baryon fraction instars is f*=0.0177 (0.0116), in excellent agreement with recent results. TheSBlimit method provides systematically higher ICL fractions and this effect islarger at lower SB limits. This is due to the light from the outer envelopes ofmember galaxies that contaminate the ICL. Though more time consuming, theGALtoICL method provides safer ICL detections that are almost free of thiscontamination. This is one of the few ICL study at redshift z > 0.3. Atcompletion, the CLASH/VLT program will allow us to extend this analysis to astatistically significant cluster sample spanning a wide redshift range:0.2<z<0.6.",V. Presotto,2014/3/19,2014/3/19
2311.18194v1,Positional Information Matters for Invariant In-Context Learning: A Case Study of Simple Function Classes,http://arxiv.org/abs/2311.18194v1,"In-context learning (ICL) refers to the ability of a model to condition on afew in-context demonstrations (input-output examples of the underlying task) togenerate the answer for a new query input, without updating parameters. Despitethe impressive ICL ability of LLMs, it has also been found that ICL in LLMs issensitive to input demonstrations and limited to short context lengths. Tounderstand the limitations and principles for successful ICL, we conduct aninvestigation with ICL linear regression of transformers. We characterizeseveral Out-of-Distribution (OOD) cases for ICL inspired by realistic LLM ICLfailures and compare transformers with DeepSet, a simple yet powerfularchitecture for ICL. Surprisingly, DeepSet outperforms transformers across avariety of distribution shifts, implying that preserving permutation invariancesymmetry to input demonstrations is crucial for OOD ICL. The phenomenonspecifies a fundamental requirement by ICL, which we termed as ICL invariance.Nevertheless, the positional encodings in LLMs will break ICL invariance. Tothis end, we further evaluate transformers with identical positional encodingsand find preserving ICL invariance in transformers achieves state-of-the-artperformance across various ICL distribution shifts",Yongqiang Chen,2023/11/30,2023/11/30
2307.12375v3,In-Context Learning Learns Label Relationships but Is Not Conventional Learning,http://arxiv.org/abs/2307.12375v3,"The predictions of Large Language Models (LLMs) on downstream tasks oftenimprove significantly when including examples of the input--label relationshipin the context. However, there is currently no consensus about how thisin-context learning (ICL) ability of LLMs works. For example, while Xie et al.(2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022)argue ICL does not even learn label relationships from in-context examples. Inthis paper, we provide novel insights into how ICL leverages label information,revealing both capabilities and limitations. To ensure we obtain acomprehensive picture of ICL behavior, we study probabilistic aspects of ICLpredictions and thoroughly examine the dynamics of ICL as more examples areprovided. Our experiments show that ICL predictions almost always depend onin-context labels, and that ICL can learn truly novel tasks in-context.However, we also find that ICL struggles to fully overcome predictionpreferences acquired from pre-training data, and, further, that ICL does notconsider all in-context information equally.",Jannik Kossen,2023/7/23,2023/10/3
2401.06469v1,"Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning",http://arxiv.org/abs/2401.06469v1,"In this paper, by treating in-context learning (ICL) as a meta-optimizationprocess, we explain why LLMs are sensitive to the order of ICL examples. Thisunderstanding leads us to the development of Batch-ICL, an effective,efficient, and order-agnostic inference algorithm for ICL. Differing from thestandard N-shot learning approach, Batch-ICL employs $N$ separate 1-shotforward computations and aggregates the resulting meta-gradients. Theseaggregated meta-gradients are then applied to a zero-shot learning to generatethe final prediction. This batch processing approach renders the LLM agnosticto the order of ICL examples. Through extensive experiments and analysis, wedemonstrate that Batch-ICL consistently outperforms most permutations ofexample sequences. In some cases, it even exceeds the performance of theoptimal order for standard ICL, all while reducing the computational resourcesrequired. Furthermore, we develop a novel variant of Batch-ICL featuringmultiple ""epochs"" of meta-optimization. This variant implicitly explorespermutations of ICL examples, further enhancing ICL performance.",Kaiyi Zhang,2024/1/12,2024/1/12
1103.1215v1,The Quantity of Intracluster Light: Comparing Theoretical and Observational Measurement Techniques Using Simulated Clusters,http://arxiv.org/abs/1103.1215v1,"Using a suite of N-body simulations of galaxy clusters specifically tailoredto study the intracluster light (ICL) component, we measure the quantity of ICLusing a number of different methods previously employed in the literature forboth observational and simulation data sets. By measuring the ICL of theclusters using multiple techniques, we identify systematic differences in howeach detection method identifies the ICL. We find that techniques which definethe ICL solely based on the current position of the cluster luminosity, such asa surface brightness or local density threshold, tend to find less ICL thanmethods utilizing time or velocity information, including stellar particles'density history or binding energy. The range of ICL fractions (the fraction ofthe clusters' total luminosity found in the ICL component) we measure at z=0across all our clusters using any definition span the range from 9-36%, andeven within a single cluster different methods can change the measured ICLfraction by up to a factor of two. Separating the cluster's central galaxy fromthe surrounding ICL component is a challenge for all ICL techniques, andbecause the ICL is centrally concentrated within the cluster, the differencesin the measured ICL quantity between techniques are largely a consequence ofthis central galaxy/ICL separation. We thoroughly explore the free parametersinvolved with each measurement method, and find that adjusting these parameterscan change the measured ICL fraction by up to a factor of two. While for alldefinitions the quantity of ICL tends to increase with time, the ICL fractiondoes not grow at a uniform rate, nor even monotonically under some definitions.Thus, the ICL can be used as a rough indicator of dynamical age, where moredynamically advanced clusters will on average have higher ICL fractions.",Craig S. Rudick,2011/3/7,2011/3/7
2311.08360v3,The Transient Nature of Emergent In-Context Learning in Transformers,http://arxiv.org/abs/2311.08360v3,"Transformer neural networks can exhibit a surprising capacity for in-contextlearning (ICL) despite not being explicitly trained for it. Prior work hasprovided a deeper understanding of how ICL emerges in transformers, e.g.through the lens of mechanistic interpretability, Bayesian inference, or byexamining the distributional properties of training data. However, in each ofthese cases, ICL is treated largely as a persistent phenomenon; namely, onceICL emerges, it is assumed to persist asymptotically. Here, we show that theemergence of ICL during transformer training is, in fact, often transient. Wetrain transformers on synthetic data designed so that both ICL and in-weightslearning (IWL) strategies can lead to correct predictions. We find that ICLfirst emerges, then disappears and gives way to IWL, all while the trainingloss decreases, indicating an asymptotic preference for IWL. The transientnature of ICL is observed in transformers across a range of model sizes anddatasets, raising the question of how much to ""overtrain"" transformers whenseeking compact, cheaper-to-run models. We find that L2 regularization mayoffer a path to more persistent ICL that removes the need for early stoppingbased on ICL-style validation tasks. Finally, we present initial evidence thatICL transience may be caused by competition between ICL and IWL circuits.",Aaditya K. Singh,2023/11/14,2023/12/11
2202.08289v1,The intracluster light on Frontier Fields clusters Abell 370 and Abell S1063,http://arxiv.org/abs/2202.08289v1,"We analyzed the contribution of the intracluster light (ICL) to the totalluminosity of two massive galaxy clusters observed by the Hubble SpaceTelescope within the Frontier Fields program, Abell 370 (z ~ 0.375) and AbellS1063 (z ~ 0.348), in order to correlate it with the dynamical stage of thesesystems.We applied an algorithm based on the Chebyshev-Fourier functions calledCICLE, specially developed to disentangle the ICL from the light of galaxiesand measure the ICL fraction. We measured the ICL fraction in three broadbandoptical filters, F435W, F606W, and F814W, without assuming any prior hypothesisabout the ICL physical properties or morphology. The results obtained from theICL fraction vary between ~7% - 25%, and ~3% - 22% for both A370 and AS1063,respectively, which are consistent with theoretical predictions for the totalamount of ICL obtained by ICL formation and evolution simulations.We foundenhanced ICL fractions in the intermediate filter F606W for both clusters andwe suggest that this is due to the presence of an excess ofyounger/lower-metallicity stars in the ICL compared to the cluster galaxies. Weconclude that both Abell 370 and Abell S1063 are merging systems since theyexhibit a similar feature as merging CLASH and Frontier Fields clusterssub-sample previously analyzed. We compare these results to the dynamicalindicators obtained through different methods and we reinforce the use of ICLas a new and independent method to determine the dynamical state of clusters ofgalaxies.",Ncolas O. L. de Oliveira,2022/2/16,2022/2/16
2305.01639v2,Privacy-Preserving In-Context Learning for Large Language Models,http://arxiv.org/abs/2305.01639v2,"In-context learning (ICL) is an important capability of Large Language Models(LLMs), enabling these models to dynamically adapt based on specific,in-context exemplars, thereby improving accuracy and relevance. However, LLM'sresponses may leak the sensitive private information contained in in-contextexemplars. To address this challenge, we propose Differentially PrivateIn-context Learning (DP-ICL), a general paradigm for privatizing ICL tasks. Thekey idea for DP-ICL paradigm is generating differentially private responsesthrough a noisy consensus among an ensemble of LLM's responses based ondisjoint exemplar sets. Based on the general paradigm of DP-ICL, we instantiateseveral techniques showing how to privatize ICL for text classification andlanguage generation. We evaluate DP-ICL on four text classification benchmarksand two language generation tasks, and our empirical results show that DP-ICLachieves a strong utility-privacy tradeoff.",Tong Wu,2023/5/2,2023/9/30
2311.07772v3,In-context Learning and Gradient Descent Revisited,http://arxiv.org/abs/2311.07772v3,"In-context learning (ICL) has shown impressive results in few-shot learningtasks, yet its underlying mechanism is still not fully understood. Recent workssuggest that ICL can be thought of as a gradient descent (GD) basedoptimization process. While promising, these results mainly focus on simplifiedsettings of ICL and provide only a preliminary evaluation of the similaritiesbetween the two methods. In this work, we revisit the comparison between ICLand GD-based finetuning and study what properties of ICL an equivalent processmust follow. We highlight a major difference in the flow of information betweenICL and standard finetuning. Namely, ICL can only rely on information fromlower layers at every point, while finetuning depends on loss gradients fromdeeper layers. We refer to this discrepancy as Layer Causality and show that alayer causal variant of the finetuning process aligns with ICL on par withvanilla finetuning and is even better in most cases across relevant metrics. Tothe best of our knowledge, this is the first work to discuss this discrepancyexplicitly and suggest a solution that tackles this problem with minimalchanges.",Gilad Deutch,2023/11/13,2023/11/18
2311.10367v1,Exploring the Relationship between In-Context Learning and Instruction Tuning,http://arxiv.org/abs/2311.10367v1,"In-Context Learning (ICL) and Instruction Tuning (IT) are two primaryparadigms of adopting Large Language Models (LLMs) to downstream applications.However, they are significantly different. In ICL, a set of demonstrations areprovided at inference time but the LLM's parameters are not updated. In IT, aset of demonstrations are used to tune LLM's parameters in training time but nodemonstrations are used at inference time. Although a growing body ofliterature has explored ICL and IT, studies on these topics have largely beenconducted in isolation, leading to a disconnect between these two paradigms. Inthis work, we explore the relationship between ICL and IT by examining how thehidden states of LLMs change in these two paradigms. Through carefully designedexperiments conducted with LLaMA-2 (7B and 13B), we find that ICL is implicitIT. In other words, ICL changes an LLM's hidden states as if the demonstrationswere used to instructionally tune the model. Furthermore, the convergencebetween ICL and IT is largely contingent upon several factors related to theprovided demonstrations. Overall, this work offers a unique perspective toexplore the connection between ICL and IT and sheds light on understanding thebehaviors of LLM.",Hanyu Duan,2023/11/17,2023/11/17
1804.03335v1,An Investigation of intra-cluster light evolution using cosmological hydro-dynamical simulations,http://arxiv.org/abs/1804.03335v1,"The intra-cluster light (ICL) in observations is usually identified throughthe surface brightness limit method. In this paper, for the first time weproduce the mock images of galaxy groups and clusters using a cosmologicalhydro- dynamical simulation, to investigate the ICL fraction and focus on itsdependence on observational parameters, e.g., the surface brightness limit(SBL), the effects of cosmological redshift dimming, point spread function andCCD pixel size. Detailed analyses suggest that the width of point spreadfunction has a significant effect on the measured ICL fraction, while therelatively small pixel size shows almost no influence. It is found that themeasured ICL fraction depends strongly on the SBL. At a fixed SBL and redshift,the measured ICL fraction decreases with increasing halo mass, while with amuch faint SBL, it does not depend on halo mass at low redshifts. In our work,the measured ICL fraction shows clear dependence on the cosmological redshiftdimming effect. It is found that there are more mass locked in ICL componentthan light, suggesting that the use of a constant mass-to-light ratio at highsurface brightness levels will lead to an underestimate of ICL mass.Furthermore, it is found that the radial profile of ICL shows a characteristicradius which is almost independent of halo mass. The current measurement of ICLfrom observations has a large dispersion due to different methods, and weemphasize the importance of using the same definition when observationalresults are compared with the theoretical predictions.",Lin Tang,2018/4/10,2018/4/10
2301.01523v1,Intracluster light is already abundant at redshift beyond unity,http://arxiv.org/abs/2301.01523v1,"Intracluster light (ICL) is diffuse light from stars that are gravitationallybound not to individual member galaxies, but to the halo of galaxy clusters.Leading theories predict that the ICL fraction, defined by the ratio of the ICLto the total light, rapidly decreases with increasing redshift, to the level ofa few per cent at z > 1. However, observational studies have remainedinconclusive about the fraction beyond redshift unity because, to date, onlytwo clusters in this redshift regime have been investigated. One shows a muchlower fraction than the mean value at low redshift, whereas the other possessesa fraction similar to the low-redshift value. Here we report an ICL study often galaxy clusters at 1 \lesssim z \lesssim 2 based on deep infrared imagingdata. Contrary to the leading theories, our study finds that ICL is alreadyabundant at z \lesssim 1, with a mean ICL fraction of approximately 17\%.Moreover, no significant correlation between cluster mass and ICL fraction orbetween ICL color and cluster-centric radius is observed. Our findings suggestthat gradual stripping can no longer be the dominant mechanism of ICLformation. Instead, our study supports the scenario wherein the dominant ICLproduction occurs in tandem with the formation and growth of the brightestcluster galaxies and/or through the accretion of preprocessed stray stars.",Hyungjin Joo,2023/1/4,2023/1/4
2305.19420v2,"What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization",http://arxiv.org/abs/2305.19420v2,"In this paper, we conduct a comprehensive study of In-Context Learning (ICL)by addressing several open questions: (a) What type of ICL estimator is learnedby large language models? (b) What is a proper performance metric for ICL andwhat is the error rate? (c) How does the transformer architecture enable ICL?To answer these questions, we adopt a Bayesian view and formulate ICL as aproblem of predicting the response corresponding to the current covariate,given a number of examples drawn from a latent variable model. To answer (a),we show that, without updating the neural network parameters, ICL implicitlyimplements the Bayesian model averaging algorithm, which is proven to beapproximately parameterized by the attention mechanism. For (b), we analyze theICL performance from an online learning perspective and establish a$\mathcal{O}(1/T)$ regret bound for perfectly pretrained ICL, where $T$ is thenumber of examples in the prompt. To answer (c), we show that, in addition toencoding Bayesian model averaging via attention, the transformer architecturealso enables a fine-grained statistical analysis of pretraining under realisticassumptions. In particular, we prove that the error of pretrained model isbounded by a sum of an approximation error and a generalization error, wherethe former decays to zero exponentially as the depth grows, and the latterdecays to zero sublinearly with the number of tokens in the pretrainingdataset. Our results provide a unified understanding of the transformer and itsICL ability with bounds on ICL regret, approximation, and generalization, whichdeepens our knowledge of these essential aspects of modern language models.",Yufeng Zhang,2023/5/30,2023/10/10
2306.15091v1,Understanding In-Context Learning via Supportive Pretraining Data,http://arxiv.org/abs/2306.15091v1,"In-context learning (ICL) improves language models' performance on a varietyof NLP tasks by simply demonstrating a handful of examples at inference time.It is not well understood why ICL ability emerges, as the model has never beenspecifically trained on such demonstrations. Unlike prior work that exploresimplicit mechanisms behind ICL, we study ICL via investigating the pretrainingdata. Specifically, we first adapt an iterative, gradient-based approach tofind a small subset of pretraining data that supports ICL. We observe that acontinued pretraining on this small subset significantly improves the model'sICL ability, by up to 18%. We then compare the supportive subset constrastivelywith random subsets of pretraining data and discover: (1) The supportivepretraining data to ICL do not have a higher domain relevance to downstreamtasks. (2) The supportive pretraining data have a higher mass of rarelyoccurring, long-tail tokens. (3) The supportive pretraining data arechallenging examples where the information gain from long-range context isbelow average, indicating learning to incorporate difficult long-range contextencourages ICL. Our work takes a first step towards understanding ICL viaanalyzing instance-level pretraining data. Our insights have a potential toenhance the ICL ability of language models by actively guiding the constructionof pretraining data in the future.",Xiaochuang Han,2023/6/26,2023/6/26
2310.08540v3,Do pretrained Transformers Really Learn In-context by Gradient Descent?,http://arxiv.org/abs/2310.08540v3,"The emergence of In-Context Learning (ICL) in LLMs remains a significantphenomenon with little understanding. To explain ICL, recent studies try toshed light on ICL by connecting it to Gradient Descent (GD). However, thequestion is, do these hold up in practice in actual pre-trained models?  We highlight the limiting assumptions in prior works that make their contextconsiderably different from the practical context in which language models aretrained. For example, the theoretical hand-constructed weights used in thesestudies have properties that don't match those of real LLMs. Furthermore, theirexperimental verification uses \emph{ICL objective} (training models explicitlyfor ICL), which differs from the emergent ICL in the wild.  We also look for evidence in real models. We observe that ICL and GD havedifferent sensitivity to the order in which they observe demonstrations.Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting.We conduct comprehensive empirical analyses on language models pre-trained onnatural data (LLaMa-7B). Our comparisons of three performance metrics highlightthe inconsistent behavior of ICL and GD as a function of various factors suchas datasets, models, and the number of demonstrations. We observe that ICL andGD modify the output distribution of language models differently. These resultsindicate that the equivalence between ICL and GD remains an open hypothesis andcalls for further studies.",Lingfeng Shen,2023/10/12,2023/11/30
1501.02251v2,On the Origin of Intracluster Light in Massive Galaxy Clusters,http://arxiv.org/abs/1501.02251v2,"We present a pilot study on the origin and assembly history of the ICL forfour galaxy clusters at 0.44<z<0.57 observed with the Hubble Space Telescopefrom the Cluster Lensing and Supernova Survey with Hubble (CLASH) sample. Usingthis sample of clusters we set an empirical limit on the amount of scatter inICL surface brightness profiles of such clusters at z=0.5 and constrain theprogenitor population and formation mechanism of the ICL by measuring the ICLsurface brightness profile, the ICL color and color gradient, and the total ICLluminosity within 10<r<110 kpc. The observed scatter is physical, which weassociate with differences in ICL assembly process, formation epoch, and/or ICLcontent. Using stellar population synthesis models we transform the observedcolors to metallicity. For three of the four clusters we find clear negativegradients that, on average, decrease from super solar in the central regions ofthe BCG to sub-solar in the ICL. Such negative color/metallicity gradients canarise from tidal stripping of L* galaxies and/or the disruption of dwarfgalaxies, but not major mergers with the BCG. We also find that the ICL at 110kpc has a color comparable to m*+2 red sequence galaxies and a total luminositybetween 10<r<110 kpc of 4-8 L*. This suggests that the ICL is dominated bystars liberated from galaxies with L>0.2 L* and that neither dwarf disruptionnor major mergers with the BCG alone can explain the observed level ofluminosity and remain consistent with either the observed evolution in thefaint end slope of the luminosity function or predictions for the number of BCGmajor mergers since z=1. Taken together, the results of this pilot study aresuggestive of a formation history for these clusters in which the ICL isbuilt-up by the stripping of >0.2 L* galaxies, and disfavor significantcontribution to the ICL by dwarf disruption or major mergers with the BCG.",Tahlia DeMaio,2015/1/9,2015/1/12
1810.01424v1,J-PLUS: analysis of the intracluster light in the Coma cluster,http://arxiv.org/abs/1810.01424v1,"The intracluster light (ICL) is a luminous component of galaxy clusterscomposed of stars that are gravitationally bound to the cluster potential butdo not belong to the individual galaxies. Previous studies of the ICL haveshown that its formation and evolution are intimately linked to theevolutionary stage of the cluster. Thus, the analysis of the ICL in the Comacluster will give insights into the main processes driving the dynamics in thishighly complex system. Using a recently developed technique, we measure the ICLfraction in Coma at several wavelengths, using the J-PLUS unique filter system.The combination of narrow- and broadband filters provides valuable informationon the dynamical state of the cluster, the ICL stellar types, and themorphology of the diffuse light. We use the Chebyshev-Fourier IntraclusterLight Estimator (CICLE) to disentangle the ICL from the light of the galaxies,and to robustly measure the ICL fraction in seven J-PLUS filters. We obtain theICL fraction distribution of the Coma cluster at different optical wavelengths,which varies from $\sim 7\%-21\%$, showing the highest values in the narrowbandfilters J0395, J0410, and J0430. This ICL fraction excess is distinctivepattern recently observed in dynamically active clusters (mergers), indicatinga higher amount of bluer stars in the ICL compared to the cluster galaxies.Both the high ICL fractions and the excess in the bluer filters are indicativeof a merging state. The presence of younger/lower-metallicity stars the ICLsuggests that the main mechanism of ICL formation for the Coma cluster is thestripping of the stars in the outskirts of infalling galaxies and, possibly,the disruption of dwarf galaxies during past/ongoing mergers.",Y. Jimnez-Teja,2018/10/2,2018/10/2
2011.12992v1,Photometric dissection of Intracluster Light and its correlations with host cluster properties,http://arxiv.org/abs/2011.12992v1,"We explore several ways to dissect Brightest Cluster Galaxies (BCGs) andtheir surrounding Intracluster Light (ICL) using a surface brightness cut, aluminosity cut, excess light above a de Vaucouleurs profile, or a doubleS\'ersic decomposition. Assuming that all light above $M<-21.85~g'~\rm{mag}$ isattributable to the ICL, we find an average ICL fraction of $f^{\rm MT}_{\rmICL}=71\pm22\%$ of all diffuse light centered on the BCG to belong to the ICL.Likewise, if we assume all light fainter than $\rm{SB}>27$ $g'$ magarcsec$^{-2}$ to belong to the ICL, the average ICL fraction is $f^{\rmSB27}_{\rm ICL}=34\pm19\%$. After fitting a de Vaucouleurs profile to the innerparts of the SB profile, we detect excess light at large radii, correspondingto an average ICL fraction of $f^{\rm DV}_{\rm ICL}=48\pm20\%$. Finally, bydecomposing the SB profile into two S\'ersic functions, we find an average ICLfraction of $f^{\rm S\times}_{\rm ICL}=52\pm21\%$ associated with the outerS\'ersic component. Our measured ICL and BCG+ICL luminosities agree well withpredictions from high-resolution simulations where the outer S\'ersic componenttraces the unrelaxed, accreted stellar material. BCG and ICL properties definedin this way are correlated with cluster parameters to study the co-evolution ofBCGs, ICL, and their host clusters. We find positive correlations betweenBCG+ICL brightness and cluster mass, cluster velocity dispersion, clusterradius, and integrated satellite brightness, confirming that BCG/ICL growth isindeed coupled with cluster growth. On average, the ICL is better aligned thanthe BCG with the host cluster in terms of position angle, ellipticity, andcentering. That makes it a potential Dark Matter tracer.",M. Kluge,2020/11/25,2020/11/25
2304.01055v2,Eigen-Factors an Alternating Optimization for Back-end Plane SLAM of 3D Point Clouds,http://arxiv.org/abs/2304.01055v2,"Modern depth sensors can generate a huge number of 3D points in few secondsto be latter processed by Localization and Mapping algorithms. Ideally, thesealgorithms should handle efficiently large sizes of Point Clouds under theassumption that using more points implies more information available. The EigenFactors (EF) is a new algorithm that solves SLAM by using planes as the maingeometric primitive. To do so, EF exhaustively calculates the error of allpoints at complexity $O(1)$, thanks to the {\em Summation matrix} $S$ ofhomogeneous points.  The solution of EF is highly efficient: i) the state variables are only thesensor poses -- trajectory, while the plane parameters are estimated previouslyin closed from and ii) EF alternating optimization uses a Newton-Raphson methodby a direct analytical calculation of the gradient and the Hessian, which turnsout to be a block diagonal matrix. Since we require to differentiate overeigenvalues and matrix elements, we have developed an intuitive methodology tocalculate partial derivatives in the manifold of rigid body transformations$SE(3)$, which could be applied to unrelated problems that require analyticalderivatives of certain complexity.  We evaluate EF and other state-of-the-art plane SLAM back-end algorithms in asynthetic environment. The evaluation is extended to ICL dataset (RGBD) andLiDAR KITTI dataset. Code is publicly available athttps://github.com/prime-slam/EF-plane-SLAM.",Gonzalo Ferrer,2023/4/3,2023/9/4
1001.3523v1,Diffuse Light in Galaxy Clusters,http://arxiv.org/abs/1001.3523v1,"Diffuse intracluster light (ICL) has now been observed in nearby and inintermediate redshift clusters. Individual intracluster stars have beendetected in the Virgo and Coma clusters and the first color-magnitude diagramand velocity measurements have been obtained. Recent studies show that the ICLcontains of the order of 10% and perhaps up to 30% of the stellar mass in thecluster, but in the cores of some dense and rich clusters like Coma, the localICL fraction can be high as 40%-50%. What can we learn from the ICL about theformation of galaxy clusters and the evolution of cluster galaxies? How andwhen did the ICL form? What is the connection to the central brightest clustergalaxy? Cosmological N-body and hydrodynamical simulations are beginning tomake predictions for the kinematics and origin of the ICL. The ICL traces theevolution of baryonic substructures in dense environments and can thus be usedto constrain some aspects of cosmological simulations that are most uncertain,such as the modeling of star formation and the mass distribution of thebaryonic component in galaxies.",Magda Arnaboldi,2010/1/20,2010/1/20
2107.02145v1,Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context,http://arxiv.org/abs/2107.02145v1,"In this paper we investigate the amount of spatial context required forchannel attention. To this end we study the popular squeeze-and-excite (SE)block which is a simple and lightweight channel attention mechanism. SE blocksand its numerous variants commonly use global average pooling (GAP) to create asingle descriptor for each channel. Here, we empirically analyze the amount ofspatial context needed for effective channel attention and find that limitedlocalcontext on the order of seven rows or columns of the original image issufficient to match the performance of global context. We propose tiledsqueeze-and-excite (TSE), which is a framework for building SE-like blocks thatemploy several descriptors per channel, with each descriptor based on localcontext only. We further show that TSE is a drop-in replacement for the SEblock and can be used in existing SE networks without re-training. This impliesthat local context descriptors are similar both to each other and to the globalcontext descriptor. Finally, we show that TSE has important practicalimplications for deployment of SE-networks to dataflow AI accelerators due totheir reduced pipeline buffering requirements. For example, using TSE reducesthe amount of activation pipeline buffering in EfficientDetD2 by 90% comparedto SE (from 50M to 4.77M) without loss of accuracy. Our code and pre-trainedmodels will be publicly available.",Niv Vosco,2021/7/5,2021/7/5
2009.05926v1,On the Use of Grey Literature: A Survey with the Brazilian Software Engineering Research Community,http://arxiv.org/abs/2009.05926v1,"Background: The use of Grey Literature (GL) has been investigate in diverseresearch areas. In Software Engineering (SE), this topic has an increasinginterest over the last years. Problem: Even with the increase of GL publishedin diverse sources, the understanding of their use on the SE research communityis still controversial. Objective: To understand how Brazilian SE researchersuse GL, we aimed to become aware of the criteria to assess the credibility oftheir use, as well as the benefits and challenges. Method: We surveyed 76active SE researchers participants of a flagship SE conference in Brazil, usinga questionnaire with 11 questions to share their views on the use of GL in thecontext of SE research. We followed a qualitative approach to analyze openquestions. Results: We found that most surveyed researchers use GL mainly tounderstand new topics. Our work identified new findings, including: 1) GLsources used by SE researchers (e.g., blogs, community website); 2) motivationsto use (e.g., to understand problems and to complement research findings) orreasons to avoid GL (e.g., lack of reliability, lack of scientific value); 3)the benefit that is easy to access and read GL and the challenge of GL to haveits scientific value recognized; and 4) criteria to assess GL credibility,showing the importance of the content owner to be renowned (e.g., renownedauthor and institutions). Conclusions: Our findings contribute to form a bodyof knowledge on the use of GL by SE researchers, by discussing novel (somecontradictory) results and providing a set of lessons learned to both SEresearchers and practitioners.",Fernando Kamei,2020/9/13,2020/9/13
2312.09620v1,A Deep Representation Learning-based Speech Enhancement Method Using Complex Convolution Recurrent Variational Autoencoder,http://arxiv.org/abs/2312.09620v1,"Generally, the performance of deep neural networks (DNNs) heavily depends onthe quality of data representation learning. Our preliminary work hasemphasized the significance of deep representation learning (DRL) in thecontext of speech enhancement (SE) applications. Specifically, our initial SEalgorithm employed a gated recurrent unit variational autoencoder (VAE) with aGaussian distribution to enhance the performance of certain existing SEsystems. Building upon our preliminary framework, this paper introduces a novelapproach for SE using deep complex convolutional recurrent networks with a VAE(DCCRN-VAE). DCCRN-VAE assumes that the latent variables of signals followcomplex Gaussian distributions that are modeled by DCCRN, as thesedistributions can better capture the behaviors of complex signals.Additionally, we propose the application of a residual loss in DCCRN-VAE tofurther improve the quality of the enhanced speech. {Compared to ourpreliminary work, DCCRN-VAE introduces a more sophisticated DCCRN structure andprobability distribution for DRL. Furthermore, in comparison to DCCRN,DCCRN-VAE employs a more advanced DRL strategy. The experimental resultsdemonstrate that the proposed SE algorithm outperforms both our preliminary SEframework and the state-of-the-art DCCRN SE method in terms of scale-invariantsignal-to-distortion ratio, speech quality, and speech intelligibility.",Yang Xiang,2023/12/15,2023/12/15
1912.09519v3,Analyzing Web Search Behavior for Software Engineering Tasks,http://arxiv.org/abs/1912.09519v3,"Web search plays an integral role in software engineering (SE) to help withvarious tasks such as finding documentation, debugging, installation, etc. Inthis work, we present the first large-scale analysis of web search behavior forSE tasks using the search query logs from Bing, a commercial web search engine.First, we use distant supervision techniques to build a machine learningclassifier to extract the SE search queries with an F1 score of 93%. We thenperform an analysis on one million search sessions to understand how softwareengineering related queries and sessions differ from other queries andsessions. Subsequently, we propose a taxonomy of intents to identify thevarious contexts in which web search is used in software engineering. Lastly,we analyze millions of SE queries to understand the distribution, searchmetrics and trends across these SE search intents. Our analysis shows that SErelated queries form a significant portion of the overall web search traffic.Additionally, we found that there are six major intent categories for which websearch is used in software engineering. The techniques and insights can notonly help improve existing tools but can also inspire the development of newtools that aid in finding information for SE related tasks.",Nikitha Rao,2019/12/19,2020/8/29
1909.03834v2,Linear Context Transform Block,http://arxiv.org/abs/1909.03834v2,"Squeeze-and-Excitation (SE) block presents a channel attention mechanism formodeling global context via explicitly capturing dependencies across channels.However, we are still far from understanding how the SE block works. In thiswork, we first revisit the SE block, and then present a detailed empiricalstudy of the relationship between global context and attention distribution,based on which we propose a simple yet effective module, called Linear ContextTransform (LCT) block. We divide all channels into different groups andnormalize the globally aggregated context features within each channel group,reducing the disturbance from irrelevant channels. Through linear transform ofthe normalized context features, we model global context for each channelindependently. The LCT block is extremely lightweight and easy to be pluggedinto different backbone models while with negligible parameters andcomputational burden increase. Extensive experiments show that the LCT blockoutperforms the SE block in image classification task on the ImageNet andobject detection/segmentation on the COCO dataset with different backbonemodels. Moreover, LCT yields consistent performance gains over existingstate-of-the-art detection architectures, e.g., 1.5$\sim$1.7% AP$^{bbox}$ and1.0$\sim$1.2% AP$^{mask}$ improvements on the COCO benchmark, irrespective ofdifferent baseline models of varied capacities. We hope our simple yeteffective approach will shed some light on future research of attention-basedmodels.",Dongsheng Ruan,2019/9/6,2019/11/23
2304.04549v1,Towards a Blockchain-based Software Engineering Education,http://arxiv.org/abs/2304.04549v1,"Blockchain technologies for rewards in education are gaining attraction as apromising approach to motivate student learning and promote academicachievement. By providing tangible rewards for educational attainment andengagement, such as digital tokens, educators can motivate learners to take amore active role in their learning and increase their sense of ownership andresponsibility for their academic outcomes. In this context, this work proposesthe Software Engineering Skill (SES) token as a way of rewarding students inorder to improve their experiences in Software Engineering Education (SEE). Weperformed a proof of concept and conclude that SES token can be deployed in aplatform to support SEE.",Filipe Fernandes,2023/4/4,2023/4/4
1811.06234v1,On Training Targets and Objective Functions for Deep-Learning-Based Audio-Visual Speech Enhancement,http://arxiv.org/abs/1811.06234v1,"Audio-visual speech enhancement (AV-SE) is the task of improving speechquality and intelligibility in a noisy environment using audio and visualinformation from a talker. Recently, deep learning techniques have been adoptedto solve the AV-SE task in a supervised manner. In this context, the choice ofthe target, i.e. the quantity to be estimated, and the objective function,which quantifies the quality of this estimate, to be used for training iscritical for the performance. This work is the first that presents anexperimental study of a range of different targets and objective functions usedto train a deep-learning-based AV-SE system. The results show that theapproaches that directly estimate a mask perform the best overall in terms ofestimated speech quality and intelligibility, although the model that directlyestimates the log magnitude spectrum performs as good in terms of estimatedspeech quality.",Daniel Michelsanti,2018/11/15,2018/11/15
2102.03586v4,CMS-LSTM: Context Embedding and Multi-Scale Spatiotemporal Expression LSTM for Predictive Learning,http://arxiv.org/abs/2102.03586v4,"Spatiotemporal predictive learning (ST-PL) is a hotspot with numerousapplications, such as object movement and meteorological prediction. It aims atpredicting the subsequent frames via observed sequences. However, inherentuncertainty among consecutive frames exacerbates the difficulty in long-termprediction. To tackle the increasing ambiguity during forecasting, we designCMS-LSTM to focus on context correlations and multi-scale spatiotemporal flowwith details on fine-grained locals, containing two elaborate designed blocks:Context Embedding (CE) and Spatiotemporal Expression (SE) blocks. CE isdesigned for abundant context interactions, while SE focuses on multi-scalespatiotemporal expression in hidden states. The newly introduced blocks alsofacilitate other spatiotemporal models (e.g., PredRNN, SA-ConvLSTM) to producerepresentative implicit features for ST-PL and improve prediction quality.Qualitative and quantitative experiments demonstrate the effectiveness andflexibility of our proposed method. With fewer params, CMS-LSTM outperformsstate-of-the-art methods in numbers of metrics on two representative benchmarksand scenarios. Code is available at https://github.com/czh-98/CMS-LSTM.",Zenghao Chai,2021/2/6,2022/4/12
2311.10609v1,Scaling TabPFN: Sketching and Feature Selection for Tabular Prior-Data Fitted Networks,http://arxiv.org/abs/2311.10609v1,"Tabular classification has traditionally relied on supervised algorithms,which estimate the parameters of a prediction model using its training data.Recently, Prior-Data Fitted Networks (PFNs) such as TabPFN have successfullylearned to classify tabular data in-context: the model parameters are designedto classify new samples based on labelled training samples given after themodel training. While such models show great promise, their applicability toreal-world data remains limited due to the computational scale needed. Here westudy the following question: given a pre-trained PFN for tabular data, what isthe best way to summarize the labelled training samples before feeding them tothe model? We conduct an initial investigation of sketching andfeature-selection methods for TabPFN, and note certain key differences betweenit and conventionally fitted tabular models.",Benjamin Feuer,2023/11/17,2023/11/17
2305.09731v1,"What In-Context Learning ""Learns"" In-Context: Disentangling Task Recognition and Task Learning",http://arxiv.org/abs/2305.09731v1,"Large language models (LLMs) exploit in-context learning (ICL) to solve taskswith only a few demonstrations, but its mechanisms are not yet well-understood.Some works suggest that LLMs only recall already learned concepts frompre-training, while others hint that ICL performs implicit learning overdemonstrations. We characterize two ways through which ICL leveragesdemonstrations. Task recognition (TR) captures the extent to which LLMs canrecognize a task through demonstrations -- even without ground-truth labels --and apply their pre-trained priors, whereas task learning (TL) is the abilityto capture new input-label mappings unseen in pre-training. Using a wide rangeof classification datasets and three LLM families (GPT-3, LLaMA and OPT), wedesign controlled experiments to disentangle the roles of TR and TL in ICL. Weshow that (1) models can achieve non-trivial performance with only TR, and TRdoes not further improve with larger models or more demonstrations; (2) LLMsacquire TL as the model scales, and TL's performance consistently improves withmore demonstrations in context. Our findings unravel two different forcesbehind ICL and we advocate for discriminating them in future ICL research dueto their distinct nature.",Jane Pan,2023/5/16,2023/5/16
2312.03703v1,Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context Learning,http://arxiv.org/abs/2312.03703v1,"In-context learning provides a new perspective for multi-task modeling forvision and NLP. Under this setting, the model can perceive tasks from promptsand accomplish them without any extra task-specific head predictions or modelfine-tuning. However, Skeleton sequence modeling via in-context learningremains unexplored. Directly applying existing in-context models from otherareas onto skeleton sequences fails due to the inter-frame and cross-task posesimilarity that makes it outstandingly hard to perceive the task correctly froma subtle context. To address this challenge, we propose Skeleton-in-Context(SiC), an effective framework for in-context skeleton sequence modeling. OurSiC is able to handle multiple skeleton-based tasks simultaneously after asingle training process and accomplish each task from context according to thegiven prompt. It can further generalize to new, unseen tasks according tocustomized prompts. To facilitate context perception, we additionally propose atask-unified prompt, which adaptively learns tasks of different natures, suchas partial joint-level generation, sequence-level prediction, or 2D-to-3Dmotion prediction. We conduct extensive experiments to evaluate theeffectiveness of our SiC on multiple tasks, including motion prediction, poseestimation, joint completion, and future pose estimation. We also evaluate itsgeneralization capability on unseen tasks such as motion-in-between. Theseexperiments show that our model achieves state-of-the-art multi-taskperformance and even outperforms single-task methods on certain tasks.",Xinshun Wang,2023/12/6,2023/12/6
0711.3576v1,Testing the RRPP vertex of effective Regge action,http://arxiv.org/abs/0711.3576v1,"In frames of effective Regge action the vertices describing conversion of tworeggeized gluons to one two and three ordinary gluons was constructed. Theself-consistency: Bose symmetry and gauge invariance properties checks wasshown to be fulfilled. The simplest one with creation of a single gluon wasintensively verified in programs of experimental and theoretical treatmentsince it determine the kernel of of the known BFKL equation. Here we discussthe possibility to check the vertex with creation of two real gluons, which canreveal itself in process of scalar mesons production in high energy peripheralnucleons collisions. We show that the mechanisms which include emission of twogluons in the same effective vertex contribution dominate compared with onewith the creation of two separate gluons. Numerical estimations of crosssection of pair of charged pions production for LHC facility give the value ororder $10 mb$. As well we estimate the excess of production of positivelycharged muons (as a decay of pions) created by cosmic ray proton collisionswith the atmosphere gas nuclei to be in a reasonable agreement with moderndata.",E. A. Kuraev,2007/11/23,2007/11/23
0710.0958v1,Response Theory for Equilibrium and Non-Equilibrium Statistical Mechanics: Causality and Generalized Kramers-Kronig relations,http://arxiv.org/abs/0710.0958v1,"We consider the general response theory proposed by Ruelle for describing theimpact of small perturbations to the non-equilibrium steady states resultingfrom Axiom A dynamical systems. We show that the causality of the responsefunctions allows for writing a set of Kramers-Kronig relations for thecorresponding susceptibilities at all orders of nonlinearity. Nonetheless, onlya special class of observable susceptibilities obey Kramers-Kronig relations.Specific results are provided for arbitrary order harmonic response, whichallows for a very comprehensive Kramers-Kronig analysis and the establishmentof sum rules connecting the asymptotic behavior of the susceptibility to theshort-time response of the system. These results generalize previous findingson optical Hamiltonian systems and simple mechanical models, and shed light onthe general impact of considering the principle of causality for testingself-consistency: the described dispersion relations constitute unavoidablebenchmarks for any experimental and model generated dataset. In order toconnect the response theory for equilibrium and non equilibrium systems, werewrite the classical results by Kubo so that response functions formallyidentical to those proposed by Ruelle, apart from the measure involved in thephase space integration, are obtained. We briefly discuss how these results,taking into account the chaotic hypothesis, might be relevant for climateresearch. In particular, whereas the fluctuation-dissipation theorem does notwork for non-equilibrium systems, because of the non-equivalence betweeninternal and external fluctuations, Kramers-Kronig relations might be morerobust tools for the definition of a self-consistent theory of climate change.",Valerio Lucarini,2007/10/4,2007/10/4
1803.04234v1,Green functions and self-consistency: insights from the spherium model,http://arxiv.org/abs/1803.04234v1,"We report an exhaustive study of the performance of different variants ofGreen function methods for the spherium model in which two electrons areconfined to the surface of a sphere and interact via a genuine long-rangeCoulomb operator. We show that the spherium model provides a unique paradigm tostudy electronic correlation effects from the weakly correlated regime to thestrongly correlated regime, since the mathematics are simple while the physicsis rich. We compare perturbative GW, partially self-consistent GW andsecond-order Green function (GF2) methods for the computation of ionizationpotentials, electron affinities, energy gaps, correlation energies as well assinglet and triplet neutral excitations by solving the Bethe-Salpeter equation(BSE). We discuss the problem of self-screening in GW and show that it can bepartially solved with a second-order screened exchange correction (SOSEX). Wefind that, in general, self-consistency deteriorates the results with respectto those obtained within perturbative approaches with a Hartree-Fock startingpoint. Finally, we unveil an important problem of partial self-consistency inGW: in the weakly correlated regime, it can produce artificial discontinuitiesin the self-energy caused by satellite resonances with large weights.",Pierre-Franois Loos,2018/3/12,2018/3/12
2401.11544v1,Hierarchical Prompts for Rehearsal-free Continual Learning,http://arxiv.org/abs/2401.11544v1,"Continual learning endeavors to equip the model with the capability tointegrate current task knowledge while mitigating the forgetting of past taskknowledge. Inspired by prompt tuning, prompt-based methods maintain a frozenbackbone and train with slight learnable prompts to minimize the catastrophicforgetting that arises due to updating a large number of backbone parameters.Nonetheless, these learnable prompts tend to concentrate on the discriminatoryknowledge of the current task while ignoring past task knowledge, leading tothat learnable prompts still suffering from catastrophic forgetting. This paperintroduces a novel rehearsal-free paradigm for continual learning termedHierarchical Prompts (H-Prompts), comprising three categories of prompts --class prompt, task prompt, and general prompt. To effectively depict theknowledge of past classes, class prompt leverages Bayesian DistributionAlignment to model the distribution of classes in each task. To reduce theforgetting of past task knowledge, task prompt employs Cross-task KnowledgeExcavation to amalgamate the knowledge encapsulated in the learned classprompts of past tasks and current task knowledge. Furthermore, general promptutilizes Generalized Knowledge Exploration to deduce highly generalizedknowledge in a self-supervised manner. Evaluations on two benchmarkssubstantiate the efficacy of the proposed H-Prompts, exemplified by an averageaccuracy of 87.8% in Split CIFAR-100 and 70.6% in Split ImageNet-R.",Yukun Zuo,2024/1/21,2024/1/21
2303.13283v1,Visual-Language Prompt Tuning with Knowledge-guided Context Optimization,http://arxiv.org/abs/2303.13283v1,"Prompt tuning is an effective way to adapt the pre-trained visual-languagemodel (VLM) to the downstream task using task-related textual tokens.Representative CoOp-based work combines the learnable textual tokens with theclass tokens to obtain specific textual knowledge. However, the specifictextual knowledge is the worse generalization to the unseen classes because itforgets the essential general textual knowledge having a strong generalizationability. To tackle this issue, we introduce a novel Knowledge-guided ContextOptimization (KgCoOp) to enhance the generalization ability of the learnableprompt for unseen classes. The key insight of KgCoOp is that forgetting aboutessential knowledge can be alleviated by reducing the discrepancy between thelearnable prompt and the hand-crafted prompt. Especially, KgCoOp minimizes thediscrepancy between the textual embeddings generated by learned prompts and thehand-crafted prompts. Finally, adding the KgCoOp upon the contrastive loss canmake a discriminative prompt for both seen and unseen tasks. Extensiveevaluation of several benchmarks demonstrates that the proposedKnowledge-guided Context Optimization is an efficient method for prompt tuning,\emph{i.e.,} achieves better performance with less training time.",Hantao Yao,2023/3/23,2023/3/23
2208.08914v1,Prompt Vision Transformer for Domain Generalization,http://arxiv.org/abs/2208.08914v1,"Though vision transformers (ViTs) have exhibited impressive ability forrepresentation learning, we empirically find that they cannot generalize wellto unseen domains with previous domain generalization algorithms. In thispaper, we propose a novel approach DoPrompt based on prompt learning to embedthe knowledge of source domains in domain prompts for target domain prediction.Specifically, domain prompts are prepended before ViT input tokens from thecorresponding source domain. Each domain prompt learns domain-specificknowledge efficiently since it is optimized only for one domain. Meanwhile, wetrain a prompt adapter to produce a suitable prompt for each input image basedon the learned source domain prompts. At test time, the adapted promptgenerated by the prompt adapter can exploit the similarity between the featureof the out-of-domain image and source domains to properly integrate the sourcedomain knowledge. Extensive experiments are conducted on four benchmarkdatasets. Our approach achieves 1.4% improvements in the averaged accuracy,which is 3.5 times the improvement of the state-of-the-art algorithm with a ViTbackbone.",Zangwei Zheng,2022/8/18,2022/8/18
2305.11497v1,TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding,http://arxiv.org/abs/2305.11497v1,"Prompt tuning has achieved great success in transferring the knowledge fromlarge pretrained vision-language models into downstream tasks, and hasdominated the performance on visual grounding (VG). However, almost allexisting prompt tuning paradigms suffer from poor interpretability. In thispaper, we argue that their poor interpretability is attributed to the holisticprompt generation and inference process. By ""holistic"", we mean that theyusually directly learn a set of vectors as the prompt (i.e., promptgeneration), and use the learned global prompt to augment the textual input forthe VG model (i.e., prompt inference). To this end, we propose a new promptconstruction paradigm with explicit explainable ability, named TreePrompt.Specifically, we first deconstruct a complex sentence into a tree, that isconsistent with human reasoning. Then, following the syntax tree, we compose astructured prompt in a bottom-up manner. Thanks to this step-by-step promptconstruction process, each intermediate prompt (i.e., tree node) permits us tounderstand the reasoning process. Extensive ablations on various backbones andbenchmarks consistently demonstrate the effectiveness and interpretability ofour TreePrompt.",Chenchi Zhang,2023/5/19,2023/5/19
2308.10445v1,When Prompt-based Incremental Learning Does Not Meet Strong Pretraining,http://arxiv.org/abs/2308.10445v1,"Incremental learning aims to overcome catastrophic forgetting when learningdeep networks from sequential tasks. With impressive learning efficiency andperformance, prompt-based methods adopt a fixed backbone to sequential tasks bylearning task-specific prompts. However, existing prompt-based methods heavilyrely on strong pretraining (typically trained on ImageNet-21k), and we findthat their models could be trapped if the potential gap between the pretrainingtask and unknown future tasks is large. In this work, we develop a learnableAdaptive Prompt Generator (APG). The key is to unify the prompt retrieval andprompt learning processes into a learnable prompt generator. Hence, the wholeprompting process can be optimized to reduce the negative effects of the gapbetween tasks effectively. To make our APG avoid learning ineffectiveknowledge, we maintain a knowledge pool to regularize APG with the featuredistribution of each class. Extensive experiments show that our methodsignificantly outperforms advanced methods in exemplar-free incrementallearning without (strong) pretraining. Besides, under strong retraining, ourmethod also has comparable performance to existing prompt-based models, showingthat our method can still benefit from pretraining. Codes can be found athttps://github.com/TOM-tym/APG",Yu-Ming Tang,2023/8/21,2023/8/21
2302.03668v2,Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery,http://arxiv.org/abs/2302.03668v2,"The strength of modern generative models lies in their ability to becontrolled through text-based prompts. Typical ""hard"" prompts are made frominterpretable words and tokens, and must be hand-crafted by humans. There arealso ""soft"" prompts, which consist of continuous feature vectors. These can bediscovered using powerful optimization methods, but they cannot be easilyinterpreted, re-used across models, or plugged into a text-based interface.  We describe an approach to robustly optimize hard text prompts throughefficient gradient-based optimization. Our approach automatically generateshard text-based prompts for both text-to-image and text-to-text applications.In the text-to-image setting, the method creates hard prompts for diffusionmodels, allowing API users to easily generate, discover, and mix and matchimage concepts without prior knowledge on how to prompt the model. In thetext-to-text setting, we show that hard prompts can be automatically discoveredthat are effective in tuning LMs for classification.",Yuxin Wen,2023/2/7,2023/6/1
2309.08008v1,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing,http://arxiv.org/abs/2309.08008v1,"Large language models (LLMs) have shown remarkable capabilities in NaturalLanguage Processing (NLP), especially in domains where labeled data is scarceor expensive, such as clinical domain. However, to unlock the clinicalknowledge hidden in these LLMs, we need to design effective prompts that canguide them to perform specific clinical NLP tasks without any task-specifictraining data. This is known as in-context learning, which is an art andscience that requires understanding the strengths and weaknesses of differentLLMs and prompt engineering approaches. In this paper, we present acomprehensive and systematic experimental study on prompt engineering for fiveclinical NLP tasks: Clinical Sense Disambiguation, Biomedical EvidenceExtraction, Coreference Resolution, Medication Status Extraction, andMedication Attribute Extraction. We assessed the prompts proposed in recentliterature, including simple prefix, simple cloze, chain of thought, andanticipatory prompts, and introduced two new types of prompts, namely heuristicprompting and ensemble prompting. We evaluated the performance of these promptson three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrastedzero-shot prompting with few-shot prompting, and provide novel insights andguidelines for prompt engineering for LLMs in clinical NLP. To the best of ourknowledge, this is one of the first works on the empirical evaluation ofdifferent prompt engineering approaches for clinical NLP in this era ofgenerative AI, and we hope that it will inspire and inform future research inthis area.",Sonish Sivarajkumar,2023/9/14,2023/9/14
2308.16269v1,Can Prompt Learning Benefit Radiology Report Generation?,http://arxiv.org/abs/2308.16269v1,"Radiology report generation aims to automatically provide clinicallymeaningful descriptions of radiology images such as MRI and X-ray. Althoughgreat success has been achieved in natural scene image captioning tasks,radiology report generation remains challenging and requires prior medicalknowledge. In this paper, we propose PromptRRG, a method that utilizes promptlearning to activate a pretrained model and incorporate prior knowledge. Sinceprompt learning for radiology report generation has not been explored before,we begin with investigating prompt designs and categorise them based on varyinglevels of knowledge: common, domain-specific and disease-enriched prompts.Additionally, we propose an automatic prompt learning mechanism to alleviatethe burden of manual prompt engineering. This is the first work tosystematically examine the effectiveness of prompt learning for radiologyreport generation. Experimental results on the largest radiology reportgeneration benchmark, MIMIC-CXR, demonstrate that our proposed method achievesstate-of-the-art performance. Code will be available upon the acceptance.",Jun Wang,2023/8/30,2023/8/30
2204.03489v1,Position-based Prompting for Health Outcome Generation,http://arxiv.org/abs/2204.03489v1,"Probing Pre-trained Language Models (PLMs) using prompts has indirectlyimplied that language models (LMs) can be treated as knowledge bases. To thisend, this phenomena has been effective especially when these LMs are fine-tunedtowards not just data of a specific domain, but also to the style or linguisticpattern of the prompts themselves. We observe that, satisfying a particularlinguistic pattern in prompts is an unsustainable constraint that unnecessarilylengthens the probing task, especially because, they are often manuallydesigned and the range of possible prompt template patterns can vary dependingon the prompting objective and domain. We therefore explore an idea of using aposition-attention mechanism to capture positional information of each word ina prompt relative to the mask to be filled, hence avoiding the need tore-construct prompts when the prompts linguistic pattern changes. Using ourapproach, we demonstrate the ability of eliciting answers to rare prompttemplates (in a case study on health outcome generation) such as Postfix andMixed patterns whose missing information is respectively at the start and inmultiple random places of the prompt. More so, using various biomedical PLMs,our approach consistently outperforms a baseline in which the default masklanguage model (MLM) representation is used to predict masked tokens.",M. Abaho,2022/3/30,2022/3/30
1911.12038v1,Benefitting from the Grey Literature in Software Engineering Research,http://arxiv.org/abs/1911.12038v1,"Researchers generally place the most trust in peer-reviewed, publishedinformation, such as journals and conference papers. By contrast, softwareengineering (SE) practitioners typically do not have the time, access orexpertise to review and benefit from such publications. As a result,practitioners are more likely to turn to other sources of information that theytrust, e.g., trade magazines, online blog-posts, survey results or technicalreports, collectively referred to as Grey Literature (GL). Furthermore,practitioners also share their ideas and experiences as GL, which can serve asa valuable data source for research. While GL itself is not a new topic in SE,using, benefitting and synthesizing knowledge from the GL in SE is acontemporary topic in empirical SE research and we are seeing that researchersare increasingly benefitting from the knowledge available within GL. The goalof this chapter is to provide an overview to GL in SE, together with insightson how SE researchers can effectively use and benefit from the knowledge andevidence available in the vast amount of GL.",Vahid Garousi,2019/11/27,2019/11/27
2210.12587v3,Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning,http://arxiv.org/abs/2210.12587v3,"Prompt tuning approaches, which learn task-specific soft prompts for adownstream task conditioning on frozen pre-trained models, have attractedgrowing interest due to its parameter efficiency. With large language modelsand sufficient training data, prompt tuning performs comparably to full-modeltuning. However, with limited training samples in few-shot settings, prompttuning fails to match the performance of full-model fine-tuning. In this work,we focus on improving the few-shot performance of prompt tuning by transferringknowledge from soft prompts of source tasks. Recognizing the goodgeneralization capabilities of ensemble methods in low-data regime, we firstexperiment and show that a simple ensemble of model predictions based ondifferent source prompts, outperforms existing multi-prompt knowledge transferapproaches such as source prompt fusion in the few-shot setting. Motivated bythis observation, we further investigate model ensembles and proposeSample-specific Ensemble of Source Models (SESoM). SESoM learns to adjust thecontribution of each source model for each target sample separately whenensembling source model outputs. Through this way, SESoM inherits the superiorgeneralization of model ensemble approaches and simultaneously captures thesample-specific competence of each source prompt. We conduct experiments acrossa diverse set of eight NLP tasks using models of different scales (T5-{base,large, XL}) and find that SESoM consistently outperforms the existing models ofthe same as well as larger parametric scale by a large margin.",Xiangyu Peng,2022/10/23,2023/3/1
1407.3896v1,Abduction and Dialogical Proof in Argumentation and Logic Programming,http://arxiv.org/abs/1407.3896v1,"We develop a model of abduction in abstract argumentation, where changes toan argumentation framework act as hypotheses to explain the support of anobservation. We present dialogical proof theories for the main decisionproblems (i.e., finding hypothe- ses that explain skeptical/credulous support)and we show that our model can be instantiated on the basis of abductive logicprograms.",Richard Booth,2014/7/15,2014/7/15
1207.0103v1,First-principles study of native point defects in Bi2Se3,http://arxiv.org/abs/1207.0103v1,"Using first-principles method within the framework of the density functionaltheory, we study the influence of native point defect on the structural andelectronic properties of Bi$_2$Se$_3$. Se vacancy in Bi$_2$Se$_3$ is a doubledonor, and Bi vacancy is a triple acceptor. Se antisite (Se$_{Bi}$) is alwaysan active donor in the system because its donor level ($\varepsilon$(+1/0))enters into the conduction band. Interestingly, Bi antisite(Bi$_{Se1}$) inBi$_2$Se$_3$ is an amphoteric dopant, acting as a donor when$\mu$$_e$$<$0.119eV (the material is typical p-type) and as an acceptor when$\mu$$_e$$>$0.251eV (the material is typical n-type). The formation energiesunder different growth environments (such as Bi-rich or Se-rich) indicate thatunder Se-rich condition, Se$_{Bi}$ is the most stable native defect independentof electron chemical potential $\mu$$_e$. Under Bi-rich condition, Se vacancyis the most stable native defect except for under the growth window as$\mu$$_e$$>$0.262eV (the material is typical n-type) and$\Delta$$\mu$$_{Se}$$<$-0.459eV(Bi-rich), under such growth windows onenegative charged Bi$_{Se1}$ is the most stable one.",L. Xue,2012/6/30,2012/6/30
1603.07260v1,"Resonant levels, vacancies and doping in Bi2Te3, Bi2Te2Se and Bi2Se3 tetradymites",http://arxiv.org/abs/1603.07260v1,"Electronic structures of the tetradymites, Bi$_2$Te$_3$, Bi$_2$Te$_2$Se andBi$_2$Se$_3$, containing various dopants and vacancies, are studied using thefirst principles calculations methods. We focus on the possibility of formationof the resonant levels (RL), confirming the formation of the RL by Sn inBi$_2$Te$_3$, and predicting similar behavior of Sn in Bi$_2$Te$_2$Se andBi$_2$Se$_3$. Vacancies, which are likely present on the chalcogen atoms in thereal samples of Bi$_2$Te$_2$Se and Bi$_2$Se$_3$, are also studied and theircharged donor and resonant behavior is discussed. Doping of thevacancy-containing materials with regular acceptors, like Ca or Mg, is shown tocompensate the donor effect of vacancies, and $n-p$ crossover, while increasingthe dopant concentration, is observed. We verify, that RL on Sn is notdisturbed by the chalcogen vacancies in Bi$_2$Te$_2$Se and Bi$_2$Se$_3$, andfor the Sn-doped materials with Se or Te vacancies, double-doping, instead ofheavy doping with Sn, is suggested as an effective way of reaching the resonantlevel. This should help to avoid the smearing of the RL, which was a possiblereason for an earlier unsuccessful experimental observation of the influence ofthe RL on thermoelectric properties of Sn doped Bi$_2$Te$_2$Se. Finally weshow, that Al and Ga are possible new resonant impurities in the tetradymites,hoping that it will stimulate further experimental studies.",Bartlomiej Wiendlocha,2016/3/23,2016/3/23
1501.01477v1,The emergence of power-law distributions of inter-spike intervals characterizes status epilepticus induced by pilocarpine administration in rats,http://arxiv.org/abs/1501.01477v1,"Objective. To ascertain the existence of power-law distributions ofinter-spike intervals (ISI) occurring during the progression of statusepilepticus (SE), so that the emergence of critical states could be reasonablyhypothesized as being part of the intrinsic nature of the SE. Methods. Statusepilepticus was induced by pilocarpine administration in post-natal 21-day rats(n=8). For each animal, 24 hours of EEG from the onset of the SE were analyzedaccording to the analytical procedure suggested by Clauset et al. (2009) whichcombines maximum-likelihood fitting methods with goodness-of-fit tests based onthe Kolmogorov-Smirnov statistics and likelihood ratios. The analyticalprocedure was implemented by the freely available R software package""poweRlaw"". Time of calculations was considerably shorten by the exploitationof High-Throughput Computing technology, a.k.a. Grid Computing technology.Results. The progression of the SE is characterized by the emergence ofpower-law correlations of ISI whose likelihood of occurrence increases the morethe time from the onset of the SE elapses. Log-normal distribution of ISI ishowever widely represented. Additionally, undetermined distributions of ISI arerepresented as well, although confined within a restricted temporal window. Thefinal stage of SE appears dominated only by power-law and log-normaldistributions of ISI. Significance. The emergence of power-law correlations ofISI concretely supports the concept of the occurrence of critical states duringthe progression of SE. It is reasonably speculated, as a working hypothesis,that the occurrence of power-law distributions of ISI within the early stagesof the SE could be a hallmark of the establishment of the route toepileptogenesis.",Massimo Rizzi,2015/1/7,2015/1/7
mtrl-th/9510001v1,Composition Dependence of the Structure and Electronic Properties of Liquid Ga-Se Alloys Studied by Ab Initio Molecular Dynamics Simulation,http://arxiv.org/abs/mtrl-th/9510001v1,"Ab initio molecular dynamics simulation is used to study the structure andelectronic properties of the liquid Ga-Se system at the three compositionsGa$_2$Se, GaSe and Ga$_2$Se$_3$, and of the GaSe and Ga$_2$Se$_3$ crystals. Thecalculated equilibrium structure of GaSe crystal agrees well with availableexperimental data. The neutron-weighted liquid structure factors calculatedfrom the simulations are in reasonable agreement with recent neutrondiffraction measurements. Simulation results for the partial radialdistribution functions show that the liquid structure is closely related tothat of the crystals. A close similarity between solid and liquid is also foundfor the electronic density of states and charge density. The calculatedelectronic conductivity decreases strongly with increasing Se content, inaccord with experimental measurements.",J. M. Holender,1995/10/2,1995/10/2
2310.06496v1,Spatially resolved photoluminescence analysis of Se passivation and defect formation in CdSe$_{x}$Te$_{1-x}$ thin films,http://arxiv.org/abs/2310.06496v1,"CdTe is the most commercially successful thin-film photovoltaic technology todate. The recent development of Se-alloyed CdSe$_{x}$Te$_{1-x}$ layers in CdTesolar cells has led to higher device efficiencies, due to a lowered bandgapimproving the photocurrent, improved voltage characteristics and longer carrierlifetimes. Evidence from cross-sectional electron microscopy is widely believedto indicate that Se passivates defects in CdSe$_{x}$Te$_{1-x}$ solar cells, andthat this is the reason for better lifetimes and voltages in these devices.Here, we utilise spatially resolved photoluminescence measurements ofCdSe$_{x}$Te$_{1-x}$ thin films on glass to study the effects of Se on carrierrecombination in the material, isolated from the impact of conductiveinterfaces and without the need to prepare cross-sections through the samples.We find further evidence to support Se passivation of grain boundaries, butalso identify an associated increase in below-bandgap photoluminescence thatindicates the presence of Se-enhanced luminescent defects. Our results showthat Se treatment, in tandem with Cl passivation, does increase radiativeefficiencies. However, the simultaneous enhancement of defects within the graininteriors suggests that although it is overall beneficial, Se incorporation maystill ultimately limit the maximum attainable efficiency ofCdSe$_{x}$Te$_{1-x}$ solar cells.",Alan R Bowman,2023/10/10,2023/10/10
1510.01588v2,Noisy intermediate-scale quantum computation with a complete graph of superconducting qubits: Beyond the single-excitation subspace,http://arxiv.org/abs/1510.01588v2,"There is currently a tremendous interest in developing practical applicationsof NISQ processors without the overhead required by full error correction.Quantum information processing is especially challenging within the gate model,as algorithms quickly lose fidelity as the problem size and circuit depth grow.This has lead to a number of non-gate-model approaches such as analog quantumsimulation and quantum annealing. These approaches come with specific hardwarerequirements that are typically different than that of a universal gate-basedquantum computer. We have previously proposed a non-gate-model approach calledthe single-excitation subspace (SES) method, which requires a complete graph ofsuperconducting qubits. Like any approach lacking error correction, the SESmethod is not scalable, but it often leads to algorithms with constant depth,allowing it to outperform the gate model in a wide variety of applications. Achallenge of the SES method is that it requires a physical qubit for everybasis state in the computer's Hilbert space. This imposes large resource costsfor algorithms using registers of ancillary qubits, as each ancilla woulddouble the required graph size. Here we show how to circumvent this doubling byleaving the SES and reintroducing a tensor product structure in thecomputational subspace. Specifically, we implement the tensor product of an SESregister holding ``data"" with one or more ancilla qubits. This enables a hybridform of quantum computation where fast SES operations are performed on thedata, traditional logic gates and measurements are performed on the ancillas,and controlled-unitaries act between. As an application we give an SESimplementation of the quantum linear system solver of Harrow, Hassidim, andLloyd.",Michael R. Geller,2015/10/6,2020/2/1
1412.2012v1,Electron Paramagnetic Resonance of Mn in Bi$_2$Se$_3$ Topological Insulator,http://arxiv.org/abs/1412.2012v1,"Electron paramagnetic resonance was used to investigate Mn impurity inBi$_2$Se$_3$ topological insulator grown by the vertical Bridgman method. Mn inhigh-spin S = 5/2, Mn$^2$$^+$ configuration, was detected regardless of theconductivity type of the host material. This means that Mn$^2$$^+$(d$^5$)energy level is located within the valence band, and Mn$^1$$^+$(d$^6$) energylevel is outside the energy gap of Bi$_2$Se$_3$. The electron paramagneticresonance spectrum of Mn$^2$$^+$ in Bi$_2$Se$_3$ is characterized by theisotropic g-factor |g| = 1.91 and large axial parameter D = -4.20 GHz x h. Thiscorresponds to the zero-field splitting of the Kramers doublets equal to 8.4GHz x h and 16.8 GHz x h, respectively, which is comparable to the Zeemansplitting for the X-band. Mn in Bi$_2$Se$_3$ acts as an acceptor, effectivelyreducing native-high electron concentration, compensating selenium vacancies,and resulting in p-type conductivity.",Agnieszka Wolos,2014/12/5,2014/12/5
2009.06827v1,Strong spin-dephasing in a topological insulator - paramagnet heterostructure,http://arxiv.org/abs/2009.06827v1,"The interface between magnetic materials and topological insulators can drivethe formation of exotic phases of matter and enable functionality throughmanipulation of the strong spin polarized transport. Here, we report that thespin-momentum-locked transport in the topological insulator Bi$_2$Se$_3$ iscompletely suppressed by scattering at a heterointerface with thekagome-lattice paramagnet, Co$_7$Se$_8$.Bi$_2$Se$_{3-}$Co$_7$Se$_{8-}$Bi$_2$Se$_3$ trilayer heterostructures were grownusing molecular beam epitaxy. Magnetotransport measurements revealed asubstantial suppression of the weak antilocalization effect for Co$_7$Se$_8$ atthicknesses as thin as a monolayer, indicating a strong dephasing mechanism.Bi$_{2-x}$Co$_x$Se$_3$ films, where Co is in a non-magnetic $3^+$ state, showweak antilocalization that survives to $x = 0.5$, which, in comparison with theheterostructures, suggests the unordered moments of the Co$^{2+}$ act as a farstronger dephasing element. This work highlights several important pointsregarding spin-polarized transport in topological insulator interfaces and howmagnetic materials can be integrated with topological materials to realize bothexotic phases as well as novel device functionality.",Jason Lapano,2020/9/15,2020/9/15
2208.08442v1,Peculiaridades de la Economia islandesa en los albores del siglo XXI,http://arxiv.org/abs/2208.08442v1,"Se repasa brevemente la historia y las finanzas islandesas de maneradiacr\'onica. Se presenta a Islandia como basti\'on del estallido de la crisisfinanciera internacional que comienza a gestarse a principios del siglo XXI ycuyo origen se hace evidente en la fecha simb\'olica del a\~no 2008. Seanalizan las razones fundamentales de esta crisis, centrandonos en lasparticularidades de la estructura econ\'omica islandesa. Se consideran lasdiferencias y parecidos de esta situaci\'on en relaci\'on a algunos otrospa\'ises en similares circunstancias. Se estudia el caso del banco Icesave. Seconsidera la repercusi\'on que la crisis experimentada por Islandia tiene en el\'ambito internacional, especialmente en los inversores extranjeros y en losconflictos jur\'idicos surgidos a ra\'iz de las medidas adoptadas por elgobierno island\'es para sacar al pa\'is de la bancarrota.  --  Icelandic history and diachronically finances are briefly reviewed. Icelandis presented as a bastion of the outbreak of the global financial crisis beginsto take shape in the early twenty-first century and whose origin is evident inthe symbolic date of 2008. The main reasons for this crisis are analyzed,focusing on the particularities of Iceland's economic structure. Thedifferences and similarities of this in relation to some other countries insimilar circumstances are considered. Bank Icesave case is studied. The impactof the crises experienced by Iceland has in the international arena, especiallyforeign investors and legal disputes arising out of actions taken by theIcelandic government to pull the country out of bankruptcy is considered.",I. Martin-de-Santos,2022/8/17,2022/8/17
1312.7502v1,"Electron capture of strongly screening nuclides $^{56}$Fe, $^{56}$Co, $^{56}$Ni , $^{56}$Mn ,$^{56}$Cr and $^{56}$V in presupernova",http://arxiv.org/abs/1312.7502v1,"According to the Shell-Model Monte Carlo method, basing on the Random PhaseApproximation and the linear response theory, we carried out an estimation onelectron capture of strongly screening nuclides $^{56}$Fe, $^{56}$Co, $^{56}$Ni, $^{56}$Mn ,$^{56}$Cr and $^{56}$V in strong electron screening (SES)inpresupernova. The  EC rates are decreased greatly and even exceed $21.5\%$ in SES. We alsocompare our results with those of Aufderheide (AFUD), which calculated by themethod of Aufderheide in SES. Our results are agreed reasonably well with AUFDat higher density-temperature surroundings (e.g. $\rho_7>60, T_9=15.40$) andthe maximum error is $\sim $0.5$\%$. However, the maximum error is $\sim$13.0$\%$ at lower density surroundings (e.g. $^{56}$Cr at $\rho_7=10,T_9=15.40, Y_e=0.41$ ). On the other hand, we also compared our results in SESwith those of FFN's and Nabi's, which is in the case without SES. Thecomparisons show that our results are lower more than one order magnitude thanFFN's, but about $7.23\%$ than Nabi's.",Jing-Jing Liu,2013/12/29,2013/12/29
1908.09455v1,Review of annealing effects and superconductivity in Fe$_{1+y}$Te$_{1-x}$Se$_x$ superconductors,http://arxiv.org/abs/1908.09455v1,"Fe$_{1+y}$Te$_{1-x}$Se$_x$ is unique in their structural simplicity,consisting of only FeTe/Se layers, which is favorable for probing the mechanismof superconductivity. Recently, a topological surface superconductivity as wellas the Majorana Fermions has been observed, which makesFe$_{1+y}$Te$_{1-x}$Se$_x$ the first high temperature topologicalsuperconductor. Since large size single crystal of Fe$_{1+y}$Te$_{1-x}$Se$_x$can be easily grown, many researches have been performed. However, a large partof the reported results are under controversy, including the resistivity,susceptibility, Hall effect, gap structure, phase diagram, etc. Thesecontroversies are believed to come from the sample-dependent Fenonstoichiometries, which originate from the partial occupation of the secondFe site (excess Fe) in the Te/Se layer. The excess Fe with valence near Fe$^+$will provide electron doping into the system. Meanwhile, the excess Fe is alsostrongly magnetic, which will act as a paring breaker and also localize thecharge carriers. Removing the excess Fe is essential to probe the intrinsicproperties and mechanism of superconductivity of Fe$_{1+y}$Te$_{1-x}$Se$_x$compounds. In this topical review, we propose the effective approaches toremove excess Fe in Fe$_{1+y}$Te$_{1-x}$Se$_x$. Furthermore, we discuss themechanism of annealing based on the evolutions of structure, composition, andmorphology with annealing. Moreover, we also review the annealing effects onthe normal state and superconducting properties, including the magnetism,transport properties, band structure, $T_{\rm{c}}$, phase diagram, uppercritical field, anisotropy, critical current density, gap structure, andsuperconducting pairing. This review presents not only the optimal way toprepare crystals without excess Fe, but also the intrinsic properties ofFe$_{1+y}$Te$_{1-x}$Se$_x$ without the influence of excess Fe.",Yue Sun,2019/8/26,2019/8/26
2005.10739v1,Assessing the Precision and Recall of msTALI as Applied to an Active-Site Study on Fold Families,http://arxiv.org/abs/2005.10739v1,"Proteins execute various activities required by biological cells. Further,they structurally support and pro-mote important biochemical reactions whichfunctionally are sparked by active-sites. Active-sites are regions wherereac-tions and binding events take place directly; they foster pro-teinpurpose. Describing functional relationships depends on factors thatincorporate sequence, structure, and the biochem-ical properties of amino acidsthat form proteins. Our ap-proach to active-site description is computational,and many other approaches utilizing available protein data fall short of ideal.Successful recognition of functional interactions is cru-cial to advancementsin protein annotation and the bioinfor-matics field at large. This researchoutlines our Multiple Structure Torsion Angle Alignment (msTALI) as a suitablestrategy for addressing active-site identification by comparing results toother existing methods. Specifically, we address the precision of msTALI acrossthree protein families. Our target proteins are PDBIDs 1A2B, 1B4V, 1B8S, 1COY,1CXZ, 3COX, 1D7E, 1DPF, 1F9I, 1FTN, 1IJH, 1KOU, 1NWZ, 2PHY, and 1SIC.",Devaun McFarland,2020/5/7,2020/5/7
2003.02674v1,Transferring Axial Molecular Chirality Through a Sequence of On-Surface Reactions,http://arxiv.org/abs/2003.02674v1,"Fine management of chiral processes on solid surfaces has progressed over theyears, yet still faces the need for the controlled and selective production ofadvanced chiral materials. Here, we report on the use of enantiomericallyenriched molecular building blocks to demonstrate the transmission of theirintrinsic chirality along a sequence of on-surface reactions. Triggered bythermal annealing, the on-surface reac-tions induced in this experiment involvefirstly the coupling of the chiral reactants into chiral polymers andsubsequently their transformation into planar prochiral graphene nanoribbons.Our study reveals that the axial chirality of the reactant is not onlytransferred to the polymers, but also to the planar chirality of the graphenenanoribbon end products. Such chirality transfer consequently allows, startingfrom ad-equate enantioenriched reactants, for the controlled production ofchiral and prochiral organic nanoarchi-tectures with pre-defined handedness.",Nstor Merino-Dez,2020/3/5,2020/3/5
2205.11024v2,Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding,http://arxiv.org/abs/2205.11024v2,"Prompt Tuning has been largely successful as a parameter-efficient method ofconditioning large-scale pre-trained language models to perform downstreamtasks. Thus far, soft prompt tuning learns a fixed set of task-specificcontinuous vectors, i.e., soft tokens that remain static across the tasksamples. A fixed prompt, however, may not generalize well to the diverse kindsof inputs the task comprises. In order to address this, we proposeVector-quantized Input-contextualized Prompts (VIP) as an extension to the softprompt tuning framework. VIP particularly focuses on two aspects -- contextualprompts that learns input-specific contextualization of the soft prompt tokensthrough a small-scale sentence encoder and quantized prompts that maps thecontextualized prompts to a set of learnable codebook vectors through a Vectorquantization network. On various language understanding tasks like SuperGLUE,QA, Relation classification, NER and NLI, VIP outperforms the soft prompttuning (PT) baseline by an average margin of 1.19%. Further, our generalizationstudies show that VIP learns more robust prompt representations, surpassing PTby a margin of 0.6% - 5.3% on Out-of-domain QA and NLI tasks respectively, andby 0.75% on Multi-Task setup over 4 tasks spanning across 12 domains.",Rishabh Bhardwaj,2022/5/23,2022/10/22
2307.00910v2,CoPL: Contextual Prompt Learning for Vision-Language Understanding,http://arxiv.org/abs/2307.00910v2,"Recent advances in multimodal learning has resulted in powerfulvision-language models, whose representations are generalizable across avariety of downstream tasks. Recently, their generalization ability has beenfurther extended by incorporating trainable prompts, borrowed from the naturallanguage processing literature. While such prompt learning techniques haveshown impressive results, we identify that these prompts are trained based onglobal image features which limits itself in two aspects: First, by usingglobal features, these prompts could be focusing less on the discriminativeforeground image, resulting in poor generalization to variousout-of-distribution test cases. Second, existing work weights all promptsequally whereas intuitively, prompts should be reweighed according to thesemantics of the image. We address these as part of our proposed ContextualPrompt Learning (CoPL) framework, capable of aligning the prompts to thelocalized features of the image. Our key innovations over earlier works includeusing local image features as part of the prompt learning process, and morecrucially, learning to weight these prompts based on local features that areappropriate for the task at hand. This gives us dynamic prompts that are bothaligned to local image features as well as aware of local contextualrelationships. Our extensive set of experiments on a variety of standard andfew-shot datasets show that our method produces substantially improvedperformance when compared to the current state of the art methods. We alsodemonstrate both few-shot and out-of-distribution performance to establish theutility of learning dynamic prompts that are aligned to local image features.",Koustava Goswami,2023/7/3,2023/12/12
2306.03435v1,On the Role of Attention in Prompt-tuning,http://arxiv.org/abs/2306.03435v1,"Prompt-tuning is an emerging strategy to adapt large language models (LLM) todownstream tasks by learning a (soft-)prompt parameter from data. Despite itssuccess in LLMs, there is limited theoretical understanding of the power ofprompt-tuning and the role of the attention mechanism in prompting. In thiswork, we explore prompt-tuning for one-layer attention architectures and studycontextual mixture-models where each input token belongs to a context-relevantor -irrelevant set. We isolate the role of prompt-tuning through aself-contained prompt-attention model. Our contributions are as follows: (1) Weshow that softmax-prompt-attention is provably more expressive thansoftmax-self-attention and linear-prompt-attention under our contextual datamodel. (2) We analyze the initial trajectory of gradient descent and show thatit learns the prompt and prediction head with near-optimal sample complexityand demonstrate how prompt can provably attend to sparse context-relevanttokens. (3) Assuming a known prompt but an unknown prediction head, wecharacterize the exact finite sample performance of prompt-attention whichreveals the fundamental performance limits and the precise benefit of thecontext information. We also provide experiments that verify our theoreticalinsights on real datasets and demonstrate how prompt-tuning enables the modelto attend to context-relevant information.",Samet Oymak,2023/6/6,2023/6/6
2011.07442v5,Improving Speech Enhancement Performance by Leveraging Contextual Broad Phonetic Class Information,http://arxiv.org/abs/2011.07442v5,"Previous studies have confirmed that by augmenting acoustic features with theplace/manner of articulatory features, the speech enhancement (SE) process canbe guided to consider the broad phonetic properties of the input speech whenperforming enhancement to attain performance improvements. In this paper, weexplore the contextual information of articulatory attributes as additionalinformation to further benefit SE. More specifically, we propose to improve theSE performance by leveraging losses from an end-to-end automatic speechrecognition (E2E-ASR) model that predicts the sequence of broad phoneticclasses (BPCs). We also developed multi-objective training with ASR andperceptual losses to train the SE system based on a BPC-based E2E-ASR.Experimental results from speech denoising, speech dereverberation, andimpaired speech enhancement tasks confirmed that contextual BPC informationimproves SE performance. Moreover, the SE model trained with the BPC-basedE2E-ASR outperforms that with the phoneme-based E2E-ASR. The results suggestthat objectives with misclassification of phonemes by the ASR system may leadto imperfect feedback, and BPC could be a potentially better choice. Finally,it is noted that combining the most-confusable phonetic targets into the sameBPC when calculating the additional objective can effectively improve the SEperformance.",Yen-Ju Lu,2020/11/15,2023/6/18
2201.08670v2,Context-Tuning: Learning Contextualized Prompts for Natural Language Generation,http://arxiv.org/abs/2201.08670v2,"Recently, pretrained language models (PLMs) have had exceptional success inlanguage generation. To leverage the rich knowledge encoded by PLMs, a simpleyet powerful paradigm is to use prompts in the form of either discrete tokensor continuous embeddings. In existing studies, these prompting methods aretypically independent of the inputs, lacking sufficient consideration of inputsemantics. To address this issue, we propose a novel continuous promptingapproach, called context-tuning, to fine-tuning PLMs for natural languagegeneration. Firstly, the prompts are derived based on the input text to elicituseful knowledge from PLMs for generation. We refer to such prompts ascontextualized prompts. Secondly, we use continuous inverse prompting toimprove the process of natural language generation by modeling an inversegeneration process from output to input, making the generated text morerelevant to the inputs. Furthermore, we utilize a lightweight context-tuningmethod that fine-tunes only 0.12% of the parameters while maintaining goodperformance. Our code is publicly available athttps://github.com/RUCAIBox/Context-Tuning.",Tianyi Tang,2022/1/21,2022/10/3
2302.04156v1,Prompting for Multimodal Hateful Meme Classification,http://arxiv.org/abs/2302.04156v1,"Hateful meme classification is a challenging multimodal task that requirescomplex reasoning and contextual background knowledge. Ideally, we couldleverage an explicit external knowledge base to supplement contextual andcultural information in hateful memes. However, there is no known explicitexternal knowledge base that could provide such hate speech contextualinformation. To address this gap, we propose PromptHate, a simple yet effectiveprompt-based model that prompts pre-trained language models (PLMs) for hatefulmeme classification. Specifically, we construct simple prompts and provide afew in-context examples to exploit the implicit knowledge in the pre-trainedRoBERTa language model for hateful meme classification. We conduct extensiveexperiments on two publicly available hateful and offensive meme datasets. Ourexperimental results show that PromptHate is able to achieve a high AUC of90.96, outperforming state-of-the-art baselines on the hateful memeclassification task. We also perform fine-grained analyses and case studies onvarious prompt settings and demonstrate the effectiveness of the prompts onhateful meme classification.",Rui Cao,2023/2/8,2023/2/8
1911.06448v1,Hypergraph Contextuality,http://arxiv.org/abs/1911.06448v1,"Quantum contextuality is a source of quantum computational power and atheoretical delimiter between classical and quantum structures. It has beensubstantiated by numerous experiments and prompted generation of stateindependent contextual sets, that is, sets of quantum observables capable ofrevealing quantum contextuality for any quantum state of a given dimension.There are two major classes of state-independent contextual sets - theKochen-Specker ones and the operator-based ones. In this paper, we present athird, hypergraph-based class of contextual sets. Hypergraph inequalities serveas a measure of contextuality. We limit ourselves to qutrits and obtainthousands of 3-dim contextual sets. The simplest of them involves only 5quantum observables, thus enabling a straightforward implementation. They alsoenable establishing new entropic contextualities.",Mladen Pavicic,2019/11/15,2019/11/15
2303.09792v2,Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction,http://arxiv.org/abs/2303.09792v2,"The visual prompts have provided an efficient manner in addressing visualcross-domain problems. In previous works, Visual Domain Prompt (VDP) firstintroduces domain prompts to tackle the classification Test-Time Adaptation(TTA) problem by warping image-level prompts on the input and fine-tuningprompts for each target domain. However, since the image-level prompts mask outcontinuous spatial details in the prompt-allocated region, it will suffer frominaccurate contextual information and limited domain knowledge extraction,particularly when dealing with dense prediction TTA problems. To overcome thesechallenges, we propose a novel Sparse Visual Domain Prompts (SVDP) approach,which holds minimal trainable parameters (e.g., 0.1\%) in the image-levelprompt and reserves more spatial information of the input. To better apply SVDPin extracting domain-specific knowledge, we introduce the Domain PromptPlacement (DPP) method to adaptively allocates trainable parameters of SVDP onthe pixels with large distribution shifts. Furthermore, recognizing that eachtarget domain sample exhibits a unique domain shift, we design Domain PromptUpdating (DPU) strategy to optimize prompt parameters differently for eachsample, facilitating efficient adaptation to the target domain. Extensiveexperiments were conducted on widely-used TTA and continual TTA benchmarks, andour proposed method achieves state-of-the-art performance in both semanticsegmentation and depth estimation tasks.",Senqiao Yang,2023/3/17,2023/10/2
2305.06221v3,Multi-Prompt with Depth Partitioned Cross-Modal Learning,http://arxiv.org/abs/2305.06221v3,"In recent years, soft prompt learning methods have been proposed to fine-tunelarge-scale vision-language pre-trained models for various downstream tasks.These methods typically combine learnable textual tokens with class tokens asinput for models with frozen parameters. However, they often employ a singleprompt to describe class contexts, failing to capture categories' diverseattributes adequately. This study introduces the Partitioned Multi-modal Prompt(PMPO), a multi-modal prompting technique that extends the soft prompt from asingle learnable prompt to multiple prompts. Our method divides the visualencoder depths and connects learnable prompts to the separated visual depths,enabling different prompts to capture the hierarchical contextual depths ofvisual representations. Furthermore, to maximize the advantages of multi-promptlearning, we incorporate prior information from manually designed templates andlearnable multi-prompts, thus improving the generalization capabilities of ourapproach. We evaluate the effectiveness of our approach on three challengingtasks: new class generalization, cross-dataset evaluation, and domaingeneralization. For instance, our method achieves a $79.28$ harmonic mean,averaged over 11 diverse image recognition datasets ($+7.62$ compared to CoOp),demonstrating significant competitiveness compared to state-of-the-artprompting methods.",Yingjie Tian,2023/5/10,2023/9/5
2310.18167v1,MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension,http://arxiv.org/abs/2310.18167v1,"The large language models have achieved superior performance on variousnatural language tasks. One major drawback of such approaches is they areresource-intensive in fine-tuning new datasets. Soft-prompt tuning presents aresource-efficient solution to fine-tune the pre-trained language models (PLMs)while keeping their weight frozen. Existing soft prompt methods mainly focus ondesigning the input-independent prompts that steer the model to fit the domainof the new dataset. Those methods often ignore the fine-grained informationabout the task and context of the text. In this paper, we propose a multi-levelprompt tuning (MPrompt) method for machine reading comprehension. It utilizesprompts at task-specific, domain-specific, and context-specific levels toenhance the comprehension of input semantics at different granularities. Wealso propose an independence constraint to steer each domain-specific prompt tofocus on information within its domain to avoid redundancy. Moreover, wepresent a prompt generator that incorporates context-related knowledge in theprompt generation to enhance contextual relevancy. We conducted extensiveexperiments on 12 benchmarks of various QA formats and achieved an averageimprovement of 1.94\% over the state-of-the-art methods.",Guoxin Chen,2023/10/27,2023/10/27
2309.07414v2,PromptASR for contextualized ASR with controllable style,http://arxiv.org/abs/2309.07414v2,"Prompts are crucial to large language models as they provide contextinformation such as topic or logical relationships. Inspired by this, wepropose PromptASR, a framework that integrates prompts in end-to-end automaticspeech recognition (E2E ASR) systems to achieve contextualized ASR withcontrollable style of transcriptions. Specifically, a dedicated text encoderencodes the text prompts and the encodings are injected into the speech encoderby cross-attending the features from two modalities. When using the groundtruth text from preceding utterances as content prompt, the proposed systemachieves 21.9% and 6.8% relative word error rate reductions on a book readingdataset and an in-house dataset compared to a baseline ASR system. The systemcan also take word-level biasing lists as prompt to improve recognitionaccuracy on rare words. An additional style prompt can be given to the textencoder and guide the ASR system to output different styles of transcriptions.The code is available at icefall.",Xiaoyu Yang,2023/9/14,2023/9/20
2301.13268v2,Contextual Dynamic Prompting for Response Generation in Task-oriented Dialog Systems,http://arxiv.org/abs/2301.13268v2,"Response generation is one of the critical components in task-oriented dialogsystems. Existing studies have shown that large pre-trained language models canbe adapted to this task. The typical paradigm of adapting such extremely largelanguage models would be by fine-tuning on the downstream tasks which is notonly time-consuming but also involves significant resources and access tofine-tuning data. Prompting (Schick and Sch\""utze, 2020) has been analternative to fine-tuning in many NLP tasks. In our work, we explore the ideaof using prompting for response generation in task-oriented dialog systems.Specifically, we propose an approach that performs contextual dynamic promptingwhere the prompts are learnt from dialog contexts. We aim to distill usefulprompting signals from the dialog context. On experiments with MultiWOZ 2.2dataset (Zang et al., 2020), we show that contextual dynamic prompts improveresponse generation in terms of combined score (Mehri et al., 2019) by 3absolute points, and a massive 20 points when dialog states are incorporated.Furthermore, human annotation on these conversations found that agents whichincorporate context were preferred over agents with vanilla prefix-tuning.",Sandesh Swamy,2023/1/30,2023/2/10
2310.04438v2,A Brief History of Prompt: Leveraging Language Models. (Through Advanced Prompting),http://arxiv.org/abs/2310.04438v2,"This paper presents a comprehensive exploration of the evolution of promptengineering and generation in the field of natural language processing (NLP).Starting from the early language models and information retrieval systems, wetrace the key developments that have shaped prompt engineering over the years.The introduction of attention mechanisms in 2015 revolutionized languageunderstanding, leading to advancements in controllability andcontext-awareness. Subsequent breakthroughs in reinforcement learningtechniques further enhanced prompt engineering, addressing issues like exposurebias and biases in generated text. We examine the significant contributions in2018 and 2019, focusing on fine-tuning strategies, control codes, andtemplate-based generation. The paper also discusses the growing importance offairness, human-AI collaboration, and low-resource adaptation. In 2020 and2021, contextual prompting and transfer learning gained prominence, while 2022and 2023 witnessed the emergence of advanced techniques like unsupervisedpre-training and novel reward shaping. Throughout the paper, we referencespecific research studies that exemplify the impact of various developments onprompt engineering. The journey of prompt engineering continues, with ethicalconsiderations being paramount for the responsible and inclusive future of AIsystems.",Golam Md Muktadir,2023/9/30,2023/11/28
2311.05114v1,Prompt Your Mind: Refine Personalized Text Prompts within Your Mind,http://arxiv.org/abs/2311.05114v1,"Large language models (LLMs) have demonstrated remarkable potential innatural language understanding and generation, making them valuable tools forenhancing conversational interactions. However, LLMs encounter challenges suchas lacking multi-step reasoning capabilities, and heavy reliance on prompts. Inthis regard, we introduce a prompt-refinement system named PromptMind, alsoknown as ""Prompt Your Mind"", to provide an automated solution for generatingcontextually relevant prompts during conversations. PromptMind enhances theoverall interaction between humans and chatbots through an automatic promptsuggestion and an automatic prompt refinement. To assess the effectiveness ofPromptMind, we designed three interaction tasks to evaluate emotional support,advice acquisition, and task-oriented interactions during human-chatbotinteractions. The results demonstrated that PromptMind reduced mental demandsduring interactions and fostered enhanced performance and social connectionsbetween users and chatbots. In summary, our findings indicate that PromptMindacts as a bridge, facilitating smoother information exchange and enhancing theusability of chatbot interactions.",Guinan Su,2023/11/9,2023/11/9
2311.07115v1,Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions,http://arxiv.org/abs/2311.07115v1,"Language model (LM) prompting--a popular paradigm for solving NLP tasks--hasbeen shown to be susceptible to miscalibration and brittleness to slight promptvariations, caused by its discriminative prompting approach, i.e., predictingthe label given the input. To address these issues, we propose Gen-Z--agenerative prompting framework for zero-shot text classification. GEN-Z isgenerative, as it measures the LM likelihood of input text, conditioned onnatural language descriptions of labels. The framework is multivariate, aslabel descriptions allow us to seamlessly integrate additional contextualinformation about the labels to improve task performance. On various standardclassification benchmarks, with six open-source LM families, we show thatzero-shot classification with simple contextualization of the data source ofthe evaluation set consistently outperforms both zero-shot and few-shotbaselines while improving robustness to prompt variations. Further, ourapproach enables personalizing classification in a zero-shot manner byincorporating author, subject, or reader information in the label descriptions.",Sachin Kumar,2023/11/13,2023/11/13
2312.08878v1,Domain Prompt Learning with Quaternion Networks,http://arxiv.org/abs/2312.08878v1,"Prompt learning has emerged as an effective and data-efficient technique inlarge Vision-Language Models (VLMs). However, when adapting VLMs to specializeddomains such as remote sensing and medical imaging, domain prompt learningremains underexplored. While large-scale domain-specific foundation models canhelp tackle this challenge, their concentration on a single vision level makesit challenging to prompt both vision and language modalities. To overcome this,we propose to leverage domain-specific knowledge from domain-specificfoundation models to transfer the robust recognition ability of VLMs fromgeneralized to specialized domains, using quaternion networks. Specifically,the proposed method involves using domain-specific vision features fromdomain-specific foundation models to guide the transformation of generalizedcontextual embeddings from the language branch into a specialized space withinthe quaternion networks. Moreover, we present a hierarchical approach thatgenerates vision prompt features by analyzing intermodal relationships betweenhierarchical language prompt features and domain-specific vision features. Inthis way, quaternion networks can effectively mine the intermodal relationshipsin the specific domain, facilitating domain-specific vision-languagecontrastive learning. Extensive experiments on domain-specific datasets showthat our proposed method achieves new state-of-the-art results in promptlearning.",Qinglong Cao,2023/12/12,2023/12/12
2203.14104v1,Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos,http://arxiv.org/abs/2203.14104v1,"Action recognition models have shown a promising capability to classify humanactions in short video clips. In a real scenario, multiple correlated humanactions commonly occur in particular orders, forming semantically meaningfulhuman activities. Conventional action recognition approaches focus on analyzingsingle actions. However, they fail to fully reason about the contextualrelations between adjacent actions, which provide potential temporal logic forunderstanding long videos. In this paper, we propose a prompt-based framework,Bridge-Prompt (Br-Prompt), to model the semantics across adjacent actions, sothat it simultaneously exploits both out-of-context and contextual informationfrom a series of ordinal actions in instructional videos. More specifically, wereformulate the individual action labels as integrated text prompts forsupervision, which bridge the gap between individual action semantics. Thegenerated text prompts are paired with corresponding video clips, and togetherco-train the text encoder and the video encoder via a contrastive approach. Thelearned vision encoder has a stronger capability for ordinal-action-relateddownstream tasks, e.g. action segmentation and human activity recognition. Weevaluate the performances of our approach on several video datasets: GeorgiaTech Egocentric Activities (GTEA), 50Salads, and the Breakfast dataset.Br-Prompt achieves state-of-the-art on multiple benchmarks. Code is availableat https://github.com/ttlmh/Bridge-Prompt",Muheng Li,2022/3/26,2022/3/26
2312.03734v1,Conditional Prompt Tuning for Multimodal Fusion,http://arxiv.org/abs/2312.03734v1,"We show that the representation of one modality can effectively guide theprompting of another modality for parameter-efficient multimodal fusion.Specifically, we first encode one modality and use its representation as aprior to conditionally prompt all frozen layers of the other modality. This isachieved by disentangling the vanilla prompt vectors into three types ofspecialized prompts that adaptively capture global-level and instance-levelfeatures. To better produce the instance-wise prompt, we introduce the mixtureof prompt experts (MoPE) to dynamically route each instance to the mostsuitable prompt experts for encoding. We further study a regularization term toavoid degenerated prompt expert routing. Thanks to our design, our method caneffectively transfer the pretrained knowledge in unimodal encoders fordownstream multimodal tasks. Compared with vanilla prompting, we show that ourMoPE-based conditional prompting is more expressive, thereby scales better withtraining data and the total number of prompts. We also demonstrate that ourprompt tuning is architecture-agnostic, thereby offering high modularity.Extensive experiments over three multimodal datasets demonstratestate-of-the-art results, matching or surpassing the performance achievedthrough fine-tuning, while only necessitating 0.7% of the trainable parameters.Code will be released: https://github.com/songrise/ConditionalPrompt.",Ruixiang Jiang,2023/11/28,2023/11/28
mtrl-th/9506002v2,Complex ion formation in liquid Ag-Se alloys,http://arxiv.org/abs/mtrl-th/9506002v2,"Ab initio molecular dynamics simulations are used to investigate thestructure and electronic properties of the liquid Ag-Se system at threecompositions. The realism of the simulations is demonstrated by comparison withdiffraction data for the stoichiometric case Ag$_2$Se. As the Se content isincreased beyond the stoichiometric value, short-lived Se$_n$ complexes areformed. The concentration of complexes and the associated changes of electronicstructure can be explained using a simple ionic model.",F. Kirchhoff,1995/6/13,1995/6/14
2308.10444v1,Dynamic Strategy Chain: Dynamic Zero-Shot CoT for Long Mental Health Support Generation,http://arxiv.org/abs/2308.10444v1,"Long counseling Text Generation for Mental health support (LTGM), aninnovative and challenging task, aims to provide help-seekers with mentalhealth support through a comprehensive and more acceptable response. Thecombination of chain-of-thought (CoT) prompting and Large Language Models(LLMs) is employed and get the SOTA performance on various NLP tasks,especially on text generation tasks. Zero-shot CoT prompting is one of the mostcommon methods in CoT prompting. However, in the LTGM task, Zero-shot CoTprompting can not simulate a counselor or provide personalized strategieswithout effective mental health counseling strategy prompts. To tackle thischallenge, we propose a zero-shot Dynamic Strategy Chain (DSC) promptingmethod. Firstly, we utilize GPT2 to learn the responses written by mentalhealth counselors and dynamically generate mental health counseling strategiestailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting isconstructed according to mental health counseling strategies and thehelp-seekers' post. Finally, the Zero-shot DSC prompting is employed to guideLLMs in generating more human-like responses for the help-seekers. Bothautomatic and manual evaluations demonstrate that Zero-shot DSC prompting candeliver more human-like responses than CoT prompting methods on LTGM tasks.",Qi Chen,2023/8/21,2023/8/21
2303.08138v1,Diversity-Aware Meta Visual Prompting,http://arxiv.org/abs/2303.08138v1,"We present Diversity-Aware Meta Visual Prompting~(DAM-VP), an efficient andeffective prompting method for transferring pre-trained models to downstreamtasks with frozen backbone. A challenging issue in visual prompting is thatimage datasets sometimes have a large data diversity whereas a per-datasetgeneric prompt can hardly handle the complex distribution shift toward theoriginal pretraining data distribution properly. To address this issue, wepropose a dataset Diversity-Aware prompting strategy whose initialization isrealized by a Meta-prompt. Specifically, we cluster the downstream dataset intosmall homogeneity subsets in a diversity-adaptive way, with each subset has itsown prompt optimized separately. Such a divide-and-conquer design reduces theoptimization difficulty greatly and significantly boosts the promptingperformance. Furthermore, all the prompts are initialized with a meta-prompt,which is learned across several datasets. It is a bootstrapped paradigm, withthe key observation that the prompting knowledge learned from previous datasetscould help the prompt to converge faster and perform better on a new dataset.During inference, we dynamically select a proper prompt for each input, basedon the feature distance between the input and each subset. Through extensiveexperiments, our DAM-VP demonstrates superior efficiency and effectiveness,clearly surpassing previous prompting methods in a series of downstreamdatasets for different pretraining models. Our code is available at:\url{https://github.com/shikiw/DAM-VP}.",Qidong Huang,2023/3/14,2023/3/14
2212.10539v1,"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?",http://arxiv.org/abs/2212.10539v1,"Large language models can perform new tasks in a zero-shot fashion, givennatural language prompts that specify the desired behavior. Such prompts aretypically hand engineered, but can also be learned with gradient-based methodsfrom labeled data. However, it is underexplored what factors make the promptseffective, especially when the prompts are natural language. In this paper, weinvestigate common attributes shared by effective prompts. We first propose ahuman readable prompt tuning method (F LUENT P ROMPT) based on Langevindynamics that incorporates a fluency constraint to find a diverse distributionof effective and fluent prompts. Our analysis reveals that effective promptsare topically related to the task domain and calibrate the prior probability oflabel words. Based on these findings, we also propose a method for generatingprompts using only unlabeled data, outperforming strong baselines by an averageof 7.0% accuracy across three tasks.",Weijia Shi,2022/12/20,2022/12/20
2205.07220v1,Adaptive Prompt Learning-based Few-Shot Sentiment Analysis,http://arxiv.org/abs/2205.07220v1,"In the field of natural language processing, sentiment analysis via deeplearning has a excellent performance by using large labeled datasets.Meanwhile, labeled data are insufficient in many sentiment analysis, andobtaining these data is time-consuming and laborious. Prompt learning devotesto resolving the data deficiency by reformulating downstream tasks with thehelp of prompt. In this way, the appropriate prompt is very important for theperformance of the model. This paper proposes an adaptive prompting(AP)construction strategy using seq2seq-attention structure to acquire the semanticinformation of the input sequence. Then dynamically construct adaptive promptwhich can not only improve the quality of the prompt, but also can effectivelygeneralize to other fields by pre-trained prompt which is constructed byexisting public labeled data. The experimental results on FewCLUE datasetsdemonstrate that the proposed method AP can effectively construct appropriateadaptive prompt regardless of the quality of hand-crafted prompt and outperformthe state-of-the-art baselines.",Pengfei Zhang,2022/5/15,2022/5/15
astro-ph/0211194v2,Shock Breakout in Core-Collapse Supernovae and its Neutrino Signature,http://arxiv.org/abs/astro-ph/0211194v2,"(Abridged) We present results from dynamical models of core-collapsesupernovae in one spatial dimension, employing a newly-developed Boltzmannneutrino radiation transport algorithm, coupled to Lagrangean hydrodynamics anda consistent high-density nuclear equation of state. We focus on shock breakoutand its neutrino signature and follow the dynamical evolution of the cores of11 M_sun, 15 M_sun, and 20 M_sun progenitors through collapse and the first 250milliseconds after bounce. We examine the effects on the emergent neutrinospectra, light curves, and mix of species of artificial opacity changes, thenumber of energy groups, the weak magnetism/recoil corrections, nucleon-nucleonbremsstrahlung, neutrino-electron scattering, and the compressibility ofnuclear matter. Furthermore, we present the first high-resolution look at theangular distribution of the neutrino radiation field both in thesemi-transparent regime and at large radii and explore the accuracy with whichour tangent-ray method tracks the free propagation of a pulse of radiation in anear vacuum. Finally, we fold the emergent neutrino spectra with theefficiencies and detection processes for a selection of modern undergroundneutrino observatories and argue that the prompt electron-neutrino breakoutburst from the next galactic supernova is in principle observable and usefullydiagnostic of fundamental collapse/supernova behavior. Though we are not inthis study focusing on the supernova mechanism per se, our simulations supportthe theoretical conclusion (already reached by others) that spherical (1D)supernovae do not explode when good physics and transport methods are employed.",Todd A. Thompson,2002/11/10,2003/4/2
2303.02909v2,Dynamic Prompting: A Unified Framework for Prompt Tuning,http://arxiv.org/abs/2303.02909v2,"It has been demonstrated that the art of prompt tuning is highly effective inefficiently extracting knowledge from pretrained foundation models,encompassing pretrained language models (PLMs), vision pretrained models, andvision-language (V-L) models. However, the efficacy of employing fixed softprompts with a predetermined position for concatenation with inputs for allinstances, irrespective of their inherent disparities, remains uncertain.Variables such as the position, length, and representations of prompts acrossdiverse instances and tasks can substantially influence the performance ofprompt tuning. In this context, we provide a theoretical analysis, whichreveals that optimizing the position of the prompt to encompass the input cancapture additional semantic information that traditional prefix or postfixprompt tuning methods fail to capture. Building upon our analysis, we present aunified dynamic prompt (DP) tuning strategy that dynamically determinesdifferent factors of prompts based on specific tasks and instances. Toaccomplish this, we employ a lightweight learning network with Gumble-Softmax,allowing us to learn instance-dependent guidance. Experimental resultsunderscore the significant performance improvement achieved by dynamic prompttuning across a wide range of tasks, including NLP tasks, vision recognitiontasks, and vision-language tasks. Furthermore, we establish the universalapplicability of our approach under full-data, few-shot, and multitaskscenarios. Codes are available at https://github.com/Xianjun-Yang/DPT.",Xianjun Yang,2023/3/6,2023/5/27
1701.02578v2,Multiprocessor Approximate Message Passing with Column-Wise Partitioning,http://arxiv.org/abs/1701.02578v2,"Solving a large-scale regularized linear inverse problem using multipleprocessors is important in various real-world applications due to thelimitations of individual processors and constraints on data sharing policies.This paper focuses on the setting where the matrix is partitioned column-wise.We extend the algorithmic framework and the theoretical analysis of approximatemessage passing (AMP), an iterative algorithm for solving linear inverseproblems, whose asymptotic dynamics are characterized by state evolution (SE).In particular, we show that column-wise multiprocessor AMP (C-MP-AMP) obeys anSE under the same assumptions when the SE for AMP holds. The SE results implythat (i) the SE of C-MP-AMP converges to a state that is no worse than that ofAMP and (ii) the asymptotic dynamics of C-MP-AMP and AMP can be identical.Moreover, for a setting that is not covered by SE, numerical results show thatdamping can improve the convergence performance of C-MP-AMP.",Yanting Ma,2017/1/10,2017/1/30
2008.11920v2,Dynamic Noise Embedding: Noise Aware Training and Adaptation for Speech Enhancement,http://arxiv.org/abs/2008.11920v2,"Estimating noise information exactly is crucial for noise aware training inspeech applications including speech enhancement (SE) which is our focus inthis paper. To estimate noise-only frames, we employ voice activity detection(VAD) to detect non-speech frames by applying optimal threshold on speechposterior. Here, the non-speech frames can be regarded as noise-only frames innoisy signal. These estimated frames are used to extract noise embedding, nameddynamic noise embedding (DNE), which is useful for an SE module to capture thecharacteristic of background noise. The DNE is extracted by a simple neuralnetwork, and the SE module with the DNE can be jointly trained to be adaptiveto the environment. Experiments are conducted on TIMIT dataset forsingle-channel denoising task and U-Net is used as a backbone SE module.Experimental results show that the DNE plays an important role in the SE moduleby increasing the quality and the intelligibility of corrupted signal even ifthe noise is non-stationary and unseen in training. In addition, we demonstratethat the DNE can be flexibly applied to other neural network-based SE modules.",Joohyung Lee,2020/8/27,2020/12/3
2005.12661v2,DAG-Net: Double Attentive Graph Neural Network for Trajectory Forecasting,http://arxiv.org/abs/2005.12661v2,"Understanding human motion behaviour is a critical task for several possibleapplications like self-driving cars or social robots, and in general for allthose settings where an autonomous agent has to navigate inside a human-centricenvironment. This is non-trivial because human motion is inherentlymulti-modal: given a history of human motion paths, there are many plausibleways by which people could move in the future. Additionally, people activitiesare often driven by goals, e.g. reaching particular locations or interactingwith the environment. We address the aforementioned aspects by proposing a newrecurrent generative model that considers both single agents' future goals andinteractions between different agents. The model exploits a doubleattention-based graph neural network to collect information about the mutualinfluences among different agents and to integrate it with data about agents'possible future objectives. Our proposal is general enough to be applied todifferent scenarios: the model achieves state-of-the-art results in both urbanenvironments and also in sports applications.",Alessio Monti,2020/5/26,2020/10/23
1712.09550v2,Active Search for High Recall: a Non-Stationary Extension of Thompson Sampling,http://arxiv.org/abs/1712.09550v2,"We consider the problem of Active Search, where a maximum of relevant objects- ideally all relevant objects - should be retrieved with the minimum effort orminimum time. Typically, there are two main challenges to face when tacklingthis problem: first, the class of relevant objects has often low prevalenceand, secondly, this class can be multi-faceted or multi-modal: objects could berelevant for completely different reasons. To solve this problem and itsassociated issues, we propose an approach based on a non-stationary (akarestless) extension of Thompson Sampling, a well-known strategy for Multi-ArmedBandits problems. The collection is first soft-clustered into a finite set ofcomponents and a posterior distribution of getting a relevant object insideeach cluster is updated after receiving the user feedback about the proposedinstances. The ""next instance"" selection strategy is a mixed, two-leveldecision process, where both the soft clusters and their instances areconsidered. This method can be considered as an insurance, where the cost ofthe insurance is an extra exploration effort in the short run, for achieving anearly ""total"" recall with less efforts in the long run.",Jean-Michel Renders,2017/12/27,2018/3/21
2309.13885v1,TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning,http://arxiv.org/abs/2309.13885v1,"How can we enhance the node features acquired from Pretrained Models (PMs) tobetter suit downstream graph learning tasks? Graph Neural Networks (GNNs) havebecome the state-of-the-art approach for many high-impact, real-world graphapplications. For feature-rich graphs, a prevalent practice involves utilizinga PM directly to generate features, without incorporating any domain adaptationtechniques. Nevertheless, this practice is suboptimal because the node featuresextracted from PM are graph-agnostic and prevent GNNs from fully utilizing thepotential correlations between the graph structure and node features, leadingto a decline in GNNs performance. In this work, we seek to improve the nodefeatures obtained from a PM for downstream graph tasks and introduce TOUCHUP-G,which has several advantages. It is (a) General: applicable to any downstreamgraph task, including link prediction which is often employed in recommendersystems; (b) Multi-modal: able to improve raw features of any modality (e.g.images, texts, audio); (c) Principled: it is closely related to a novel metric,feature homophily, which we propose to quantify the potential correlationsbetween the graph structure and node features and we show that TOUCHUP-G caneffectively shrink the discrepancy between the graph structure and nodefeatures; (d) Effective: achieving state-of-the-art results on four real-worlddatasets spanning different tasks and modalities.",Jing Zhu,2023/9/25,2023/9/25
2311.01886v1,Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion,http://arxiv.org/abs/2311.01886v1,"Multi-modal image fusion (MMIF) integrates valuable information fromdifferent modality images into a fused one. However, the fusion of multiplevisible images with different focal regions and infrared images is aunprecedented challenge in real MMIF applications. This is because of thelimited depth of the focus of visible optical lenses, which impedes thesimultaneous capture of the focal information within the same scene. To addressthis issue, in this paper, we propose a MMIF framework for joint focusedintegration and modalities information extraction. Specifically, asemi-sparsity-based smoothing filter is introduced to decompose the images intostructure and texture components. Subsequently, a novel multi-scale operator isproposed to fuse the texture components, capable of detecting significantinformation by considering the pixel focus attributes and relevant data fromvarious modal images. Additionally, to achieve an effective capture of sceneluminance and reasonable contrast maintenance, we consider the distribution ofenergy information in the structural components in terms of multi-directionalfrequency variance and information entropy. Extensive experiments on existingMMIF datasets, as well as the object detection and depth estimation tasks,consistently demonstrate that the proposed algorithm can surpass thestate-of-the-art methods in visual perception and quantitative evaluation. Thecode is available at https://github.com/ixilai/MFIF-MMIF.",Xilai Li,2023/11/3,2023/11/3
2302.04237v2,Black Box Adversarial Prompting for Foundation Models,http://arxiv.org/abs/2302.04237v2,"Prompting interfaces allow users to quickly adjust the output of generativemodels in both vision and language. However, small changes and design choicesin the prompt can lead to significant differences in the output. In this work,we develop a black-box framework for generating adversarial prompts forunstructured image and text generation. These prompts, which can be standaloneor prepended to benign prompts, induce specific behaviors into the generativeprocess, such as generating images of a particular object or generating highperplexity text.",Natalie Maus,2023/2/8,2023/5/29
2311.11261v2,Adversarial Prompt Tuning for Vision-Language Models,http://arxiv.org/abs/2311.11261v2,"With the rapid advancement of multimodal learning, pre-trainedVision-Language Models (VLMs) such as CLIP have demonstrated remarkablecapacities in bridging the gap between visual and language modalities. However,these models remain vulnerable to adversarial attacks, particularly in theimage modality, presenting considerable security risks. This paper introducesAdversarial Prompt Tuning (AdvPT), a novel technique to enhance the adversarialrobustness of image encoders in VLMs. AdvPT innovatively leverages learnabletext prompts and aligns them with adversarial image embeddings, to address thevulnerabilities inherent in VLMs without the need for extensive parametertraining or modification of the model architecture. We demonstrate that AdvPTimproves resistance against white-box and black-box adversarial attacks andexhibits a synergistic effect when combined with existingimage-processing-based defense techniques, further boosting defensivecapabilities. Comprehensive experimental analyses provide insights intoadversarial prompt tuning, a novel paradigm devoted to improving resistance toadversarial images through textual input modifications, paving the way forfuture robust multimodal learning research. These findings open up newpossibilities for enhancing the security of VLMs. Our code is available athttps://github.com/jiamingzhang94/Adversarial-Prompt-Tuning.",Jiaming Zhang,2023/11/19,2023/12/25
2306.04528v4,PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts,http://arxiv.org/abs/2306.04528v4,"The increasing reliance on Large Language Models (LLMs) across academia andindustry necessitates a comprehensive understanding of their robustness toprompts. In response to this vital need, we introduce PromptBench, a robustnessbenchmark designed to measure LLMs' resilience to adversarial prompts. Thisstudy uses a plethora of adversarial textual attacks targeting prompts acrossmultiple levels: character, word, sentence, and semantic. The adversarialprompts, crafted to mimic plausible user errors like typos or synonyms, aim toevaluate how slight deviations can affect LLM outcomes while maintainingsemantic integrity. These prompts are then employed in diverse tasks, such assentiment analysis, natural language inference, reading comprehension, machinetranslation, and math problem-solving. Our study generates 4788 adversarialprompts, meticulously evaluated over 8 tasks and 13 datasets. Our findingsdemonstrate that contemporary LLMs are not robust to adversarial prompts.Furthermore, we present comprehensive analysis to understand the mystery behindprompt robustness and its transferability. We then offer insightful robustnessanalysis and pragmatic recommendations for prompt composition, beneficial toboth researchers and everyday users. Code is available at:https://github.com/microsoft/promptbench.",Kaijie Zhu,2023/6/7,2023/10/18
2309.02705v2,Certifying LLM Safety against Adversarial Prompting,http://arxiv.org/abs/2309.02705v2,"Large language models (LLMs) released for public use incorporate guardrailsto ensure their output is safe, often referred to as ""model alignment."" Analigned language model should decline a user's request to produce harmfulcontent. However, such safety measures are vulnerable to adversarial attacks,which add maliciously designed token sequences to a harmful prompt to bypassthe model's safety guards. In this work, we introduce erase-and-check, thefirst framework to defend against adversarial prompts with verifiable safetyguarantees. We defend against three attack modes: i) adversarial suffix, whichappends an adversarial sequence at the end of the prompt; ii) adversarialinsertion, where the adversarial sequence is inserted anywhere in the middle ofthe prompt; and iii) adversarial infusion, where adversarial tokens areinserted at arbitrary positions in the prompt, not necessarily as a contiguousblock. Our experimental results demonstrate that this procedure can obtainstrong certified safety guarantees on harmful prompts while maintaining goodempirical performance on safe prompts. For example, against adversarialsuffixes of length 20, it certifiably detects 92% of harmful prompts and labels94% of safe prompts correctly using the open-source language model Llama 2 asthe safety filter. We further improve the filter's performance, in terms ofaccuracy and speed, by replacing Llama 2 with a DistilBERT safety classifierfine-tuned on safe and harmful prompts. Additionally, we propose two efficientempirical defenses: i) RandEC, a randomized version of erase-and-check thatevaluates the safety filter on a small subset of the erased subsequences, andii) GradEC, a gradient-based version that optimizes the erased tokens to removethe adversarial sequence. The code for our experiments is available athttps://github.com/aounon/certified-llm-safety.",Aounon Kumar,2023/9/6,2023/11/28
2311.11509v2,Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information,http://arxiv.org/abs/2311.11509v2,"In recent years, Large Language Models (LLM) have emerged as pivotal tools invarious applications. However, these models are susceptible to adversarialprompt attacks, where attackers can carefully curate input strings that lead toundesirable outputs. The inherent vulnerability of LLMs stems from theirinput-output mechanisms, especially when presented with intenselyout-of-distribution (OOD) inputs. This paper proposes a token-level detectionmethod to identify adversarial prompts, leveraging the LLM's capability topredict the next token's probability. We measure the degree of the model'sperplexity and incorporate neighboring token information to encourage thedetection of contiguous adversarial prompt sequences. As a result, we proposetwo methods: one that identifies each token as either being part of anadversarial prompt or not, and another that estimates the probability of eachtoken being part of an adversarial prompt.",Zhengmian Hu,2023/11/20,2023/11/27
2303.16576v2,WordStylist: Styled Verbatim Handwritten Text Generation with Latent Diffusion Models,http://arxiv.org/abs/2303.16576v2,"Text-to-Image synthesis is the task of generating an image according to aspecific text description. Generative Adversarial Networks have been consideredthe standard method for image synthesis virtually since their introduction.Denoising Diffusion Probabilistic Models are recently setting a new baseline,with remarkable results in Text-to-Image synthesis, among other fields. Asideits usefulness per se, it can also be particularly relevant as a tool for dataaugmentation to aid training models for other document image processing tasks.In this work, we present a latent diffusion-based method for styledtext-to-text-content-image generation on word-level. Our proposed method isable to generate realistic word image samples from different writer styles, byusing class index styles and text content prompts without the need ofadversarial training, writer recognition, or text recognition. We gauge systemperformance with the Fr\'echet Inception Distance, writer recognition accuracy,and writer retrieval. We show that the proposed model produces samples that areaesthetically pleasing, help boosting text recognition performance, and getsimilar writer retrieval score as real data. Code is available at:https://github.com/koninik/WordStylist.",Konstantina Nikolaidou,2023/3/29,2023/5/17
2311.00172v1,Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield,http://arxiv.org/abs/2311.00172v1,"Large Language Models' safety remains a critical concern due to theirvulnerability to adversarial attacks, which can prompt these systems to produceharmful responses. In the heart of these systems lies a safety classifier, acomputational model trained to discern and mitigate potentially harmful,offensive, or unethical outputs. However, contemporary safety classifiers,despite their potential, often fail when exposed to inputs infused withadversarial noise. In response, our study introduces the Adversarial PromptShield (APS), a lightweight model that excels in detection accuracy anddemonstrates resilience against adversarial prompts. Additionally, we proposenovel strategies for autonomously generating adversarial training datasets,named Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets aredesigned to fortify the safety classifier's robustness, and we investigate theconsequences of incorporating adversarial examples into the training process.Through evaluations involving Large Language Models, we demonstrate that ourclassifier has the potential to decrease the attack success rate resulting fromadversarial attacks by up to 60%. This advancement paves the way for the nextgeneration of more reliable and resilient conversational agents.",Jinhwa Kim,2023/10/31,2023/10/31
2310.11970v1,Quantifying Privacy Risks of Prompts in Visual Prompt Learning,http://arxiv.org/abs/2310.11970v1,"Large-scale pre-trained models are increasingly adapted to downstream tasksthrough a new paradigm called prompt learning. In contrast to fine-tuning,prompt learning does not update the pre-trained model's parameters. Instead, itonly learns an input perturbation, namely prompt, to be added to the downstreamtask data for predictions. Given the fast development of prompt learning, awell-generalized prompt inevitably becomes a valuable asset as significanteffort and proprietary data are used to create it. This naturally raises thequestion of whether a prompt may leak the proprietary information of itstraining data. In this paper, we perform the first comprehensive privacyassessment of prompts learned by visual prompt learning through the lens ofproperty inference and membership inference attacks. Our empirical evaluationshows that the prompts are vulnerable to both attacks. We also demonstrate thatthe adversary can mount a successful property inference attack with limitedcost. Moreover, we show that membership inference attacks against prompts canbe successful with relaxed adversarial assumptions. We further make someinitial investigations on the defenses and observe that our method can mitigatethe membership inference attacks with a decent utility-defense trade-off butfails to defend against property inference attacks. We hope our results canshed light on the privacy risks of the popular prompt learning paradigm. Tofacilitate the research in this direction, we will share our code and modelswith the community.",Yixin Wu,2023/10/18,2023/10/18
2210.06284v4,Visual Prompting for Adversarial Robustness,http://arxiv.org/abs/2210.06284v4,"In this work, we leverage visual prompting (VP) to improve adversarialrobustness of a fixed, pre-trained model at testing time. Compared toconventional adversarial defenses, VP allows us to design universal (i.e.,data-agnostic) input prompting templates, which have plug-and-play capabilitiesat testing time to achieve desired model performance without introducing muchcomputation overhead. Although VP has been successfully applied to improvingmodel generalization, it remains elusive whether and how it can be used todefend against adversarial attacks. We investigate this problem and show thatthe vanilla VP approach is not effective in adversarial defense since auniversal input prompt lacks the capacity for robust learning againstsample-specific adversarial perturbations. To circumvent it, we propose a newVP method, termed Class-wise Adversarial Visual Prompting (C-AVP), to generateclass-wise visual prompts so as to not only leverage the strengths of ensembleprompts but also optimize their interrelations to improve model robustness. Ourexperiments show that C-AVP outperforms the conventional VP method, with 2.1Xstandard accuracy gain and 2X robust accuracy gain. Compared to classicaltest-time defenses, C-AVP also yields a 42X inference time speedup.",Aochuan Chen,2022/10/12,2023/5/1
2306.11066v2,Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding,http://arxiv.org/abs/2306.11066v2,"State-of-the-art few-shot learning (FSL) methods leverage prompt-basedfine-tuning to obtain remarkable results for natural language understanding(NLU) tasks. While much of the prior FSL methods focus on improving downstreamtask performance, there is a limited understanding of the adversarialrobustness of such methods. In this work, we conduct an extensive study ofseveral state-of-the-art FSL methods to assess their robustness to adversarialperturbations. To better understand the impact of various factors towardsrobustness (or the lack of it), we evaluate prompt-based FSL methods againstfully fine-tuned models for aspects such as the use of unlabeled data, multipleprompts, number of few-shot examples, model size and type. Our results on sixGLUE tasks indicate that compared to fully fine-tuned models, vanilla FSLmethods lead to a notable relative drop in task performance (i.e., are lessrobust) in the face of adversarial perturbations. However, using (i) unlabeleddata for prompt-based FSL and (ii) multiple prompts flip the trend. We furtherdemonstrate that increasing the number of few-shot examples and model size leadto increased adversarial robustness of vanilla FSL methods. Broadly, our worksheds light on the adversarial robustness evaluation of prompt-based FSLmethods for NLU tasks.",Venkata Prabhakara Sarath Nookala,2023/6/19,2023/6/21
2311.07689v1,MART: Improving LLM Safety with Multi-round Automatic Red-Teaming,http://arxiv.org/abs/2311.07689v1,"Red-teaming is a common practice for mitigating unsafe behaviors in LargeLanguage Models (LLMs), which involves thoroughly assessing LLMs to identifypotential flaws and addressing them with responsible and accurate responses.While effective, manual red-teaming is costly, and existing automaticred-teaming typically discovers safety risks without addressing them. In thispaper, we propose a Multi-round Automatic Red-Teaming (MART) method, whichincorporates both automatic adversarial prompt writing and safe responsegeneration, significantly increasing red-teaming scalability and the safety ofthe target LLM. Specifically, an adversarial LLM and a target LLM interplaywith each other in an iterative manner, where the adversarial LLM aims togenerate challenging prompts that elicit unsafe responses from the target LLM,while the target LLM is fine-tuned with safety aligned data on theseadversarial prompts. In each round, the adversarial LLM crafts better attackson the updated target LLM, while the target LLM also improves itself throughsafety fine-tuning. On adversarial prompt benchmarks, the violation rate of anLLM with limited safety alignment reduces up to 84.7% after 4 rounds of MART,achieving comparable performance to LLMs with extensive adversarial promptwriting. Notably, model helpfulness on non-adversarial prompts remains stablethroughout iterations, indicating the target LLM maintains strong performanceon instruction following.",Suyu Ge,2023/11/13,2023/11/13
2311.14450v1,Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on Segmentation Models,http://arxiv.org/abs/2311.14450v1,"General purpose segmentation models are able to generate (semantic)segmentation masks from a variety of prompts, including visual (points, boxed,etc.) and textual (object names) ones. In particular, input images arepre-processed by an image encoder to obtain embedding vectors which are laterused for mask predictions. Existing adversarial attacks target the end-to-endtasks, i.e. aim at altering the segmentation mask predicted for a specificimage-prompt pair. However, this requires running an individual attack for eachnew prompt for the same image. We propose instead to generate prompt-agnosticadversarial attacks by maximizing the $\ell_2$-distance, in the latent space,between the embedding of the original and perturbed images. Since the encodingprocess only depends on the image, distorted image representations will causeperturbations in the segmentation masks for a variety of prompts. We show thateven imperceptible $\ell_\infty$-bounded perturbations of radius$\epsilon=1/255$ are often sufficient to drastically modify the masks predictedwith point, box and text prompts by recently proposed foundation models forsegmentation. Moreover, we explore the possibility of creating universal, i.e.non image-specific, attacks which can be readily applied to any input withoutfurther computational cost.",Francesco Croce,2023/11/24,2023/11/24
2309.12263v1,On the Relationship between Skill Neurons and Robustness in Prompt Tuning,http://arxiv.org/abs/2309.12263v1,"Prompt Tuning is a popular parameter-efficient finetuning method forpre-trained large language models (PLMs). Recently, based on experiments withRoBERTa, it has been suggested that Prompt Tuning activates specific neurons inthe transformer's feed-forward networks, that are highly predictive andselective for the given task. In this paper, we study the robustness of PromptTuning in relation to these ""skill neurons"", using RoBERTa and T5. We show thatprompts tuned for a specific task are transferable to tasks of the same typebut are not very robust to adversarial data, with higher robustness for T5 thanRoBERTa. At the same time, we replicate the existence of skill neurons inRoBERTa and further show that skill neurons also seem to exist in T5.Interestingly, the skill neurons of T5 determined on non-adversarial data arealso among the most predictive neurons on the adversarial data, which is notthe case for RoBERTa. We conclude that higher adversarial robustness may berelated to a model's ability to activate the relevant skill neurons onadversarial data.",Leon Ackermann,2023/9/21,2023/9/21
2311.09127v2,Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts,http://arxiv.org/abs/2311.09127v2,"Existing work on jailbreak Multimodal Large Language Models (MLLMs) hasfocused primarily on adversarial examples in model inputs, with less attentionto vulnerabilities, especially in model API. To fill the research gap, we carryout the following work: 1) We discover a system prompt leakage vulnerability inGPT-4V. Through carefully designed dialogue, we successfully extract theinternal system prompts of GPT-4V. This finding indicates potential exploitablesecurity risks in MLLMs; 2) Based on the acquired system prompts, we propose anovel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack viaSystem Prompt). By employing GPT-4 as a red teaming tool against itself, we aimto search for potential jailbreak prompts leveraging stolen system prompts.Furthermore, in pursuit of better performance, we also add human modificationbased on GPT-4's analysis, which further improves the attack success rate to98.7\%; 3) We evaluated the effect of modifying system prompts to defendagainst jailbreaking attacks. Results show that appropriately designed systemprompts can significantly reduce jailbreak success rates. Overall, our workprovides new insights into enhancing MLLM security, demonstrating the importantrole of system prompts in jailbreaking. This finding could be leveraged togreatly facilitate jailbreak success rates while also holding the potential fordefending against jailbreaks.",Yuanwei Wu,2023/11/15,2024/1/20
2208.02532v1,Prompt Tuning for Generative Multimodal Pretrained Models,http://arxiv.org/abs/2208.02532v1,"Prompt tuning has become a new paradigm for model tuning and it hasdemonstrated success in natural language pretraining and even visionpretraining. In this work, we explore the transfer of prompt tuning tomultimodal pretraining, with a focus on generative multimodal pretrainedmodels, instead of contrastive ones. Specifically, we implement prompt tuningon the unified sequence-to-sequence pretrained model adaptive to bothunderstanding and generation tasks. Experimental results demonstrate that thelight-weight prompt tuning can achieve comparable performance with finetuningand surpass other light-weight tuning methods. Besides, in comparison withfinetuned models, the prompt-tuned models demonstrate improved robustnessagainst adversarial attacks. We further figure out that experimental factors,including the prompt length, prompt depth, and reparameteratization, have greatimpacts on the model performance, and thus we empirically provide arecommendation for the setups of prompt tuning. Despite the observedadvantages, we still find some limitations in prompt tuning, and wecorrespondingly point out the directions for future studies. Codes areavailable at \url{https://github.com/OFA-Sys/OFA}",Hao Yang,2022/8/4,2022/8/4
2311.11538v1,Assessing Prompt Injection Risks in 200+ Custom GPTs,http://arxiv.org/abs/2311.11538v1,"In the rapidly evolving landscape of artificial intelligence, ChatGPT hasbeen widely used in various applications. The new feature: customization ofChatGPT models by users to cater to specific needs has opened new frontiers inAI utility. However, this study reveals a significant security vulnerabilityinherent in these user-customized GPTs: prompt injection attacks. Throughcomprehensive testing of over 200 user-designed GPT models via adversarialprompts, we demonstrate that these systems are susceptible to promptinjections. Through prompt injection, an adversary can not only extract thecustomized system prompts but also access the uploaded files. This paperprovides a first-hand analysis of the prompt injection, alongside theevaluation of the possible mitigation of such attacks. Our findings underscorethe urgent need for robust security frameworks in the design and deployment ofcustomizable GPT models. The intent of this paper is to raise awareness andprompt action in the AI community, ensuring that the benefits of GPTcustomization do not come at the cost of compromised security and privacy.",Jiahao Yu,2023/11/20,2023/11/20
2311.16119v2,Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition,http://arxiv.org/abs/2311.16119v2,"Large Language Models (LLMs) are deployed in interactive contexts with directuser engagement, such as chatbots and writing assistants. These deployments arevulnerable to prompt injection and jailbreaking (collectively, prompt hacking),in which models are manipulated to ignore their original instructions andfollow potentially malicious ones. Although widely acknowledged as asignificant security threat, there is a dearth of large-scale resources andquantitative studies on prompt hacking. To address this lacuna, we launch aglobal prompt hacking competition, which allows for free-form human inputattacks. We elicit 600K+ adversarial prompts against three state-of-the-artLLMs. We describe the dataset, which empirically verifies that current LLMs canindeed be manipulated via prompt hacking. We also present a comprehensivetaxonomical ontology of the types of adversarial prompts.",Sander Schulhoff,2023/10/24,2023/11/30
2308.10315v2,Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting,http://arxiv.org/abs/2308.10315v2,"In this paper, we investigate the adversarial robustness of visiontransformers that are equipped with BERT pretraining (e.g., BEiT, MAE). Asurprising observation is that MAE has significantly worse adversarialrobustness than other BERT pretraining methods. This observation drives us torethink the basic differences between these BERT pretraining methods and howthese differences affect the robustness against adversarial perturbations. Ourempirical analysis reveals that the adversarial robustness of BERT pretrainingis highly related to the reconstruction target, i.e., predicting the raw pixelsof masked image patches will degrade more adversarial robustness of the modelthan predicting the semantic context, since it guides the model to concentratemore on medium-/high-frequency components of images. Based on our analysis, weprovide a simple yet effective way to boost the adversarial robustness of MAE.The basic idea is using the dataset-extracted domain knowledge to occupy themedium-/high-frequency of images, thus narrowing the optimization space ofadversarial perturbations. Specifically, we group the distribution ofpretraining data and optimize a set of cluster-specific visual prompts onfrequency domain. These prompts are incorporated with input images throughprototype-based prompt selection during test period. Extensive evaluation showsthat our method clearly boost MAE's adversarial robustness while maintainingits clean performance on ImageNet-1k classification. Our code is available at:https://github.com/shikiw/RobustMAE.",Qidong Huang,2023/8/20,2023/8/22
2204.04497v1,IDPG: An Instance-Dependent Prompt Generation Method,http://arxiv.org/abs/2204.04497v1,"Prompt tuning is a new, efficient NLP transfer learning paradigm that adds atask-specific prompt in each input instance during the model training stage. Itfreezes the pre-trained language model and only optimizes a few task-specificprompts. In this paper, we propose a conditional prompt generation method togenerate prompts for each input instance, referred to as the Instance-DependentPrompt Generation (IDPG). Unlike traditional prompt tuning methods that use afixed prompt, IDPG introduces a lightweight and trainable component to generateprompts based on each input sentence. Extensive experiments on ten naturallanguage understanding (NLU) tasks show that the proposed strategy consistentlyoutperforms various prompt tuning baselines and is on par with other efficienttransfer learning methods such as Compacter while tuning far fewer modelparameters.",Zhuofeng Wu,2022/4/9,2022/4/9
2303.02861v1,Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning,http://arxiv.org/abs/2303.02861v1,"Prompt tuning, in which a base pretrained model is adapted to each task viaconditioning on learned prompt vectors, has emerged as a promising approach forefficiently adapting large language models to multiple downstream tasks.However, existing methods typically learn soft prompt vectors from scratch, andit has not been clear how to exploit the rich cross-task knowledge with promptvectors in a multitask learning setting. We propose multitask prompt tuning(MPT), which first learns a single transferable prompt by distilling knowledgefrom multiple task-specific source prompts. We then learn multiplicative lowrank updates to this shared prompt to efficiently adapt it to each downstreamtarget task. Extensive experiments on 23 NLP datasets demonstrate that ourproposed approach outperforms the state-of-the-art methods, including the fullfinetuning baseline in some cases, despite only tuning 0.035% as manytask-specific parameters.",Zhen Wang,2023/3/6,2023/3/6
2110.07904v2,SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer,http://arxiv.org/abs/2110.07904v2,"There has been growing interest in parameter-efficient methods to applypre-trained language models to downstream tasks. Building on the Prompt Tuningapproach of Lester et al. (2021), which learns task-specific soft prompts tocondition a frozen pre-trained model to perform different tasks, we propose anovel prompt-based transfer learning approach called SPoT: Soft PromptTransfer. SPoT first learns a prompt on one or more source tasks and then usesit to initialize the prompt for a target task. We show that SPoT significantlyboosts the performance of Prompt Tuning across many tasks. More remarkably,across all model sizes, SPoT matches or outperforms standard Model Tuning(which fine-tunes all model parameters) on the SuperGLUE benchmark, while usingup to 27,000x fewer task-specific parameters. To understand where SPoT is mosteffective, we conduct a large-scale study on task transferability with 26 NLPtasks in 160 combinations, and demonstrate that many tasks can benefit eachother via prompt transfer. Finally, we propose an efficient retrieval approachthat interprets task prompts as task embeddings to identify similar tasks andpredict the most transferable source tasks for a novel target task.",Tu Vu,2021/10/15,2022/3/16
2205.01543v2,Learning to Transfer Prompts for Text Generation,http://arxiv.org/abs/2205.01543v2,"Pretrained language models (PLMs) have made remarkable progress in textgeneration tasks via fine-tuning. While, it is challenging to fine-tune PLMs ina data-scarce situation. Therefore, it is non-trivial to develop a general andlightweight model that can adapt to various text generation tasks based onPLMs. To fulfill this purpose, the recent prompt-based learning offers apotential solution. In this paper, we improve this technique and propose anovel prompt-based method (PTG) for text generation in a transferable setting.First, PTG learns a set of source prompts for various source generation tasksand then transfers these prompts as target prompts to perform target generationtasks. To consider both task- and instance-level information, we design anadaptive attention mechanism to derive the target prompts. For each datainstance, PTG learns a specific target prompt by attending to highly relevantsource prompts. In extensive experiments, PTG yields competitive or betterresults than fine-tuning methods. We release our source prompts as an openresource, where users can add or reuse them to improve new text generationtasks for future research. Code and data can be available athttps://github.com/RUCAIBox/Transfer-Prompts-for-Text-Generation.",Junyi Li,2022/5/3,2022/5/15
2311.01967v1,The language of prompting: What linguistic properties make a prompt successful?,http://arxiv.org/abs/2311.01967v1,"The latest generation of LLMs can be prompted to achieve impressive zero-shotor few-shot performance in many NLP tasks. However, since performance is highlysensitive to the choice of prompts, considerable effort has been devoted tocrowd-sourcing prompts or designing methods for prompt optimisation. Yet, westill lack a systematic understanding of how linguistic properties of promptscorrelate with task performance. In this work, we investigate how LLMs ofdifferent sizes, pre-trained and instruction-tuned, perform on prompts that aresemantically equivalent, but vary in linguistic structure. We investigate bothgrammatical properties such as mood, tense, aspect and modality, as well aslexico-semantic variation through the use of synonyms. Our findings contradictthe common assumption that LLMs achieve optimal performance on lower perplexityprompts that reflect language use in pretraining or instruction-tuning data.Prompts transfer poorly between datasets or models, and performance cannotgenerally be explained by perplexity, word frequency, ambiguity or promptlength. Based on our results, we put forward a proposal for a more robust andcomprehensive evaluation standard for prompting research.",Alina Leidinger,2023/11/3,2023/11/3
2303.05266v1,From Visual Prompt Learning to Zero-Shot Transfer: Mapping Is All You Need,http://arxiv.org/abs/2303.05266v1,"Visual prompt learning, as a newly emerged technique, leverages the knowledgelearned by a large-scale pre-trained model and adapts it to downstream tasksthrough the usage of prompts. While previous research has focused on designingeffective prompts, in this work, we argue that compared to prompt design, agood mapping strategy matters more. In this sense, we propose SeMap, a moreeffective mapping using the semantic alignment between the pre-trained model'sknowledge and the downstream task. Our experimental results show that SeMap canlargely boost the performance of visual prompt learning. Moreover, ourexperiments show that SeMap is capable of achieving competitive zero-shottransfer, indicating that it can perform the downstream task without anyfine-tuning on the corresponding dataset. This demonstrates the potential ofour proposed method to be used in a broader range of applications where thezero-shot transfer is desired. Results suggest that our proposed SeMap couldlead to significant advancements in both visual prompt learning and zero-shottransfer. We hope with SeMap, we can help the community move forward to moreefficient and lightweight utilization of large vision models.",Ziqing Yang,2023/3/9,2023/3/9
2210.07225v1,Unified Vision and Language Prompt Learning,http://arxiv.org/abs/2210.07225v1,"Prompt tuning, a parameter- and data-efficient transfer learning paradigmthat tunes only a small number of parameters in a model's input space, hasbecome a trend in the vision community since the emergence of largevision-language models like CLIP. We present a systematic study on tworepresentative prompt tuning methods, namely text prompt tuning and visualprompt tuning. A major finding is that none of the unimodal prompt tuningmethods performs consistently well: text prompt tuning fails on data with highintra-class visual variances while visual prompt tuning cannot handle lowinter-class variances. To combine the best from both worlds, we propose asimple approach called Unified Prompt Tuning (UPT), which essentially learns atiny neural network to jointly optimize prompts across different modalities.Extensive experiments on over 11 vision datasets show that UPT achieves abetter trade-off than the unimodal counterparts on few-shot learningbenchmarks, as well as on domain generalization benchmarks. Code and modelswill be released to facilitate future research.",Yuhang Zang,2022/10/13,2022/10/13
2303.09100v1,Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models,http://arxiv.org/abs/2303.09100v1,"For downstream applications of vision-language pre-trained models, there hasbeen significant interest in constructing effective prompts. Existing works onprompt engineering, which either require laborious manual designs or optimizethe prompt tuning as a point estimation problem, may fail to describe diversecharacteristics of categories and limit their applications. We introduce aBayesian probabilistic resolution to prompt learning, where the label-specificstochastic prompts are generated hierarchically by first sampling a latentvector from an underlying distribution and then employing a lightweightgenerative model. Importantly, we semantically regularize prompt learning withthe visual knowledge and view images and the corresponding prompts as patch andtoken sets under optimal transport, which pushes the prompt tokens tofaithfully capture the label-specific visual concepts, instead of overfittingthe training categories. Moreover, the proposed model can also bestraightforwardly extended to the conditional case where theinstance-conditional prompts are generated to improve the generalizability.Extensive experiments on 15 datasets show promising transferability andgeneralization performance of our proposed model.",Xinyang Liu,2023/3/16,2023/3/16
2310.05095v1,How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts,http://arxiv.org/abs/2310.05095v1,"In recent years, there has been a rapid proliferation of AI-generated text,primarily driven by the release of powerful pre-trained language models (PLMs).To address the issue of misuse associated with AI-generated text, varioushigh-performing detectors have been developed, including the OpenAI detectorand the Stanford DetectGPT. In our study, we ask how reliable these detectorsare. We answer the question by designing a novel approach that can prompt anyPLM to generate text that evades these high-performing detectors. The proposedapproach suggests a universal evasive prompt, a novel type of soft prompt,which guides PLMs in producing ""human-like"" text that can mislead thedetectors. The novel universal evasive prompt is achieved in two steps: First,we create an evasive soft prompt tailored to a specific PLM through prompttuning; and then, we leverage the transferability of soft prompts to transferthe learned evasive soft prompt from one PLM to another. Employing multiplePLMs in various writing tasks, we conduct extensive experiments to evaluate theefficacy of the evasive soft prompts in their evasion of state-of-the-artdetectors.",Tharindu Kumarage,2023/10/8,2023/10/8
2310.06239v1,Model Tuning or Prompt Tuning? A Study of Large Language Models for Clinical Concept and Relation Extraction,http://arxiv.org/abs/2310.06239v1,"Objective To develop soft prompt-based learning algorithms for large languagemodels (LLMs), examine the shape of prompts, prompt-tuning usingfrozen/unfrozen LLMs, transfer learning, and few-shot learning abilities.Methods We developed a soft prompt-based LLM model and compared 4 trainingstrategies including (1) fine-tuning without prompts; (2) hard-prompt withunfrozen LLMs; (3) soft-prompt with unfrozen LLMs; and (4) soft-prompt withfrozen LLMs. We evaluated 7 pretrained LLMs using the 4 training strategies forclinical concept and relation extraction on two benchmark datasets. Weevaluated the transfer learning ability of the prompt-based learning algorithmsin a cross-institution setting. We also assessed the few-shot learning ability.Results and Conclusion When LLMs are unfrozen, GatorTron-3.9B with softprompting achieves the best strict F1-scores of 0.9118 and 0.8604 for conceptextraction, outperforming the traditional fine-tuning and hard prompt-basedmodels by 0.6~3.1% and 1.2~2.9%, respectively; GatorTron-345M with softprompting achieves the best F1-scores of 0.8332 and 0.7488 for end-to-endrelation extraction, outperforming the other two models by 0.2~2% and0.6~11.7%, respectively. When LLMs are frozen, small (i.e., 345 millionparameters) LLMs have a big gap to be competitive with unfrozen models; scalingLLMs up to billions of parameters makes frozen LLMs competitive with unfrozenLLMs. For cross-institute evaluation, soft prompting with a frozenGatorTron-8.9B model achieved the best performance. This study demonstratesthat (1) machines can learn soft prompts better than humans, (2) frozen LLMshave better few-shot learning ability and transfer learning ability tofacilitate muti-institution applications, and (3) frozen LLMs require largemodels.",Cheng Peng,2023/10/10,2023/10/10
2309.07760v2,PRE: Vision-Language Prompt Learning with Reparameterization Encoder,http://arxiv.org/abs/2309.07760v2,"Large pre-trained vision-language models such as CLIP have demonstrated greatpotential in zero-shot transferability to downstream tasks. However, to attainoptimal performance, the manual selection of prompts is necessary to improvealignment between the downstream image distribution and the textual classdescriptions. This manual prompt engineering is the major challenge fordeploying such models in practice since it requires domain expertise and isextremely time-consuming. To avoid non-trivial prompt engineering, recent workContext Optimization (CoOp) introduced the concept of prompt learning to thevision domain using learnable textual tokens. While CoOp can achievesubstantial improvements over manual prompts, its learned context is worsegeneralizable to wider unseen classes within the same dataset. In this work, wepresent Prompt Learning with Reparameterization Encoder (PRE) - a simple andefficient method that enhances the generalization ability of the learnableprompt to unseen classes while maintaining the capacity to learn Base classes.Instead of directly optimizing the prompts, PRE employs a prompt encoder toreparameterize the input prompt embeddings, enhancing the exploration oftask-specific knowledge from few-shot samples. Experiments and extensiveablation studies on 8 benchmarks demonstrate that our approach is an efficientmethod for prompt learning. Specifically, PRE achieves a notable enhancement of5.60% in average accuracy on New classes and 3% in Harmonic mean compared toCoOp in the 16-shot setting, all achieved within a good training time.",Anh Pham Thi Minh,2023/9/14,2023/11/6
1810.03548v1,Meta-Learning: A Survey,http://arxiv.org/abs/1810.03548v1,"Meta-learning, or learning to learn, is the science of systematicallyobserving how different machine learning approaches perform on a wide range oflearning tasks, and then learning from this experience, or meta-data, to learnnew tasks much faster than otherwise possible. Not only does this dramaticallyspeed up and improve the design of machine learning pipelines or neuralarchitectures, it also allows us to replace hand-engineered algorithms withnovel approaches learned in a data-driven way. In this chapter, we provide anoverview of the state of the art in this fascinating and continuously evolvingfield.",Joaquin Vanschoren,2018/10/8,2018/10/8
2109.14595v2,Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis,http://arxiv.org/abs/2109.14595v2,"We derive a novel information-theoretic analysis of the generalizationproperty of meta-learning algorithms. Concretely, our analysis proposes ageneric understanding of both the conventional learning-to-learn framework andthe modern model-agnostic meta-learning (MAML) algorithms. Moreover, we providea data-dependent generalization bound for a stochastic variant of MAML, whichis non-vacuous for deep few-shot learning. As compared to previous bounds thatdepend on the square norm of gradients, empirical validations on both simulateddata and a well-known few-shot benchmark show that our bound is orders ofmagnitude tighter in most situations.",Qi Chen,2021/9/29,2021/12/10
2304.04748v1,Exploring Effective Factors for Improving Visual In-Context Learning,http://arxiv.org/abs/2304.04748v1,"The In-Context Learning (ICL) is to understand a new task via a fewdemonstrations (aka. prompt) and predict new inputs without tuning the models.While it has been widely studied in NLP, it is still a relatively new area ofresearch in computer vision. To reveal the factors influencing the performanceof visual in-context learning, this paper shows that prompt selection andprompt fusion are two major factors that have a direct impact on the inferenceperformance of visual context learning. Prompt selection is the process ofidentifying the most appropriate prompt or example to help the model understandnew tasks. This is important because providing the model with relevant promptscan help it learn more effectively and efficiently. Prompt fusion involvescombining knowledge from different positions within the large-scale visualmodel. By doing this, the model can leverage the diverse knowledge stored indifferent parts of the model to improve its performance on new tasks. Basedthese findings, we propose a simple framework prompt-SelF for visual in-contextlearning. Specifically, we first use the pixel-level retrieval method to selecta suitable prompt, and then use different prompt fusion methods to activate allthe knowledge stored in the large-scale model, and finally ensemble theprediction results obtained from different prompt fusion methods to obtain thefinal prediction results. And we conduct extensive experiments on single-objectsegmentation and detection tasks to demonstrate the effectiveness ofprompt-SelF. Remarkably, the prompt-SelF has outperformed OSLSM basedmeta-learning in 1-shot segmentation for the first time. This indicated thegreat potential of visual in-context learning. The source code and models willbe available at \url{https://github.com/syp2ysy/prompt-SelF}.",Yanpeng Sun,2023/4/10,2023/4/10
2310.07295v2,VSANet: Real-time Speech Enhancement Based on Voice Activity Detection and Causal Spatial Attention,http://arxiv.org/abs/2310.07295v2,"The deep learning-based speech enhancement (SE) methods always take the cleanspeech's waveform or time-frequency spectrum feature as the learning target,and train the deep neural network (DNN) by reducing the error loss between theDNN's output and the target. This is a conventional single-task learningparadigm, which has been proven to be effective, but we find that themulti-task learning framework can improve SE performance. Specifically, wedesign a framework containing a SE module and a voice activity detection (VAD)module, both of which share the same encoder, and the whole network isoptimized by the weighted loss of the two modules. Moreover, we design a causalspatial attention (CSA) block to promote the representation capability of DNN.Combining the VAD aided multi-task learning framework and CSA block, our SEnetwork is named VSANet. The experimental results prove the benefits ofmulti-task learning and the CSA block, which give VSANet an excellent SEperformance.",Yuewei Zhang,2023/10/11,2023/11/1
2306.03799v1,Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models,http://arxiv.org/abs/2306.03799v1,"Prompt engineering is an essential technique for enhancing the abilities oflarge language models (LLMs) by providing explicit and specific instructions.It enables LLMs to excel in various tasks, such as arithmetic reasoning,question answering, summarization, relation extraction, machine translation,and sentiment analysis. Researchers have been actively exploring differentprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, andIn-context learning. However, an unresolved problem arises from the fact thatcurrent approaches lack a solid theoretical foundation for determining optimalprompts. To address this issue in prompt engineering, we propose a new andeffective approach called Prompt Space. Our methodology utilizes textembeddings to obtain basis vectors by matrix decomposition, and then constructsa space for representing all prompts. Prompt Space significantly outperformsstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,without the help of the CoT method and the prompt ""Let's think step by step"",Prompt Space shows superior performance over the few-shot method. Overall, ourapproach provides a robust and fundamental theoretical framework for selectingsimple and effective prompts. This advancement marks a significant step towardsimproving prompt engineering for a wide variety of applications in LLMs.",Fobo Shi,2023/6/6,2023/6/6
1901.11440v1,Toward Sensor-based Sleep Monitoring with Electrodermal Activity Measures,http://arxiv.org/abs/1901.11440v1,"We use self-report and electrodermal activity (EDA) wearable sensor data from77 nights of sleep on six participants to test the efficacy of EDA data forsleep monitoring. We used factor analysis to find latent factors in the EDAdata, and causal model search to find the most probable graphical modelaccounting for self-reported sleep efficiency (SE), sleep quality (SQ), and thelatent EDA factors. Structural equation modeling was used to confirm fit of theextracted graph. Based on the generated graph, logistic regression and naiveBayes models were used to test the efficacy of the EDA data in predicting SEand SQ. Six EDA features extracted from the total signal over a night's sleepcould be explained by two latent factors, EDA Magnitude and EDA Storms. EDAMagnitude performed as a strong predictor for SE to aid detection ofsubstantial changes in time asleep. The performance of EDA Magnitured and SE inclassifying SQ showed promise for wearable sleep monitoring applications.However, our data suggest that obtaining a more accurate sensor-based measureof SE will be necessary before smaller changes in SQ can be detected from EDAsensor data alone.",William Romine,2019/1/31,2019/1/31
2210.07565v3,Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning,http://arxiv.org/abs/2210.07565v3,"Prompt tuning is a parameter-efficient approach to adapting pre-trainedlanguage models to downstream tasks. Although prompt tuning has been shown tomatch the performance of full model tuning when training data is sufficient, ittends to struggle in few-shot learning settings. In this paper, we presentMulti-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shotlearning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.On downstream tasks, the pre-trained prompts are selectively activated andcombined, leading to strong compositional generalization to unseen tasks. Tobridge the gap between pre-training and fine-tuning, we formulate upstream anddownstream tasks into a unified machine reading comprehension task. Extensiveexperiments under two learning paradigms, i.e., gradient descent and black-boxtuning, show that MP2 significantly outperforms prompt tuning, full modeltuning, and prior prompt pre-training methods in few-shot settings. Inaddition, we demonstrate that MP2 can achieve surprisingly fast and strongadaptation to downstream tasks by merely learning 8 parameters to combine thepre-trained modular prompts.",Tianxiang Sun,2022/10/14,2023/5/6
2301.06661v1,An Empirical Study of Deep Learning Sentiment Detection Tools for Software Engineering in Cross-Platform Settings,http://arxiv.org/abs/2301.06661v1,"Sentiment detection in software engineering (SE) has shown promise to supportdiverse development activities. However, given the diversity of SE platforms,SE-specific sentiment detection tools may suffer in performance incross-platform settings. Recently deep learning (DL)-based SE-specificsentiment detection tools are found to offer superior performance than shallowmachine learning (ML) based/rule-based tools. However, it is not known how theDL tools perform in cross-platform settings. In this paper, we study whetherSE-specific DL sentiment detectors are more effective than shallowML-based/rule-based sentiment detectors in cross-platform settings. In threedatasets, we study three DL tools (SEntiMoji, BERT4SEntiSE, RNN4SentiSE) andcompare those against three baselines: two shallow learning tools (Senti4SD,SentiCR) and one rule-based tool (SentistrengthSE). We find that (1) The deeplearning SD tools for SE, BERT4SentiSE outperform other supervised tools incross-platform settings in most cases, but then the tool is outperformed by therule-based tool SentistrengthSE in most cases. (2) BERT4SentiSE outperformsSentistrengthSE by large margin in within-platform settings across the threedatasets and is only narrowly outperformed by SentiStrengthSE in four out ofthe six cross-platform settings. This finding offers hope for the feasibilityto further improve a pre-trained transformer model like BERT4SentiSE incross-platform settings. (3) The two best-performing deep learning tools(BERT4SentiSE and SentiMoji) show varying level performance drop across thethree datasets. We find that this inconsistency is mainly due to the""subjectivity in annotation"" and performance improvement for the studiedsupervised tools in cross-platform settings may require the fixing of thedatasets.",Gias Uddin,2023/1/17,2023/1/17
2305.17826v1,NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models,http://arxiv.org/abs/2305.17826v1,"Prompt-based learning is vulnerable to backdoor attacks. Existing backdoorattacks against prompt-based models consider injecting backdoors into theentire embedding layers or word embedding vectors. Such attacks can be easilyaffected by retraining on downstream tasks and with different promptingstrategies, limiting the transferability of backdoor attacks. In this work, wepropose transferable backdoor attacks against prompt-based models, calledNOTABLE, which is independent of downstream tasks and prompting strategies.Specifically, NOTABLE injects backdoors into the encoders of PLMs by utilizingan adaptive verbalizer to bind triggers to specific words (i.e., anchors). Itactivates the backdoor by pasting input with triggers to reachadversary-desired anchors, achieving independence from downstream tasks andprompting strategies. We conduct experiments on six NLP tasks, three popularmodels, and three prompting strategies. Empirical results show that NOTABLEachieves superior attack performance (i.e., attack success rate over 90% on allthe datasets), and outperforms two state-of-the-art baselines. Evaluations onthree defenses show the robustness of NOTABLE. Our code can be found athttps://github.com/RU-System-Software-and-Security/Notable.",Kai Mei,2023/5/28,2023/5/28
2306.10259v2,Active Policy Improvement from Multiple Black-box Oracles,http://arxiv.org/abs/2306.10259v2,"Reinforcement learning (RL) has made significant strides in various complexdomains. However, identifying an effective policy via RL often necessitatesextensive exploration. Imitation learning aims to mitigate this issue by usingexpert demonstrations to guide exploration. In real-world scenarios, one oftenhas access to multiple suboptimal black-box experts, rather than a singleoptimal oracle. These experts do not universally outperform each other acrossall states, presenting a challenge in actively deciding which oracle to use andin which state. We introduce MAPS and MAPS-SE, a class of policy improvementalgorithms that perform imitation learning from multiple suboptimal oracles. Inparticular, MAPS actively selects which of the oracles to imitate and improvetheir value function estimates, and MAPS-SE additionally leverages an activestate exploration criterion to determine which states one should explore. Weprovide a comprehensive theoretical analysis and demonstrate that MAPS andMAPS-SE enjoy sample efficiency advantage over the state-of-the-art policyimprovement algorithms. Empirical results show that MAPS-SE significantlyaccelerates policy optimization via state-wise imitation learning from multipleoracles across a broad spectrum of control tasks in the DeepMind Control Suite.Our code is publicly available at: https://github.com/ripl/maps.",Xuefeng Liu,2023/6/17,2023/7/5
2211.08358v3,MEAL: Stable and Active Learning for Few-Shot Prompting,http://arxiv.org/abs/2211.08358v3,"Few-shot classification has made great strides due to foundation models that,through priming and prompting, are highly effective few-shot learners. However,this approach has high variance both across different sets of few shots (dataselection) and across different finetuning runs (run variability). This isproblematic not only because it impedes the fair comparison of differentapproaches, but especially because it makes few-shot learning too unreliablefor many real-world applications. To alleviate these issues, we make twocontributions for more stable and effective few-shot learning: First, wepropose novel ensembling methods and show that they substantially reduce runvariability. Second, we introduce a new active learning (AL) criterion for dataselection and present the first AL-based approach specifically tailored towardsprompt-based learning. In our experiments, we show that our combined method,MEAL (Multiprompt finetuning and prediction Ensembling with Active Learning),improves overall performance of prompt-based finetuning by 2.3 points on fivediverse tasks. We publicly share our code and data splits inhttps://github.com/akoksal/MEAL.",Abdullatif Kksal,2022/11/15,2023/11/20
2306.02140v1,Unsupervised Human Activity Recognition through Two-stage Prompting with ChatGPT,http://arxiv.org/abs/2306.02140v1,"Wearable sensor devices, which offer the advantage of recording daily objectsused by a person while performing an activity, enable the feasibility ofunsupervised Human Activity Recognition (HAR). Unfortunately, previousunsupervised approaches using the usage sequence of objects usually require aproper description of activities manually prepared by humans. Instead, weleverage the knowledge embedded in a Large Language Model (LLM) of ChatGPT.Because the sequence of objects robustly characterizes the activity identity,it is possible that ChatGPT already learned the association between activitiesand objects from existing contexts. However, previous prompt engineering forChatGPT exhibits limited generalization ability when dealing with a list ofwords (i.e., sequence of objects) due to the similar weighting assigned to eachword in the list. In this study, we propose a two-stage prompt engineering,which first guides ChatGPT to generate activity descriptions associated withobjects while emphasizing important objects for distinguishing similaractivities; then outputs activity classes and explanations for enhancing thecontexts that are helpful for HAR. To the best of our knowledge, this is thefirst study that utilizes ChatGPT to recognize activities using objects in anunsupervised manner. We conducted our approach on three datasets anddemonstrated the state-of-the-art performance.",Qingxin Xia,2023/6/3,2023/6/3
2309.14779v1,Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification,http://arxiv.org/abs/2309.14779v1,"Domain-specific text classification faces the challenge of scarce labeleddata due to the high cost of manual labeling. Prompt-learning, known for itsefficiency in few-shot scenarios, is proposed as an alternative to traditionalfine-tuning methods. And besides, although large language models (LLMs) havegained prominence, small language models (SLMs, with under 1B parameters) offersignificant customizability, adaptability, and cost-effectiveness fordomain-specific tasks, given industry constraints. In this study, weinvestigate the potential of SLMs combined with prompt-learning paradigm fordomain-specific text classification, specifically within customer-agentinteractions in retail. Our evaluations show that, in few-shot settings whenprompt-based model fine-tuning is possible, T5-base, a typical SLM with 220Mparameters, achieve approximately 75% accuracy with limited labeled data (up to15% of full data), which shows great potentials of SLMs with prompt-learning.Based on this, We further validate the effectiveness of active few-shotsampling and the ensemble strategy in the prompt-learning pipeline thatcontribute to a remarkable performance gain. Besides, in zero-shot settingswith a fixed model, we underscore a pivotal observation that, although theGPT-3.5-turbo equipped with around 154B parameters garners an accuracy of55.16%, the power of well designed prompts becomes evident when theFLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achievesan accuracy exceeding 31% with the optimized prompt, a leap from its sub-18%performance with an unoptimized one. Our findings underscore the promise ofprompt-learning in classification tasks with SLMs, emphasizing the benefits ofactive few-shot sampling, and ensemble strategies in few-shot settings, and theimportance of prompt engineering in zero-shot settings.",Hengyu Luo,2023/9/26,2023/9/26
2005.06885v1,Enabling Edge Cloud Intelligence for Activity Learning in Smart Home,http://arxiv.org/abs/2005.06885v1,"We propose a novel activity learning framework based on Edge Cloudarchitecture for the purpose of recognizing and predicting human activities.Although activity recognition has been vastly studied by many researchers, thetemporal features that constitute an activity, which can provide usefulinsights for activity models, have not been exploited to their full potentialsby mining algorithms. In this paper, we utilize temporal features for activityrecognition and prediction in a single smart home setting. We discover activitypatterns and temporal relations such as the order of activities from real datato develop a prompting system. Analysis of real data collected from smart homeswas used to validate the proposed method.",Bing Huang,2020/5/14,2020/5/14
2307.00097v3,Prompting classes: Exploring the Power of Prompt Class Learning in Weakly Supervised Semantic Segmentation,http://arxiv.org/abs/2307.00097v3,"Recently, CLIP-based approaches have exhibited remarkable performance ongeneralization and few-shot learning tasks, fueled by the power of contrastivelanguage-vision pre-training. In particular, prompt tuning has emerged as aneffective strategy to adapt the pre-trained language-vision models todownstream tasks by employing task-related textual tokens. Motivated by thisprogress, in this work we question whether other fundamental problems, such asweakly supervised semantic segmentation (WSSS), can benefit from prompt tuning.Our findings reveal two interesting observations that shed light on the impactof prompt tuning on WSSS. First, modifying only the class token of the textprompt results in a greater impact on the Class Activation Map (CAM), comparedto arguably more complex strategies that optimize the context. And second, theclass token associated with the image ground truth does not necessarilycorrespond to the category that yields the best CAM. Motivated by theseobservations, we introduce a novel approach based on a PrOmpt cLass lEarning(POLE) strategy. Through extensive experiments we demonstrate that our simple,yet efficient approach achieves SOTA performance in a well-known WSSSbenchmark. These results highlight not only the benefits of language-visionmodels in WSSS but also the potential of prompt learning for this problem. Thecode is available at https://github.com/rB080/WSS_POLE.",Balamurali Murugesan,2023/6/30,2024/1/13
2312.04839v1,Understanding Teacher Perspectives and Experiences after Deployment of AI Literacy Curriculum in Middle-school Classrooms,http://arxiv.org/abs/2312.04839v1,"Artificial Intelligence (AI) and its associated applications are ubiquitousin today's world, making it imperative that students and their teachersunderstand how it works and the ramifications arising from its usage. In thisstudy, we investigate the experiences of seven teachers following theirimplementation of modules from the MIT RAICA (Responsible AI for ComputationalAction) curriculum. Through semi-structured interviews, we investigated theirinstructional strategies as they engaged with the AI curriculum in theirclassroom, how their teaching and learning beliefs about AI evolved with thecurriculum as well as how those beliefs impacted their implementation of thecurriculum. Our analysis suggests that the AI modules not only expanded ourteachers' knowledge in the field, but also prompted them to recognize its dailyapplications and their ethical and societal implications, so that they couldbetter engage with the content they deliver to students. Teachers were able toleverage their own interdisciplinary backgrounds to creatively introducefoundational AI topics to students to maximize engagement and playful learning.Our teachers advocated their need for better external support when navigatingtechnological resources, additional time for preparation given the novelty ofthe curriculum, more flexibility within curriculum timelines, and additionalaccommodations for students of determination. Our findings provide valuableinsights for enhancing future iterations of AI literacy curricula and teacherprofessional development (PD) resources.",Prerna Ravi,2023/12/8,2023/12/8
1711.10837v1,Curriculum Q-Learning for Visual Vocabulary Acquisition,http://arxiv.org/abs/1711.10837v1,"The structure of curriculum plays a vital role in our learning process, bothas children and adults. Presenting material in ascending order of difficultythat also exploits prior knowledge can have a significant impact on the rate oflearning. However, the notion of difficulty and prior knowledge differs fromperson to person. Motivated by the need for a personalised curriculum, wepresent a novel method of curriculum learning for vocabulary words in the formof visual prompts. We employ a reinforcement learning model grounded inpedagogical theories that emulates the actions of a tutor. We simulate threestudents with different levels of vocabulary knowledge in order to evaluate thehow well our model adapts to the environment. The results of the simulationreveal that through interaction, the model is able to identify the areas ofweakness, as well as push students to the edge of their ZPD. We hypothesisethat these methods can also be effective in training agents to learn languagerepresentations in a simulated environment where it has previously been shownthat order of words and prior knowledge play an important role in the efficacyof language learning.",Ahmed H. Zaidi,2017/11/29,2017/11/29
2308.06450v1,Simple Model Also Works: A Novel Emotion Recognition Network in Textual Conversation Based on Curriculum Learning Strategy,http://arxiv.org/abs/2308.06450v1,"Emotion Recognition in Conversation (ERC) has emerged as a research hotspotin domains such as conversational robots and question-answer systems. How toefficiently and adequately retrieve contextual emotional cues has been one ofthe key challenges in the ERC task. Existing efforts do not fully model thecontext and employ complex network structures, resulting in excessivecomputational resource overhead without substantial performance improvement. Inthis paper, we propose a novel Emotion Recognition Network based on CurriculumLearning strategy (ERNetCL). The proposed ERNetCL primarily consists ofTemporal Encoder (TE), Spatial Encoder (SE), and Curriculum Learning (CL) loss.We utilize TE and SE to combine the strengths of previous methods in asimplistic manner to efficiently capture temporal and spatial contextualinformation in the conversation. To simulate the way humans learn curriculumfrom easy to hard, we apply the idea of CL to the ERC task to progressivelyoptimize the network parameters of ERNetCL. At the beginning of training, weassign lower learning weights to difficult samples. As the epoch increases, thelearning weights for these samples are gradually raised. Extensive experimentson four datasets exhibit that our proposed method is effective and dramaticallybeats other baseline models.",Jiang Li,2023/8/12,2023/8/12
2205.00498v2,CUP: Curriculum Learning based Prompt Tuning for Implicit Event Argument Extraction,http://arxiv.org/abs/2205.00498v2,"Implicit event argument extraction (EAE) aims to identify arguments thatcould scatter over the document. Most previous work focuses on learning thedirect relations between arguments and the given trigger, while the implicitrelations with long-range dependency are not well studied. Moreover, recentneural network based approaches rely on a large amount of labeled data fortraining, which is unavailable due to the high labelling cost. In this paper,we propose a Curriculum learning based Prompt tuning (CUP) approach, whichresolves implicit EAE by four learning stages. The stages are defined accordingto the relations with the trigger node in a semantic graph, which well capturesthe long-range dependency between arguments and the trigger. In addition, weintegrate a prompt-based encoder-decoder model to elicit related knowledge frompre-trained language models (PLMs) in each stage, where the prompt templatesare adapted with the learning progress to enhance the reasoning for arguments.Experimental results on two well-known benchmark datasets show the greatadvantages of our proposed approach. In particular, we outperform thestate-of-the-art models in both fully-supervised and low-data scenarios.",Jiaju Lin,2022/5/1,2022/6/12
cs/0403026v1,"What we should teach, but don't: Proposal for a cross pollinated HCI-SE curriculum",http://arxiv.org/abs/cs/0403026v1,"Software engineering (SE) and usability engineering (UE), as disciplines,have reached substantial levels of maturity. Each of these two disciplines isnow well represented with respect to most computer science (CS) curricula. But,the two disciplines are practiced almost independently - missing oppurtunitiesto collaborate, coordinate and communicate about the overall design - andthereby contributing to system failures. Today, a confluence of severalingredients contribute to these failures: the increasing importance of the userinterface (UI) component in the overall system, the independent maturation ofthe human computer interaction area, and the lack of a cohesive process modelto integrate the UI experts' UE development efforts with that of SE. This inturn, we believe, is a result of a void in computing curricula: a lack ofeducation and training regarding the importance of communication, collaborationand coordination between the SE and UE processes. In this paper we describe thecurrent approach to teaching SE and UE and its shortcomings. We identify andanalyze the barriers and issues involved in developing systems havingsubstantial interactive components. We then propose four major themes oflearning for a comprehensive computing curriculum integrating SE, UE, andsystem architectures in a project environment.",Pardha S. Pyla,2004/3/15,2004/3/15
2308.01472v1,Reverse Stable Diffusion: What prompt was used to generate this image?,http://arxiv.org/abs/2308.01472v1,"Text-to-image diffusion models such as Stable Diffusion have recentlyattracted the interest of many researchers, and inverting the diffusion processcan play an important role in better understanding the generative process andhow to engineer prompts in order to obtain the desired images. To this end, weintroduce the new task of predicting the text prompt given an image generatedby a generative diffusion model. We combine a series of white-box and black-boxmodels (with and without access to the weights of the diffusion network) todeal with the proposed task. We propose a novel learning framework comprisingof a joint prompt regression and multi-label vocabulary classificationobjective that generates improved prompts. To further improve our method, weemploy a curriculum learning procedure that promotes the learning ofimage-prompt pairs with lower labeling noise (i.e. that are better aligned),and an unsupervised domain-adaptive kernel learning method that uses thesimilarities between samples in the source and target domains as extrafeatures. We conduct experiments on the DiffusionDB data set, predicting textprompts from images generated by Stable Diffusion. Our novel learning frameworkproduces excellent results on the aforementioned task, yielding the highestgains when applied on the white-box model. In addition, we make an interestingdiscovery: training a diffusion model on the prompt generation task can makethe model generate images that are much better aligned with the input prompts,when the model is directly reused for text-to-image generation.",Florinel-Alin Croitoru,2023/8/2,2023/8/2
2102.09990v3,"Analyzing Curriculum Learning for Sentiment Analysis along Task Difficulty, Pacing and Visualization Axes",http://arxiv.org/abs/2102.09990v3,"While Curriculum Learning (CL) has recently gained traction in Naturallanguage Processing Tasks, it is still not adequately analyzed. Previous worksonly show their effectiveness but fail short to explain and interpret theinternal workings fully. In this paper, we analyze curriculum learning insentiment analysis along multiple axes. Some of these axes have been proposedby earlier works that need more in-depth study. Such analysis requiresunderstanding where curriculum learning works and where it does not. Our axesof analysis include Task difficulty on CL, comparing CL pacing techniques, andqualitative analysis by visualizing the movement of attention scores in themodel as curriculum phases progress. We find that curriculum learning worksbest for difficult tasks and may even lead to a decrement in performance fortasks with higher performance without curriculum learning. We see that One-Passcurriculum strategies suffer from catastrophic forgetting and attentionmovement visualization within curriculum pacing. This shows that curriculumlearning breaks down the challenging main task into easier sub-tasks solvedsequentially.",Anvesh Rao Vijjini,2021/2/19,2021/3/3
2102.10438v2,Unsupervised Medical Image Alignment with Curriculum Learning,http://arxiv.org/abs/2102.10438v2,"We explore different curriculum learning methods for training convolutionalneural networks on the task of deformable pairwise 3D medical imageregistration. To the best of our knowledge, we are the first to attempt toimprove performance by training medical image registration models usingcurriculum learning, starting from an easy training setup in the first trainingstages, and gradually increasing the complexity of the setup. On the one hand,we consider two existing curriculum learning approaches, namely curriculumdropout and curriculum by smoothing. On the other hand, we propose a novel andsimple strategy to achieve curriculum, namely to use purposely blurred imagesat the beginning, then gradually transit to sharper images in the latertraining stages. Our experiments with an underlying state-of-the-art deeplearning model show that curriculum learning can lead to superior resultscompared to conventional training. Additionally, we show that curriculum byinput blur has the best accuracy versus speed trade-off among the comparedcurriculum learning approaches.",Mihail Burduja,2021/2/20,2021/6/8
2307.16364v1,Promptly: Using Prompt Problems to Teach Learners How to Effectively Utilize AI Code Generators,http://arxiv.org/abs/2307.16364v1,"With their remarkable ability to generate code, large language models (LLMs)are a transformative technology for computing education practice. They havecreated an urgent need for educators to rethink pedagogical approaches andteaching strategies for newly emerging skill sets. Traditional approaches tolearning programming have focused on frequent and repeated practice at writingcode. The ease with which code can now be generated has resulted in a shift infocus towards reading, understanding and evaluating LLM-generated code. Inparallel with this shift, a new essential skill is emerging -- the ability toconstruct good prompts for code-generating models. This paper introduces anovel pedagogical concept known as a `Prompt Problem', designed to helpstudents learn how to craft effective prompts for LLMs. A Prompt Problemchallenges a student to create a natural language prompt that leads an LLM toproduce the correct code for a specific problem. To support the delivery ofPrompt Problems at scale, in this paper we also present a novel tool calledPromptly which hosts a repository of Prompt Problems and automates theevaluation of prompt-generated code. We report empirical findings from a fieldstudy in which Promptly was deployed in a first-year Python programming course(n=54). We explore student interactions with the tool and their perceptions ofthe Prompt Problem concept. We found that Promptly was largely well-received bystudents for its ability to engage their computational thinking skills andexpose them to new programming constructs. We also discuss avenues for futurework, including variations on the design of Prompt Problems and the need tostudy their integration into the curriculum and teaching practice.",Paul Denny,2023/7/31,2023/7/31
2312.02445v2,LLaRA: Aligning Large Language Models with Sequential Recommenders,http://arxiv.org/abs/2312.02445v2,"Sequential recommendation aims to predict the subsequent items matching userpreference based on her/his historical interactions. With the development ofLarge Language Models (LLMs), there is growing interest in exploring thepotential of LLMs for sequential recommendation by framing it as a languagemodeling task. Prior works represent items in the textual prompts using eitherID indexing or text indexing and feed the prompts into LLMs, but falling shortof either encapsulating comprehensive world knowledge or exhibiting sufficientsequential understanding. To harness the complementary strengths of traditionalrecommenders (which encode user behavioral knowledge) and LLMs (which possessworld knowledge about items), we propose LLaRA -- a Large Language andRecommendation Assistant framework. Specifically, LLaRA represents items inLLM's input prompts using a novel hybrid approach that integrates ID-based itemembeddings from traditional recommenders with textual item features. Viewingthe ``sequential behavior of the user'' as a new modality in recommendation, weemploy an adapter to bridge the modality gap between ID embeddings of thetraditional recommenders and the input space of LLMs. Furthermore, instead ofdirectly exposing the hybrid prompt to LLMs, we apply a curriculum learningapproach to gradually ramp up training complexity. We first warm up the LLMwith text-only prompting, which aligns more naturally with the LLM's languagemodeling capabilities. Thereafter, we progressively transition to hybridprompting, training the adapter to incorporate behavioral knowledge from thetraditional sequential recommender into the LLM. Extensive experimentsdemonstrate the efficacy of LLaRA framework. Our code and data are available athttps://github.com/ljy0ustc/LLaRA .",Jiayi Liao,2023/12/5,2023/12/31
2111.05827v2,Data-Driven AI Model Signal-Awareness Enhancement and Introspection,http://arxiv.org/abs/2111.05827v2,"AI modeling for source code understanding tasks has been making significantprogress, and is being adopted in production development pipelines. However,reliability concerns, especially whether the models are actually learningtask-related aspects of source code, are being raised. While recentmodel-probing approaches have observed a lack of signal awareness in manyAI-for-code models, i.e. models not capturing task-relevant signals, they donot offer solutions to rectify this problem. In this paper, we exploredata-driven approaches to enhance models' signal-awareness: 1) we combine theSE concept of code complexity with the AI technique of curriculum learning; 2)we incorporate SE assistance into AI models by customizing Delta Debugging togenerate simplified signal-preserving programs, augmenting them to the trainingdataset. With our techniques, we achieve up to 4.8x improvement in model signalawareness. Using the notion of code complexity, we further present a novelmodel learning introspection approach from the perspective of the dataset.",Sahil Suneja,2021/11/10,2022/1/7
2306.08997v2,Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models,http://arxiv.org/abs/2306.08997v2,"We curate a comprehensive dataset of 4,550 questions and solutions fromproblem sets, midterm exams, and final exams across all MIT Mathematics andElectrical Engineering and Computer Science (EECS) courses required forobtaining a degree. We evaluate the ability of large language models to fulfillthe graduation requirements for any MIT major in Mathematics and EECS. Ourresults demonstrate that GPT-3.5 successfully solves a third of the entire MITcurriculum, while GPT-4, with prompt engineering, achieves a perfect solve rateon a test set excluding questions based on images. We fine-tune an open-sourcelarge language model on this dataset. We employ GPT-4 to automatically grademodel responses, providing a detailed performance breakdown by course,question, and answer type. By embedding questions in a low-dimensional space,we explore the relationships between questions, topics, and classes anddiscover which questions and classes are required for solving other questionsand classes through few-shot learning. Our analysis offers valuable insightsinto course prerequisites and curriculum design, highlighting language models'potential for learning and improving Mathematics and EECS education.",Sarah J. Zhang,2023/6/15,2023/6/24
1801.06053v1,Lab Based Curriculum for CIS and Related Technology,http://arxiv.org/abs/1801.06053v1,"The Computer Information System (CIS) is information and communicationtechnology in support of business processes. In this paper, we present atypical undergraduate computer information system curriculum examining thedegree of lab intensity and its effect on the course efficacy. A CIS program isusually part of the school of business as it is in support of businessprocesses. We also explore the differences between a CIS curriculum and othercomputer related technology courses, such as Information Technology (IT),Computer Science (CS), and Software Engineering (SE). The curriculum iscomposed of several elements such as content and sequence of subjects,classrooms equipped with computer projection, internet, and local networkaccess, and appropriate computing and software infrastructure. We will focus onthe importance and adequacy of labs for the CIS curriculum. The proposed CIScurriculum works for a 4-year as well as a 3-year program. This paper providesa recommendation for local and Federal Accreditation agencies and curriculumcommittees.",Shahriar Movafaghi,2018/1/17,2018/1/17
2310.20121v1,Ling-CL: Understanding NLP Models through Linguistic Curricula,http://arxiv.org/abs/2310.20121v1,"We employ a characterization of linguistic complexity from psycholinguisticand language acquisition research to develop data-driven curricula tounderstand the underlying linguistic knowledge that models learn to address NLPtasks. The novelty of our approach is in the development of linguisticcurricula derived from data, existing knowledge about linguistic complexity,and model behavior during training. By analyzing several benchmark NLPdatasets, our curriculum learning approaches identify sets of linguisticmetrics (indices) that inform the challenges and reasoning required to addresseach task. Our work will inform future research in all NLP areas, allowinglinguistic complexity to be considered early in the research and developmentprocess. In addition, our work prompts an examination of gold standards andfair evaluation in NLP.",Mohamed Elgaar,2023/10/31,2023/10/31
2008.00511v2,Curriculum Learning with a Progression Function,http://arxiv.org/abs/2008.00511v2,"Curriculum Learning for Reinforcement Learning is an increasingly populartechnique that involves training an agent on a sequence of intermediate tasks,called a Curriculum, to increase the agent's performance and learning speed.This paper introduces a novel paradigm for curriculum generation based onprogression and mapping functions. While progression functions specify thecomplexity of the environment at any given time, mapping functions generateenvironments of a specific complexity. Different progression functions areintroduced, including an autonomous online task progression based on theagent's performance. Our approach's benefits and wide applicability are shownby empirically comparing its performance to two state-of-the-art CurriculumLearning algorithms on six domains.",Andrea Bassich,2020/8/2,2021/10/31
2106.08068v2,An Analytical Theory of Curriculum Learning in Teacher-Student Networks,http://arxiv.org/abs/2106.08068v2,"In humans and animals, curriculum learning -- presenting data in a curatedorder - is critical to rapid learning and effective pedagogy. Yet in machinelearning, curricula are not widely used and empirically often yield onlymoderate benefits. This stark difference in the importance of curriculum raisesa fundamental theoretical question: when and why does curriculum learning help?  In this work, we analyse a prototypical neural network model of curriculumlearning in the high-dimensional limit, employing statistical physics methods.Curricula could in principle change both the learning speed and asymptoticperformance of a model. To study the former, we provide an exact description ofthe online learning setting, confirming the long-standing experimentalobservation that curricula can modestly speed up learning. To study the latter,we derive performance in a batch learning setting, in which a network trains toconvergence in successive phases of learning on dataset slices of varyingdifficulty. With standard training losses, curriculum does not providegeneralisation benefit, in line with empirical observations. However, we showthat by connecting different learning phases through simple Gaussian priors,curriculum can yield a large improvement in test performance. Taken together,our reduced analytical descriptions help reconcile apparently conflictingempirical results and trace regimes where curriculum learning yields thelargest gains. More broadly, our results suggest that fully exploiting acurriculum may require explicit changes to the loss function at curriculumboundaries.",Luca Saglietti,2021/6/15,2022/10/12
2310.17330v1,CQM: Curriculum Reinforcement Learning with a Quantized World Model,http://arxiv.org/abs/2310.17330v1,"Recent curriculum Reinforcement Learning (RL) has shown notable progress insolving complex tasks by proposing sequences of surrogate tasks. However, theprevious approaches often face challenges when they generate curriculum goalsin a high-dimensional space. Thus, they usually rely on manually specified goalspaces. To alleviate this limitation and improve the scalability of thecurriculum, we propose a novel curriculum method that automatically defines thesemantic goal space which contains vital information for the curriculumprocess, and suggests curriculum goals over it. To define the semantic goalspace, our method discretizes continuous observations via vectorquantized-variational autoencoders (VQ-VAE) and restores the temporal relationsbetween the discretized observations by a graph. Concurrently, ours suggestsuncertainty and temporal distance-aware curriculum goals that converges to thefinal goals over the automatically composed goal space. We demonstrate that theproposed method allows efficient explorations in an uninformed environment withraw goal examples only. Also, ours outperforms the state-of-the-art curriculumRL methods on data efficiency and performance, in various goal-reaching taskseven with ego-centric visual inputs.",Seungjae Lee,2023/10/26,2023/10/26
1004.2560v1,Enhancing Curriculum Acceptance among Students with E-learning 2.0,http://arxiv.org/abs/1004.2560v1,"E-learning; enhanced by communicating and interacting is becomingincreasingly accepted and this puts Web 2.0 at the center of the neweducational technologies. E-Learning 2.0 emerges as an innovative method ofonline learning for its incorporation of Web 2.0 tools. For any academic study,the curriculum provides overview of intact learning area. The Curriculumprovides overview to content of the Subject. Many institutions place studentinteraction as a priority of their online curriculum design. It is proved thatinteraction has a great effect on the students' involvement in learning andacceptance of Curriculum. Students are accepting curriculum that is designed byteacher; whereas E-learning 2.0 enabled Curriculum management system allowsstudent to involve in learning activities. It works as a stimulus and increasestheir dedication to the Curriculum. While Institute adapts E-Learning 2.0 asLearning Management System, it also provides Social Networking services andprovides direct and transparent interaction between students and teachers. Thisview of the e-Learning 2.0 shifts its focus from LMS to the students, equippingthem, with the means to become ever more autonomous, accepting them to make useof these means in solving problems on their own initiative. Curriculum usagewill empower student involvement and enhancing E-learning 2.0 spreading. Thispaper, analyzing implementation E-learning 2.0 for Curriculum management anddiscusses Opportunities & Challenges for Curriculum over Web 2.0.",Kamaljit I. Lakhtaria,2010/4/15,2010/4/15
1804.01770v1,Teaching Requirements Engineering Concepts using Case-Based Learning,http://arxiv.org/abs/1804.01770v1,"Requirements Engineering (RE) is known to be critical for the success ofsoftware projects, and hence forms an important part of any SoftwareEngineering (SE) education curriculum offered at tertiary level. In this paper,we report the results of an exploratory pilot study conducted to assess theeffectiveness of Case-Based Learning (CBL) methodology in facilitating thelearning of several RE concepts. The evaluation was made on the basis ofgraduate students' responses to a set of questions representing various keylearning principles, collected after the execution of two CBL sessions atDA-IICT, Gandhinagar (India). We investigate the perceived effectiveness of CBLin students' learning of various RE concepts, based on factors like casedifference, gender diversity, and team size. Additionally, we collect andanalyze the Teaching Assistants' (TAs) opinions about the conducted CBLsessions. The outcome of this CBL exercise was positive as maximum studentswere able to achieve all the five stated learning objectives. The authors alsoreport various challenges, recommendations, and lessons learned whileexperiencing CBL sessions.",Saurabh Tiwari,2018/4/5,2018/4/5
1611.06204v1,Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks,http://arxiv.org/abs/1611.06204v1,"Curriculum Learning emphasizes the order of training instances in acomputational learning setup. The core hypothesis is that simpler instancesshould be learned early as building blocks to learn more complex ones. Despiteits usefulness, it is still unknown how exactly the internal representation ofmodels are affected by curriculum learning. In this paper, we study the effectof curriculum learning on Long Short-Term Memory (LSTM) networks, which haveshown strong competency in many Natural Language Processing (NLP) problems. Ourexperiments on sentiment analysis task and a synthetic task similar to sequenceprediction tasks in NLP show that curriculum learning has a positive effect onthe LSTM's internal states by biasing the model towards building constructiverepresentations i.e. the internal representation at the previous timesteps areused as building blocks for the final prediction. We also find that smallermodels significantly improves when they are trained with curriculum learning.Lastly, we show that curriculum learning helps more when the amount of trainingdata is limited.",Volkan Cirik,2016/11/18,2016/11/18
2310.00152v1,Automatic Prompt Rewriting for Personalized Text Generation,http://arxiv.org/abs/2310.00152v1,"Facilitated by large language models (LLMs), personalized text generation hasbecome a rapidly growing research direction. Most existing studies focus ondesigning specialized models for a particular domain, or they requirefine-tuning the LLMs to generate personalized text. We consider a typicalscenario in which the large language model, which generates personalizedoutput, is frozen and can only be accessed through APIs. Under this constraint,all one can do is to improve the input text (i.e., text prompts) sent to theLLM, a procedure that is usually done manually. In this paper, we propose anovel method to automatically revise prompts for personalized text generation.The proposed method takes the initial prompts generated by a state-of-the-art,multistage framework for personalized generation and rewrites a few criticalcomponents that summarize and synthesize the personal context. The promptrewriter employs a training paradigm that chains together supervised learning(SL) and reinforcement learning (RL), where SL reduces the search space of RLand RL facilitates end-to-end training of the rewriter. Using datasets fromthree representative domains, we demonstrate that the rewritten promptsoutperform both the original prompts and the prompts optimized via supervisedlearning or reinforcement learning alone. In-depth analysis of the rewrittenprompts shows that they are not only human readable, but also able to guidemanual revision of prompts when there is limited resource to employreinforcement learning to train the prompt rewriter, or when it is costly todeploy an automatic prompt rewriter for inference.",Cheng Li,2023/9/29,2023/9/29
2308.10088v1,PACE: Improving Prompt with Actor-Critic Editing for Large Language Model,http://arxiv.org/abs/2308.10088v1,"Large language models (LLMs) have showcased remarkable potential acrossvarious tasks by conditioning on prompts. However, the quality of differenthuman-written prompts leads to substantial discrepancies in LLMs' performance,and improving prompts usually necessitates considerable human effort andexpertise. To this end, this paper proposes Prompt with Actor-Critic Editing(PACE) for LLMs to enable automatic prompt editing. Drawing inspiration fromthe actor-critic algorithm in reinforcement learning, PACE leverages LLMs asthe dual roles of actors and critics, conceptualizing prompt as a type ofpolicy. PACE refines prompt, taking into account the feedback from both actorsperforming prompt and critics criticizing response. This process helps LLMsbetter align prompt to a specific task, thanks to real responses and thinkingfrom LLMs. We conduct extensive experiments on 24 instruction induction tasksand 21 big-bench tasks. Experimental results indicate that PACE elevates therelative performance of medium/low-quality human-written prompts by up to 98\%,which has comparable performance to high-quality human-written prompts.Moreover, PACE also exhibits notable efficacy for prompt generation.",Yihong Dong,2023/8/19,2023/8/19
2312.08642v2,Metacognition-Enhanced Few-Shot Prompting With Positive Reinforcement,http://arxiv.org/abs/2312.08642v2,"Few-shot prompting elicits the remarkable abilities of large language modelsby equipping them with a few demonstration examples in the input. However, thetraditional method of providing large language models with all demonstrationinput-output pairs at once may not effectively guide large language models tolearn the specific input-output mapping relationship. In this paper, inspiredby the regulatory and supportive role of metacognition in students' learning,we propose a novel metacognition-enhanced few-shot prompting, which guideslarge language models to reflect on their thought processes to comprehensivelylearn the given demonstration examples. Furthermore, considering that positivereinforcement can improve students' learning motivation, we introduce positivereinforcement into our metacognition-enhanced few-shot prompting to promote thefew-shot learning of large language models by providing response-based positivefeedback. The experimental results on two real-world datasets show that ourmetacognition-enhanced few-shot prompting with positive reinforcement surpassestraditional few-shot prompting in classification accuracy and macro F1.",Yu Ji,2023/12/14,2023/12/24
2205.12548v3,RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,http://arxiv.org/abs/2205.12548v3,"Prompting has shown impressive success in enabling large pretrained languagemodels (LMs) to perform diverse NLP tasks, especially when only few downstreamdata are available. Automatically finding the optimal prompt for each task,however, is challenging. Most existing work resorts to tuning soft prompt(e.g., embeddings) which falls short of interpretability, reusability acrossLMs, and applicability when gradients are not accessible. Discrete prompt, onthe other hand, is difficult to optimize, and is often created by ""enumeration(e.g., paraphrasing)-then-selection"" heuristics that do not explore the promptspace systematically. This paper proposes RLPrompt, an efficient discreteprompt optimization approach with reinforcement learning (RL). RLPromptformulates a parameter-efficient policy network that generates the desireddiscrete prompt after training with reward. To overcome the complexity andstochasticity of reward signals by the large LM environment, we incorporateeffective reward stabilization that substantially enhances the trainingefficiency. RLPrompt is flexibly applicable to different types of LMs, such asmasked (e.g., BERT) and left-to-right models (e.g., GPTs), for bothclassification and generation tasks. Experiments on few-shot classification andunsupervised text style transfer show superior performance over a wide range ofexisting finetuning or prompting methods. Interestingly, the resultingoptimized prompts are often ungrammatical gibberish text; and surprisingly,those gibberish prompts are transferrable between different LMs to retainsignificant performance, indicating LM prompting may not follow human languagepatterns.",Mingkai Deng,2022/5/25,2022/10/22
2401.08189v1,PRewrite: Prompt Rewriting with Reinforcement Learning,http://arxiv.org/abs/2401.08189v1,"Prompt engineering is critical for the development of LLM-based applications.However, it is usually done manually in a ""trial and error"" fashion. Thismanual procedure can be time consuming, ineffective, and the generated promptsare, in a lot of cases, sub-optimal. Even for the prompts which seemingly workwell, there is always a lingering question: can the prompts be made better withfurther modifications?  To address these questions, in this paper, we investigate prompt engineeringautomation. We consider a specific use case scenario in which developers/usershave drafted initial prompts, but lack the time/expertise to optimize them. Wepropose PRewrite, an automated tool to rewrite these drafts and to generatehighly effective new prompts. PRewrite is based on the Reinforcement Learning(RL) framework which allows for end-to-end optimization and our design allowsthe RL search to happen in a large action space. The automated tool leveragesmanually crafted prompts as starting points which makes the rewriting proceduremore guided and efficient. The generated prompts are human readable, andself-explanatory, unlike some of those in previous works. We conductedextensive experiments on diverse datasets and found that the prompts generatedwith this new method not only outperform professionally crafted prompts, butalso prompts generated with other previously proposed methods.",Weize Kong,2024/1/16,2024/1/16
2212.09611v2,Optimizing Prompts for Text-to-Image Generation,http://arxiv.org/abs/2212.09611v2,"Well-designed prompts can guide text-to-image models to generate amazingimages. However, the performant prompts are often model-specific and misalignedwith user input. Instead of laborious human engineering, we propose promptadaptation, a general framework that automatically adapts original user inputto model-preferred prompts. Specifically, we first perform supervisedfine-tuning with a pretrained language model on a small collection of manuallyengineered prompts. Then we use reinforcement learning to explore betterprompts. We define a reward function that encourages the policy to generatemore aesthetically pleasing images while preserving the original userintentions. Experimental results on Stable Diffusion show that our methodoutperforms manual prompt engineering in terms of both automatic metrics andhuman preference ratings. Moreover, reinforcement learning further boostsperformance, especially on out-of-domain prompts. The pretrained checkpointsare available at https://aka.ms/promptist. The demo can be found athttps://aka.ms/promptist-demo.",Yaru Hao,2022/12/19,2023/12/29
2206.13499v1,Prompting Decision Transformer for Few-Shot Policy Generalization,http://arxiv.org/abs/2206.13499v1,"Humans can leverage prior experience and learn novel tasks from a handful ofdemonstrations. In contrast to offline meta-reinforcement learning, which aimsto achieve quick adaptation through better algorithm design, we investigate theeffect of architecture inductive bias on the few-shot learning capability. Wepropose a Prompt-based Decision Transformer (Prompt-DT), which leverages thesequential modeling ability of the Transformer architecture and the promptframework to achieve few-shot adaptation in offline RL. We design thetrajectory prompt, which contains segments of the few-shot demonstrations, andencodes task-specific information to guide policy generation. Our experimentsin five MuJoCo control benchmarks show that Prompt-DT is a strong few-shotlearner without any extra finetuning on unseen target tasks. Prompt-DToutperforms its variants and strong meta offline RL baselines by a large marginwith a trajectory prompt containing only a few timesteps. Prompt-DT is alsorobust to prompt length changes and can generalize to out-of-distribution (OOD)environments.",Mengdi Xu,2022/6/27,2022/6/27
2211.11890v1,TEMPERA: Test-Time Prompting via Reinforcement Learning,http://arxiv.org/abs/2211.11890v1,"Careful prompt design is critical to the use of large language models inzero-shot or few-shot learning. As a consequence, there is a growing interestin automated methods to design optimal prompts. In this work, we proposeTest-time Prompt Editing using Reinforcement learning (TEMPERA). In contrast toprior prompt generation methods, TEMPERA can efficiently leverage priorknowledge, is adaptive to different queries and provides an interpretableprompt for every query. To achieve this, we design a novel action space thatallows flexible editing of the initial prompts covering a wide set ofcommonly-used components like instructions, few-shot exemplars, andverbalizers. The proposed method achieves significant gains compared withrecent SoTA approaches like prompt tuning, AutoPrompt, and RLPrompt, across avariety of tasks including sentiment analysis, topic classification, naturallanguage inference, and reading comprehension. Our method achieves 5.33x onaverage improvement in sample efficiency when compared to the traditionalfine-tuning methods.",Tianjun Zhang,2022/11/21,2022/11/21
2308.08758v1,Discrete Prompt Compression with Reinforcement Learning,http://arxiv.org/abs/2308.08758v1,"Instruction-tuned Language Models (LMs) are widely used by users to addressvarious problems with task-specific prompts. Constraints associated with thecontext window length and computational costs encourage the development ofcompressed prompts. Existing methods rely heavily on training embeddings, whichare designed to accommodate multiple token meanings. This presents challengesin terms of interpretability, a fixed number of embedding tokens, reusabilityacross different LMs, and inapplicability when interacting with black-box APIs.This study proposes prompt compression with reinforcement learning (PCRL), anovel discrete prompt compression method that addresses these issues. PCRLemploys a computationally efficient policy network that directly edits prompts.The PCRL training approach can be flexibly applied to various types of LMs, aswell as decoder-only and encoder-decoder architecture, and can be trainedwithout gradient access to LMs or labeled data. PCRL achieves an averagereduction of 24.6% in token count across various instruction prompts whilepreserving performance. Further, we demonstrate that the learned policy can betransferred to larger LMs, and through various analyses, we aid theunderstanding of token importance within prompts.",Hoyoun Jung,2023/8/17,2023/8/17
2308.07272v2,Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Generation for Few-shot Learning,http://arxiv.org/abs/2308.07272v2,"Prompt-based pre-trained language models (PLMs) paradigm have succeededsubstantially in few-shot natural language processing (NLP) tasks. However,prior discrete prompt optimization methods require expert knowledge to designthe base prompt set and identify high-quality prompts, which is costly,inefficient, and subjective. Meanwhile, existing continuous prompt optimizationmethods improve the performance by learning the ideal prompts through thegradient information of PLMs, whose high computational cost, and lowreadability and generalizability are often concerning. To address the researchgap, we propose a Dialogue-comprised Policy-gradient-based Discrete PromptOptimization ($DP_2O$) method. We first design a multi-round dialogue alignmentstrategy for readability prompt set generation based on GPT-4. Furthermore, wepropose an efficient prompt screening metric to identify high-quality promptswith linear complexity. Finally, we construct a reinforcement learning (RL)framework based on policy gradients to match the prompts to inputs optimally.By training a policy network with only 0.67% of the PLM parameter size on thetasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)method by 1.52% in accuracy on average on four open-source datasets. Moreover,subsequent experiments also demonstrate that $DP_2O$ has good universality,robustness, and generalization ability.",Chengzhengxu Li,2023/8/14,2024/1/16
1811.04224v1,Reinforcement Learning Based Speech Enhancement for Robust Speech Recognition,http://arxiv.org/abs/1811.04224v1,"Conventional deep neural network (DNN)-based speech enhancement (SE)approaches aim to minimize the mean square error (MSE) between enhanced speechand clean reference. The MSE-optimized model may not directly improve theperformance of an automatic speech recognition (ASR) system. If the target isto minimize the recognition error, the recognition results should be used todesign the objective function for optimizing the SE model. However, thestructure of an ASR system, which consists of multiple units, such as acousticand language models, is usually complex and not differentiable. In this study,we proposed to adopt the reinforcement learning algorithm to optimize the SEmodel based on the recognition results. We evaluated the propsoed SE system onthe Mandarin Chinese broadcast news corpus (MATBN). Experimental resultsdemonstrate that the proposed method can effectively improve the ASR resultswith a notable 12.40% and 19.23% error rate reductions for signal to noiseratio at 0 dB and 5 dB conditions, respectively.",Yih-Liang Shen,2018/11/10,2018/11/10
2309.06553v3,Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL,http://arxiv.org/abs/2309.06553v3,"In this study, we aim to enhance the arithmetic reasoning ability of LargeLanguage Models (LLMs) through zero-shot prompt optimization. We identify apreviously overlooked objective of query dependency in such optimization andelucidate two ensuing challenges that impede the successful and economicaldesign of prompt optimization techniques. One primary issue is the absence ofan effective method to evaluate prompts during inference when the golden answeris unavailable. Concurrently, learning via interactions with the LLMs tonavigate the expansive natural language prompting space proves to beresource-intensive. To address this, we introduce Prompt-OIRL, which harnessesoffline inverse reinforcement learning to draw insights from offline promptingdemonstration data. Such data exists as by-products when diverse prompts arebenchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependentprompt optimization objective is achieved by first learning an offline rewardmodel. This model can evaluate any query-prompt pairs without accessing LLMs.Subsequently, a best-of-N strategy is deployed to recommend the optimal prompt.Our experimental evaluations across various LLM scales and arithmetic reasoningdatasets underscore both the efficacy and economic viability of the proposedapproach.",Hao Sun,2023/9/13,2023/10/21
2303.12371v2,$P^{3}O$: Transferring Visual Representations for Reinforcement Learning via Prompting,http://arxiv.org/abs/2303.12371v2,"It is important for deep reinforcement learning (DRL) algorithms to transfertheir learned policies to new environments that have different visual inputs.In this paper, we introduce Prompt based Proximal Policy Optimization($P^{3}O$), a three-stage DRL algorithm that transfers visual representationsfrom a target to a source environment by applying prompting. The process of$P^{3}O$ consists of three stages: pre-training, prompting, and predicting. Inparticular, we specify a prompt-transformer for representation conversion andpropose a two-step training process to train the prompt-transformer for thetarget environment, while the rest of the DRL pipeline remains unchanged. Weimplement $P^{3}O$ and evaluate it on the OpenAI CarRacing video game. Theexperimental results show that $P^{3}O$ outperforms the state-of-the-art visualtransferring schemes. In particular, $P^{3}O$ allows the learned policies toperform well in environments with different visual inputs, which is much moreeffective than retraining the policies in these environments.",Guoliang You,2023/3/22,2023/3/27
2206.03931v3,Learning to Generate Prompts for Dialogue Generation through Reinforcement Learning,http://arxiv.org/abs/2206.03931v3,"Much literature has shown that prompt-based learning is an efficient methodto make use of the large pre-trained language model. Recent works also exhibitthe possibility of steering a chatbot's output by plugging in an appropriateprompt. Gradient-based methods are often used to perturb the prompts. However,some language models are not even available to the public. In this work, wefirst explored the combination of prompting and reinforcement learning (RL) tosteer models' generation without accessing any of the models' parameters.Second, to reduce the training effort and enhance the generalizability to theunseen task, we apply multi-task learning to make the model learn to generalizeto new tasks better. The experiment results show that our proposed method cansuccessfully control several state-of-the-art (SOTA) dialogue models withoutaccessing their parameters. Furthermore, the model demonstrates the strongability to quickly adapt to an unseen task in fewer steps than the baselinemodel.",Hsuan Su,2022/6/8,2022/10/13
2311.06752v1,BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis,http://arxiv.org/abs/2311.06752v1,"Recently, diffusion-based deep generative models (e.g., Stable Diffusion)have shown impressive results in text-to-image synthesis. However, currenttext-to-image models often require multiple passes of prompt engineering byhumans in order to produce satisfactory results for real-world applications. Wepropose BeautifulPrompt, a deep generative model to produce high-qualityprompts from very simple raw descriptions, which enables diffusion-based modelsto generate more beautiful images. In our work, we first fine-tuned theBeautifulPrompt model over low-quality and high-quality collecting promptpairs. Then, to ensure that our generated prompts can generate more beautifulimages, we further propose a Reinforcement Learning with Visual AI Feedbacktechnique to fine-tune our model to maximize the reward values of the generatedprompts, where the reward values are calculated based on the PickScore and theAesthetic Scores. Our results demonstrate that learning from visual AI feedbackpromises the potential to improve the quality of generated prompts and imagessignificantly. We further showcase the integration of BeautifulPrompt to acloud-native AI platform to provide better text-to-image generation service inthe cloud.",Tingfeng Cao,2023/11/12,2023/11/12
2112.02347v4,Evaluation of the Constant Fraction Time-Over-Threshold (CF-TOT) method for neutron-gamma pulse shape discrimination,http://arxiv.org/abs/2112.02347v4,"The use of Time-over-Threshold (TOT) for the discrimination between fastneutrons and gamma-rays is advantageous when large number of detection channelsare required due to the simplicity of its implementation. However, the resultsobtained using the standard, Constant Threshold TOT (CT-TOT) are usuallyinferior to those obtained using other pulse shape discrimination (PSD)methods, such as Charge Comparison or Zero-Crossing approaches, especially forlow amplitude neutron/gamma-ray pulses. We evaluate another TOT approach forfast neutron/gamma-ray PSD using Constant-Fraction Time-over-Threshold (CF-TOT)pulse shape analysis. The CT-TOT and CF-TOT methods were comparedquantitatively using digitized waveforms from a liquid scintillator coupled toa photomultiplier tube as well as from a stilbene scintillator coupled to aphotomultiplier tube and a silicon photomultiplier. The quality of CF-TOTneutron/gamma-ray discrimination was evaluated using Receiver OperatorCharacteristics curves and the results obtained with this approach werecompared to the that of the standard CT-TOT method. The CF-TOT PSD methodresults in > 99.9% rejection of gamma-rays with > 80% neutron acceptance, muchbetter than CT-TOT.",A. Roy,2021/12/4,2022/4/19
2305.08291v1,Large Language Model Guided Tree-of-Thought,http://arxiv.org/abs/2305.08291v1,"In this paper, we introduce the Tree-of-Thought (ToT) framework, a novelapproach aimed at improving the problem-solving capabilities of auto-regressivelarge language models (LLMs). The ToT technique is inspired by the human mind'sapproach for solving complex reasoning tasks through trial and error. In thisprocess, the human mind explores the solution space through a tree-like thoughtprocess, allowing for backtracking when necessary. To implement ToT as asoftware system, we augment an LLM with additional modules including a prompteragent, a checker module, a memory module, and a ToT controller. In order tosolve a given problem, these modules engage in a multi-round conversation withthe LLM. The memory module records the conversation and state history of theproblem solving process, which allows the system to backtrack to the previoussteps of the thought-process and explore other directions from there. To verifythe effectiveness of the proposed technique, we implemented a ToT-based solverfor the Sudoku Puzzle. Experimental results show that the ToT framework cansignificantly increase the success rate of Sudoku puzzle solving. Ourimplementation of the ToT-based Sudoku solver is available on GitHub:\url{https://github.com/jieyilong/tree-of-thought-puzzle-solver}.",Jieyi Long,2023/5/15,2023/5/15
1102.0020v2,Homology operations and cosimplicial iterated loop spaces,http://arxiv.org/abs/1102.0020v2,If X is a cosimplical $E_{n+1}$ space then Tot(X) is an $E_{n+1}$ space andits mod 2 homology $H_*(Tot(X))$ has Dyer-Lashof and Browder operations. It'snatural to ask if the spectral sequence converging to $H_*(Tot(X))$ admitscompatible operations. In this paper I give a positive answer to this question.,Philip Hackney,2011/1/31,2014/1/28
1702.07124v1,Trojan of Things: Embedding Malicious NFC Tags into Common Objects,http://arxiv.org/abs/1702.07124v1,"We present a novel proof-of-concept attack named Trojan of Things (ToT),which aims to attack NFC- enabled mobile devices such as smartphones. The keyidea of ToT attacks is to covertly embed maliciously programmed NFC tags intocommon objects routinely encountered in daily life such as banknotes, clothing,or furniture, which are not considered as NFC touchpoints. To fully explore thethreat of ToT, we develop two striking techniques named ToT device and Phantomtouch generator. These techniques enable an attacker to carry out varioussevere and sophisticated attacks unbeknownst to the device owner whounintentionally puts the device close to a ToT. We discuss the feasibility ofthe attack as well as the possible countermeasures against the threats of ToTattacks.",Seita Maruyama,2017/2/23,2017/2/23
1811.02451v1,Numerical study of flow patterns and heat transfer in mini twisted oval tubes,http://arxiv.org/abs/1811.02451v1,"Flow patterns and heat transfer inside mini twisted oval tubes (TOTs) heatedby constant-temperature walls are numerically investigated. Differentconfigurations of tubes are simulated using water as the working fluid withtemperature-dependent thermo-physical properties at Reynolds numbers rangingbetween 500 and 1100. After validating the numerical method with the publishedcorrelations and available experimental results, the performance of TOTs iscompared to a smooth circular tube. The overall performance of TOTs isevaluated by investigating the thermal-hydraulic performance and the resultsare analyzed in terms of the field synergy principle and entropy generation.Enhanced heat transfer performance for TOTs is observed at the expense of ahigher pressure drop. Additionally, the secondary flow generated by thetube-wall twist is concluded to play a critical role in the augmentation ofconvective heat transfer, and consequently, better heat transfer performance.It is also observed that the improvement of synergy between velocity andtemperature gradient and lower irreversibility cause heat transfer enhancementfor TOTs.",Amin Ebrahimi,2018/11/6,2018/11/6
hep-th/0207269v1,Electrons-Holes on Noncommutative Plane and Hall Effect,http://arxiv.org/abs/hep-th/0207269v1,"By considering N_e-electrons and N_h-holes together in uniform externalmagnetic and electric fields, we end up with a total Hall conductivity\sigma_{H}^{tot}, which is depending to the difference between N_e and N_h andbecomes null when N_e=N_h. Dealing with the same system but requiring that thecoordinates of plane are noncommuting, we obtain a new Hall conductivity\sigma_{H}^{(tot,nc)}. In the limit N_e=N_h, we find that \sigma_{H}^{(tot,nc)}is only noncommutativity parameters \theta_i-dependent, which means thattheoretically it is possible to have Hall effect without B. Moreover, at thecritical points \theta_e=l^2 and \theta_h=-l^2, we find that\sigma_{H}^{(tot,nc)} becomes two times the usual Hall conductivity for annoninteracting mixing system.",Ahmed Jellal,2002/7/30,2002/7/30
1011.1652v1,Measurement of the energy dependence of the total photon-proton cross section at HERA,http://arxiv.org/abs/1011.1652v1,"The energy dependence of the photon-proton total cross section, sigma-tot,was determined from ep scattering data collected with the ZEUS detector at HERAat three values of the center-of-mass energy, W, of the gamma-p system in therange 194<W<296 GeV. This is the first determination of the W dependence ofsigma-tot from a single experiment at high W. Parameterizing sigma-totproportional to W^(2 epsilon), epsilon = 0.111 +/- 0.009 (stat.) +/- 0.036(syst.) was obtained.",ZEUS Collaboration,2010/11/7,2010/11/7
1101.5395v3,Spectral sequence operations converge to Araki-Kudo operations,http://arxiv.org/abs/1101.5395v3,"Previously we constructed operations in the mod 2 homology spectral sequenceassociated to a cosimplicial E-infinity space X. The correct target for thisspectral sequence is the homology of Tot X. Noting that in this setting Tot Xis an E-infinity space, we show that our operations agree with the usualAraki-Kudo operations in the target. We also prove that the multiplication inthe spectral sequence agrees with the multiplication in H_*(Tot X).",Philip Hackney,2011/1/27,2012/12/20
2301.02770v1,On Primorial Numbers,http://arxiv.org/abs/2301.02770v1,"Prime numbers have attracted the attention of mathematiciansand enthusiastsfor millenniums due to their simple definition and remarkable properties. Inthis paper, we study primorial numbers (the product of the first prime numbers)to define primorial sets, primorial intervals, primorial tables, and primorialtotative numbers. We establish relationships between prime numbers andprimorial totative numbers and between admissible k-tuples of prime numbers andadmissible k-tuples of primorial totative. Finally, we study the Goldbachconjecture and derive four Goldbach conjectures using primordial intervals,twin, cousin, and sexy prime numbers.",Jonatan Gomez,2023/1/7,2023/1/7
1501.06846v1,TOT Measurement Implemented in FPGA TDC,http://arxiv.org/abs/1501.06846v1,"Time measurement plays a crucial rule for the purpose of particleidentification in high energy physical experiments. With the upgrading ofphysical goal and the developing of electronics, modern time measurement systemmeets the requirement of excellent resolution specification as well as highintegrity. Due to Field Programmable Gate Array (FPGA), FPGA time-to-digitalconverter (TDC) becomes one of mature and prominent time measurement methods inrecent years. For correcting time-walk effect caused by leading timing,time-over-threshold (TOT) measurement should be added in the FPGA TDC. TOT canbe obtained by measuring the interval time of signal leading and trailing edge.Unfortunately, a traditional TDC can recognize only one kind of signal edge,the leading or the trailing. Generally, to measure the interval, two TDCchannels can be used at the same time, one for leading, the other for trailing.However, this method will increase the amount of used FPGA resource and reducethe TDC's integrity unavoidably. This paper presents one method of TOTmeasurement implemented in a Xilinx Virtex-5 FPGA. In this method, TOT measurecan be achieved in only one TDC input channel. The consumed resources and timeresolution can both be guaranteed. Test shows that this TDC can achieveresolution better than 15 ps for leading edge measurement and 37 ps for TOTmeasurement. Furthermore, the TDC measuring dead time is about 2 clock cycles,which makes it be good for applications of higher physical event rate",Huanhuan Fan,2015/1/26,2015/1/26
2212.09711v1,Optimization and first electronic implementation of the Constant-Fraction Time-Over-Threshold pulse shape discrimination method,http://arxiv.org/abs/2212.09711v1,"In this contribution we report on further investigations of therecently-evaluated Constant-Fraction Time-over-Threshold (CF-ToT) method forneutron/gamma-ray pulse shape discrimination (PSD). The superiority of theCF-ToT PSD method over the constant-threshold (CT-ToT) method was previouslydemonstrated, down to low neutron energy thresholds of 100 keVee. Here, wereport on a quantitative comparison between the traditionally used ChargeComparison (CC) method and the CF-ToT method using a stilbene scintillatorcoupled to a silicon photomultiplier, implementing an offline analysis ofrecorded fast-neutron and gamma-ray waveforms. An optimization of the constantfraction value indicates that a 20%-fraction yields the optimum figure-of-merit(FOM) and gamma-ray peak-to-valley (P/V) ratio. The results obtained for aparticle energy threshold of 100 keVee show that the FOM and P/V valuesachieved with the CF-ToT method are superior to those obtained using thestandard CC method. In addition, a first electronic implementation of theCF-ToT method was performed using simple circuitry suitable for multichannelarchitecture. Initial results obtained with this circuit prototype arepresented.",A. Roy,2022/12/19,2022/12/19
cs/0204008v1,The tip-of-the-tongue phenomenon: Irrelevant neural network localization or disruption of its interneuron links ?,http://arxiv.org/abs/cs/0204008v1,On the base of recently proposed three-stage quantitative neural networkmodel of the tip-of-the-tongue (TOT) phenomenon a possibility to occur of TOTstates coursed by neural network interneuron links' disruption has beenstudied. Using a numerical example it was found that TOTs coursed by interneronlinks' disruption are in (1.5 + - 0.3)x1000 times less probable then thosecoursed by irrelevant (incomplete) neural network localization. It was shownthat delayed TOT states' etiology cannot be related to neural networkinterneuron links' disruption.,Petro M. Gopych,2002/4/4,2002/4/4
1501.04700v1,The paradoxical relationship of difficulty and lateral frontal cortex activity,http://arxiv.org/abs/1501.04700v1,"Task difficulty is widely cited in current theory regarding cognitive controland fronto-parietal function. Ongoing debate surrounds the extent to whichglobal difficulty across multiple cognitive demands is the main driver oflateral frontal activity. Here, we examine a commonly cited behavioral markerof difficulty in these accounts: time-on-task (ToT), as assessed by responsetime. Specifically, we investigate the task-dependent scaling of frontal BOLDresponses with ToT during hierarchical cognitive control. We observe aparadoxical relationship, whereby rostral regions show greater scaling with ToTon a first-order task, despite showing greater recruitment on a second-ordertask; caudal regions show the converse relationships. Together, these resultsdemonstrate that ToT does not reflect a single dimension of difficulty thatuniformly drives lateral frontal activity. Rather, this discrepancy in the meanand scaling of BOLD requires that multiple, distinct processes are instantiatedacross these fronto-parietal regions in the service of cognitive controlfunction.",Christopher H. Chatham,2015/1/20,2015/1/20
1601.03158v2,Nonequilibrium Thermodynamic Formalism of Nonlinear Chemical Reaction Systems with Waage-Guldberg's Law of Mass Action,http://arxiv.org/abs/1601.03158v2,"Macroscopic entropy production $\sigma^{(tot)}$ in the general nonlinearisothermal chemical reaction system with mass action kinetics is decomposedinto a free energy dissipation and a house-keeping heat:$\sigma^{(tot)}=\sigma^{(fd)}+\sigma^{(hk)}$; $\sigma^{(fd)}=-\rd A/\rd t$,where $A$ is a generalized free energy function. This yields a novelnonequilibrium free energy balance equation $\rd A/\rdt=-\sigma^{(tot)}+\sigma^{(hk)}$, which is on a par with celebrated entropybalance equation $\rd S/\rd t=\sigma^{(tot)}+\eta^{(ex)}$ where $\eta^{(ex)}$is the rate of entropy exchange with the environment.For kinetic systems withcomplex balance, $\sigma^{(fd)}$ and $\sigma^{(hk)}$ are the macroscopic limitsof stochastic free energy dissipation and house-keeping heat, which are bothnonnegative, in the Delbr\""uck-Gillespie description of the stochastic chemicalkinetics.Therefore, we show that a full kinetic and thermodynamic theory ofchemical reaction systems that transcends mesoscopic and macroscopic levelsemerges.",Hao Ge,2016/1/13,2016/4/26
2106.02893v1,Stern and Diffuse Layer Interactions During Ionic Strength Cycling,http://arxiv.org/abs/2106.02893v1,"Second harmonic generation amplitude and phase measurements are acquired inreal time from fused silica:water interfaces that are subjected to ionicstrength transitions conducted at pH 5.8. In conjunction with atomisticmodeling, we identify correlations between structure in the Stern layer,encoded in the total second-order nonlinear susceptibility, chi(2)tot, and inthe diffuse layer, encoded in the product of chi(2)tot and the totalinterfacial potential, phi(0)tot. chi(2)tot:phi(0)tot correlation plotsindicate that the dynamics in the Stern and diffuse layers are decoupled fromone another under some conditions (large change in ionic strength), while theychange in lockstep under others (smaller change in ionic strength) as the ionicstrength in the aqueous bulk solution varies. The quantitative structural andelectrostatic information obtained also informs on the molecular origin ofhysteresis in ionic strength cycling over fused silica. Atomistic simulationssuggest a prominent role of contact ion pairs (as opposed to solvent-separatedion pairs) in the Stern layer. Those simulations also indicate that net wateralignment is limited to the first 2 nm from the interface, even at 0 M ionicstrength, highlighting water's polarization as an important contributor tononlinear optical signal generation.",Emily Ma,2021/6/5,2021/6/5
hep-ph/0605337v2,"Proposing a new constraint for predictions of pp, pbar p total cross sections and rho ratio at LHC",http://arxiv.org/abs/hep-ph/0605337v2,"We propose a new constraint(1) corresponding to the FESR (with the momentn=-1) free from unphysical regions. Using this constraint(1) together with theconstraint(2) (with the moment n=1), we search for the simultaneous best fit tothe data points of sigma-tot and rho ratio up to the SPS energies to determinethose values at higher energies. We then predict sigma-tot=107.1 +- 2.6 mb,rho=0.127 +- 0.004 at the LHC energy(E=14 TeV).",Keiji Igi,2006/5/31,2006/7/20
hep-ph/0510129v2,"Predictions of pp, pbar p total cross section and rho ratio at LHC and cosmic-ray energies based on duality",http://arxiv.org/abs/hep-ph/0510129v2,"Based on duality, we previously proposed to use rich informations on pi ptotal cross sections below N=10GeV in addition to high-energy data in order todiscriminate whether these cross sections increase like log nu or log2 nu athigh energies. We then arrived at the conclusion that our analysis prefers thelog2 nu behaviours. Using the FESR as a constraint for high energy parametersalso for the pp, pbar p scattering, we search for the simultaneous best fit tothe data points of sigma(tot) and rho ratio up to some energy (e.g., ISR,Tevatron) to determine the high-energy parameters. We then predict sigma(tot)and rho in the LHC and high-energy cosmic-ray regions. Using the data up toE=1.8TeV (Tevatron), we predict sigma(tot)pp and rho(pp) at the LHC energy(E=14TeV) as 106.3+- 5.1syst +- 2.4stat mb and 0.126 +- 0.007syst +- 0.004stat,respectively. The predicted values of sigma(tot) in terms of the sameparameters are in good agreement with the cosmic-ray experimental data up toPlab = 10 (8--9) GeV.",Keiji Igi,2005/10/11,2005/11/2
2101.07124v1,Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification,http://arxiv.org/abs/2101.07124v1,"While current information retrieval systems are effective for known-itemretrieval where the searcher provides a precise name or identifier for the itembeing sought, systems tend to be much less effective for cases where thesearcher is unable to express a precise name or identifier. We refer to this astip of the tongue (TOT) known-item retrieval, named after the cognitive stateof not being able to retrieve an item from memory. Using movie search as a casestudy, we explore the characteristics of questions posed by searchers in TOTstates in a community question answering website. We analyze how searchersexpress their information needs during TOT states in the movie domain.Specifically, what information do searchers remember about the item beingsought and how do they convey this information? Our results suggest thatsearchers use a combination of information about: (1) the content of the itemsought, (2) the context in which they previously engaged with the item, and (3)previous attempts to find the item using other resources (e.g., searchengines). Additionally, searchers convey information by sometimes expressinguncertainty (i.e., hedging), opinions, emotions, and by performing relative(vs. absolute) comparisons with attributes of the item. As a result of ouranalysis, we believe that searchers in TOT states may require specialized queryunderstanding methods or document representations. Finally, our preliminaryretrieval experiments show the impact of each information type presented ininformation requests on retrieval performance.",Jaime Arguello,2021/1/18,2021/1/18
2112.03166v1,X-ray characterization of BUSARD chip: A HV-SOI monolithic particle detector with pixel sensors under the buried oxide,http://arxiv.org/abs/2112.03166v1,"This work presents the design of BUSARD, an application specific integratedcircuit (ASIC) for the detection of ionizing particles. The ASIC is amonolithic active pixel sensor which has been fabricated in a High-VoltageSilicon-On-Insulator (HV-SOI) process that allows the fabrication of a buriedN+ diffusion below the Buried OXide (BOX) as a standard processing step. Thefirst version of the chip, BUSARD-A, takes advantage of this buried diffusionas an ionizing particle sensor. It includes a small array of 13$\times$13pixels, with a pitch of $80\,\mu$m, and each pixel has one buried diffusionwith a charge amplifier, discriminator with offset tuning and digitalprocessing. The detector has several operation modes including particlecounting and Time-over-Threshold (ToT). An initial X-ray characterization ofthe detector was carried out, obtaining several pulse height and ToT spectra,which then were used to perform the energy calibration of the device. TheMolybdenum $\mathbf{K_{\alpha}}$ emission was measured with a standarddeviation of $127\,e^{-}$ of ENC by using the analog pulse output, and with$276\,e^{-}$ of ENC by using the ToT digital output. The resolution in ToT modeis dominated by the pixel-to-pixel variation.",Fabricio Alcalde Bessia,2021/12/6,2021/12/6
hep-ph/0512135v1,"On the Discrepancy of pp, pbar p Total Cross Sections at sqrt s = 1.8TeV",http://arxiv.org/abs/hep-ph/0512135v1,"Based on the previous approach, we have investigated a possibility to resolvethe discrepancy between the E710, E811 and CDF at sqrt s =1.8TeV, using theexperimental data of the pp, pbar p total cross sections sigma tot(+) andrho(+)$ ratio up to the SPS experiments (sqrt s = 0.9TeV) as inputs. We predictsigma tot(pbar p) and rho(pbar p) at the Tevatron energy(sqrt s=1.8TeV) assigma tot(pbar p)=75.9+- 1.0mb, rho(pbar p)=0.136+- 0.005.  It turns out that only the data of E710 is consistent with the prediction inthe one standard deviation. So we can conclude that E710 is preferable but wecan exclude neither CDF nor E811 results.",Keiji Igi,2005/12/11,2005/12/11
2303.05995v1,Exploring Gender Bias in Remote Pair Programming among Software Engineering Students: The twincode Original Study and First External Replication,http://arxiv.org/abs/2303.05995v1,"Context. Software Engineering (SE) has low female representation due togender bias that men are better at programming. Pair programming (PP) is commonin industry and can increase student interest in SE, especially women; but ifgender bias affects PP, it may discourage women from joining the field.  Objective. We explore gender bias in PP. In a remote setting where studentscannot see their peers' gender, we study how perceived productivity, technicalcompetency and collaboration/interaction behaviors of SE students vary byperceived gender of their remote partner.  Method. We developed an online PP platform (twincode) with a collaborativeediting window and a chat pane. Control group had no gender information abouttheir partner, while treatment group saw a gendered avatar as a man or woman.Avatar gender was swapped between tasks to analyze 45 variables oncollaborative coding behavior, chat utterances and questionnaire responses of46 pairs in original study at the University of Seville and 23 pairs in thereplication at the University of California, Berkeley.  Results. No significant effect of gender bias treatment or interactionbetween perceived partner's gender and subject's gender in any variable inoriginal study. In replication, significant effects with moderate to largesizes in four variables within experimental group comparing subjects' actionswhen partner was male vs female.",Amador Durn,2023/3/10,2023/3/10
1911.00665v1,Chat-Bot-Kit: A web-based tool to simulate text-based interactions between humans and with computers,http://arxiv.org/abs/1911.00665v1,"In this paper, we describe Chat-Bot-Kit, a web-based tool for text-basedchats that we designed for research purposes in computer-mediated communication(CMC). Chat-Bot-Kit enables to carry out language studies on text-basedreal-time chats for the purpose of research: The generated messages arestructured with language performance data such as pause and speed ofkeyboard-handling and the movement of the mouse. The tool provides two modes ofchat communications - quasi-synchron and synchron modes - and various typingindicators. The tool is also designed to be used in wizard-of-oz studies inHuman-Computer Interaction (HCI) and for the evaluation of chatbots (dialoguesystems) in Natural Language Processing (NLP).",Kyoko Sugisaki,2019/11/2,2019/11/2
2012.02640v2,A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering,http://arxiv.org/abs/2012.02640v2,"Chatbots are envisioned to dramatically change the future of SoftwareEngineering, allowing practitioners to chat and inquire about their softwareprojects and interact with different services using natural language. At theheart of every chatbot is a Natural Language Understanding (NLU) component thatenables the chatbot to understand natural language input. Recently, many NLUplatforms were provided to serve as an off-the-shelf NLU component forchatbots, however, selecting the best NLU for Software Engineering chatbotsremains an open challenge.  Therefore, in this paper, we evaluate four of the most commonly used NLUs,namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light onwhich NLU should be used in Software Engineering based chatbots. Specifically,we examine the NLUs' performance in classifying intents, confidence scoresstability, and extracting entities. To evaluate the NLUs, we use two datasetsthat reflect two common tasks performed by Software Engineering practitioners,1) the task of chatting with the chatbot to ask questions about softwarerepositories 2) the task of asking development questions on Q&A forums (e.g.,Stack Overflow). According to our findings, IBM Watson is the best performingNLU when considering the three aspects (intents classification, confidencescores, and entity extraction). However, the results from each individualaspect show that, in intents classification, IBM Watson performs the best withan F1-measure > 84%, but in confidence scores, Rasa comes on top with a medianconfidence score higher than 0.91. Our results also show that all NLUs, exceptfor Dialogflow, generally provide trustable confidence scores. For entityextraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SEtasks. Our results provide guidance to software engineering practitioners whendeciding which NLU to use in their chatbots.",Ahmad Abdellatif,2020/12/4,2021/7/22
2307.03826v1,How does AI chat change search behaviors?,http://arxiv.org/abs/2307.03826v1,"Generative AI tools such as chatGPT are poised to change the way peopleengage with online information. Recently, Microsoft announced their ""new Bing""search system which incorporates chat and generative AI technology from OpenAI.Google has announced plans to deploy search interfaces that incorporate similartypes of technology. These new technologies will transform how people cansearch for information. The research presented here is an early investigationinto how people make use of a generative AI chat system (referred to simply aschat from here on) as part of a search process, and how the incorporation ofchat systems with existing search tools may effect users search behaviors andstrategies.  We report on an exploratory user study with 10 participants who used acombined Chat+Search system that utilized the OpenAI GPT-3.5 API and the BingWeb Search v5 API. Participants completed three search tasks. In this pre-printpaper of preliminary results, we report on ways that users integrated AI chatinto their search process, things they liked and disliked about the chatsystem, their trust in the chat responses, and their mental models of how thechat system generated responses.",Robert Capra,2023/7/7,2023/7/7
2308.01044v1,Chat Translation Error Detection for Assisting Cross-lingual Communications,http://arxiv.org/abs/2308.01044v1,"In this paper, we describe the development of a communication support systemthat detects erroneous translations to facilitate crosslingual communicationsdue to the limitations of current machine chat translation methods. We trainedan error detector as the baseline of the system and constructed a newJapanese-English bilingual chat corpus, BPersona-chat, which comprisesmultiturn colloquial chats augmented with crowdsourced quality ratings. Theerror detector can serve as an encouraging foundation for more advancederroneous translation detection systems.",Yunmeng Li,2023/8/2,2023/8/2
2106.14704v1,"Chat Room Using HTML, PHP, CSS, JS, AJAX",http://arxiv.org/abs/2106.14704v1,Earlier there was no mode of online communication between users. In big orsmall organizations communication between users posed a challenge. There was arequirement to record these communications and store the data for furtherevaluation. The idea is to automate the existing Simple Chat Room system andmake the users utilize the software so that their valuable information isstored digitally and can be retrieved for further management purposes. Therewas no online method of communicating with different users. There were manydifferent interfaces available in the market but this method of using windowssockets to communicate between nodes would be fast and reliable. The mainobjective of our Simple Chat Room project is to create a chat application thathelps different users to communicate with each other through a serverconnected. This is a simple chat program with a server and can have manyclients. The server needs to be started first and clients can be connectedlater. Simple Chat Room provides bidirectional communication between client andserver. It enables users to seamlessly communicate with each other. The usercan chat using this chat application. If the user at the other end is activethen they can start a chat session. The chat is recorded in this application.,Amey Thakur,2021/6/28,2021/6/28
1204.2774v1,An Empirical Study of Spam and Prevention Mechanisms in Online Video Chat Services,http://arxiv.org/abs/1204.2774v1,"Recently, online video chat services are becoming increasingly popular. Whileexperiencing tremendous growth, online video chat services have also become yetanother spamming target. Unlike spam propagated via traditional medium likeemails and social networks, we find that spam propagated via online video chatservices is able to draw much larger attention from the users. We haveconducted several experiments to investigate spam propagation on Chatroulette -the largest online video chat website. We have found that the largest spamcampaign on online video chat websites is dating scams. Our study indicatesthat spam carrying dating or pharmacy scams have much higher clickthrough ratesthan email spam carrying the same content. In particular, dating scams reach aclickthrough rate of 14.97%. We also examined and analysed spam preventionmechanisms that online video chat websites have designed and implemented. Ourstudy indicates that the prevention mechanisms either harm legitimate userexperience or can be easily bypassed.",Xinyu Xing,2012/4/12,2012/4/12
1704.08500v1,Rationale in Development Chat Messages: An Exploratory Study,http://arxiv.org/abs/1704.08500v1,"Chat messages of development teams play an increasingly significant role insoftware development, having replaced emails in some cases. Chat messagescontain information about discussed issues, considered alternatives andargumentation leading to the decisions made during software development. Theseelements, defined as rationale, are invaluable during software evolution fordocumenting and reusing development knowledge. Rationale is also essential forcoping with changes and for effective maintenance of the software system.However, exploiting the rationale hidden in the chat messages is challengingdue to the high volume of unstructured messages covering a wide range oftopics. This work presents the results of an exploratory study examining thefrequency of rationale in chat messages, the completeness of the availablerationale and the potential of automatic techniques for rationale extraction.For this purpose, we apply content analysis and machine learning techniques onmore than 8,700 chat messages from three software development projects. Ourresults show that chat messages are a rich source of rationale and that machinelearning is a promising technique for detecting rationale and identifyingdifferent rationale elements.",Rana Alkadhi,2017/4/27,2017/4/27
2012.07300v2,Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and Context-Aware Auto-Encoders,http://arxiv.org/abs/2012.07300v2,"Automatic chat summarization can help people quickly grasp importantinformation from numerous chat messages. Unlike conventional documents, chatlogs usually have fragmented and evolving topics. In addition, these logscontain a quantity of elliptical and interrogative sentences, which make thechat summarization highly context dependent. In this work, we propose a novelunsupervised framework called RankAE to perform chat summarization withoutemploying manually labeled data. RankAE consists of a topic-oriented rankingstrategy that selects topic utterances according to centrality and diversitysimultaneously, as well as a denoising auto-encoder that is carefully designedto generate succinct but context-informative summaries based on the selectedutterances. To evaluate the proposed method, we collect a large-scale datasetof chat logs from a customer service environment and build an annotated setonly for model evaluation. Experimental results show that RankAE significantlyoutperforms other unsupervised methods and is able to generate high-qualitysummaries in terms of relevance and topic coverage.",Yicheng Zou,2020/12/14,2021/6/25
2110.08032v1,UniDS: A Unified Dialogue System for Chit-Chat and Task-oriented Dialogues,http://arxiv.org/abs/2110.08032v1,"With the advances in deep learning, tremendous progress has been made withchit-chat dialogue systems and task-oriented dialogue systems. However, thesetwo systems are often tackled separately in current methods. To achieve morenatural interaction with humans, a dialogue agent needs to be capable of bothchatting and accomplishing tasks. To this end, we propose a unified dialoguesystem (UniDS) with the two aforementioned skills. In particular, we design aunified dialogue data schema, compatible for both chit-chat and task-orienteddialogues, and we train UniDS with mixed dialogue data from a pretrainedchit-chat dialogue model. Without adding extra parameters to SOTA baselines,UniDS can alternatively handle chit-chat and task-oriented dialogues in aunified framework. Experimental results demonstrate that the proposed UniDSworks comparably well as the pure chit-chat system, and it outperformsstate-of-the-art task-oriented dialogue systems. More importantly, UniDSachieves better robustness as it is able to smoothly switch between two typesof dialogues. These results demonstrate the feasibility and potential ofbuilding an one-for-all dialogue system.",Xinyan Zhao,2021/10/15,2021/10/15
2205.03766v2,Scheduled Multi-task Learning for Neural Chat Translation,http://arxiv.org/abs/2205.03766v2,"Neural Chat Translation (NCT) aims to translate conversational text intodifferent languages. Existing methods mainly focus on modeling the bilingualdialogue characteristics (e.g., coherence) to improve chat translation viamulti-task learning on small-scale chat translation data. Although the NCTmodels have achieved impressive success, it is still far from satisfactory dueto insufficient chat translation data and simple joint training manners. Toaddress the above issues, we propose a scheduled multi-task learning frameworkfor NCT. Specifically, we devise a three-stage training framework toincorporate the large-scale in-domain chat translation data into training byadding a second pre-training stage between the original pre-training andfine-tuning stages. Further, we investigate where and how to schedule thedialogue-related auxiliary tasks in multiple training stages to effectivelyenhance the main chat translation task. Extensive experiments in four languagedirections (English-Chinese and English-German) verify the effectiveness andsuperiority of the proposed approach. Additionally, we have made thelarge-scale in-domain paired bilingual dialogue dataset publicly available tothe research community.",Yunlong Liang,2022/5/8,2022/5/10
2311.04755v1,Towards Understanding Emotions in Informal Developer Interactions: A Gitter Chat Study,http://arxiv.org/abs/2311.04755v1,"Emotions play a significant role in teamwork and collaborative activitieslike software development. While researchers have analyzed developer emotionsin various software artifacts (e.g., issues, pull requests), few studies havefocused on understanding the broad spectrum of emotions expressed in chats. Asone of the most widely used means of communication, chats contain valuableinformation in the form of informal conversations, such as negativeperspectives about adopting a tool. In this paper, we present a dataset ofdeveloper chat messages manually annotated with a wide range of emotion labels(and sub-labels), and analyze the type of information present in thosemessages. We also investigate the unique signals of emotions specific to chatsand distinguish them from other forms of software communication. Our findingssuggest that chats have fewer expressions of Approval and Fear but moreexpressions of Curiosity compared to GitHub comments. We also notice thatConfusion is frequently observed when discussing programming-relatedinformation such as unexpected software behavior. Overall, our study highlightsthe potential of mining emotions in developer chats for supporting softwaremaintenance and evolution tools.",Amirali Sajadi,2023/11/8,2023/11/8
2310.04799v1,Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities,http://arxiv.org/abs/2310.04799v1,"With the advancements in conversational AI, such as ChatGPT, this paperfocuses on exploring developing Large Language Models (LLMs) for non-Englishlanguages, especially emphasizing alignment with human preferences. Weintroduce a computationally efficient method, leveraging chat vector, tosynergize pre-existing knowledge and behaviors in LLMs, restructuring theconventional training paradigm from continual pre-train -> SFT -> RLHF tocontinual pre-train + chat vector. Our empirical studies, primarily focused onTraditional Chinese, employ LLaMA2 as the base model and acquire the chatvector by subtracting the pre-trained weights, LLaMA2, from the weights ofLLaMA2-chat. Evaluating from three distinct facets, which are toxicity, abilityof instruction following, and multi-turn dialogue demonstrates the chatvector's superior efficacy in chatting. To confirm the adaptability of ourapproach, we extend our experiments to include models pre-trained in bothKorean and Simplified Chinese, illustrating the versatility of our methodology.Overall, we present a significant solution in aligning LLMs with humanpreferences efficiently across various languages, accomplished by the chatvector.",Shih-Cheng Huang,2023/10/7,2023/10/7
1503.05533v1,Fundamental Analysis of a Developer Support Chat Log for Identifying Process Improvement Opportunities,http://arxiv.org/abs/1503.05533v1,In this report analysis of a support chat log of a development team is shown.Developer support chat is used to provide internal support to other developmentteams. The report shows how a fundamental data analysis helped to identify gapsand action items to boost performance of a development team by reducing timespent on developer support chat and minimizing interrupts from other developerteams. The report also shows an example of how a root cause analysis can besupported by simple data analysis in finding process improvement opportunities.,Zdor Dniel Kelemen,2015/3/18,2015/3/18
1704.05543v1,Coordinating Collaborative Chat in Massive Open Online Courses,http://arxiv.org/abs/1704.05543v1,An earlier study of a collaborative chat intervention in a Massive OpenOnline Course (MOOC) identified negative effects on attrition stemming from arequirement for students to be matched with exactly one partner prior tobeginning the activity. That study raised questions about how to orchestrate acollaborative chat intervention in a MOOC context in order to provide thebenefit of synchronous social engagement without the coordination difficulties.In this paper we present a careful analysis of an intervention designed toovercome coordination difficulties by welcoming students into the chat on arolling basis as they arrive rather than requiring them to be matched with apartner before beginning. The results suggest the most positive impact whenexperiencing a chat with exactly one partner rather than more or less. Aqualitative analysis of the chat data reveals differential experiences betweenthese configurations that suggests a potential explanation for the effect andraises questions for future research.,Gaurav Singh Tomar,2017/4/18,2017/4/18
2010.10447v1,Snap-and-Chat Protocols: System Aspects,http://arxiv.org/abs/2010.10447v1,"The availability-finality dilemma says that blockchain protocols cannot beboth available under dynamic participation and safe under network partition.Snap-and-chat protocols have recently been proposed as a resolution to thisdilemma. A snap-and-chat protocol produces an always available ledgercontaining a finalized prefix ledger which is always safe and catches up withthe available ledger whenever network conditions permit. In contrast toexisting handcrafted finality gadget based designs like Ethereum 2.0'sconsensus protocol Gasper, snap-and-chat protocols are constructed as ablack-box composition of off-the-shelf BFT and longest chain protocols. In thispaper, we consider system aspects of snap-and-chat protocols and show how theycan provide two important features: 1) accountability, 2) support of lightclients. Through this investigation, a deeper understanding of the strengthsand challenges of snap-and-chat protocols is gained.",Joachim Neu,2020/10/20,2020/10/20
2004.09786v1,Chat activity is a better predictor than chat sentiment on software developers productivity,http://arxiv.org/abs/2004.09786v1,"Recent works have proposed that software developers' positive emotion has apositive impact on software developers' productivity. In this paper weinvestigate two data sources: developers chat messages (from Slack and Hipchat)and source code commits of a single co-located Agile team over 200 workingdays. Our regression analysis shows that the number of chat messages is thebest predictor and predicts productivity measured both in the number of commitsand lines of code with $R^2$ of 0.33 and 0.27 respectively. We then addsentiment analysis variables until AIC of our model no longer improves and gets$R^2$ values of 0.37 (commits) and 0.30 (lines of code). Thus, analyzing chatsentiment improves productivity prediction over chat activity alone but thedifference is not massive. This work supports the idea that emotional state andproductivity are linked in software development. We find that three positivesentiment metrics, but surprisingly also one negative sentiment metric isassociated with higher productivity.",Miikka Kuutila,2020/4/21,2020/4/21
2011.08074v1,Answer Identification in Collaborative Organizational Group Chat,http://arxiv.org/abs/2011.08074v1,"We present a simple unsupervised approach for answer identification inorganizational group chat. In recent years, organizational group chat is on therise enabling asynchronous text-based collaboration between co-workers indifferent locations and time zones. Finding answers to questions is oftencritical for work efficiency. However, group chat is characterized byintertwined conversations and 'always on' availability, making it hard forusers to pinpoint answers to questions they care about in real-time or searchfor answers in retrospective. In addition, structural and lexicalcharacteristics differ between chat groups, making it hard to find a 'one modelfits all' approach. Our Kernel Density Estimation (KDE) based clusteringapproach termed Ans-Chat implicitly learns discussion patterns as a means foranswer identification, thus eliminating the need to channel-specific tagging.Empirical evaluation shows that this solution outperforms other approached.",Naama Tepper,2020/11/4,2020/11/4
2111.14282v2,Customer Sentiment Analysis using Weak Supervision for Customer-Agent Chat,http://arxiv.org/abs/2111.14282v2,"Prior work on sentiment analysis using weak supervision primarily focuses ondifferent reviews such as movies (IMDB), restaurants (Yelp), products(Amazon).~One under-explored field in this regard is customer chat data for acustomer-agent chat in customer support due to the lack of availability of freepublic data. Here, we perform sentiment analysis on customer chat using weaksupervision on our in-house dataset. We fine-tune the pre-trained languagemodel (LM) RoBERTa as a sentiment classifier using weak supervision. Ourcontribution is as follows:1) We show that by using weak sentiment classifiersalong with domain-specific lexicon-based rules as Labeling Functions (LF), wecan train a fairly accurate customer chat sentiment classifier using weaksupervision. 2) We compare the performance of our custom-trained model withoff-the-shelf google cloud NLP API for sentiment analysis. We show that byinjecting domain-specific knowledge using LFs, even with weak supervision, wecan train a model to handle some domain-specific use cases better thanoff-the-shelf google cloud NLP API. 3) We also present an analysis of howcustomer sentiment in a chat relates to problem resolution.",Navdeep Jain,2021/11/29,2021/11/30
2312.02949v1,LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models,http://arxiv.org/abs/2312.02949v1,"With the recent significant advancements in large multi-modal models (LMMs),the importance of their grounding capability in visual chat is increasinglyrecognized. Despite recent efforts to enable LMMs to support grounding, theircapabilities for grounding and chat are usually separate, and their chatperformance drops dramatically when asked to ground. The problem is the lack ofa dataset for grounded visual chat (GVC). Existing grounding datasets onlycontain short captions. To address this issue, we have created GVC data thatallows for the combination of grounding and chat capabilities. To betterevaluate the GVC capabilities, we have introduced a benchmark calledGrounding-Bench. Additionally, we have proposed a model design that can supportGVC and various types of visual prompts by connecting segmentation models withlanguage models. Experimental results demonstrate that our model outperformsother LMMs on Grounding-Bench. Furthermore, our model achieves competitiveperformance on classic grounding benchmarks like RefCOCO/+/g and Flickr30KEntities. Our code will be released athttps://github.com/UX-Decoder/LLaVA-Grounding .",Hao Zhang,2023/12/5,2023/12/5
2311.11031v2,Having Difficulty Understanding Manuals? Automatically Converting User Manuals into Instructional Videos,http://arxiv.org/abs/2311.11031v2,"While users tend to perceive instructional videos as an experience ratherthan a lesson with a set of instructions, instructional videos are moreeffective and appealing than textual user manuals and eliminate the ambiguityin text-based descriptions. However, most software vendors only offer documentmanuals that describe how to install and use their software, leading burden fornon-professionals to comprehend the instructions. In this paper, we present aframework called M2V to generate instructional videos automatically based onthe provided instructions and images in user manuals. M2V is a two-stepframework. First, an action sequence is extracted from the given user manualvia natural language processing and computer vision techniques. Second, M2Voperates the software sequentially based on the extracted actions; meanwhile,the operation procedure is recorded into an instructional video. We evaluatethe usability of automatically generated instructional videos via user studiesand an online survey. The evaluation results show, with our toolkit, thegenerated instructional videos can better assist non-professional end userswith the software operations. Moreover, more than 85% of survey participantsprefer to use the instructional videos rather than the original user manuals.",Songsong Liu,2023/11/18,2023/11/21
2305.14327v2,Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation,http://arxiv.org/abs/2305.14327v2,"Instruction tuning has emerged to enhance the capabilities of large languagemodels (LLMs) to comprehend instructions and generate appropriate responses.Existing methods either manually annotate or employ LLM (e.g., GPT-series) togenerate data for instruction tuning. However, they often overlook associatinginstructions with existing annotated datasets. In this paper, we proposeDynosaur, a dynamic growth paradigm for the automatic curation ofinstruction-tuning data. Based on the metadata of existing datasets, we useLLMs to automatically construct instruction-tuning data by identifying relevantdata fields and generating appropriate instructions.  By leveraging the existing annotated datasets, Dynosaur offers severaladvantages: 1) it reduces the API cost for generating instructions (e.g., itcosts less than $12 USD by calling GPT-3.5-turbo for generating 800Kinstruction tuning samples; 2) it provides high-quality data for instructiontuning (e.g., it performs better than Alpaca and Flan on Super-NI and Longformwith comparable data sizes); and 3) it supports the continuous improvement ofmodels by generating instruction-tuning data when a new annotated datasetbecomes available. We further investigate a continual learning scheme forlearning with the ever-growing instruction-tuning dataset, and demonstrate thatreplaying tasks with diverse instruction embeddings not only helps mitigateforgetting issues but generalizes to unseen tasks better.  Code and data are available at https://github.com/WadeYin9712/Dynosaur.",Da Yin,2023/5/23,2023/10/26
2101.10504v1,On the Evaluation of Vision-and-Language Navigation Instructions,http://arxiv.org/abs/2101.10504v1,"Vision-and-Language Navigation wayfinding agents can be enhanced byexploiting automatically generated navigation instructions. However, existinginstruction generators have not been comprehensively evaluated, and theautomatic evaluation metrics used to develop them have not been validated.Using human wayfinders, we show that these generators perform on par with oronly slightly better than a template-based generator and far worse than humaninstructors. Furthermore, we discover that BLEU, ROUGE, METEOR and CIDEr areineffective for evaluating grounded navigation instructions. To improveinstruction evaluation, we propose an instruction-trajectory compatibilitymodel that operates without reference instructions. Our model shows the highestcorrelation with human wayfinding outcomes when scoring individualinstructions. For ranking instruction generation systems, if referenceinstructions are available we recommend using SPICE.",Ming Zhao,2021/1/26,2021/1/26
2310.13127v1,Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models,http://arxiv.org/abs/2310.13127v1,"Large language models (LLMs) can perform a wide range of tasks by followingnatural language instructions, without the necessity of task-specificfine-tuning. Unfortunately, the performance of LLMs is greatly influenced bythe quality of these instructions, and manually writing effective instructionsfor each task is a laborious and subjective process. In this paper, weintroduce Auto-Instruct, a novel method to automatically improve the quality ofinstructions provided to LLMs. Our method leverages the inherent generativeability of LLMs to produce diverse candidate instructions for a given task, andthen ranks them using a scoring model trained on a variety of 575 existing NLPtasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses bothhuman-written instructions and existing baselines of LLM-generatedinstructions. Furthermore, our method exhibits notable generalizability evenwith other LLMs that are not incorporated into its training process.",Zhihan Zhang,2023/10/19,2023/10/19
2311.13246v1,Automatic Instruction Optimization for Open-source LLM Instruction Tuning,http://arxiv.org/abs/2311.13246v1,"Instruction tuning is crucial for enabling Language Learning Models (LLMs) inresponding to human instructions. The quality of instruction pairs used fortuning greatly affects the performance of LLMs. However, the manual creation ofhigh-quality instruction datasets is costly, leading to the adoption ofautomatic generation of instruction pairs by LLMs as a popular alternative inthe training of open-source LLMs. To ensure the high quality of LLM-generatedinstruction datasets, several approaches have been proposed. Nevertheless,existing methods either compromise dataset integrity by filtering a largeproportion of samples, or are unsuitable for industrial applications. In thispaper, instead of discarding low-quality samples, we propose CoachLM, a novelapproach to enhance the quality of instruction datasets through automaticrevisions on samples in the dataset. CoachLM is trained from the samplesrevised by human experts and significantly increases the proportion ofhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness ofCoachLM is further assessed on various real-world instruction test sets. Theresults show that CoachLM improves the instruction-following capabilities ofthe instruction-tuned LLM by an average of 29.9%, which even surpasses largerLLMs with nearly twice the number of parameters. Furthermore, CoachLM issuccessfully deployed in a data management system for LLMs at Huawei, resultingin an efficiency improvement of up to 20% in the cleaning of 40k real-worldinstruction pairs. We release the training data and code of CoachLM(https://github.com/lunyiliu/CoachLM).",Yilun Liu,2023/11/22,2023/11/22
2311.18215v1,Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models,http://arxiv.org/abs/2311.18215v1,"Caution: this paper may include material that could be offensive ordistressing.  The advent of Large Language Models (LLMs) necessitates the development oftraining approaches that mitigate the generation of unethical language andaptly manage toxic user queries. Given the challenges related to human laborand the scarcity of data, we present KoTox, comprising 39K unethicalinstruction-output pairs. This collection of automatically generated toxicinstructions refines the training of LLMs and establishes a foundationalframework for improving LLMs' ethical awareness and response to various toxicinputs, promoting more secure and responsible interactions in Natural LanguageProcessing (NLP) applications.",Sungjoo Byun,2023/11/30,2023/11/30
2305.04429v1,Improving Cross-Task Generalization with Step-by-Step Instructions,http://arxiv.org/abs/2305.04429v1,"Instruction tuning has been shown to be able to improve cross-taskgeneralization of language models. However, it is still challenging forlanguage models to complete the target tasks following the instructions, as theinstructions are general and lack intermediate steps. To address this problem,we propose to incorporate the step-by-step instructions to help language modelsto decompose the tasks, which can provide the detailed and specific proceduresfor completing the target tasks. The step-by-step instructions are obtainedautomatically by prompting ChatGPT, which are further combined with theoriginal instructions to tune language models. The extensive experiments onSUP-NATINST show that the high-quality step-by-step instructions can improvecross-task generalization across different model sizes. Moreover, the furtheranalysis indicates the importance of the order of steps of the step-by-stepinstruction for the improvement. To facilitate future research, we release thestep-by-step instructions and their human quality evaluation results.",Yang Wu,2023/5/8,2023/5/8
2307.15504v2,Exploring Format Consistency for Instruction Tuning,http://arxiv.org/abs/2307.15504v2,"Instruction tuning has emerged as a promising approach to enhancing largelanguage models in following human instructions. It is shown that increasingthe diversity and number of instructions in the training data can consistentlyenhance generalization performance, which facilitates a recent endeavor tocollect various instructions and integrate existing instruction tuning datasetsinto larger collections. However, different users have their unique ways ofexpressing instructions, and there often exist variations across differentdatasets in the instruction styles and formats, i.e., format inconsistency. Inthis work, we propose a framework named Unified Instruction Tuning (UIT), whichcalls OpenAI APIs for automatic format transfer among different instructiontuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we(1) demonstrate the necessity of maintaining format consistency in instructiontuning; (2) improve the generalization performance on unseen instructions onT5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce thenoise of automatic format transfer to make the UIT framework more practical anda smaller offline model based on GPT-J that achieves comparable format transfercapability to OpenAI APIs to reduce costs in practice. Further analysisregarding variations of targeted formats and other effects is intended.",Shihao Liang,2023/7/28,2024/1/8
2108.03356v1,HelpViz: Automatic Generation of Contextual Visual MobileTutorials from Text-Based Instructions,http://arxiv.org/abs/2108.03356v1,"We present HelpViz, a tool for generating contextual visual mobile tutorialsfrom text-based instructions that are abundant on the web. HelpViz transformstext instructions to graphical tutorials in batch, by extracting a sequence ofactions from each text instruction through an instruction parsing model, andexecuting the extracted actions on a simulation infrastructure that manages anarray of Android emulators. The automatic execution of each instructionproduces a set of graphical and structural assets, including images, videos,and metadata such as clicked elements for each step. HelpViz then synthesizes atutorial by combining parsed text instructions with the generated assets, andcontextualizes the tutorial to user interaction by tracking the user's progressand highlighting the next step.  Our experiments with HelpViz indicate that our pipeline improved tutorialexecution robustness and that participants preferred tutorials generated byHelpViz over text-based instructions. HelpViz promises a cost-effectiveapproach for generating contextual visual tutorials for mobile interaction atscale.",Mingyuan Zhong,2021/8/7,2021/8/7
2312.02436v1,MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following,http://arxiv.org/abs/2312.02436v1,"In the realm of large language models (LLMs), enhancing instruction-followingcapability often involves curating expansive training data. This is achievedthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)pairs per task instruction, aiming for better instruction adherence. ii)Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,output) pair (without requiring a separate input anymore). However, LLMs underScaling-Inputs tend to be overly sensitive to inputs, leading tomisinterpretation or non-compliance with instructions. Conversely, ScalingInput-Free Tasks demands a substantial number of tasks but is less effective ininstruction following when dealing with instances in Scaling-Inputs. This workintroduces MUFFIN, a new scheme of instruction-following dataset curation.Specifically, we automatically Scale Tasks per Input by diversifying thesetasks with various input facets. Experimental results across four zero-shotbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,reveal that LLMs, at various scales, trained on MUFFIN generally demonstratesuperior instruction-following capabilities compared to those trained on thetwo aforementioned schemes.",Renze Lou,2023/12/5,2023/12/5
2304.12244v2,WizardLM: Empowering Large Language Models to Follow Complex Instructions,http://arxiv.org/abs/2304.12244v2,"Training large language models (LLMs) with open-domain instruction followingdata brings colossal success. However, manually creating such instruction datais very time-consuming and labor-intensive. Moreover, humans may struggle toproduce high-complexity instructions. In this paper, we show an avenue forcreating large amounts of instruction data with varying levels of complexityusing LLM instead of humans. Starting with an initial set of instructions, weuse our proposed Evol-Instruct to rewrite them step by step into more complexinstructions. Then, we mix all generated instruction data to fine-tune LLaMA.We call the resulting model WizardLM. Human evaluations on acomplexity-balanced test bed and Vicuna's testset show that instructions fromEvol-Instruct are superior to human-created ones. By analyzing the humanevaluation results of the high complexity part, we demonstrate that outputsfrom our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4automatic evaluation, WizardLM achieves more than 90\% capacity of ChatGPT on17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in someaspects, our findings suggest that fine-tuning with AI-evolved instructions isa promising direction for enhancing LLMs. Our code and data are public athttps://github.com/nlpxucan/WizardLM",Can Xu,2023/4/24,2023/6/10
2304.14402v2,LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions,http://arxiv.org/abs/2304.14402v2,"Large language models (LLMs) with instruction fine-tuning demonstratesuperior generative capabilities. However, these models are resource-intensive.To alleviate this issue, we explore distilling knowledge from instruction-tunedLLMs into much smaller ones. To this end, we carefully develop a large set of2.58M instructions based on both existing and newly-generated instructions. Inaddition to being sizable, we design our instructions to cover a broad set oftopics to ensure diversity. Extensive analysis of our instruction datasetconfirms its diversity, and we generate responses for these instructions usinggpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd ofmodels, collectively referred to as LaMini-LM, which includes models from boththe encoder-decoder and decoder-only families, with varying sizes. We evaluatethe performance of our models using automatic metrics on 15 different naturallanguage processing (NLP) benchmarks, as well as through human assessment. Theresults demonstrate that our proposed LaMini-LM models are comparable tocompetitive baselines, while being nearly 10 times smaller in size.",Minghao Wu,2023/4/27,2023/5/24
2206.12034v2,DialogID: A Dialogic Instruction Dataset for Improving Teaching Effectiveness in Online Environments,http://arxiv.org/abs/2206.12034v2,"Online dialogic instructions are a set of pedagogical instructions used inreal-world online educational contexts to motivate students, help understandlearning materials, and build effective study habits. In spite of thepopularity and advantages of online learning, the education technology andeducational data mining communities still suffer from the lack of large-scale,high-quality, and well-annotated teaching instruction datasets to studycomputational approaches to automatically detect online dialogic instructionsand further improve the online teaching effectiveness. Therefore, in thispaper, we present a dataset of online dialogic instruction detection,\textsc{DialogID}, which contains 30,431 effective dialogic instructions. Theseteaching instructions are well annotated into 8 categories. Furthermore, weutilize the prevalent pre-trained language models (PLMs) and propose a simpleyet effective adversarial training learning paradigm to improve the quality andgeneralization of dialogic instruction detection. Extensive experimentsdemonstrate that our approach outperforms a wide range of baseline methods. Thedata and our code are available for research purposes from:https://github.com/ai4ed/DialogID.",Jiahao Chen,2022/6/24,2022/10/11
2211.01910v2,Large Language Models Are Human-Level Prompt Engineers,http://arxiv.org/abs/2211.01910v2,"By conditioning on natural language instructions, large language models(LLMs) have displayed impressive capabilities as general-purpose computers.However, task performance depends significantly on the quality of the promptused to steer the model, and most effective prompts have been handcrafted byhumans. Inspired by classical program synthesis and the human approach toprompt engineering, we propose Automatic Prompt Engineer (APE) for automaticinstruction generation and selection. In our method, we treat the instructionas the ""program,"" optimized by searching over a pool of instruction candidatesproposed by an LLM in order to maximize a chosen score function. To evaluatethe quality of the selected instruction, we evaluate the zero-shot performanceof another LLM following the selected instruction. Experiments on 24 NLP tasksshow that our automatically generated instructions outperform the prior LLMbaseline by a large margin and achieve better or comparable performance to theinstructions generated by human annotators on 19/24 tasks. We conduct extensivequalitative and quantitative analyses to explore the performance of APE. Weshow that APE-engineered prompts can be applied to steer models towardtruthfulness and/or informativeness, as well as to improve few-shot learningperformance by simply prepending them to standard in-context learning prompts.Please check out our webpage athttps://sites.google.com/view/automatic-prompt-engineer.",Yongchao Zhou,2022/11/3,2023/3/10
2311.08685v1,Safer-Instruct: Aligning Language Models with Automated Preference Data,http://arxiv.org/abs/2311.08685v1,"Reinforcement Learning from Human Feedback (RLHF) is a vital strategy forenhancing model safety in language models. However, annotating preference datafor RLHF is a resource-intensive and creativity-demanding process, whileautomatic generation methods face limitations in data diversity and quality. Inresponse, we present Safer-Instruct, a novel pipeline for semi-automaticallyconstructing large-scale preference datasets. Our approach leverages reversedinstruction tuning, instruction induction, and expert model evaluation toefficiently generate high-quality preference data without human annotators. Weevaluate Safer-Instruct using LLaMA for instruction induction and GPT-4 as anexpert model, generating approximately 10K preference samples. Finetuning anAlpaca model on this dataset demonstrates improved harmlessness whilemaintaining competitive performance on conversation and downstream tasks.Safer-Instruct addresses the challenges in preference data acquisition,advancing the development of safer and more responsible AI systems. Our codeand data are available at https://github.com/uscnlp-lime/safer-instruct",Taiwei Shi,2023/11/15,2023/11/15
2105.14273v2,Automatically Locating ARM Instructions Deviation between Real Devices and CPU Emulators,http://arxiv.org/abs/2105.14273v2,"Emulator is widely used to build dynamic analysis frameworks due to itsfine-grained tracing capability, full system monitoring functionality, andscalability of running on different operating systemsand architectures.However, whether the emulator is consistent with real devices is unknown. Tounderstand this problem, we aim to automatically locate inconsistentinstructions, which behave differently between emulators and real devices.  We target ARM architecture, which provides machine readable specification.Based on the specification, we propose a test case generator by designing andimplementing the first symbolic execution engine for ARM architecturespecification language (ASL). We generate 2,774,649 representative instructionstreams and conduct differential testing with these instruction streams betweenfour ARM real devices in different architecture versions (i.e., ARMv5, ARMv6,ARMv7-a, and ARMv8-a) and the state-of-the-art emulators (i.e., QEMU). Welocate 155,642 inconsistent instruction streams, which cover 30% of allinstruction encodings and 47.8% of the instructions. We find undefinedimplementation in ARM manual and implementation bugs of QEMU are the majorcauses of inconsistencies. Furthermore, we discover four QEMU bugs, which areconfirmed and patched by thedevelopers, covering 13 instruction encodingsincluding the most commonly used ones (e.g.,STR,BLX). With the inconsistentinstructions, we build three security applications and demonstratethecapability of these instructions on detecting emulators, anti-emulation, andanti-fuzzing.",Muhui Jiang,2021/5/29,2021/8/12
2308.06595v4,VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use,http://arxiv.org/abs/2308.06595v4,"We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark forevaluation of instruction-following vision-language models for real-world use.Our starting point is curating 70 'instruction families' that we envisioninstruction tuned vision-language models should be able to address. Extendingbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition togame playing and creative generation. Following curation, our dataset comprises592 test queries, each with a human-authored instruction-conditioned caption.These descriptions surface instruction-specific factors, e.g., for aninstruction asking about the accessibility of a storefront for wheelchairusers, the instruction-conditioned caption describes ramps/potential obstacles.These descriptions enable 1) collecting human-verified reference outputs foreach instance; and 2) automatic evaluation of candidate multimodal generationsusing a text-only LLM, aligning with human judgment. We quantify quality gapsbetween models and references using both human and automatic evaluations; e.g.,the top-performing instruction-following model wins against the GPT-4 referencein just 27% of the comparison. VisIT-Bench is dynamic to participate,practitioners simply submit their model's response on the project website;Data, code and leaderboard is available at visit-bench.github.io.",Yonatan Bitton,2023/8/12,2023/12/26
2308.12711v1,Harnessing the Power of David against Goliath: Exploring Instruction Data Generation without Using Closed-Source Models,http://arxiv.org/abs/2308.12711v1,"Instruction tuning is instrumental in enabling Large Language Models~(LLMs)to follow user instructions to complete various open-domain tasks. The successof instruction tuning depends on the availability of high-quality instructiondata. Owing to the exorbitant cost and substandard quality of human annotation,recent works have been deeply engaged in the exploration of the utilization ofpowerful closed-source models to generate instruction data automatically.However, these methods carry potential risks arising from the usagerequirements of powerful closed-source models, which strictly forbid theutilization of their outputs to develop machine learning models. To deal withthis problem, in this work, we explore alternative approaches to generatehigh-quality instruction data that do not rely on closed-source models. Ourexploration includes an investigation of various existing instructiongeneration methods, culminating in the integration of the most efficientvariant with two novel strategies to enhance the quality further. Evaluationresults from two benchmarks and the GPT-4 model demonstrate the effectivenessof our generated instruction data, which can outperform Alpaca, a methodreliant on closed-source models. We hope that more progress can be achieved ingenerating high-quality instruction data without using closed-source models.",Yue Wang,2023/8/24,2023/8/24
2309.02301v2,CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning,http://arxiv.org/abs/2309.02301v2,"Nowadays, the research on Large Vision-Language Models (LVLMs) has beensignificantly promoted thanks to the success of Large Language Models (LLM).Nevertheless, these Vision-Language Models (VLMs) are suffering from thedrawback of hallucination -- due to insufficient understanding of vision andlanguage modalities, VLMs may generate incorrect perception information whendoing downstream applications, for example, captioning a non-existent entity.To address the hallucination phenomenon, on the one hand, we introduce aContrastive Instruction Evaluation Method (CIEM), which is an automaticpipeline that leverages an annotated image-text dataset coupled with an LLM togenerate factual/contrastive question-answer pairs for the evaluation of thehallucination of VLMs. On the other hand, based on CIEM, we further propose anew instruction tuning method called CIT (the abbreviation of ContrastiveInstruction Tuning) to alleviate the hallucination of VLMs by automaticallyproducing high-quality factual/contrastive question-answer pairs andcorresponding justifications for model tuning. Through extensive experiments onCIEM and CIT, we pinpoint the hallucination issues commonly present in existingVLMs, the disability of the current instruction-tuning dataset to handle thehallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEMand public datasets.",Hongyu Hu,2023/9/5,2023/11/24
2312.04687v1,LLM4TDD: Best Practices for Test Driven Development Using Large Language Models,http://arxiv.org/abs/2312.04687v1,"In today's society, we are becoming increasingly dependent on softwaresystems. However, we also constantly witness the negative impacts of buggysoftware. Program synthesis aims to improve software correctness byautomatically generating the program given an outline of the expected behavior.For decades, program synthesis has been an active research field, with recentapproaches looking to incorporate Large Language Models to help generate code.This paper explores the concept of LLM4TDD, where we guide Large LanguageModels to generate code iteratively using a test-driven developmentmethodology. We conduct an empirical evaluation using ChatGPT and codingproblems from LeetCode to investigate the impact of different test, prompt andproblem attributes on the efficacy of LLM4TDD.",Sanyogita Piya,2023/12/7,2023/12/7
2304.10423v1,Fully Autonomous Programming with Large Language Models,http://arxiv.org/abs/2304.10423v1,"Current approaches to program synthesis with Large Language Models (LLMs)exhibit a ""near miss syndrome"": they tend to generate programs thatsemantically resemble the correct answer (as measured by text similaritymetrics or human evaluation), but achieve a low or even zero accuracy asmeasured by unit tests due to small imperfections, such as the wrong input oroutput format. This calls for an approach known as Synthesize, Execute, Debug(SED), whereby a draft of the solution is generated first, followed by aprogram repair phase addressing the failed tests. To effectively apply thisapproach to instruction-driven LLMs, one needs to determine which promptsperform best as instructions for LLMs, as well as strike a balance betweenrepairing unsuccessful programs and replacing them with newly generated ones.We explore these trade-offs empirically, comparing replace-focused,repair-focused, and hybrid debug strategies, as well as differenttemplate-based and model-based prompt-generation techniques. We use OpenAICodex as the LLM and Program Synthesis Benchmark 2 as a database of problemdescriptions and tests for evaluation. The resulting framework outperforms bothconventional usage of Codex without the repair phase and traditional geneticprogramming approaches.",Vadim Liventsev,2023/4/20,2023/4/20
2306.01394v1,Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors,http://arxiv.org/abs/2306.01394v1,"Although the dynamic type system of Python facilitates the developers inwriting Python programs, it also brings type errors at run-time. There existrule-based approaches for automatically repairing Python type errors. Theapproaches can generate accurate patches but they require domain experts todesign patch synthesis rules and suffer from low template coverage ofreal-world type errors. Learning-based approaches alleviate the manual effortsin designing patch synthesis rules. Among the learning-based approaches, theprompt-based approach which leverages the knowledge base of code pre-trainedmodels via pre-defined prompts, obtains state-of-the-art performance in generalprogram repair tasks. However, such prompts are manually defined and do notinvolve any specific clues for repairing Python type errors, resulting inlimited effectiveness. How to automatically improve prompts with the domainknowledge for type error repair is challenging yet under-explored. In thispaper, we present TypeFix, a novel prompt-based approach with fix templatesincorporated for repairing Python type errors. TypeFix first mines generalizedfix templates via a novel hierarchical clustering algorithm. The identified fixtemplates indicate the common edit patterns and contexts of existing type errorfixes. TypeFix then generates code prompts for code pre-trained models byemploying the generalized fix templates as domain knowledge, in which the masksare adaptively located for each type error instead of being pre-determined.Experiments on two benchmarks, including BugsInPy and TypeBugs, show thatTypeFix successfully repairs 26 and 55 type errors, outperforming the bestbaseline approach by 9 and 14, respectively. Besides, the proposed fix templatemining approach can cover 75% of developers' patches in both benchmarks,increasing the best rule-based approach PyTER by more than 30%.",Yun Peng,2023/6/2,2023/6/2
2401.01128v1,SSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM,http://arxiv.org/abs/2401.01128v1,"Recently, text-to-image (T2I) synthesis has undergone significantadvancements, particularly with the emergence of Large Language Models (LLM)and their enhancement in Large Vision Models (LVM), greatly enhancing theinstruction-following capabilities of traditional T2I models. Nevertheless,previous methods focus on improving generation quality but introduce unsafefactors into prompts. We explore that appending specific camera descriptions toprompts can enhance safety performance. Consequently, we propose a simple andsafe prompt engineering method (SSP) to improve image generation quality byproviding optimal camera descriptions. Specifically, we create a dataset frommulti-datasets as original prompts. To select the optimal camera, we design anoptimal camera matching approach and implement a classifier for originalprompts capable of automatically matching. Appending camera descriptions tooriginal prompts generates optimized prompts for further LVM image generation.Experiments demonstrate that SSP improves semantic consistency by an average of16% compared to others and safety metrics by 48.9%.",Weijin Cheng,2024/1/2,2024/1/2
2203.03575v3,Quantum Computing for Software Engineering: Prospects,http://arxiv.org/abs/2203.03575v3,"Quantum computers (QCs) are maturing. When QCs are powerful enough, they maybe able to handle problems in chemistry, physics, and finance that are notclassically solvable. However, the applicability of quantum algorithms to speedup Software Engineering (SE) tasks has not been explored. We examine eightgroups of quantum algorithms that may accelerate SE tasks across the differentphases of SE and sketch potential opportunities and challenges.",Andriy Miranskyy,2022/3/7,2022/11/14
2111.07875v1,Choose Your Programming Copilot: A Comparison of the Program Synthesis Performance of GitHub Copilot and Genetic Programming,http://arxiv.org/abs/2111.07875v1,"GitHub Copilot, an extension for the Visual Studio Code developmentenvironment powered by the large-scale language model Codex, makes automaticprogram synthesis available for software developers. This model has beenextensively studied in the field of deep learning, however, a comparison togenetic programming, which is also known for its performance in automaticprogram synthesis, has not yet been carried out. In this paper, we evaluateGitHub Copilot on standard program synthesis benchmark problems and compare theachieved results with those from the genetic programming literature. Inaddition, we discuss the performance of both approaches. We find that theperformance of the two approaches on the benchmark problems is quite similar,however, in comparison to GitHub Copilot, the program synthesis approachesbased on genetic programming are not yet mature enough to support programmersin practical software development. Genetic programming usually needs a hugeamount of expensive hand-labeled training cases and takes too much time togenerate solutions. Furthermore, source code generated by genetic programmingapproaches is often bloated and difficult to understand. For future work onprogram synthesis with genetic programming, we suggest researchers to focus onimproving the execution time, readability, and usability.",Dominik Sobania,2021/11/15,2021/11/15
2301.10563v1,Evidence Profiles for Validity Threats in Program Comprehension Experiments,http://arxiv.org/abs/2301.10563v1,"Searching for clues, gathering evidence, and reviewing case files are alltechniques used by criminal investigators to draw sound conclusions and avoidwrongful convictions. Similarly, in software engineering (SE) research, we candevelop sound methodologies and mitigate threats to validity by basing studydesign decisions on evidence.  Echoing a recent call for the empirical evaluation of design decisions inprogram comprehension experiments, we conducted a 2-phases study consisting ofsystematic literature searches, snowballing, and thematic synthesis. We foundout (1) which validity threat categories are most often discussed in primarystudies of code comprehension, and we collected evidence to build (2) theevidence profiles for the three most commonly reported threats to validity.  We discovered that few mentions of validity threats in primary studies (31 of409) included a reference to supporting evidence. For the three most commonlymentioned threats, namely the influence of programming experience, programlength, and the selected comprehension measures, almost all cited studies (17of 18) did not meet our criteria for evidence. We show that for many threats tovalidity that are currently assumed to be influential across all studies, theiractual impact may depend on the design and context of each specific study.  Researchers should discuss threats to validity within the context of theirparticular study and support their discussions with evidence. The present papercan be one resource for evidence, and we call for more meta-studies of thistype to be conducted, which will then inform design decisions in primarystudies. Further, although we have applied our methodology in the context ofprogram comprehension, our approach can also be used in other SE research areasto enable evidence-based experiment design decisions and meaningful discussionsof threats to validity.",Marvin Muoz Barn,2023/1/25,2023/1/25
2302.11382v1,A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT,http://arxiv.org/abs/2302.11382v1,"Prompt engineering is an increasingly important skill set needed to converseeffectively with large language models (LLMs), such as ChatGPT. Prompts areinstructions given to an LLM to enforce rules, automate processes, and ensurespecific qualities (and quantities) of generated output. Prompts are also aform of programming that can customize the outputs and interactions with anLLM. This paper describes a catalog of prompt engineering techniques presentedin pattern form that have been applied to solve common problems when conversingwith LLMs. Prompt patterns are a knowledge transfer method analogous tosoftware patterns since they provide reusable solutions to common problemsfaced in a particular context, i.e., output generation and interaction whenworking with LLMs. This paper provides the following contributions to researchon prompt engineering that apply LLMs to automate software development tasks.First, it provides a framework for documenting patterns for structuring promptsto solve a range of problems so that they can be adapted to different domains.Second, it presents a catalog of patterns that have been applied successfullyto improve the outputs of LLM conversations. Third, it explains how prompts canbe built from multiple patterns and illustrates prompt patterns that benefitfrom combination with other prompt patterns.",Jules White,2023/2/21,2023/2/21
2307.06056v1,How Many Papers Should You Review? A Research Synthesis of Systematic Literature Reviews in Software Engineering,http://arxiv.org/abs/2307.06056v1,"[Context] Systematic Literature Review (SLR) has been a major type of studypublished in Software Engineering (SE) venues for about two decades. However,there is a lack of understanding of whether an SLR is really needed incomparison to a more conventional literature review. Very often, SE researchersembark on an SLR with such doubts. We aspire to provide more understanding ofwhen an SLR in SE should be conducted. [Objective] The first step of ourinvestigation was focused on the dataset, i.e., the reviewed papers, in an SLR,which indicates the development of a research topic or area. The objective ofthis step is to provide a better understanding of the characteristics of thedatasets of SLRs in SE. [Method] A research synthesis was conducted on a sampleof 170 SLRs published in top-tier SE journals. We extracted and analysed thequantitative attributes of the datasets of these SLRs. [Results] The findingsshow that the median size of the datasets in our sample is 57 reviewed papers,and the median review period covered is 14 years. The number of reviewed papersand review period have a very weak and non-significant positive correlation.[Conclusions] The results of our study can be used by SE researchers as anindicator or benchmark to understand whether an SLR is conducted at a goodtime.",Xiaofeng Wang,2023/7/12,2023/7/12
1807.06809v3,Comparing Techniques for Aggregating Interrelated Replications in Software Engineering,http://arxiv.org/abs/1807.06809v3,"Context: Researchers from different groups and institutions are collaboratingtowards the construction of groups of interrelated replications. Applyingunsuitable techniques to aggregate interrelated replications' results mayimpact the reliability of joint conclusions.  Objectives: Comparing the advantages and disadvantages of the techniquesapplied to aggregate interrelated replications' results in Software Engineering(SE).  Method: We conducted a literature review to identify the techniques appliedto aggregate interrelated replications' results in SE. We analyze aprototypical group of interrelated replications in SE with the techniques thatwe identified. We check whether the advantages and disadvantages of eachtechnique -according to mature experimental disciplines such as medicine-materialize in the SE context.  Results: Narrative synthesis and Aggregation of p-values do not takeadvantage of all the information contained within the raw-data for providingjoint conclusions. Aggregated Data (AD) meta-analysis provides visual summariesof results and allows assessing experiment-level moderators. IndividualParticipant Data (IPD) meta-analysis allows interpreting results in naturalunits and assessing experiment-level and participant-level moderators.  Conclusion: All the information contained within the raw-data should be usedto provide joint conclusions. AD and IPD, when used in tandem, seem suitable toanalyze groups of interrelated replications in SE.",Adrian Santos,2018/7/18,2018/7/29
2203.13474v5,CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis,http://arxiv.org/abs/2203.13474v5,"Program synthesis strives to generate a computer program as a solution to agiven problem specification, expressed with input-output examples or naturallanguage descriptions. The prevalence of large language models advances thestate-of-the-art for program synthesis, though limited training resources anddata impede open access to such models. To democratize this, we train andrelease a family of large language models up to 16.1B parameters, calledCODEGEN, on natural language and programming language data, and open source thetraining library JAXFORMER. We show the utility of the trained model bydemonstrating that it is competitive with the previous state-of-the-art onzero-shot Python code generation on HumanEval. We further investigate themulti-step paradigm for program synthesis, where a single program is factorizedinto multiple prompts specifying subproblems. To this end, we construct an openbenchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverseproblem sets that are factorized into multi-turn prompts. Our analysis on MTPBshows that the same intent provided to CODEGEN in multi-turn fashionsignificantly improves program synthesis over that provided as a single turn.We make the training library JAXFORMER and model checkpoints available as opensource contribution: https://github.com/salesforce/CodeGen.",Erik Nijkamp,2022/3/25,2023/2/27
2106.06086v1,PSB2: The Second Program Synthesis Benchmark Suite,http://arxiv.org/abs/2106.06086v1,"For the past six years, researchers in genetic programming and other programsynthesis disciplines have used the General Program Synthesis Benchmark Suiteto benchmark many aspects of automatic program synthesis systems. Theseproblems have been used to make notable progress toward the goal of generalprogram synthesis: automatically creating the types of software that humanprogrammers code. Many of the systems that have attempted the problems in theoriginal benchmark suite have used it to demonstrate performance improvementsgranted through new techniques. Over time, the suite has gradually becomeoutdated, hindering the accurate measurement of further improvements. The fieldneeds a new set of more difficult benchmark problems to move beyond what waspreviously possible.  In this paper, we describe the 25 new general program synthesis benchmarkproblems that make up PSB2, a new benchmark suite. These problems are curatedfrom a variety of sources, including programming katas and college courses. Weselected these problems to be more difficult than those in the original suite,and give results using PushGP showing this increase in difficulty. These newproblems give plenty of room for improvement, pointing the way for the next sixor more years of general program synthesis research.",Thomas Helmuth,2021/6/10,2021/6/10
2310.09235v2,CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming,http://arxiv.org/abs/2310.09235v2,"Natural language (NL) programming has become more approachable due to thepowerful code-generation capability of large language models (LLMs). This shiftto using NL to program enhances collaborative programming by reducingcommunication barriers and context-switching among programmers from varyingbackgrounds. However, programmers may face challenges during prompt engineeringin a collaborative setting as they need to actively keep aware of theircollaborators' progress and intents. In this paper, we aim to investigate waysto assist programmers' prompt engineering in a collaborative context. We firstconducted a formative study to understand the workflows and challenges ofprogrammers when using NL for collaborative programming. Based on our findings,we implemented a prototype, CoPrompt, to support collaborative promptengineering by providing referring, requesting, sharing, and linkingmechanisms. Our user study indicates that CoPrompt assists programmers incomprehending collaborators' prompts and building on their collaborators' work,reducing repetitive updates and communication costs.",Felicia Li Feng,2023/10/13,2023/12/26
2111.08267v1,Solving Probability and Statistics Problems by Program Synthesis,http://arxiv.org/abs/2111.08267v1,"We solve university level probability and statistics questions by programsynthesis using OpenAI's Codex, a Transformer trained on text and fine-tuned oncode. We transform course problems from MIT's 18.05 Introduction to Probabilityand Statistics and Harvard's STAT110 Probability into programming tasks. Wethen execute the generated code to get a solution. Since these course questionsare grounded in probability, we often aim to have Codex generate probabilisticprograms that simulate a large number of probabilistic dependencies to computeits solution. Our approach requires prompt engineering to transform thequestion from its original form to an explicit, tractable form that results ina correct program and solution. To estimate the amount of work needed totranslate an original question into its tractable form, we measure thesimilarity between original and transformed questions. Our work is the first tointroduce a new dataset of university-level probability and statistics problemsand solve these problems in a scalable fashion using the program synthesiscapabilities of large language models.",Leonard Tang,2021/11/16,2021/11/16
2311.03832v1,Requirements Engineering using Generative AI: Prompts and Prompting Patterns,http://arxiv.org/abs/2311.03832v1,"[Context]: Companies are increasingly recognizing the importance ofautomating Requirements Engineering (RE) tasks due to their resource-intensivenature. The advent of GenAI has made these tasks more amenable to automation,thanks to its ability to understand and interpret context effectively.[Problem]: However, in the context of GenAI, prompt engineering is a criticalfactor for success. Despite this, we currently lack tools and methods tosystematically assess and determine the most effective prompt patterns toemploy for a particular RE task. [Method]: Two tasks related to requirements,specifically requirement classification and tracing, were automated using theGPT-3.5 turbo API. The performance evaluation involved assessing variousprompts created using 5 prompt patterns and implemented programmatically toperform the selected RE tasks, focusing on metrics such as precision, recall,accuracy, and F-Score. [Results]: This paper evaluates the effectiveness of the5 prompt patterns' ability to make GPT-3.5 turbo perform the selected RE tasksand offers recommendations on which prompt pattern to use for a specific REtask. Additionally, it also provides an evaluation framework as a reference forresearchers and practitioners who want to evaluate different prompt patternsfor different RE tasks.",Krishna Ronanki,2023/11/7,2023/11/7
2306.02230v1,Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for AI-Native Services,http://arxiv.org/abs/2306.02230v1,"Foundation models, such as GPT-4, DALL-E have brought unprecedented AI""operating system"" effect and new forms of human-AI interaction, sparking awave of innovation in AI-native services, where natural language prompts serveas executable ""code"" directly (prompt as executable code), eliminating the needfor programming language as an intermediary and opening up the door to personalAI. Prompt Sapper has emerged in response, committed to support the developmentof AI-native services by AI chain engineering. It creates a large languagemodel (LLM) empowered software engineering infrastructure for authoring AIchains through human-AI collaborative intelligence, unleashing the AIinnovation potential of every individual, and forging a future where everyonecan be a master of AI innovation. This article will introduce the R\&Dmotivation behind Prompt Sapper, along with its corresponding AI chainengineering methodology and technical practices.",Zhenchang Xing,2023/6/4,2023/6/4
2303.07839v1,"ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design",http://arxiv.org/abs/2303.07839v1,"This paper presents prompt design techniques for software engineering, in theform of patterns, to solve common problems when using large language models(LLMs), such as ChatGPT to automate common software engineering activities,such as ensuring code is decoupled from third-party libraries and simulating aweb application API before it is implemented. This paper provides twocontributions to research on using LLMs for software engineering. First, itprovides a catalog of patterns for software engineering that classifiespatterns according to the types of problems they solve. Second, it exploresseveral prompt patterns that have been applied to improve requirementselicitation, rapid prototyping, code quality, refactoring, and system design.",Jules White,2023/3/11,2023/3/11
2308.00229v1,Prompts Matter: Insights and Strategies for Prompt Engineering in Automated Software Traceability,http://arxiv.org/abs/2308.00229v1,"Large Language Models (LLMs) have the potential to revolutionize automatedtraceability by overcoming the challenges faced by previous methods andintroducing new possibilities. However, the optimal utilization of LLMs forautomated traceability remains unclear. This paper explores the process ofprompt engineering to extract link predictions from an LLM. We provide detailedinsights into our approach for constructing effective prompts, offering ourlessons learned. Additionally, we propose multiple strategies for leveragingLLMs to generate traceability links, improving upon previous zero-shot methodson the ranking of candidate links after prompt refinement. The primaryobjective of this paper is to inspire and assist future researchers andengineers by highlighting the process of constructing traceability prompts toeffectively harness LLMs for advancing automatic traceability.",Alberto D. Rodriguez,2023/8/1,2023/8/1
2305.13860v1,Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study,http://arxiv.org/abs/2305.13860v1,"Large Language Models (LLMs), like ChatGPT, have demonstrated vast potentialbut also introduce challenges related to content constraints and potentialmisuse. Our study investigates three key research questions: (1) the number ofdifferent prompt types that can jailbreak LLMs, (2) the effectiveness ofjailbreak prompts in circumventing LLM constraints, and (3) the resilience ofChatGPT against these jailbreak prompts. Initially, we develop a classificationmodel to analyze the distribution of existing prompts, identifying ten distinctpatterns and three categories of jailbreak prompts. Subsequently, we assess thejailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing adataset of 3,120 jailbreak questions across eight prohibited scenarios.Finally, we evaluate the resistance of ChatGPT against jailbreak prompts,finding that the prompts can consistently evade the restrictions in 40 use-casescenarios. The study underscores the importance of prompt structures injailbreaking LLMs and discusses the challenges of robust jailbreak promptgeneration and prevention.",Yi Liu,2023/5/23,2023/5/23
2306.12028v2,Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains,http://arxiv.org/abs/2306.12028v2,"The emergence of foundation models, such as large language models (LLMs)GPT-4 and text-to-image models DALL-E, has opened up numerous possibilitiesacross various domains. People can now use natural language (i.e. prompts) tocommunicate with AI to perform tasks. While people can use foundation modelsthrough chatbots (e.g., ChatGPT), chat, regardless of the capabilities of theunderlying models, is not a production tool for building reusable AI services.APIs like LangChain allow for LLM-based application development but requiresubstantial programming knowledge, thus posing a barrier. To mitigate this, wepropose the concept of AI chain and introduce the best principles and practicesthat have been accumulated in software engineering for decades into AI chainengineering, to systematise AI chain engineering methodology. We also develop ano-code integrated development environment, Prompt Sapper, which embodies theseAI chain engineering principles and patterns naturally in the process ofbuilding AI chains, thereby improving the performance and quality of AI chains.With Prompt Sapper, AI chain engineers can compose prompt-based AI services ontop of foundation models through chat-based requirement analysis and visualprogramming. Our user study evaluated and demonstrated the efficiency andcorrectness of Prompt Sapper.",Yu Cheng,2023/6/21,2023/12/20
2308.12697v1,Prompt-Enhanced Software Vulnerability Detection Using ChatGPT,http://arxiv.org/abs/2308.12697v1,"With the increase in software vulnerabilities that cause significant economicand social losses, automatic vulnerability detection has become essential insoftware development and maintenance. Recently, large language models (LLMs)like GPT have received considerable attention due to their stunningintelligence, and some studies consider using ChatGPT for vulnerabilitydetection. However, they do not fully consider the characteristics of LLMs,since their designed questions to ChatGPT are simple without a specific promptdesign tailored for vulnerability detection. This paper launches a study on theperformance of software vulnerability detection using ChatGPT with differentprompt designs. Firstly, we complement previous work by applying variousimprovements to the basic prompt. Moreover, we incorporate structural andsequential auxiliary information to improve the prompt design. Besides, weleverage ChatGPT's ability of memorizing multi-round dialogue to designsuitable prompts for vulnerability detection. We conduct extensive experimentson two vulnerability datasets to demonstrate the effectiveness ofprompt-enhanced vulnerability detection using ChatGPT. We also analyze themerit and demerit of using ChatGPT for vulnerability detection.",Chenyuan Zhang,2023/8/24,2023/8/24
2310.14843v1,End-to-End Software Construction using ChatGPT: An Experience Report,http://arxiv.org/abs/2310.14843v1,"In this paper, we explore the application of Large Language Models (LLMs) inthe particular context of end-to-end software construction, i.e., in contextswhere software developers have a set of requirements and have to design,implement, test, and validate a new software system. Particularly, we report anexperiment where we asked three software developers to use ChatGPT to fullyimplement a Web-based application using mainstream software architectures andtechnologies. After that, we compare the apps produced by ChatGPT with areference implementation that we manually implemented for our research. As aresult, we document four categories of prompts that can be used by developersin similar contexts, including initialization prompts, feature requests,bug-fixing, and layout prompts. Additionally, we discuss the advantages anddisadvantages of two prompt construction approaches: top-down (where we startwith a high-level description of the target software, typically in the form ofuser stories) and bottom-up (where we request the construction of the systemfeature by feature).",Mauricio Monteiro,2023/10/23,2023/10/23
2312.13115v2,A Novel Approach for Rapid Development Based on ChatGPT and Prompt Engineering,http://arxiv.org/abs/2312.13115v2,"Code generation stands as a powerful technique in modern softwaredevelopment, improving development efficiency, reducing errors, and fosteringstandardization and consistency. Recently, ChatGPT has exhibited immensepotential in automatic code generation. However, existing researches on codegeneration lack guidance for practical software development process. In thisstudy, we utilized ChatGPT to develop a web-based code generation platformconsisting of key components: User Interface, Prompt Builder and BackendService. Specifically, Prompt Builder dynamically generated comprehensiveprompts to enhance model generation performance. We conducted experiments on 2datasets, evaluating the generated code through 8 widely used metrics.Theresults demonstrate that (1) Our Prompt Builder is effective, resulting in a65.06% improvement in EM, a 38.45% improvement in BLEU, a 15.70% improvement inCodeBLEU, and a 50.64% improvement in Pass@1. (2) In real developmentscenarios, 98.5% of test cases can be validated through manual validation,highlighting the genuine assistance provided by the ChatGPT-based codegeneration approach.",Youjia Li,2023/12/20,2023/12/21
2308.04788v1,Adaptive Intellect Unleashed: The Feasibility of Knowledge Transfer in Large Language Models,http://arxiv.org/abs/2308.04788v1,"We conduct the first empirical study on using knowledge transfer to improvethe generalization ability of large language models (LLMs) in softwareengineering tasks, which often require LLMs to generalize beyond their trainingdata. Our proposed general knowledge transfer approach guides the LLM towards asimilar and familiar API or code snippet it has encountered before, improvingthe model's generalization ability for unseen knowledge. We apply this approachto three software engineering tasks: API inference, code example generation,and FQN inference, and find transfer span, transfer strategy, and transferarchitecture as key factors affecting the method. Our findings demonstrate thefeasibility of knowledge transfer and its potential to enhance LLMs'performance in various software engineering tasks. The effectiveness ofknowledge transfer varies depending on the target domain and task, with thehierarchical strategy being more effective than direct transfer, and AI-Chainoutperforming CoT in prompt design. The implications of these findings extendbeyond software engineering tasks and suggest that knowledge transfer canenhance LLMs' ability to handle unknowns in any natural language task.",Qing Huang,2023/8/9,2023/8/9
2310.06174v1,How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?,http://arxiv.org/abs/2310.06174v1,"Entity Resolution (ER) is the problem of semi-automatically determining whentwo entities refer to the same underlying entity, with applications rangingfrom healthcare to e-commerce. Traditional ER solutions required considerablemanual expertise, including feature engineering, as well as identification andcuration of training data. In many instances, such techniques are highlydependent on the domain. With recent advent in large language models (LLMs),there is an opportunity to make ER much more seamless and domain-independent.However, it is also well known that LLMs can pose risks, and that the qualityof their outputs can depend on so-called prompt engineering. Unfortunately, asystematic experimental study on the effects of different prompting methods foraddressing ER, using LLMs like ChatGPT, has been lacking thus far. This paperaims to address this gap by conducting such a study. Although preliminary innature, our results show that prompting can significantly affect the quality ofER, although it affects some metrics more than others, and can also be datasetdependent.",Khanin Sisaengsuwanchai,2023/10/9,2023/10/9
2305.15809v1,ChatGPT for PLC/DCS Control Logic Generation,http://arxiv.org/abs/2305.15809v1,"Large language models (LLMs) providing generative AI have become popular tosupport software engineers in creating, summarizing, optimizing, anddocumenting source code. It is still unknown how LLMs can support controlengineers using typical control programming languages in programming tasks.Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source codegeneration but did not yet tackle control logic programming. The contributionof this paper is an exploratory study, for which we created 100 LLM prompts in10 representative categories to analyze control logic generation for of PLCsand DCS from natural language. We tested the prompts by generating answers withChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3Structured Text code in many cases and demonstrated useful reasoning skillsthat could boost control engineer productivity. Our prompt collection is thebasis for a more formal LLM benchmark to test and compare such models forcontrol logic generation.",Heiko Koziolek,2023/5/25,2023/5/25
2312.16066v1,A Prompt Learning Framework for Source Code Summarization,http://arxiv.org/abs/2312.16066v1,"(Source) code summarization is the task of automatically generating naturallanguage summaries for given code snippets. Such summaries play a key role inhelping developers understand and maintain source code. Recently, with thesuccessful application of large language models (LLMs) in numerous fields,software engineering researchers have also attempted to adapt LLMs to solvecode summarization tasks. The main adaptation schemes include instructionprompting and task-oriented fine-tuning. However, instruction promptinginvolves designing crafted prompts for zero-shot learning or selectingappropriate samples for few-shot learning and requires users to haveprofessional domain knowledge, while task-oriented fine-tuning requires hightraining costs. In this paper, we propose a novel prompt learning framework forcode summarization called PromptCS. PromptCS trains a prompt agent that cangenerate continuous prompts to unleash the potential for LLMs in codesummarization. Compared to the human-written discrete prompt, the continuousprompts are produced under the guidance of LLMs and are therefore easier tounderstand by LLMs. PromptCS freezes the parameters of LLMs when training theprompt agent, which can greatly reduce the requirements for training resources.We evaluate PromptCS on the CodeSearchNet dataset involving multipleprogramming languages. The results show that PromptCS significantly outperformsinstruction prompting schemes on all four widely used metrics. In some baseLLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS evenoutperforms the task-oriented fine-tuning scheme. More importantly, thetraining efficiency of PromptCS is faster than the task-oriented fine-tuningscheme, with a more pronounced advantage on larger LLMs. The results of thehuman evaluation demonstrate that PromptCS can generate more good summariescompared to baselines.",Weisong Sun,2023/12/26,2023/12/26
2310.03691v1,DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models,http://arxiv.org/abs/2310.03691v1,"We characterize and demonstrate how the principles of direct manipulation canimprove interaction with large language models. This includes: continuousrepresentation of generated objects of interest; reuse of prompt syntax in atoolbar of commands; manipulable outputs to compose or control the effect ofprompts; and undo mechanisms. This idea is exemplified in DirectGPT, a userinterface layer on top of ChatGPT that works by transforming directmanipulation actions to engineered prompts. A study shows participants were 50%faster and relied on 50% fewer and 72% shorter prompts to edit text, code, andvector images compared to baseline ChatGPT. Our work contributes a validatedapproach to integrate LLMs into traditional software using direct manipulation.",Damien Masson,2023/10/5,2023/10/5
2311.11123v1,(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs,http://arxiv.org/abs/2311.11123v1,"Large Language Models (LLMs) are increasingly integrated into softwareapplications. Downstream application developers often access LLMs through APIsprovided as a service. However, LLM APIs are often updated silently andscheduled to be deprecated, forcing users to continuously adapt to evolvingmodels. This can cause performance regression and affect prompt design choices,as evidenced by our case study on toxicity detection. Based on our case study,we emphasize the need for and re-examine the concept of regression testing forevolving LLM APIs. We argue that regression testing LLMs requires fundamentalchanges to traditional testing approaches, due to different correctnessnotions, prompting brittleness, and non-determinism in LLM APIs.",Wanqin Ma,2023/11/18,2023/11/18
2310.06680v1,Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach,http://arxiv.org/abs/2310.06680v1,"While code generation has been widely used in various software developmentscenarios, the quality of the generated code is not guaranteed. This has been aparticular concern in the era of large language models (LLMs)- based codegeneration, where LLMs, deemed a complex and powerful black-box model, isinstructed by a high-level natural language specification, namely a prompt, togenerate code. Nevertheless, effectively evaluating and explaining the codegeneration capability of LLMs is inherently challenging, given the complexityof LLMs and the lack of transparency.  Inspired by the recent progress in causality analysis and its application insoftware engineering, this paper launches a causality analysis-based approachto systematically analyze the causal relations between the LLM input promptsand the generated code. To handle various technical challenges in this study,we first propose a novel causal graph-based representation of the prompt andthe generated code, which is established over the fine-grained,human-understandable concepts in the input prompts. The formed causal graph isthen used to identify the causal relations between the prompt and the derivedcode. We illustrate the insights that our framework can provide by studyingover 3 popular LLMs with over 12 prompt adjustment strategies. The results ofthese studies illustrate the potential of our technique to provide insightsinto LLM effectiveness, and aid end-users in understanding predictions.Additionally, we demonstrate that our approach provides actionable insights toimprove the quality of the LLM-generated code by properly calibrating theprompt.",Zhenlan Ji,2023/10/10,2023/10/10
2307.14349v1,Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models,http://arxiv.org/abs/2307.14349v1,"This paper presents an AI-assisted programming tool called Copilot for Xcodefor program composition and design to support human software developers. Byseamlessly integrating cloud-based Large Language Models (LLM) with Apple'slocal development environment, Xcode, this tool enhances productivity andunleashes creativity for software development in Apple software ecosystem(e.g., iOS apps, macOS). Leveraging advanced natural language processing (NLP)techniques, Copilot for Xcode effectively processes source code tokens andpatterns within code repositories, enabling features such as code generation,autocompletion, documentation, and error detection. Software developers canalso query and make ""small"" decisions for program composition, some of whichcan be made simultaneously, and this is facilitated through prompt engineeringin a chat interface of Copilot for Xcode. Finally, we present simple casestudies as evidence of the effectiveness of utilizing NLP in Xcode to promptpopular LLM services like OpenAI ChatGPT for program composition and design.",Chee Wei Tan,2023/7/8,2023/7/8
2304.08191v1,"A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair",http://arxiv.org/abs/2304.08191v1,"ChatGPT has revolutionized many research and industrial fields. ChatGPT hasshown great potential in software engineering to boost various traditionaltasks such as program repair, code understanding, and code generation. However,whether automatic program repair (APR) applies to deep learning (DL) programsis still unknown. DL programs, whose decision logic is not explicitly encodedin the source code, have posed unique challenges to APR. While to repair DLprograms, an APR approach needs to not only parse the source code syntacticallybut also needs to understand the code intention. With the best prior work, theperformance of fault localization is still far less than satisfactory (onlyabout 30\%). Therefore, in this paper, we explore ChatGPT's capability for DLprogram repair by asking three research questions. (1) Can ChatGPT debug DLprograms effectively? (2) How can ChatGPT's repair performance be improved byprompting? (3) In which way can dialogue help facilitate the repair? On top ofthat, we categorize the common aspects useful for prompt design for DL programrepair. Also, we propose various prompt templates to facilitate the performanceand summarize the advantages and disadvantages of ChatGPT's abilities such asdetecting bad code smell, code refactoring, and detecting APImisuse/deprecation.",Jialun Cao,2023/4/17,2023/4/17
2307.00593v1,LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation,http://arxiv.org/abs/2307.00593v1,"Compiler bugs pose a significant threat to safety-critical applications, andpromptly and effectively isolating these bugs is crucial for assuring thequality of compilers. However, the limited availability of debugginginformation on reported bugs complicates the compiler bug isolation task.Existing compiler bug isolation approaches typically convert the problem into atest program mutation problem, but they are still limited by ineffectivemutation strategies or high human effort requirements. Drawing inspiration fromthe recent progress of pre-trained Large Language Models (LLMs), such asChatGPT, in code generation, we propose a new approach named LLM4CBI to tameLLMs to generate effective test programs for compiler bug isolation. However,using LLMs directly for test program mutation may not yield the desired resultsdue to the challenges associated with formulating precise prompts and selectingspecialized prompts. To overcome the challenges, three new components aredesigned in LLM4CBI. (1) LLM4CBI utilizes a program complexity-guided promptproduction component, which leverages data and control flow analysis toidentify the most valuable variables and locations in programs for mutation.(2) LLM4CBI employs a memorized prompt selection component, which adoptsreinforcement learning to select specialized prompts for mutating test programscontinuously. (3) A test program validation component is proposed to selectspecialized feedback prompts to avoid repeating the same mistakes during themutation process. Compared with the state-of-the-art approaches (DiWi andRecBi), our evaluation demonstrates the advantages of LLM4CBI: It isolates morebugs, ranging from 13.6% to 90.9% in various settings, than the otherapproaches. Additionally, we demonstrate that LLM4CBI is extensible, allowingfor easy integration with other LLMs.",Haoxin Tu,2023/7/2,2023/7/2
2306.11981v1,A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code,http://arxiv.org/abs/2306.11981v1,"API documentation, technical blogs and programming Q&A sites contain numerouspartial code that can be reused in programming tasks, but often these code areuncompilable due to unresolved names and syntax errors. To facilitate partialcode reuse, we propose the Partial Code Reuse Chain (PCR-Chain) for resolvingfully-qualified names (FQNs) and fixing last-mile syntax errors in partial codebased on a giant large language model (LLM) like ChatGPT. Methodologically,PCR-Chain is backed up by the underlying global-level prompt architecture(which combines three design ideas: hierarchical task breakdown, promptcomposition, and a mix of prompt-based AI and non-AI units) and the local-levelprompt design. Technically, we propose PCR-Chain, which employs in-contextlearning rather than symbolic, costly training methods. Experimental resultsdemonstrate that in dynamically-typed languages (Python), PCR-Chain outperformscurrent state-of-the-art (SOTA) 5% accuracy like RING. For statically-typelanguages (Java), our approach achieves high accuracy of 80.5% in resolvingboth non-FQNs and last-mile syntax errors, surpassing SOTA methods (RING) thatcan only address last-mile syntax errors. The correct execution of the unit,module, and PCR-Chain demonstrates the effectiveness of the prompt design,composition, and architecture and opens up possibilities for building softwareengineering tools based on LLMs, replacing traditional program analysismethods.",Qing Huang,2023/6/21,2023/6/21
2311.11690v1,Refactoring Programs Using Large Language Models with Few-Shot Examples,http://arxiv.org/abs/2311.11690v1,"A less complex and more straightforward program is a crucial factor thatenhances its maintainability and makes writing secure and bug-free programseasier. However, due to its heavy workload and the risks of breaking theworking programs, programmers are reluctant to do code refactoring, and thus,it also causes the loss of potential learning experiences. To mitigate this, wedemonstrate the application of using a large language model (LLM), GPT-3.5, tosuggest less complex versions of the user-written Python program, aiming toencourage users to learn how to write better programs. We propose a method toleverage the prompting with few-shot examples of the LLM by selecting thebest-suited code refactoring examples for each target programming problem basedon the prior evaluation of prompting with the one-shot example. Thequantitative evaluation shows that 95.68% of programs can be refactored bygenerating 10 candidates each, resulting in a 17.35% reduction in the averagecyclomatic complexity and a 25.84% decrease in the average number of linesafter filtering only generated programs that are semantically correct.Furthermore, the qualitative evaluation shows outstanding capability in codeformatting, while unnecessary behaviors such as deleting or translatingcomments are also observed.",Atsushi Shirafuji,2023/11/20,2023/11/20
2006.07058v1,Task-Oriented API Usage Examples Prompting Powered By Programming Task Knowledge Graph,http://arxiv.org/abs/2006.07058v1,"Programming tutorials are often created to demonstrate programming tasks withcode examples. However, our study of Stack Overflow questions reveals the lowutilization of high-quality programming tutorials, which is caused taskdescription mismatch and code information overload. Document search can findrelevant tutorial documents, but they often cannot find specific programmingactions and code solutions relevant to the developers' task needs. The recentlyproposed activity-centric search over knowledge graph supports direct search ofprogramming actions, but it has limitations in action coverage, naturallanguage based task search, and coarse-grained code example recommendation. Inthis work, we enhance action coverage in knowledge graph with actions extractedfrom comments in code examples and more forms of activity sentences. Toovercome the task description mismatch problem, we develop a code matchingbased task search method to find relevant programming actions and code examplesto the code under development. We integrate our knowledge graph and task searchmethod in the IDE, and develop an observe-push based tool to prompt developerswith task-oriented API usage examples. To alleviate the code informationoverload problem, our tool highlights programming action and API information inthe prompted tutorial task excerpts and code examples based on the underlyingknowledge graph. Our evaluation confirms the high quality of the constructedknowledge graph, and show that our code matching based task search canrecommend effective code solutions to programming issues asked on StackOverflow. A small-scale user study demonstrates that our tool is useful forassisting developers in finding and using relevant programming tutorials intheir programming tasks.",Jiamou Sun,2020/6/12,2020/6/12
2303.07263v1,InferFix: End-to-End Program Repair with LLMs,http://arxiv.org/abs/2303.07263v1,"Software development life cycle is profoundly influenced by bugs: theirintroduction, identification, and eventual resolution account for a significantportion of software cost. This has motivated software engineering researchersand practitioners to propose different approaches for automating theidentification and repair of software defects. Large language models have beenadapted to the program repair task through few-shot demonstration learning andinstruction prompting, treating this as an infilling task. However, thesemodels have only focused on learning general bug-fixing patterns foruncategorized bugs mined from public repositories. In this paper, we proposeInferFix: a transformer-based program repair framework paired with astate-of-the-art static analyzer to fix critical security and performance bugs.InferFix combines a Retriever -- transformer encoder model pretrained viacontrastive learning objective, which aims at searching for semanticallyequivalent bugs and corresponding fixes; and a Generator -- a large languagemodel (Codex Cushman) finetuned on supervised bug-fix data with promptsaugmented via bug type annotations and semantically similar fixes retrievedfrom an external non-parametric memory. To train and evaluate our approach, wecurated InferredBugs, a novel, metadata-rich dataset of bugs extracted byexecuting the Infer static analyzer on the change histories of thousands ofJava and C# repositories. Our evaluation demonstrates that InferFix outperformsstrong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C#and 76.8% in Java. We discuss the deployment of InferFix alongside Infer atMicrosoft which offers an end-to-end solution for detection, classification,and localization of bugs, as well as fixing and validation of candidatepatches, integrated in the continuous integration pipeline to automate thesoftware development workflow.",Matthew Jin,2023/3/13,2023/3/13
2209.14876v1,Repairing Bugs in Python Assignments Using Large Language Models,http://arxiv.org/abs/2209.14876v1,"Students often make mistakes on their introductory programming assignments aspart of their learning process. Unfortunately, providing custom repairs forthese mistakes can require a substantial amount of time and effort from classinstructors. Automated program repair (APR) techniques can be used tosynthesize such fixes. Prior work has explored the use of symbolic and neuraltechniques for APR in the education domain. Both types of approaches requireeither substantial engineering efforts or large amounts of data and training.We propose to use a large language model trained on code, such as Codex, tobuild an APR system -- MMAPR -- for introductory Python programmingassignments. Our system can fix both syntactic and semantic mistakes bycombining multi-modal prompts, iterative querying, test-case-based selection offew-shots, and program chunking. We evaluate MMAPR on 286 real student programsand compare to a baseline built by combining a state-of-the-art Python syntaxrepair engine, BIFI, and state-of-the-art Python semantic repair engine forstudent assignments, Refactory. We find that MMAPR can fix more programs andproduce smaller patches on average.",Jialu Zhang,2022/9/29,2022/9/29
2305.17951v1,ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER,http://arxiv.org/abs/2305.17951v1,"Prompt-based language models have produced encouraging results in numerousapplications, including Named Entity Recognition (NER) tasks. NER aims toidentify entities in a sentence and provide their types. However, the strongperformance of most available NER approaches is heavily dependent on the designof discrete prompts and a verbalizer to map the model-predicted outputs toentity categories, which are complicated undertakings. To address thesechallenges, we present ContrastNER, a prompt-based NER framework that employsboth discrete and continuous tokens in prompts and uses a contrastive learningapproach to learn the continuous prompts and forecast entity types. Theexperimental results demonstrate that ContrastNER obtains competitiveperformance to the state-of-the-art NER methods in high-resource settings andoutperforms the state-of-the-art models in low-resource circumstances withoutrequiring extensive manual prompt engineering and verbalizer design.",Amirhossein Layegh,2023/5/29,2023/5/29
2302.07435v1,Log Parsing with Prompt-based Few-shot Learning,http://arxiv.org/abs/2302.07435v1,"Logs generated by large-scale software systems provide crucial informationfor engineers to understand the system status and diagnose problems of thesystems. Log parsing, which converts raw log messages into structured data, isthe first step to enabling automated log analytics. Existing log parsersextract the common part as log templates using statistical features. However,these log parsers often fail to identify the correct templates and parametersbecause: 1) they often overlook the semantic meaning of log messages, and 2)they require domain-specific knowledge for different log datasets. To addressthe limitations of existing methods, in this paper, we propose LogPPT tocapture the patterns of templates using prompt-based few-shot learning. LogPPTutilises a novel prompt tuning method to recognise keywords and parametersbased on a few labelled log data. In addition, an adaptive random samplingalgorithm is designed to select a small yet diverse training set. We haveconducted extensive experiments on 16 public log datasets. The experimentalresults show that LogPPT is effective and efficient for log parsing.",Van-Hoang Le,2023/2/15,2023/2/15
2306.01987v2,Prompting Is All You Need: Automated Android Bug Replay with Large Language Models,http://arxiv.org/abs/2306.01987v2,"Bug reports are vital for software maintenance that allow users to informdevelopers of the problems encountered while using the software. As such,researchers have committed considerable resources toward automating bug replayto expedite the process of software maintenance. Nonetheless, the success ofcurrent automated approaches is largely dictated by the characteristics andquality of bug reports, as they are constrained by the limitations ofmanually-crafted patterns and pre-defined vocabulary lists. Inspired by thesuccess of Large Language Models (LLMs) in natural language understanding, wepropose AdbGPT, a new lightweight approach to automatically reproduce the bugsfrom bug reports through prompt engineering, without any training andhard-coding effort. AdbGPT leverages few-shot learning and chain-of-thoughtreasoning to elicit human knowledge and logical reasoning from LLMs toaccomplish the bug replay in a manner similar to a developer. Our evaluationsdemonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3%of bug reports in 253.6 seconds, outperforming the state-of-the-art baselinesand ablation studies. We also conduct a small-scale user study to confirm theusefulness of AdbGPT in enhancing developers' bug replay capabilities.",Sidong Feng,2023/6/3,2023/7/18
2306.03324v2,Impact of Large Language Models on Generating Software Specifications,http://arxiv.org/abs/2306.03324v2,"Software specifications are essential for ensuring the reliability ofsoftware systems. Existing specification extraction approaches, however, sufferfrom limited generalizability and require manual efforts. The recent emergenceof Large Language Models (LLMs), which have been successfully applied tonumerous software engineering tasks, offers a promising avenue for automatingthis process. In this paper, we conduct the first empirical study to evaluatethe capabilities of LLMs for generating software specifications from softwarecomments or documentation. We evaluate LLMs' performance with Few Shot Learning(FSL), enabling LLMs to generalize from a small number of examples, as well asdifferent prompt construction strategies, and compare the performance of LLMswith traditional approaches. Additionally, we conduct a comparative diagnosisof the failure cases from both LLMs and traditional methods, identifying theirunique strengths and weaknesses. Lastly, we conduct extensive experiments on 15state of the art LLMs, evaluating their performance and cost effectiveness forgenerating software specifications.  Our results show that with FSL, LLMs outperform traditional methods (by5.6%), and more sophisticated prompt construction strategies can furtherenlarge this performance gap (up to 5.1 to 10.0%). Yet, LLMs suffer from theirunique challenges, such as ineffective prompts and the lack of domainknowledge, which together account for 53 to 60% of LLM unique failures. Thestrong performance of open source models (e.g., StarCoder) makes closed sourcemodels (e.g., GPT 3 Davinci) less desirable due to size and cost. Our studyoffers valuable insights for future research to improve specificationgeneration.",Danning Xie,2023/6/6,2023/10/2
2312.05733v1,DevBots can co-design APIs,http://arxiv.org/abs/2312.05733v1,"DevBots are automated tools that perform various tasks in order to supportsoftware development. They are a growing trend and have been used inrepositories to automate repetitive tasks, as code generators, and ascollaborators in eliciting requirements and defining architectures. In thisstudy, we analyzed 24 articles to investigate the state of the art of usingDevBots in software development, trying to understand their characteristics,identify use cases, learn the relationship between DevBots and conversationalsoftware development, and discuss how prompt engineering can enablecollaboration between human developers and bots. Additionally, we identified agap to address by applying prompt engineering to collaborative API designbetween human designers and DevBots and proposed an experiment to assess whatapproach, between using Retrieval Augmented Generation or not, is moresuitable. Our conclusion is that DevBots can collaborate with human APIdesigners, but the two approaches have advantages and disadvantages.",Vinicius Soares Silva Marques,2023/12/10,2023/12/10
2206.12839v3,Repository-Level Prompt Generation for Large Language Models of Code,http://arxiv.org/abs/2206.12839v3,"With the success of large language models (LLMs) of code and their use ascode assistants (e.g. Codex used in GitHub Copilot), techniques for introducingdomain-specific knowledge in the prompt design process become important. Inthis work, we propose a framework called Repo-Level Prompt Generator thatlearns to generate example-specific prompts using prompt proposals. The promptproposals take context from the entire repository, thereby incorporating boththe structure of the repository and the context from other relevant files (e.g.imports, parent class files). Our technique doesn't require any access to theweights of the LLM, making it applicable in cases where we only have black-boxaccess to the LLM. We conduct experiments on the task of single-linecode-autocompletion using code repositories taken from Google Code archives. Wedemonstrate that an oracle constructed from our prompt proposals gives aremarkably high relative improvement of 36% over Codex, showing the quality ofthese proposals. Further, we show that when we train a model to predict aprompt proposal, we can achieve significant performance gains over Codex andother baselines. We release our code, data, and trained checkpoints at:\url{https://github.com/shrivastavadisha/repo_level_prompt_generation}.",Disha Shrivastava,2022/6/26,2023/6/5
2303.09384v1,LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations,http://arxiv.org/abs/2303.09384v1,"Large Language Models (LLMs) like Codex are powerful tools for performingcode completion and code generation tasks as they are trained on billions oflines of code from publicly available sources. Moreover, these models arecapable of generating code snippets from Natural Language (NL) descriptions bylearning languages and programming practices from public GitHub repositories.Although LLMs promise an effortless NL-driven deployment of softwareapplications, the security of the code they generate has not been extensivelyinvestigated nor documented. In this work, we present LLMSecEval, a datasetcontaining 150 NL prompts that can be leveraged for assessing the securityperformance of such models. Such prompts are NL descriptions of code snippetsprone to various security vulnerabilities listed in MITRE's Top 25 CommonWeakness Enumeration (CWE) ranking. Each prompt in our dataset comes with asecure implementation example to facilitate comparative evaluations againstcode produced by LLMs. As a practical application, we show how LLMSecEval canbe used for evaluating the security of snippets automatically generated from NLdescriptions.",Catherine Tony,2023/3/16,2023/3/16
2212.03404v1,Towards using Few-Shot Prompt Learning for Automating Model Completion,http://arxiv.org/abs/2212.03404v1,We propose a simple yet a novel approach to improve completion in domainmodeling activities. Our approach exploits the power of large language modelsby using few-shot prompt learning without the need to train or fine-tune thosemodels with large datasets that are scarce in this field. We implemented ourapproach and tested it on the completion of static and dynamic domain diagrams.Our initial evaluation shows that such an approach is effective and can beintegrated in different ways during the modeling activities.,Meriem Ben Chaaben,2022/12/7,2022/12/7
2304.01523v1,Analysis of Software Engineering Practices in General Software and Machine Learning Startups,http://arxiv.org/abs/2304.01523v1,"Context: On top of the inherent challenges startup software companies faceapplying proper software engineering practices, the non-deterministic nature ofmachine learning techniques makes it even more difficult for machine learning(ML) startups.  Objective: Therefore, the objective of our study is to understand the wholepicture of software engineering practices followed by ML startups and identifyadditional needs.  Method: To achieve our goal, we conducted a systematic literature reviewstudy on 37 papers published in the last 21 years. We selected papers on bothgeneral software startups and ML startups. We collected data to understandsoftware engineering (SE) practices in five phases of the software developmentlife-cycle: requirement engineering, design, development, quality assurance,and deployment.  Results: We find some interesting differences in software engineeringpractices in ML startups and general software startups. The data management andmodel learning phases are the most prominent among them.  Conclusion: While ML startups face many similar challenges to generalsoftware startups, the additional difficulties of using stochastic ML modelsrequire different strategies in using software engineering practices to producehigh-quality products.",Bishal Lakha,2023/4/4,2023/4/4
2005.13299v1,Machine Learning for Software Engineering: A Systematic Mapping,http://arxiv.org/abs/2005.13299v1,"Context: The software development industry is rapidly adopting machinelearning for transitioning modern day software systems towards highlyintelligent and self-learning systems. However, the full potential of machinelearning for improving the software engineering life cycle itself is yet to bediscovered, i.e., up to what extent machine learning can help reducing theeffort/complexity of software engineering and improving the quality ofresulting software systems. To date, no comprehensive study exists thatexplores the current state-of-the-art on the adoption of machine learningacross software engineering life cycle stages. Objective: This articleaddresses the aforementioned problem and aims to present a state-of-the-art onthe growing number of uses of machine learning in software engineering. Method:We conduct a systematic mapping study on applications of machine learning tosoftware engineering following the standard guidelines and principles ofempirical software engineering. Results: This study introduces a machinelearning for software engineering (MLSE) taxonomy classifying thestate-of-the-art machine learning techniques according to their applicabilityto various software engineering life cycle stages. Overall, 227 articles wererigorously selected and analyzed as a result of this study. Conclusion: Fromthe selected articles, we explore a variety of aspects that should be helpfulto academics and practitioners alike in understanding the potential of adoptingmachine learning techniques during software engineering projects.",Saad Shafiq,2020/5/27,2020/5/27
2012.01614v1,Explainable AI for Software Engineering,http://arxiv.org/abs/2012.01614v1,"Artificial Intelligence/Machine Learning techniques have been widely used insoftware engineering to improve developer productivity, the quality of softwaresystems, and decision-making. However, such AI/ML models for softwareengineering are still impractical, not explainable, and not actionable. Theseconcerns often hinder the adoption of AI/ML models in software engineeringpractices. In this article, we first highlight the need for explainable AI insoftware engineering. Then, we summarize three successful case studies on howexplainable AI techniques can be used to address the aforementioned challengesby making software defect prediction models more practical, explainable, andactionable.",Chakkrit Tantithamthavorn,2020/12/3,2020/12/3
1905.05786v2,Software Engineering for Fairness: A Case Study with Hyperparameter Optimization,http://arxiv.org/abs/1905.05786v2,"We assert that it is the ethical duty of software engineers to strive toreduce software discrimination. This paper discusses how that might be done.This is an important topic since machine learning software is increasinglybeing used to make decisions that affect people's lives. Potentially, theapplication of that software will result in fairer decisions because (unlikehumans) machine learning software is not biased. However, recent results showthat the software within many data mining packages exhibits ""groupdiscrimination""; i.e. their decisions are inappropriately affected by""protected attributes""(e.g., race, gender, age, etc.).  There has been much prior work on validating the fairness of machine-learningmodels (by recognizing when such software discrimination exists). But afterdetection, comes mitigation. What steps can ethical software engineers take toreduce discrimination in the software they produce?  This paper shows that making \textit{fairness} as a goal duringhyperparameter optimization can (a) preserve the predictive power of a modellearned from a data miner while also (b) generates fairer results. To the bestof our knowledge, this is the first application of hyperparameter optimizationas a tool for software engineers to generate fairer software.",Joymallya Chakraborty,2019/5/14,2019/10/30
1110.1301v1,Predicting User Actions in Software Processes,http://arxiv.org/abs/1110.1301v1,"This paper describes an approach for user (e.g. SW architect) assisting insoftware processes. The approach observes the user's action and tries topredict his next step. For this we use approaches in the area of machinelearning (sequence learning) and adopt these for the use in software processes.  Keywords: Software engineering, Software process description languages,Software processes, Machine learning, Sequence prediction",Michael Deynet,2011/10/6,2011/10/6
2103.11249v1,SELM: Software Engineering of Machine Learning Models,http://arxiv.org/abs/2103.11249v1,"One of the pillars of any machine learning model is its concepts. Usingsoftware engineering, we can engineer these concepts and then develop andexpand them. In this article, we present a SELM framework for SoftwareEngineering of machine Learning Models. We then evaluate this framework througha case study. Using the SELM framework, we can improve a machine learningprocess efficiency and provide more accuracy in learning with less processinghardware resources and a smaller training dataset. This issue highlights theimportance of an interdisciplinary approach to machine learning. Therefore, inthis article, we have provided interdisciplinary teams' proposals for machinelearning.",Nafiseh Jafari,2021/3/20,2021/3/20
2002.10163v1,Software Engineering Timeline: major areas of interest and multidisciplinary trends,http://arxiv.org/abs/2002.10163v1,"Society today cannot run without software and by extension, without SoftwareEngineering. Since this discipline emerged in 1968, practitioners have learnedvaluable lessons that have contributed to current practices. Some have becomeoutdated but many are still relevant and widely used. From the personal andincomplete perspective of the authors, this paper not only reviews the majormilestones and areas of interest in the Software Engineering timeline helpingsoftware engineers to appreciate the state of things, but also tries to givesome insights into the trends that this complex engineering will see in thenear future.",Isabel M. del guila,2020/2/24,2020/2/24
2011.01590v2,Turning Software Engineers into AI Engineers,http://arxiv.org/abs/2011.01590v2,"In industry as well as education as well as academics we see a growing needfor knowledge on how to apply machine learning in software applications. Withthe educational programme ICT & AI at Fontys UAS we had to find an answer tothe question: ""How should we educate software engineers to become AIengineers?"" This paper describes our educational programme, the open sourcetools we use, and the literature it is based on. After three years ofexperience, we present our lessons learned for both educational institutionsand software engineers in practice.",Petra Heck,2020/11/3,2021/1/4
2103.10703v1,Lessons Learned from Educating AI Engineers,http://arxiv.org/abs/2103.10703v1,"Over the past three years we have built a practice-oriented, bachelor level,educational programme for software engineers to specialize as AI engineers. Theexperience with this programme and the practical assignments our studentsexecute in industry has given us valuable insights on the profession of AIengineer. In this paper we discuss our programme and the lessons learned forindustry and research.",Petra Heck,2021/3/19,2021/3/19
2109.04738v2,On the validity of pre-trained transformers for natural language processing in the software engineering domain,http://arxiv.org/abs/2109.04738v2,"Transformers are the current state-of-the-art of natural language processingin many domains and are using traction within software engineering research aswell. Such models are pre-trained on large amounts of data, usually from thegeneral domain. However, we only have a limited understanding regarding thevalidity of transformers within the software engineering domain, i.e., how goodsuch models are at understanding words and sentences within a softwareengineering context and how this improves the state-of-the-art. Within thisarticle, we shed light on this complex, but crucial issue. We compare BERTtransformer models trained with software engineering data with transformersbased on general domain data in multiple dimensions: their vocabulary, theirability to understand which words are missing, and their performance inclassification tasks. Our results show that for tasks that requireunderstanding of the software engineering context, pre-training with softwareengineering data is valuable, while general domain models are sufficient forgeneral language understanding, also within the software engineering domain.",Julian von der Mosel,2021/9/10,2022/5/12
2101.02704v1,Toward Inclusion of Children as Software Engineering Stakeholders,http://arxiv.org/abs/2101.02704v1,"Background: A growing amount of software is available to children today.Children use both software that has been explicitly developed for them andsoftware for general users. While they obtain clear benefits from software,such as access to creativity tools and learning resources, children are alsoexposed to several risks and disadvantages, such as privacy violation,inactivity, or safety risks that can even lead to death. The research anddevelopment community is addressing and investigating positive and negativeimpacts of software for children one by one, but no comprehensive model existsthat relates software engineering and children as stakeholders in their ownright. Aims: The final objective of this line of research is to proposeeffective ways in which children can be involved in Software Engineeringactivities as stakeholders. Specifically, in this paper, we investigate thequality aspects that are of interest for children, as quality is a crucialaspect in the development of any kind of software, especially for stakeholderslike children. Method: Our contribution is based mainly on an analysis ofstudies at the intersection between Software Engineering (especially softwarequality) and Child Computer Interaction. Results: We identify a set ofqualities and a preliminary set of guidelines that can be used by researchersand practitioners in understanding the complex interrelations between SoftwareEngineering and children. Based on the qualities and the guidelines,researchers can design empirical investigations to obtain deeper insights intothe phenomenon and propose new Software Engineering knowledge specific for thistype of stakeholders. Conclusions: This conceptualization is a first steptowards a framework to support children as stakeholders in softwareengineering.",Letizia Jaccheri,2021/1/7,2021/1/7
1912.11512v4,The Evolution of Empirical Methods in Software Engineering,http://arxiv.org/abs/1912.11512v4,"Empirical methods like experimentation have become a powerful means to drivethe field of software engineering by creating scientific evidence on softwaredevelopment, operation, and maintenance, but also by supporting practitionersin their decision making and learning. Today empirical methods are fullyapplied in software engineering. However, they have developed in severaliterations since the 1960s. In this chapter we tell the history of empiricalsoftware engineering and present the evolution of empirical methods in softwareengineering in five iterations, i.e., (1) mid-1960s to mid-1970s, (2) mid-1970sto mid-1980s, (3) mid-1980s to end of the 1990s, (4) the 2000s, and (5) the2010s. We present the five iterations of the development of empirical softwareengineering mainly from a methodological perspective and additionally take keypapers, venues, and books, which are covered in chronological order in aseparate section on recommended further readings, into account. We complementour presentation of the evolution of empirical software engineering bypresenting the current situation and an outlook in Sect. 4 and the availablebooks on empirical software engineering. Furthermore, based on the chapterscovered in this book we discuss trends on contemporary empirical methods insoftware engineering related to the plurality of research methods, humanfactors, data collection and processing, aggregation and synthesis of evidence,and impact of software engineering research.",Michael Felderer,2019/12/24,2020/5/8
2104.03476v1,Secure Software Engineering in the Financial Services: A Practitioners' Perspective,http://arxiv.org/abs/2104.03476v1,"Secure software engineering is a fundamental activity in modern softwaredevelopment. However, while the field of security research has been advancingquite fast, in practice, there is still a vast knowledge gap between thesecurity experts and the software development teams. After all, we cannotexpect developers and other software practitioners to be security experts.Understanding how software development teams incorporate security in theirprocesses and the challenges they face is a step towards reducing this gap. Inthis paper, we study how financial services companies ensure the security oftheir software systems. To that aim, we performed a qualitative study based onsemi-structured interviews with 16 software practitioners from 11 differentfinancial companies in three continents. Our results shed light on the securityconsiderations that practitioners take during the different phases of theirsoftware development processes, the different security practices that softwareteams make use of to ensure the security of their software systems, theimprovements that practitioners perceive as important in existingstate-of-the-practice security tools, the different knowledge-sharing andlearning practices that developers use to learn more about software security,and the challenges that software practitioners currently face when it comes tosecure their systems.",Vivek Arora,2021/4/8,2021/4/8
2001.11956v1,Documentation of Machine Learning Software,http://arxiv.org/abs/2001.11956v1,"Machine Learning software documentation is different from most of thedocumentations that were studied in software engineering research. Often, theusers of these documentations are not software experts. The increasing interestin using data science and in particular, machine learning in different fieldsattracted scientists and engineers with various levels of knowledge aboutprogramming and software engineering. Our ultimate goal is automated generationand adaptation of machine learning software documents for users with differentlevels of expertise. We are interested in understanding the nature and triggersof the problems and the impact of the users' levels of expertise in the processof documentation evolution. We will investigate the Stack Overflow Q/As andclassify the documentation related Q/As within the machine learning domain tounderstand the types and triggers of the problems as well as the potentialchange requests to the documentation. We intend to use the results for buildingon top of the state of the art techniques for automatic documentationgeneration and extending on the adoption, summarization, and explanation ofsoftware functionalities.",Yalda Hashemi,2020/1/30,2020/1/30
2103.07950v2,Software Architecture for ML-based Systems: What Exists and What Lies Ahead,http://arxiv.org/abs/2103.07950v2,"The increasing usage of machine learning (ML) coupled with the softwarearchitectural challenges of the modern era has resulted in two broad researchareas: i) software architecture for ML-based systems, which focuses ondeveloping architectural techniques for better developing ML-based softwaresystems, and ii) ML for software architectures, which focuses on developing MLtechniques to better architect traditional software systems. In this work, wefocus on the former side of the spectrum with a goal to highlight the differentarchitecting practices that exist in the current scenario for architectingML-based software systems. We identify four key areas of software architecturethat need the attention of both the ML and software practitioners to betterdefine a standard set of practices for architecting ML-based software systems.We base these areas in light of our experience in architecting an ML-basedsoftware system for solving queuing challenges in one of the largest museums inItaly.",Henry Muccini,2021/3/14,2021/3/16
2204.14180v1,Industry-academia research collaboration and knowledge co-creation: Patterns and anti-patterns,http://arxiv.org/abs/2204.14180v1,"Increasing the impact of software engineering research in the softwareindustry and the society at large has long been a concern of high priority forthe software engineering community. The problem of two cultures, researchconducted in a vacuum (disconnected from the real world), or misaligned timehorizons are just some of the many complex challenges standing in the way ofsuccessful industry-academia collaborations. This paper reports on theexperience of research collaboration and knowledge co-creation between industryand academia in software engineering as a way to bridge the research-practicecollaboration gap. Our experience spans 14 years of collaboration betweenresearchers in software engineering and the European and Norwegian software andIT industry. Using the participant observation and interview methods we havecollected and afterwards analyzed an extensive record of qualitative data.Drawing upon the findings made and the experience gained, we provide a set of14 patterns and 14 anti-patterns for industry-academia collaborations, aimed tosupport other researchers and practitioners in establishing and runningresearch collaboration projects in software engineering.",Dusica Marijan,2022/4/29,2022/4/29
1701.06000v1,Applying empirical software engineering to software architecture: challenges and lessons learned,http://arxiv.org/abs/1701.06000v1,"In the last 15 years, software architecture has emerged as an importantsoftware engineering field for managing the development and maintenance oflarge, software- intensive systems. Software architecture community hasdeveloped numerous methods, techniques, and tools to support the architectureprocess (analysis, design, and review). Historically, most advances in softwarearchitecture have been driven by talented people and industrial experience, butthere is now a growing need to systematically gather empirical evidence aboutthe advantages or otherwise of tools and methods rather than just rely onpromotional anecdotes or rhetoric. The aim of this paper is to promote andfacilitate the application of the empirical paradigm to software architecture.To this end, we describe the challenges and lessons learned when assessingsoftware architecture research that used controlled experiments, replications,expert opinion, systematic literature reviews, obser- vational studies, andsurveys. Our research will support the emergence of a body of knowledgeconsisting of the more widely-accepted and well-formed software architecturetheories.",Davide Falessi,2017/1/21,2017/1/21
2306.08431v1,Team Composition in Software Engineering Education,http://arxiv.org/abs/2306.08431v1,"One of the objectives of software engineering education is to make studentsto learn essential teamwork skills. This is done by having the students work ingroups for course assignments. Student team composition plays a vital role inthis, as it significantly affects learning outcomes, what is learned, and how.The study presented in this paper aims to better understand the student teamcomposition in software engineering education and investigate the factorsaffecting it in the international software engineering education context. Thosefactors should be taken into consideration by software engineering teacherswhen they design group work assignments in their courses. In this paper, theinitial findings of the ongoing Action research study are presented. Theresults give some identified principles that should be considered whendesigning student team composition in software engineering courses.",Sajid Ibrahim Hashmi,2023/6/14,2023/6/14
2004.06174v1,Understanding What Software Engineers Are Working on -- The Work-Item Prediction Challenge,http://arxiv.org/abs/2004.06174v1,"Understanding what a software engineer (a developer, an incident responder, aproduction engineer, etc.) is working on is a challenging problem -- especiallywhen considering the more complex software engineering workflows insoftware-intensive organizations: i) engineers rely on a multitude (perhapshundreds) of loosely integrated tools; ii) engineers engage in concurrent andrelatively long running workflows; ii) infrastructure (such as logging) is notfully aware of work items; iv) engineering processes (e.g., for incidentresponse) are not explicitly modeled. In this paper, we explain thecorresponding 'work-item prediction challenge' on the grounds of representativescenarios, report on related efforts at Facebook, discuss some lessons learned,and review related work to call to arms to leverage, advance, and combinetechniques from program comprehension, mining software repositories, processmining, and machine learning.",Ralf Lmmel,2020/4/13,2020/4/13
2102.07574v1,Machine Learning Model Development from a Software Engineering Perspective: A Systematic Literature Review,http://arxiv.org/abs/2102.07574v1,"Data scientists often develop machine learning models to solve a variety ofproblems in the industry and academy but not without facing several challengesin terms of Model Development. The problems regarding Machine LearningDevelopment involves the fact that such professionals do not realize that theyusually perform ad-hoc practices that could be improved by the adoption ofactivities presented in the Software Engineering Development Lifecycle. Ofcourse, since machine learning systems are different from traditional Softwaresystems, some differences in their respective development processes are to beexpected. In this context, this paper is an effort to investigate thechallenges and practices that emerge during the development of ML models fromthe software engineering perspective by focusing on understanding how softwaredevelopers could benefit from applying or adapting the traditional softwareengineering process to the Machine Learning workflow.",Giuliano Lorenzoni,2021/2/15,2021/2/15
2310.01727v1,Can GPT-4 Replicate Empirical Software Engineering Research?,http://arxiv.org/abs/2310.01727v1,"Empirical software engineering research on production systems has broughtforth a better understanding of the software engineering process forpractitioners and researchers alike. However, only a small subset of productionsystems is studied, limiting the impact of this research. While softwareengineering practitioners benefit from replicating research on their own data,this poses its own set of challenges, since performing replications requires adeep understanding of research methodologies and subtle nuances in softwareengineering data. Given that large language models (LLMs), such as GPT-4, showpromise in tackling both software engineering- and science-related tasks, thesemodels could help democratize empirical software engineering research.  In this paper, we examine LLMs' abilities to perform replications ofempirical software engineering research on new data. We specifically studytheir ability to surface assumptions made in empirical software engineeringresearch methodologies, as well as their ability to plan and generate code foranalysis pipelines on seven empirical software engineering papers. We perform auser study with 14 participants with software engineering research expertise,who evaluate GPT-4-generated assumptions and analysis plans (i.e., a list ofmodule specifications) from the papers. We find that GPT-4 is able to surfacecorrect assumptions, but struggle to generate ones that reflect commonknowledge about software engineering data. In a manual analysis of thegenerated code, we find that the GPT-4-generated code contains the correcthigh-level logic, given a subset of the methodology. However, the code containsmany small implementation-level errors, reflecting a lack of softwareengineering knowledge. Our findings have implications for leveraging LLMs forsoftware engineering research as well as practitioner data scientists insoftware teams.",Jenny T. Liang,2023/10/3,2023/10/3
2103.01387v1,On a Factorial Knowledge Architecture for Data Science-powered Software Engineering,http://arxiv.org/abs/2103.01387v1,"Given the data-intensive and collaborative trend in science, the softwareengineering community also pays increasing attention to obtaining valuable anduseful insights from data repositories. Nevertheless, applying data science tosoftware engineering (e.g., mining software repositories) can be blindfold andmeaningless, if lacking a suitable knowledge architecture (KA). By observingthat software engineering practices are generally recorded through a set offactors (e.g., programmer capacity, different environmental conditions, etc.)involved in various software project aspects, we propose a factor-basedhierarchical KA of software engineering to help maximize the value of softwarerepositories and inspire future software data-driven studies. In particular, itis the organized factors and their relationships that help guide softwareengineering knowledge mining, while the mined knowledge will in turn beindexed/managed through the relevant factors and their interactions. This paperexplains our idea about the factorial KA and concisely demonstrates a KAcomponent, i.e. the early-version KA of software product engineering. Oncefully scoped, this proposed KA will supplement the well-known SWEBOK in termsof both the factor-centric knowledge management and the coverage/implication ofpotential software engineering knowledge.",Zheng Li,2021/3/2,2021/3/2
1809.08827v1,The Essence Theory of Software Engineering - Large-Scale Classroom Experiences from 450+ Software Engineering BSc Students,http://arxiv.org/abs/1809.08827v1,"Software Engineering as an industry is highly diverse in terms of developmentmethods and practices. Practitioners employ a myriad of methods and tend tofurther tailor them by e.g. omitting some practices or rules. This diversity indevelopment methods poses a challenge for software engineering education,creating a gap between education and industry. General theories such as theEssence Theory of Software Engineering can help bridge this gap by presentingsoftware engineering students with higher-level frameworks upon which to buildan understanding of software engineering methods and practical project work. Inthis paper, we study Essence in an educational setting to evaluate itsusefulness for software engineering students while also investigating barriersto its adoption in this context. To this end, we observe 102 student teamsutilize Essence in practical software engineering projects during a semesterlong, project-based course.",Kai-Kristian Kemell,2018/9/24,2018/9/24
1407.2905v1,Run-time extensibility and librarization of simulation software,http://arxiv.org/abs/1407.2905v1,Build-time configuration and environment assumptions are hampering progressand usability in scientific software. That which would be utterly unacceptablein non-scientific software somehow passes for the norm in scientific packages.The community needs reusable software packages that are easy use and flexibleenough to accommodate next-generation simulation and analysis demands.,Jed Brown,2014/7/10,2014/7/10
1304.4539v1,A Survey of Software Reliability Models,http://arxiv.org/abs/1304.4539v1,"Software reliability analysis is performed at various stages during theprocess of engineering software as an attempt to evaluate if the softwarereliability requirements have been (or might be) met. In this report, I presenta summary of some fundamental black-box and white-box software reliabilitymodels. I also present some general shortcomings of these models and suggestavenues for further research.",Ganesh J. Pai,2013/4/16,2013/4/16
1507.06901v1,An Architecture Process Maturity Model of Software Product Line Engineering,http://arxiv.org/abs/1507.06901v1,"Software architecture has been a key research area in the softwareengineering community due to its significant role in creating high qualitysoftware. The trend of developing product lines rather than single products hasmade the software product line a viable option in the industry. Softwareproduct line architecture is regarded as one of the crucial components in theproduct lines, since all of the resulting products share this commonarchitecture. The increased popularity of software product lines demands aprocess maturity evaluation methodology. Consequently, this paper presents anarchitecture process maturity model for software product line engineering toevaluate the current maturity of the product line architecture developmentprocess in an organization. Assessment questionnaires and a rating methodologycomprise the framework of this model. The objective of the questionnaires is tocollect information about the software product line architecture developmentprocess. Thus, in general this work contributes towards the establishment of acomprehensive and unified strategy for the process maturity evaluation ofsoftware product line engineering. Furthermore, we conducted two case studiesand reported the assessment results, which show the maturity of thearchitecture development process in two organizations",Faheem Ahmed,2015/7/24,2015/7/24
1808.02723v1,Essencery - A Tool for Essentializing Software Engineering Practices,http://arxiv.org/abs/1808.02723v1,"Software Engineering practitioners work using highly diverse methods andpractices, and general theories in software engineering are lacking. Oneattempt at creating a common ground in the area of software engineeringmethodologies has been the Essence Theory of Software Engineering, which can beconsidered a method-agnostic project management tool for software engineering.Essence supports the use of any development practices and provides a frameworkfor building a suitable method for any software engineering context. However,Essence presently suffers from low practitioner adoption that is partiallyconsidered to be caused by a lack of proper tooling. In this paper, we presentEssencery, a tool for essentializing software engineering methods and practicesusing the Essence graphical syntax. Essencery aims to facilitate adoption ofEssence among potential future users. We present an empirical evaluation of thetool by means of a qualitative, quasi-formal experiment and, based on theexperiment, confirm that the tool is easy to use and useful for its intendedpurpose.",Arthur Evensen,2018/8/8,2018/8/8
0806.2730v1,A Process Algebra Software Engineering Environment,http://arxiv.org/abs/0806.2730v1,"In previous work we described how the process algebra based language PSF canbe used in software engineering, using the ToolBus, a coordination architecturealso based on process algebra, as implementation model. In this article wesummarize that work and describe the software development process more formallyby presenting the tools we use in this process in a CASE setting, leading tothe PSF-ToolBus software engineering environment. We generalize the refine stepin this environment towards a process algebra based software engineeringworkbench of which several instances can be combined to form an environment.",B. Diertens,2008/6/17,2008/6/17
2202.07519v1,Social Science Theories in Software Engineering Research,http://arxiv.org/abs/2202.07519v1,"As software engineering research becomes more concerned with thepsychological, sociological and managerial aspects of software development,relevant theories from reference disciplines are increasingly important forunderstanding the field's core phenomena of interest. However, the degree towhich software engineering research draws on relevant social sciences remainsunclear. This study therefore investigates the use of social science theoriesin five influential software engineering journals over 13 years. It analyzesnot only the extent of theory use but also what, how and where these theoriesare used. While 87 different theories are used, less than two percent of papersuse a social science theory, most theories are used in only one paper, mostsocial sciences are ignored, and the theories are rarely tested forapplicability to software engineering contexts. Ignoring relevant socialscience theories may (1) undermine the community's ability to generate,elaborate and maintain a cumulative body of knowledge; and (2) lead tooversimplified models of software engineering phenomena. More attention totheory is needed for software engineering to mature as a scientific discipline.",Tobias Lorey,2022/2/15,2022/2/15
2211.13990v1,Quantum Software Engineering: A New Genre of Computing,http://arxiv.org/abs/2211.13990v1,"Quantum computing (QC) is no longer only a scientific interest but is rapidlybecoming an industrially available technology that can potentially tackle thelimitations of classical computing. Over the last few years, major technologygiants have invested in developing hardware and programming frameworks todevelop quantum-specific applications. QC hardware technologies are gainingmomentum, however, operationalizing the QC technologies trigger the need forsoftware-intensive methodologies, techniques, processes, tools, roles, andresponsibilities for developing industrial-centric quantum softwareapplications. This paper presents the vision of the quantum softwareengineering (QSE) life cycle consisting of quantum requirements engineering,quantum software design, quantum software implementation, quantum softwaretesting, and quantum software maintenance. This paper particularly calls forjoint contributions of software engineering research and industrial communityto present real-world solutions to support the entire quantum softwaredevelopment activities. The proposed vision facilitates the researchers andpractitioners to propose new processes, reference architectures, novel tools,and practices to leverage quantum computers and develop emerging and nextgenerations of quantum software.",Muhammad Azeem Akbar,2022/11/25,2022/11/25
2312.12404v1,Towards Automatic Support of Software Model Evolution with Large Language~Models,http://arxiv.org/abs/2312.12404v1,"Modeling structure and behavior of software systems plays a crucial role, invarious areas of software engineering. As with other software engineeringartifacts, software models are subject to evolution. Supporting modelers inevolving models by model completion facilities and providing high-level editoperations such as frequently occurring editing patterns is still an openproblem. Recently, large language models (i.e., generative neural networks)have garnered significant attention in various research areas, includingsoftware engineering. In this paper, we explore the potential of large languagemodels in supporting the evolution of software models in software engineering.We propose an approach that utilizes large language models for model completionand discovering editing patterns in model histories of software systems.Through controlled experiments using simulated model repositories, we conductan evaluation of the potential of large language models for these two tasks. Wehave found that large language models are indeed a promising technology forsupporting software model evolution, and that it is worth investigating furtherin the area of software model evolution.",Christof Tinnes,2023/12/19,2023/12/19
1707.03869v3,Cognitive Biases in Software Engineering: A Systematic Mapping Study,http://arxiv.org/abs/1707.03869v3,"One source of software project challenges and failures is the systematicerrors introduced by human cognitive biases. Although extensively explored incognitive psychology, investigations concerning cognitive biases have onlyrecently gained popularity in software engineering (SE) research. This papertherefore systematically maps, aggregates and synthesizes the literature oncognitive biases in software engineering to generate a comprehensive body ofknowledge, understand state of the art research and provide guidelines forfuture research and practise. Focusing on bias antecedents, effects andmitigation techniques, we identified 65 articles, which investigate 37cognitive biases, published between 1990 and 2016. Despite strong andincreasing interest, the results reveal a scarcity of research on mitigationtechniques and poor theoretical foundations in understanding and interpretingcognitive biases. Although bias-related research has generated many newinsights in the software engineering community, specific bias mitigationtechniques are still needed for software professionals to overcome thedeleterious effects of cognitive biases on their work.",Rahul Mohanani,2017/7/12,2018/10/23
1307.2075v2,A Web-based modeling tool for the SEMAT Essence theory of Software Engineering,http://arxiv.org/abs/1307.2075v2,"As opposed to more mature subjects, software engineering lacks generaltheories to establish its foundations as a discipline. The Essence Theory ofsoftware engineering (Essence) has been proposed by the Software EngineeringMethods and Theory (SEMAT) initiative. Essence goal is to develop atheoretically sound basis for software engineering practice and its wideadoption. Essence is yet far from reaching academic and industry adoption.Reasons include a struggle to foresee its utilization potential and the lack oftools implementing it. SEMAT Accelerator (SematAcc) is a Web-positioning toolfor a software engineering endeavor, which implements the SEMAT's Essencekernel. SematAcc allows using Essence, thus helping to understand it. The toolenables teaching, adopting, and researching Essence in controlled experimentsand case studies.",Daniel Graziotin,2013/7/8,2013/7/31
1109.1651v1,SRS BUILDER 1.0: An Upper Type CASE Tool For Requirement Specification,http://arxiv.org/abs/1109.1651v1,"Software (SW) development is a labor intensive activity. Modern softwareprojects generally have to deal with producing and managing large and complexsoftware products. Developing such software has become an extremely challengingjob not only because of inherent complexity, but also mainly for economicconstraints unlike time, quality, maintainability concerns. Hence, developingmodern software within the budget still remains as one of the main softwarecrisis. The most significant way to reduce the software development cost is touse the Computer-Aided Software Engineering (CASE) tools over the entireSoftware Development Life Cycle (SDLC) process as substitute to expensive humanlabor cost. We think that automation of software development methods is avaluable support for the software engineers in coping with this complexity andfor improving quality too. This paper demonstrates the newly developed CASEtools name ""SRS Builder 1.0"" for software requirement specification developedat our university laboratory, University of North Bengal, India. This paperdiscusses our new developed product with its functionalities and usages. Webelieve the tool has the potential to play an important role in the softwaredevelopment process.",Ardhendu Mandal,2011/9/8,2011/9/8
1904.11540v1,"First things first: If software engineering is the solution, then what is the problem?",http://arxiv.org/abs/1904.11540v1,"Software engineering (SE) undergoes an ontological crisis and it lacks of atheory. Why? Among other reasons, because always it succumbed to the pragmatismdemanded by the commercial and political interests and abandoned any intentionto become a science instead of a professional discipline. For beginning adiscussion for define a theory of software, first, is required to know whatsoftware is.",Jesus Zavala Ruiz,2019/4/11,2019/4/11
2309.13358v1,Towards Quantum Software Requirements Engineering,http://arxiv.org/abs/2309.13358v1,"Quantum software engineering (QSE) is receiving increasing attention, asevidenced by increasing publications on topics, e.g., quantum softwaremodeling, testing, and debugging. However, in the literature, quantum softwarerequirements engineering (QSRE) is still a software engineering area that isrelatively less investigated. To this end, in this paper, we provide an initialset of thoughts about how requirements engineering for quantum software mightdiffer from that for classical software after making an effort to map classicalrequirements classifications (e.g., functional and extra-functionalrequirements) into the context of quantum software. Moreover, we providediscussions on various aspects of QSRE that deserve attention from the quantumsoftware engineering community.",Tao Yue,2023/9/23,2023/9/23
1409.2223v1,Assessment of classification techniques on predicting success or failure of Software reusability,http://arxiv.org/abs/1409.2223v1,Assessment of classification techniques on predicting success or failure ofSoftware reusability,Nahid Hajizadeh,2014/9/8,2014/9/8
2204.08880v1,Antipatterns in Software Classification Taxonomies,http://arxiv.org/abs/2204.08880v1,"Empirical results in software engineering have long started to show thatfindings are unlikely to be applicable to all software systems, or any domain:results need to be evaluated in specified contexts, and limited to the type ofsystems that they were extracted from. This is a known issue, and requires theestablishment of a classification of software types.  This paper makes two contributions: the first is to evaluate the quality ofthe current software classifications landscape. The second is to perform a casestudy showing how to create a classification of software types using a curatedset of software systems.  Our contributions show that existing, and very likely even new,classification attempts are deemed to fail for one or more issues, that wenamed as the `antipatterns' of software classification tasks. We collected 7 ofthese antipatterns that emerge from both our case study, and the existingclassifications.  These antipatterns represent recurring issues in a classification, so wediscuss practical ways to help researchers avoid these pitfalls. It becomesclear that classification attempts must also face the daunting task offormulating a taxonomy of software types, with the objective of establishing ahierarchy of categories in a classification.",Cezar Sas,2022/4/19,2022/4/19
1306.1958v1,Software Testing Models Against Information Security Requirements,http://arxiv.org/abs/1306.1958v1,An overview and classification of software testing models are done.Recommendations on the choice of models are proposed,Alexey Markov,2013/6/8,2013/6/8
1305.4776v1,Classification of automatic software build methods,http://arxiv.org/abs/1305.4776v1,"The process of creating working software from source code and othercomponents (like libraries, database files, etc.) is called ""software build"".Apart from linking and compiling, it can include other steps like automatedtesting, static code analysis, documentation generation, deployment and other.All that steps can be automated using a build description of some sort (e.g.script). This article classifies the automatic software build processesbeginning at build script and reaching the various types of continuousintegration.",Marcin Kawalerowicz,2013/5/21,2013/5/21
1806.03260v1,DBBRBF- Convalesce optimization for software defect prediction problem using hybrid distribution base balance instance selection and radial basis Function classifier,http://arxiv.org/abs/1806.03260v1,"Software is becoming an indigenous part of human life with the rapiddevelopment of software engineering, demands the software to be most reliable.The reliability check can be done by efficient software testing methods usinghistorical software prediction data for development of a quality softwaresystem. Machine Learning plays a vital role in optimizing the prediction ofdefect-prone modules in real life software for its effectiveness. The softwaredefect prediction data has class imbalance problem with a low ratio ofdefective class to non-defective class, urges an efficient machine learningclassification technique which otherwise degrades the performance of theclassification. To alleviate this problem, this paper introduces a novel hybridinstance-based classification by combining distribution base balance basedinstance selection and radial basis function neural network classifier model(DBBRBF) to obtain the best prediction in comparison to the existing research.Class imbalanced data sets of NASA, Promise and Softlab were used for theexperimental analysis. The experimental results in terms of Accuracy,F-measure, AUC, Recall, Precision, and Balance show the effectiveness of theproposed approach. Finally, Statistical significance tests are carried out tounderstand the suitability of the proposed model.",Mrutyunjaya Panda,2018/6/8,2018/6/8
2211.05286v1,Deep Learning Methods for Software Requirement Classification: A Performance Study on the PURE dataset,http://arxiv.org/abs/2211.05286v1,"Requirement engineering (RE) is the first and the most important step insoftware production and development. The RE is aimed to specify softwarerequirements. One of the tasks in RE is the categorization of softwarerequirements as functional and non-functional requirements. The functionalrequirements (FR) show the responsibilities of the system while non-functionalrequirements represent the quality factors of software. Discrimination betweenFR and NFR is a challenging task. Nowadays Deep Learning (DL) has entered allfields of engineering and has increased accuracy and reduced time in theirimplementation process. In this paper, we use deep learning for theclassification of software requirements. Five prominent DL algorithms aretrained for classifying requirements. Also, two voting classificationalgorithms are utilized for creating ensemble classifiers based on five DLmethods. The PURE, a repository of Software Requirement Specification (SRS)documents, is selected for our experiments. We created a dataset from PUREwhich contains 4661 requirements where 2617 requirements are functional and theremaining are non-functional. Our methods are applied to the dataset and theirperformance analysis is reported. The results show that the performance of deeplearning models is satisfactory and the voting mechanisms provide betterresults.",Fatemeh Khayashi,2022/11/10,2022/11/10
2210.04275v2,Research Software Engineers: Career Entry Points and Training Gaps,http://arxiv.org/abs/2210.04275v2,"As software has become more essential to research across disciplines, and asthe recognition of this fact has grown, the importance of professionalizing thedevelopment and maintenance of this software has also increased. The communityof software professionals who work on this software have come together underthe title Research Software Engineer (RSE) over the last decade. This has ledto the formalization of RSE roles and organized RSE groups in universities,national labs, and industry. This, in turn, has created the need to understandhow RSEs come into this profession and into these groups, how to furtherpromote this career path to potential members, as well as the need tounderstand what training gaps need to be filled for RSEs coming from differententry points. We have categorized three main classifications of entry pathsinto the RSE profession and identified key elements, both advantages anddisadvantages, that should be acknowledged and addressed by the broaderresearch community in order to attract and retain a talented and diverse poolof future RSEs.",Ian A. Cosden,2022/10/9,2023/3/15
1801.06810v1,Guidelines for Systematic Mapping Studies in Security Engineering,http://arxiv.org/abs/1801.06810v1,"Security engineering in the software lifecycle aims at protecting informationand systems to guarantee confidentiality, integrity, and availability. Assecurity engineering matures and the number of research papers grows, there isan increasing need for papers that summarize results and provide an overview ofthe area. A systematic mapping study ""maps"" a research area by classifyingpapers to identify which topics are well-studied and which need additionalstudy. Therefore, systematic mapping studies are becoming increasinglyimportant in security engineering. This chapter provides methodological supportfor systematic mapping studies in security engineering based on examples frompublished security engineering papers. Because security engineering is similarto software engineering in that it bridges research and practice, researcherscan use the same basic systematic mapping process, as follows: (1) studyplanning, (2) searching for studies, (3) study selection, (4) study qualityassessment, (5) data extraction, (6) data classification, (7) data analysis,and (8) reporting of results. We use published mapping studies to describe thetailoring of this process for security engineering. In addition to guidance onhow to perform systematic mapping studies in security engineering, this chaptershould increase awareness in the security engineering community of the need foradditional mapping studies.",Michael Felderer,2018/1/21,2018/1/21
2302.12599v1,A Machine Learning Approach for Hierarchical Classification of Software Requirements,http://arxiv.org/abs/2302.12599v1,"Context: Classification of software requirements into different categories isa critically important task in requirements engineering (RE). Developingmachine learning (ML) approaches for requirements classification has attractedgreat interest in the RE community since the 2000s. Objective: This paper aimsto address two related problems that have been challenging real-worldapplications of ML approaches: the problems of class imbalance and highdimensionality with low sample size data (HDLSS). These problems can greatlydegrade the classification performance of ML methods. Method: The paperproposes HC4RC, a novel ML approach for multiclass classification ofrequirements. HC4RC solves the aforementioned problems throughsemantic-role-based feature selection, dataset decomposition and hierarchicalclassification. We experimentally compare the effectiveness of HC4RC with threeclosely related approaches - two of which are based on a traditionalstatistical classification model whereas one uses an advanced deep learningmodel. Results: Our experiment shows: 1) The class imbalance and HDLSS problemspresent a challenge to both traditional and advanced ML approaches. 2) TheHC4RC approach is simple to use and can effectively address the class imbalanceand HDLSS problems compared to similar approaches. Conclusion: This paper makesan important practical contribution to addressing the class imbalance and HDLSSproblems in multiclass classification of software requirements.",Manal Binkhonain,2023/2/24,2023/2/24
2312.06382v1,SciCat: A Curated Dataset of Scientific Software Repositories,http://arxiv.org/abs/2312.06382v1,"The proliferation of open-source scientific software for science and researchpresents opportunities and challenges. In this paper, we introduce the SciCatdataset -- a comprehensive collection of Free-Libre Open Source Software(FLOSS) projects, designed to address the need for a curated repository ofscientific and research software. This collection is crucial for understandingthe creation of scientific software and aiding in its development. To ensureextensive coverage, our approach involves selecting projects from a pool of 131million deforked repositories from the World of Code data source. Subsequently,we analyze README.md files using OpenAI's advanced language models. Ourclassification focuses on software designed for scientific purposes,research-related projects, and research support software. The SciCat datasetaims to become an invaluable tool for researching science-related software,shedding light on emerging trends, prevalent practices, and challenges in thefield of scientific software development. Furthermore, it includes data thatcan be linked to the World of Code, GitHub, and other platforms, providing asolid foundation for conducting comparative studies between scientific andnon-scientific software.",Addi Malviya-Thakur,2023/12/11,2023/12/11
1203.1717v1,Requirements Engineering Methods: A Classification Framework and Research Challenges,http://arxiv.org/abs/1203.1717v1,"Requirements Engineering Methods (REMs) support Requirements Engineering (RE)tasks, from elicitation, through modeling and analysis, to validation andevolution of requirements. Despite the growing interest to design, validate andteach REMs, it remains unclear what components REMs should have. Aclassification framework for REMs is proposed. It distinguishes REMs based onthe domain-independent properties of their components. The classificationframework is intended to facilitate (i) analysis, teaching and extension ofexisting REMs, (ii) engineering and validation of new REMs, and (iii)identifying research challenges in REM design. The framework should helpclarify further the relations between REM and other concepts of interest in andto RE, including Requirements Problem and Solution, Requirements ModelingLanguage, and Formal Method.",Ivan Jureta,2012/3/8,2012/3/8
2301.00495v1,Adaptive Fine-tuning for Multiclass Classification over Software Requirement Data,http://arxiv.org/abs/2301.00495v1,"The analysis of software requirement specifications (SRS) using NaturalLanguage Processing (NLP) methods has been an important study area in thesoftware engineering field in recent years. Especially thanks to the advancesbrought by deep learning and transfer learning approaches in NLP, SRS data canbe utilized for various learning tasks more easily. In this study, we employ athree-stage domain-adaptive fine-tuning approach for three prediction tasksregarding software requirements, which improve the model robustness on a realdistribution shift. The multi-class classification tasks involve predicting thetype, priority and severity of the requirement texts specified by the users. Wecompare our results with strong classification baselines such as word embeddingpooling and Sentence BERT, and show that the adaptive fine-tuning leads toperformance improvements across the tasks. We find that an adaptivelyfine-tuned model can be specialized to particular data distribution, which isable to generate accurate results and learns from abundantly available textualdata in software engineering task management systems.",Savas Yildirim,2023/1/2,2023/1/2
2307.13104v1,Software development in startup companies: A systematic mapping study,http://arxiv.org/abs/2307.13104v1,"Context: Software startups are newly created companies with no operatinghistory and fast in producing cutting-edge technologies. These companiesdevelop software under highly uncertain conditions, tackling fast-growingmarkets under severe lack of resources. Therefore, software startups present anunique combination of characteristics which pose several challenges to softwaredevelopment activities. Objective: This study aims to structure and analyze theliterature on software development in startup companies, determining therebythe potential for technology transfer and identifying software development workpractices reported by practitioners and researchers. Method: We conducted asystematic mapping study, developing a classification schema, ranking theselected primary studies according their rigor and relevance, and analyzingreported software development work practices in startups. Results: A total of43 primary studies were identified and mapped, synthesizing the availableevidence on software development in startups. Only 16 studies are entirelydedicated to software development in startups, of which 10 result in a weakcontribution (advice and implications (6); lesson learned (3); tool (1)).Nineteen studies focus on managerial and organizational factors. Moreover, only9 studies exhibit high scientific rigor and relevance. From the reviewedprimary studies, 213 software engineering work practices were extracted,categorized and analyzed. Conclusion: This mapping study provides the firstsystematic exploration of the state-of-art on software startup research. Theexisting body of knowledge is limited to a few high quality studies.Furthermore, the results indicate that software engineering work practices arechosen opportunistically, adapted and configured to provide value under theconstrains imposed by the startup context.",Nicol Paternoster,2023/7/24,2023/7/24
1806.01742v2,Adapting Neural Text Classification for Improved Software Categorization,http://arxiv.org/abs/1806.01742v2,"Software Categorization is the task of organizing software into groups thatbroadly describe the behavior of the software, such as ""editors"" or ""science.""Categorization plays an important role in several maintenance tasks, such asrepository navigation and feature elicitation. Current approaches attempt tocast the problem as text classification, to make use of the rich body ofliterature from the NLP domain. However, as we will show in this paper, textclassification algorithms are generally not applicable off-the-shelf to sourcecode; we found that they work well when high-level project descriptions areavailable, but suffer very large performance penalties when classifying sourcecode and comments only. We propose a set of adaptations to a state-of-the-artneural classification algorithm and perform two evaluations: one with referencedata from Debian end-user programs, and one with a set of C/C++ libraries thatwe hired professional programmers to annotate. We show that our proposedapproach achieves performance exceeding that of previous softwareclassification techniques as well as a state-of-the-art neural textclassification technique.",Alexander LeClair,2018/6/5,2018/6/15
2103.08890v1,LabelGit: A Dataset for Software Repositories Classification using Attributed Dependency Graphs,http://arxiv.org/abs/2103.08890v1,"Software repository hosting services contain large amounts of open-sourcesoftware, with GitHub hosting more than 100 million repositories, from new toestablished ones. Given this vast amount of projects, there is a pressing needfor a search based on the software's content and features. However, even thoughGitHub offers various solutions to aid software discovery, most repositories donot have any labels, reducing the utility of search and topic-based analysis.Moreover, classifying software modules is also getting more importance giventhe increase in Component-Based Software Development. However, previous workfocused on software classification using keyword-based approaches or proxiesfor the project (e.g., README), which is not always available. In this work, wecreate a new annotated dataset of GitHub Java projects called LabelGit. Ourdataset uses direct information from the source code, like the dependency graphand source code neural representations from the identifiers. Using thisdataset, we hope to aid the development of solutions that do not rely onproxies but use the entire source code to perform classification.",Cezar Sas,2021/3/16,2021/3/16
2311.03365v1,Leveraging Generative AI: Improving Software Metadata Classification with Generated Code-Comment Pairs,http://arxiv.org/abs/2311.03365v1,"In software development, code comments play a crucial role in enhancing codecomprehension and collaboration. This research paper addresses the challenge ofobjectively classifying code comments as ""Useful"" or ""Not Useful."" We propose anovel solution that harnesses contextualized embeddings, particularly BERT, toautomate this classification process. We address this task by incorporatinggenerated code and comment pairs. The initial dataset comprised 9048 pairs ofcode and comments written in C, labeled as either Useful or Not Useful. Toaugment this dataset, we sourced an additional 739 lines of code-comment pairsand generated labels using a Large Language Model Architecture, specificallyBERT. The primary objective was to build classification models that caneffectively differentiate between useful and not useful code comments. Variousmachine learning algorithms were employed, including Logistic Regression,Decision Tree, K-Nearest Neighbors (KNN), Support Vector Machine (SVM),Gradient Boosting, Random Forest, and a Neural Network. Each algorithm wasevaluated using precision, recall, and F1-score metrics, both with the originalseed dataset and the augmented dataset. This study showcases the potential ofgenerative AI for enhancing binary code comment quality classification models,providing valuable insights for software developers and researchers in thefield of natural language processing and software engineering.",Samah Syed,2023/10/14,2023/10/14
2003.03843v1,Software-testing education: A systematic literature mapping,http://arxiv.org/abs/2003.03843v1,"Context: With the rising complexity and scale of software systems, there isan ever-increasing demand for sophisticated and cost-effective softwaretesting. To meet such a demand, there is a need for a highly-skilled softwaretesting work-force (test engineers) in the industry. To address that need, manyuniversity educators worldwide have included software-testing education intheir software engineering (SE) or computer science (CS) programs. Objective:Our objective in this paper is to summarize the body of experience andknowledge in the area of software-testing education to benefit the readers(both educators and researchers) in designing and delivering software testingcourses in university settings, and to also conduct further education researchin this area. Method: To address the above need, we conducted a systematicliterature mapping (SLM) to synthesize what the community of educators havepublished on this topic. After compiling a candidate pool of 307 papers, andapplying a set of inclusion/exclusion criteria, our final pool included 204papers published between 1992 and 2019. Results: The topic of software-testingeducation is becoming more active, as we can see by the increasing number ofpapers. Many pedagogical approaches (how to best teach testing), course-ware,and specific tools for testing education have been proposed. Many challenges intesting education and insights on how to overcome those challenges have beenproposed. Conclusion: This paper provides educators and researchers with aclassification of existing studies within software-testing education. Wefurther synthesize challenges and insights reported when teaching softwaretesting. The paper also provides a reference (""index"") to the vast body ofknowledge and experience on teaching software testing.",Vahid Garousi,2020/3/8,2020/3/8
1802.02033v2,Ways of Applying Artificial Intelligence in Software Engineering,http://arxiv.org/abs/1802.02033v2,"As Artificial Intelligence (AI) techniques have become more powerful andeasier to use they are increasingly deployed as key components of modernsoftware systems. While this enables new functionality and often allows betteradaptation to user needs it also creates additional problems for softwareengineers and exposes companies to new risks. Some work has been done to betterunderstand the interaction between Software Engineering and AI but we lackmethods to classify ways of applying AI in software systems and to analyse andunderstand the risks this poses. Only by doing so can we devise tools andsolutions to help mitigate them. This paper presents the AI in SE ApplicationLevels (AI-SEAL) taxonomy that categorises applications according to theirpoint of AI application, the type of AI technology used and the automationlevel allowed. We show the usefulness of this taxonomy by classifying 15 papersfrom previous editions of the RAISE workshop. Results show that the taxonomyallows classification of distinct AI applications and provides insightsconcerning the risks associated with them. We argue that this will be importantfor companies in deciding how to apply AI in their software applications and tocreate strategies for its use.",Robert Feldt,2018/2/6,2018/2/7
0908.2506v1,Software Engineering with Process Algebra: Modelling Client / Server Architectures,http://arxiv.org/abs/0908.2506v1,"In previous work we described how the process algebra based language PSF canbe used in software engineering, using the ToolBus, a coordination architecturealso based on process algebra, as implementation model. We also described thissoftware development process more formally by presenting the tools we use inthis process in a CASE setting, leading to the PSF-ToolBus software engineeringenvironment. In this article we summarize that work and describe a similarsoftware development process for implementation of software systems using aclient / server model and present this in a CASE setting as well.",B. Diertens,2009/8/18,2009/8/18
1712.05078v2,Fourteen Years of Software Engineering at ETH Zurich,http://arxiv.org/abs/1712.05078v2,"A Chair of Software Engineering existed at ETH Zurich, the Swiss FederalInsti-tute of Technology, from 1 October 2001 to 31 January 2016, under myleader-ship. Our work, summarized here, covered a wide range of theoretical andpracti-cal topics, with object technology in the Eiffel method as the unifyingthread .",Bertrand Meyer,2017/12/14,2017/12/16
2207.12578v1,A Retrospective on ICSE 2022,http://arxiv.org/abs/2207.12578v1,"The 44th International Conference on Software Engineering (ICSE 2022) washeld in person from May 22 to May 27, 2022 in Pittsburgh, PA, USA. Here, wesummarize themes of research and the direction of research in the field ofsoftware engineering and testing that we observed at the conference.",Cailin Winston,2022/7/26,2022/7/26
2108.10763v1,ComSum: Commit Messages Summarization and Meaning Preservation,http://arxiv.org/abs/2108.10763v1,"We present ComSum, a data set of 7 million commit messages for textsummarization. When documenting commits, software code changes, both a messageand its summary are posted. We gather and filter those to curate developers'work summarization data set. Along with its growing size, practicality andchallenging language domain, the data set benefits from the living field ofempirical software engineering. As commits follow a typology, we propose to notonly evaluate outputs by Rouge, but by their meaning preservation.",Leshem Choshen,2021/8/23,2021/8/23
1901.01186v1,Supporting software documentation with source code summarization,http://arxiv.org/abs/1901.01186v1,"Source code summarization is a process of generating summaries that describesoftware code, the majority of source code summarization usually generatedmanually, where the summaries are written by software developers. Recently, newautomated approaches are becoming more useful. These approaches have been foundto be effective in some cases. The main weaknesses of these approaches are thatthey never exploit code dependencies and summarize either the software classesor methods but not both. This paper proposes a source code summarizationapproach (Suncode) that produces a short description for each class and methodin the software system. To validate the approach, it has been applied toseveral case studies. Moreover, the generated summaries are compared tosummaries that written by human experts and to summaries that written by astate-of-the-art solution. Results of this paper found that Suncode summariesprovide better information about code dependencies comparing with otherstudies. In addition, Suncode summaries can improve and support the currentsoftware documentation. The results found that manually written summaries weremore precise and short as well.",Ra'Fat Al-Msie'deen,2018/12/14,2018/12/14
1904.12742v2,How software engineering research aligns with design science: A review,http://arxiv.org/abs/1904.12742v2,"Background: Assessing and communicating software engineering research can bechallenging. Design science is recognized as an appropriate research paradigmfor applied research but is seldom referred to in software engineering.Applying the design science lens to software engineering research may improvethe assessment and communication of research contributions. Aim: The aim ofthis study is 1) to understand whether the design science lens helps summarizeand assess software engineering research contributions, and 2) to characterizedifferent types of design science contributions in the software engineeringliterature. Method: In previous research, we developed a visual abstracttemplate, summarizing the core constructs of the design science paradigm. Inthis study, we use this template in a review of a set of 38 top softwareengineering publications to extract and analyze their design sciencecontributions. Results: We identified five clusters of papers, classifying themaccording to their alignment with the design science paradigm. Conclusions: Thedesign science lens helps emphasize the theoretical contribution of researchoutput---in terms of technological rules---and reflect on the practicalrelevance, novelty, and rigor of the rules proposed by the research.",Emelie Engstrm,2019/4/29,2019/11/8
2007.07047v2,Quantum Software Engineering: Landscapes and Horizons,http://arxiv.org/abs/2007.07047v2,"Quantum software plays a critical role in exploiting the full potential ofquantum computing systems. As a result, it has been drawing increasingattention recently. This paper defines the term ""quantum software engineering""and introduces a quantum software life cycle. The paper also gives a genericview of quantum software engineering and discusses the quantum softwareengineering processes, methods, and tools. Based on these, the paper provides acomprehensive survey of the current state of the art in the field and presentsthe challenges and opportunities we face. The survey summarizes the technologyavailable in the various phases of the quantum software life cycle, includingquantum software requirements analysis, design, implementation, test, andmaintenance. It also covers the crucial issues of quantum software reuse andmeasurement.",Jianjun Zhao,2020/7/14,2021/12/31
1309.5377v1,Advanced Techniques for Scientific Programming and Collaborative Development of Open Source Software Packages at the International Centre for Theoretical Physics (ICTP),http://arxiv.org/abs/1309.5377v1,"A large number of computational scientific research projects make use of opensource software packages. However, the development process of such toolsfrequently differs from conventional software development; partly because ofthe nature of research, where the problems being addressed are not always fullyunderstood; partly because the majority of the development is often carried outby scientists with limited experience and exposure to best practices ofsoftware engineering. Often the software development suffers from the pressureto publish scientific results and that credit for software development islimited in comparison. Fundamental components of software engineering likemodular and reusable design, validation, documentation, and softwareintegration as well as effective maintenance and user support tend to bedisregarded due to lack of resources and qualified specialists. Thus innovativedevelopments are often hindered by steep learning curves required to masterdevelopment for legacy software packages full of ad hoc solutions. The growingcomplexity of research, however, requires suitable and maintainablecomputational tools, resulting in a widening gap between the potential users(often growing in number) and contributors to the development of such apackage. In this paper we share our experiences aiming to improve the situationby training particularly young scientists, through disseminating our ownexperiences at contributing to open source software packages and practicing keycomponents of software engineering adapted for scientists and scientificsoftware development. Specifically we summarize the outcome of the Workshop inAdvanced Techniques for Scientific Programming and Collaborative Development ofOpen Source Software Packages run at the Abdus Salam International Centre forTheoretical Physics in March 2013, and discuss our conclusions for futureefforts.",Ivan Girotto,2013/9/6,2013/9/6
1309.1781v1,Experiences from Software Engineering of Large Scale AMR Multiphysics Code Frameworks,http://arxiv.org/abs/1309.1781v1,"Among the present generation of multiphysics HPC simulation codes there aremany that are built upon general infrastructural frameworks. This is especiallytrue of the codes that make use of structured adaptive mesh refinement (SAMR)because of unique demands placed on the housekeeping aspects of the code. Theyhave varying degrees of abstractions between the infrastructure such as meshmanagement and IO and the numerics of the physics solvers. In this experiencereport we summarize the experiences and lessons learned from two of such majorsoftware efforts, FLASH and Chombo.",A. Dubey,2013/9/6,2013/9/6
1810.00125v1,Towards Better Summarizing Bug Reports with Crowdsourcing Elicited Attributes,http://arxiv.org/abs/1810.00125v1,"Recent years have witnessed the growing demands for resolving numerous bugreports in software maintenance. Aiming to reduce the time testers/developerstake in perusing bug reports, the task of bug report summarization hasattracted a lot of research efforts in the literature. However, no systematicanalysis has been conducted on attribute construction which heavily impacts theperformance of supervised algorithms for bug report summarization. In thisstudy, we first conduct a survey to reveal the existing methods for attributeconstruction in mining software repositories. Then, we propose a new methodnamed Crowd-Attribute to infer new effective attributes from the crowdgenerateddata in crowdsourcing and develop a new tool named Crowdsourcing SoftwareEngineering Platform to facilitate this method. With Crowd-Attribute, wesuccessfully construct 11 new attributes and propose a new supervised algorithmnamed Logistic Regression with Crowdsourced Attributes (LRCA). To evaluate theeffectiveness of LRCA, we build a series of large scale data sets with 105,177bug reports. Experiments over both the public data set SDS with 36 manuallyannotated bug reports and new large-scale data sets demonstrate that LRCA canconsistently outperform the state-of-the-art algorithms for bug reportsummarization.",He Jiang,2018/9/29,2018/9/29
2307.15224v1,AI in Software Engineering: A Survey on Project Management Applications,http://arxiv.org/abs/2307.15224v1,"Artificial Intelligence (AI) refers to the intelligence demonstrated bymachines, and within the realm of AI, Machine Learning (ML) stands as a notablesubset. ML employs algorithms that undergo training on data sets, enabling themto carry out specific tasks autonomously. Notably, AI holds immense potentialin the field of software engineering, particularly in project management andplanning. In this literature survey, we explore the use of AI in SoftwareEngineering and summarize previous works in this area. We first review elevendifferent publications related to this subject, then compare the surveyedworks. We then comment on the possible challenges present in the utilization ofAI in software engineering and suggest possible further research avenues andthe ways in which AI could evolve with software engineering in the future.",Talia Crawford,2023/7/27,2023/7/27
1807.07387v1,The State of Sustainable Research Software: Results from the Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE5.1),http://arxiv.org/abs/1807.07387v1,"This article summarizes motivations, organization, and activities of theWorkshop on Sustainable Software for Science: Practice and Experiences(WSSSPE5.1) held in Manchester, UK in September 2017. The WSSSPE seriespromotes sustainable research software by positively impacting principles andbest practices, careers, learning, and credit. This article discusses the Codeof Conduct, idea papers, position papers, experience papers, demos, andlightning talks presented during the workshop. The main part of the articlediscusses the speed-blogging groups that formed during the meeting, along withthe outputs of those sessions.",Daniel S. Katz,2018/7/19,2018/7/19
2205.08487v2,Systematic Mapping Protocol: Variability Management in Dynamic Software Product Lines for Self-Adaptive Systems,http://arxiv.org/abs/2205.08487v2,Context: The Importance of Dynamic Variability Management in Dynamic SoftwareProduct Lines. Objective: Define a protocol for conducting a systematic mappingstudy to summarize and synthesize evidence on dynamic variability managementfor Dynamic Software Product Lines in self-adaptive systems. Method:Application the protocol to conduct a systematic mapping study according theguidelines of K. Petersen. Results: A validated protocol to conduct asystematic mapping study. Conclusions: First findings show that it is necessaryto visualize new ways to manage variability in dynamic software product lines.,Oscar Aguayo,2022/5/17,2022/6/29
2305.12865v1,Automatic Code Summarization via ChatGPT: How Far Are We?,http://arxiv.org/abs/2305.12865v1,"To support software developers in understanding and maintaining programs,various automatic code summarization techniques have been proposed to generatea concise natural language comment for a given code snippet. Recently, theemergence of large language models (LLMs) has led to a great boost in theperformance of natural language processing tasks. Among them, ChatGPT is themost popular one which has attracted wide attention from the softwareengineering community. However, it still remains unclear how ChatGPT performsin (automatic) code summarization. Therefore, in this paper, we focus onevaluating ChatGPT on a widely-used Python dataset called CSN-Python andcomparing it with several state-of-the-art (SOTA) code summarization models.Specifically, we first explore an appropriate prompt to guide ChatGPT togenerate in-distribution comments. Then, we use such a prompt to ask ChatGPT togenerate comments for all code snippets in the CSN-Python test set. We adoptthree widely-used metrics (including BLEU, METEOR, and ROUGE-L) to measure thequality of the comments generated by ChatGPT and SOTA models (including NCS,CodeBERT, and CodeT5). The experimental results show that in terms of BLEU andROUGE-L, ChatGPT's code summarization performance is significantly worse thanall three SOTA models. We also present some cases and discuss the advantagesand disadvantages of ChatGPT in code summarization. Based on the findings, weoutline several open challenges and opportunities in ChatGPT-based codesummarization.",Weisong Sun,2023/5/22,2023/5/22
2105.02703v1,Development and Application of Sentiment Analysis Tools in Software Engineering: A Systematic Literature Review,http://arxiv.org/abs/2105.02703v1,"Software development is a collaborative task and, hence, involves differentpersons. Research has shown the relevance of social aspects in the developmentteam for a successful and satisfying project closure. Especially the mood of ateam has been proven to be of particular importance. Thus, project managers orproject leaders want to be aware of situations in which negative mood ispresent to allow for interventions. So-called sentiment analysis tools offer away to determine the mood based on text-based communication. In this paper, wepresent the results of a systematic literature review of sentiment analysistools developed for or applied in the context of software engineering. Ourresults summarize insights from 80 papers with respect to (1) the applicationdomain, (2) the purpose, (3) the used data sets, (4) the approaches fordeveloping sentiment analysis tools and (5) the difficulties researchers facewhen applying sentiment analysis in the context of software projects. Accordingto our results, sentiment analysis is frequently applied to open-sourcesoftware projects, and most tools are based on support-vector machines. Despitethe frequent use of sentiment analysis in software engineering, there are openissues, e.g., regarding the identification of irony or sarcasm, pointing tofuture research directions.",Martin Obaidi,2021/5/6,2021/5/6
2004.10361v2,Testing Machine Translation via Referential Transparency,http://arxiv.org/abs/2004.10361v2,"Machine translation software has seen rapid progress in recent years due tothe advancement of deep neural networks. People routinely use machinetranslation software in their daily lives, such as ordering food in a foreignrestaurant, receiving medical diagnosis and treatment from foreign doctors, andreading international political news online. However, due to the complexity andintractability of the underlying neural networks, modern machine translationsoftware is still far from robust and can produce poor or incorrecttranslations; this can lead to misunderstanding, financial loss, threats topersonal safety and health, and political conflicts. To address this problem,we introduce referentially transparent inputs (RTIs), a simple, widelyapplicable methodology for validating machine translation software. Areferentially transparent input is a piece of text that should have similartranslations when used in different contexts. Our practical implementation,Purity, detects when this property is broken by a translation. To evaluate RTI,we use Purity to test Google Translate and Bing Microsoft Translator with 200unlabeled sentences, which detected 123 and 142 erroneous translations withhigh precision (79.3% and 78.3%). The translation errors are diverse, includingexamples of under-translation, over-translation, word/phrase mistranslation,incorrect modification, and unclear logic.",Pinjia He,2020/4/22,2021/2/28
0811.3328v1,chi2TeX Semi-automatic translation from chiwriter to LaTeX,http://arxiv.org/abs/0811.3328v1,Semi-automatic translation of math-filled book from obsolete ChiWriter formatto LaTeX. Is it possible? Idea of criterion whether to use automatic or handmode for translation. Illustrations.,Justislav Bogevolnov,2008/11/20,2008/11/20
2302.03908v2,Syntax and Domain Aware Model for Unsupervised Program Translation,http://arxiv.org/abs/2302.03908v2,"There is growing interest in software migration as the development ofsoftware and society. Manually migrating projects between languages iserror-prone and expensive. In recent years, researchers have begun to exploreautomatic program translation using supervised deep learning techniques bylearning from large-scale parallel code corpus. However, parallel resources arescarce in the programming language domain, and it is costly to collectbilingual data manually. To address this issue, several unsupervisedprogramming translation systems are proposed. However, these systems still relyon huge monolingual source code to train, which is very expensive. Besides,these models cannot perform well for translating the languages that are notseen during the pre-training procedure. In this paper, we propose SDA-Trans, asyntax and domain-aware model for program translation, which leverages thesyntax structure and domain knowledge to enhance the cross-lingual transferability. SDA-Trans adopts unsupervised training on a smaller-scale corpus,including Python and Java monolingual programs. The experimental results onfunction translation tasks between Python, Java, and C++ show that SDA-Transoutperforms many large-scale pre-trained models, especially for unseen languagetranslation.",Fang Liu,2023/2/8,2023/3/10
1508.02031v2,What Is Software Engineering?,http://arxiv.org/abs/1508.02031v2,A later translation (2015) of the article in Russian published in 1990. Thearticle proposes an approach to defining a set of basic notions for subjectarea of software engineering discipline. The set of notions is intended toserve as a basis for detection and correction of some widespread conceptualmistakes in the efforts aimed at improving the quality and work productivity increation and operation of software.,Fedor Dzerzhinskiy,2015/8/9,2015/8/11
1402.0292v1,GQM+Strategies: A Comprehensive Methodology for Aligning Business Strategies with Software Measurement,http://arxiv.org/abs/1402.0292v1,"In software-intensive organizations, an organizational management system willnot guarantee organizational success unless the business strategy can betranslated into a set of operational software goals. The Goal Question Metric(GQM) approach has proven itself useful in a variety of industrial settings tosupport quantitative software project management. However, it does not addresslinking software measurement goals to higher-level goals of the organization inwhich the software is being developed. This linkage is important, as it helpsto justify software measurement efforts and allows measurement data tocontribute to higher-level decisions. In this paper, we propose aGQM+Strategies(R) measurement approach that builds on the GQM approach to planand implement software measurement. GQM+Strategies(R) provides mechanisms forexplicitly linking software measurement goals to higher-level goals for thesoftware organization, and further to goals and strategies at the level of theentire business. The proposed method is illustrated in the context of anexample application of the method.",Victor Basili,2014/2/3,2014/2/3
2202.07682v1,Better Together? An Evaluation of AI-Supported Code Translation,http://arxiv.org/abs/2202.07682v1,"Generative machine learning models have recently been applied to source code,for use cases including translating code between programming languages,creating documentation from code, and auto-completing methods. Yet,state-of-the-art models often produce code that is erroneous or incomplete. Ina controlled study with 32 software engineers, we examined whether suchimperfect outputs are helpful in the context of Java-to-Python codetranslation. When aided by the outputs of a code translation model,participants produced code with fewer errors than when working alone. We alsoexamined how the quality and quantity of AI translations affected the workprocess and quality of outcomes, and observed that providing multipletranslations had a larger impact on the translation process than varying thequality of provided translations. Our results tell a complex, nuanced storyabout the benefits of generative code models and the challenges softwareengineers face when working with their outputs. Our work motivates the need forintelligent user interfaces that help software engineers effectively work withgenerative code models in order to understand and evaluate their outputs andachieve superior outcomes to working alone.",Justin D. Weisz,2022/2/15,2022/2/15
2103.02820v1,Diagrammatic Formalism for Complex Systems: More than One Way to Eventize a Railcar System,http://arxiv.org/abs/2103.02820v1,"This paper is in the intersection of software engineering and systemengineering, two intimately intertwined disciplines. A dominating theme in thispaper is the integral conceptualization of systems at large, as well as anunderlying concern with software systems. In the software development lifecycle, challenges still exist in translating requirements into a designartifact and then into an implementation (e.g., coding), then validating theresults. From our perspective, software engineering requires an integratingparadigm toward a unified modeling orientation. Many methodologies, languages,and tools exist for facilitating system development processes. This paper is aventure into project development. To focus the materials, we concentrate onHarel s novel (and classic) development environment, which integrates ascenario-based engineering object orientation and statecharts throughdeveloping a railcar system. The railcar system is used as a detailed sample oftranslating requirements into a design artifact and then into animplementation, then validating the result. The project is re-cased as a singleintegrated modeling endeavor to be contrasted with the scenario and statechartsdevelopment. The result of this scheme is an enriched understanding throughexperimenting with and contrasting various development methods of softwareprojects.",Sabah Al-Fedaghi,2021/3/4,2021/3/4
2302.10812v1,On ML-Based Program Translation: Perils and Promises,http://arxiv.org/abs/2302.10812v1,"With the advent of new and advanced programming languages, it becomesimperative to migrate legacy software to new programming languages.Unsupervised Machine Learning-based Program Translation could play an essentialrole in such migration, even without a sufficiently sizeable reliable corpus ofparallel source code. However, these translators are far from perfect due totheir statistical nature. This work investigates unsupervised programtranslators and where and why they fail. With in-depth error analysis of suchfailures, we have identified that the cases where such translators fail followa few particular patterns. With this insight, we develop a rule-based programmutation engine, which pre-processes the input code if the input followsspecific patterns and post-process the output if the output follows certainpatterns. We show that our code processing tool, in conjunction with theprogram translator, can form a hybrid program translator and significantlyimprove the state-of-the-art. In the future, we envision an end-to-end programtranslation tool where programming domain knowledge can be embedded into anML-based translation pipeline using pre- and post-processing steps.",Aniketh Malyala,2023/2/21,2023/2/21
1907.08710v3,Structure-Invariant Testing for Machine Translation,http://arxiv.org/abs/1907.08710v3,"In recent years, machine translation software has increasingly beenintegrated into our daily lives. People routinely use machine translation forvarious applications, such as describing symptoms to a foreign doctor andreading political news in a foreign language. However, the complexity andintractability of neural machine translation (NMT) models that power modernmachine translation make the robustness of these systems difficult to evenassess, much less guarantee. Machine translation systems can return inferiorresults that lead to misunderstanding, medical misdiagnoses, threats topersonal safety, or political conflicts. Despite its apparent importance,validating the robustness of machine translation systems is very difficult andhas, therefore, been much under-explored.  To tackle this challenge, we introduce structure-invariant testing (SIT), anovel metamorphic testing approach for validating machine translation software.Our key insight is that the translation results of ""similar"" source sentencesshould typically exhibit similar sentence structures. Specifically, SIT (1)generates similar source sentences by substituting one word in a given sentencewith semantically similar, syntactically equivalent words; (2) representssentence structure by syntax parse trees (obtained via constituency ordependency parsing); (3) reports sentence pairs whose structures differquantitatively by more than some threshold. To evaluate SIT, we use it to testGoogle Translate and Bing Microsoft Translator with 200 source sentences asinput, which led to 64 and 70 buggy issues with 69.5\% and 70\% top-1 accuracy,respectively. The translation errors are diverse, including under-translation,over-translation, incorrect modification, word/phrase mistranslation, andunclear logic.",Pinjia He,2019/7/19,2020/7/14
2302.05669v1,Treat societally impactful scientific insights as open-source software artifacts,http://arxiv.org/abs/2302.05669v1,"So far, the relationship between open science and software engineeringexpertise has largely focused on the open release of software engineeringresearch insights and reproducible artifacts, in the form of open-accesspapers, open data, and open-source tools and libraries. In this position paper,we draw attention to another perspective: scientific insight itself is acomplex and collaborative artifact under continuous development and in need ofcontinuous quality assurance, and as such, has many parallels to softwareartifacts. Considering current calls for more open, collaborative andreproducible science; increasing demands for public accountability on mattersof scientific integrity and credibility; methodological challenges coming withtransdisciplinary science; political and communication tensions when scientificinsight on societally relevant topics is to be translated to policy; andstruggles to incentivize and reward academics who truly want to move into thesedirections beyond traditional publishing habits and cultures, we make theparallels between the emerging open science requirements and concepts alreadywell-known in (open-source) software engineering research more explicit. Weargue that the societal impact of software engineering expertise can reach farbeyond the software engineering research community, and call upon the communitymembers to pro-actively help driving the necessary systems and cultural changestowards more open and accountable research.",Cynthia C. S. Liem,2023/2/11,2023/2/11
2310.11476v1,Program Translation via Code Distillation,http://arxiv.org/abs/2310.11476v1,"Software version migration and program translation are an important andcostly part of the lifecycle of large codebases. Traditional machinetranslation relies on parallel corpora for supervised translation, which is notfeasible for program translation due to a dearth of aligned data. Recentunsupervised neural machine translation techniques have overcome datalimitations by included techniques such as back translation and low levelcompiler intermediate representations (IR). These methods face significantchallenges due to the noise in code snippet alignment and the diversity of IRsrespectively. In this paper we propose a novel model called Code Distillation(CoDist) whereby we capture the semantic and structural equivalence of code ina language agnostic intermediate representation. Distilled code serves as atranslation pivot for any programming language, leading by construction toparallel corpora which scale to all available source code by simply applyingthe distillation compiler. We demonstrate that our approach achievesstate-of-the-art performance on CodeXGLUE and TransCoder GeeksForGeekstranslation benchmarks, with an average absolute increase of 12.7% on theTransCoder GeeksforGeeks translation benchmark compare to TransCoder-ST.",Yufan Huang,2023/10/17,2023/10/17
1703.08242v1,Concurrent Software Design Based on Constraints on State Diagrams,http://arxiv.org/abs/1703.08242v1,"Concurrent software for engineering computations consists of multiplecooperating modules. The behavior of individual modules is described by meanson state diagrams. In the paper, the constraints on state diagrams areproposed, allowing for the specification of designer's intentions as to thesynchronization of modules. Also, the translation of state diagrams (withenforcement constraints) into Concurrent State Machines is shown, whichprovides formal framework for the verification of inter-module synchronization.An example of engineering software design based on the method is presented.",Bogdan D. Czejdo,2017/3/23,2017/3/23
1910.09902v1,Theory-Software Translation: Research Challenges and Future Directions,http://arxiv.org/abs/1910.09902v1,"The Theory-Software Translation Workshop, held in New Orleans in February2019, explored in depth the process of both instantiating theory in software -for example, implementing a mathematical model in code as part of a simulation- and using the outputs of software - such as the behavior of a simulation - toadvance knowledge. As computation within research is now ubiquitous, theworkshop provided a timely opportunity to reflect on the particular challengesof research software engineering - the process of developing and maintainingsoftware for scientific discovery. In addition to the general challenges commonto all software development projects, research software additionally mustrepresent, manipulate, and provide data for complex theoretical constructs.Ensuring this process is robust is essential to maintaining the integrity ofthe science resulting from it, and the workshop highlighted a number of areaswhere the current approach to research software engineering would benefit froman evidence base that could be used to inform best practice.  The workshop brought together expert research software engineers andacademics to discuss the challenges of Theory-Software Translation over atwo-day period. This report provides an overview of the workshop activities,and a synthesises of the discussion that was recorded. The body of the reportpresents a thematic analysis of the challenges of Theory-Software Translationas identified by workshop participants, summarises these into a set of researchareas, and provides recommendations for the future direction of this work.",Caroline Jay,2019/10/22,2019/10/22
2110.13995v1,Software Engineering Meets Systems Engineering: Conceptual Modeling Applied to Engineering Operations,http://arxiv.org/abs/2110.13995v1,"Models are fundamentally crucial to many scientific fields, includingsoftware engineering, systems engineering, enterprise modeling, and businessmodeling. This paper focuses on diagrammatic conceptual modeling, as opposed tomathematical or computational models, wherein a conceptual model is atranslation of reality processes into an abstract mechanism that has similarstructure and parallel events of the external processes. Although variousmodeling approaches exist, including UML (Unified Modeling Language) insoftware engineering and its dialect, SysML (System Modeling Language), insystems engineering, several difficulties arise in such models, including theproblem of model multiplicity that is related to the lack an integrated view ofstructure and behavior. This paper generalizes conceptual modeling to beapplied in organizations at large. According to authorities, the so-calledorganization theory portrays organizations as machine-like systems. As amachine, an organization coordinates its parts to transform inputs intooutputs. Therefore, we synthesize the notion of an organization as a machineand apply a new modeling methodology called thinging machine (TM) to realengineering operations. The results show the viability of the TM methodologyserving as a foundation for high-level modelling of systems.",Sabah Al-Fedaghi,2021/10/26,2021/10/26
2008.10707v2,Patching as Translation: the Data and the Metaphor,http://arxiv.org/abs/2008.10707v2,"Machine Learning models from other fields, like Computational Linguistics,have been transplanted to Software Engineering tasks, often quite successfully.Yet a transplanted model's initial success at a given task does not necessarilymean it is well-suited for the task. In this work, we examine a common exampleof this phenomenon: the conceit that ""software patching is like languagetranslation"". We demonstrate empirically that there are subtle, but criticaldistinctions between sequence-to-sequence models and translation model: whileprogram repair benefits greatly from the former, general modeling architecture,it actually suffers from design decisions built into the latter, both in termsof translation accuracy and diversity. Given these findings, we demonstrate howa more principled approach to model design, based on our empirical findings andgeneral knowledge of software development, can lead to better solutions. Ourfindings also lend strong support to the recent trend towards synthesizingedits of code conditional on the buggy context, to repair bugs. We implementsuch models ourselves as ""proof-of-concept"" tools and empirically confirm thatthey behave in a fundamentally different, more effective way than the studiedtranslation-based architectures. Overall, our results demonstrate the merit ofstudying the intricacies of machine learned models in software engineering: notonly can this help elucidate potential issues that may be overshadowed byincreases in accuracy; it can also help innovate on these models to raise thestate-of-the-art further. We will publicly release our replication data andmaterials at https://github.com/ARiSE-Lab/Patch-as-translation.",Yangruibo Ding,2020/8/24,2020/9/1
1908.06748v2,Adabot: Fault-Tolerant Java Decompiler,http://arxiv.org/abs/1908.06748v2,"Reverse Engineering(RE) has been a fundamental task in software engineering.However, most of the traditional Java reverse engineering tools are strictlyrule defined, thus are not fault-tolerant, which pose serious problem whennoise and interference were introduced into the system. In this paper, we viewreverse engineering as a statistical machine translation task instead ofrule-based task, and propose a fault-tolerant Java decompiler based on machinetranslation models. Our model is based on attention-based Neural MachineTranslation (NMT) and Transformer architectures. First, we measure thetranslation quality on both the redundant and purified datasets. Next, weevaluate the fault-tolerance(anti-noise ability) of our framework on test setswith different unit error probability (UEP). In addition, we compare thesuitability of different word segmentation algorithms for decompilation task.Experimental results demonstrate that our model is more robust andfault-tolerant compared to traditional Abstract Syntax Tree (AST) baseddecompilers. Specifically, in terms of BLEU-4 and Word Error Rate (WER), ourperformance has reached 94.50% and 2.65% on the redundant test set; 92.30% and3.48% on the purified test set.",Zhiming Li,2019/8/14,2019/10/15
0808.1721v1,Initial Results on the F-logic to OWL Bi-directional Translation on a Tabled Prolog Engine,http://arxiv.org/abs/0808.1721v1,"In this paper, we show our results on the bi-directional data exchangebetween the F-logic language supported by the Flora2 system and the OWLlanguage. Most of the TBox and ABox axioms are translated preserving thesemantics between the two representations, such as: proper inclusion,individual definition, functional properties, while some axioms andrestrictions require a change in the semantics, such as: numbered and qualifiedcardinality restrictions. For the second case, we translate the OWL definitestyle inference rules into F-logic style constraints. We also describe a set ofreasoning examples using the above translation, including the reasoning inFlora2 of a variety of ABox queries.",Paul Fodor,2008/8/12,2008/8/12
1309.1485v3,Formally expressing the semantics of observer-based fault detection software,http://arxiv.org/abs/1309.1485v3,"The aim is to create reliable and verifiable fault detection software todetect abrupt changes in safety-critical dynamic systems. Fault detectionmethods are implemented as software on digital computers that monitor andcontrol the system. We implement three observer-based fault detection methodson a 3 degrees of freedom (3DOF) laboratory helicopter, in the form ofsoftware. We examine the performance of those methods to detect differentfaults during flight in a closed-loop setup. All selected methods showacceptable detection performance. However, it is not possible to repeat thetest for every possible conditions, inputs and fault scenarios. In this paper,we translate fault detection properties and mathematical proofs into a formallanguage, previously used in software validation and verification. We includethe translated properties in software in the form of non-executable annotationsthat can be read by machine. Consequently, some high level functionalproperties of the code can be verified by automatic software verificationtools. This certifies fault detection software for a set of bounded data andincreases the reliability in practice.",Alireza Esna Ashari,2013/9/5,2013/12/3
2104.03820v1,Perfection Not Required? Human-AI Partnerships in Code Translation,http://arxiv.org/abs/2104.03820v1,"Generative models have become adept at producing artifacts such as images,videos, and prose at human-like levels of proficiency. New generativetechniques, such as unsupervised neural machine translation (NMT), haverecently been applied to the task of generating source code, translating itfrom one programming language to another. The artifacts produced in this waymay contain imperfections, such as compilation or logical errors. We examinethe extent to which software engineers would tolerate such imperfections andexplore ways to aid the detection and correction of those errors. Using adesign scenario approach, we interviewed 11 software engineers to understandtheir reactions to the use of an NMT model in the context of applicationmodernization, focusing on the task of translating source code from onelanguage to another. Our three-stage scenario sparked discussions about theutility and desirability of working with an imperfect AI system, how acceptanceof that system's outputs would be established, and future opportunities forgenerative AI in application modernization. Our study highlights how UIfeatures such as confidence highlighting and alternate translations helpsoftware engineers work with and better understand generative NMT models.",Justin D. Weisz,2021/4/8,2021/4/8
2401.00751v1,Machine Translation Testing via Syntactic Tree Pruning,http://arxiv.org/abs/2401.00751v1,"Machine translation systems have been widely adopted in our daily life,making life easier and more convenient. Unfortunately, erroneous translationsmay result in severe consequences, such as financial losses. This requires toimprove the accuracy and the reliability of machine translation systems.However, it is challenging to test machine translation systems because of thecomplexity and intractability of the underlying neural models. To tackle thesechallenges, we propose a novel metamorphic testing approach by syntactic treepruning (STP) to validate machine translation systems. Our key insight is thata pruned sentence should have similar crucial semantics compared with theoriginal sentence. Specifically, STP (1) proposes a core semantics-preservingpruning strategy by basic sentence structure and dependency relations on thelevel of syntactic tree representation; (2) generates source sentence pairsbased on the metamorphic relation; (3) reports suspicious issues whosetranslations break the consistency property by a bag-of-words model. We furtherevaluate STP on two state-of-the-art machine translation systems (i.e., GoogleTranslate and Bing Microsoft Translator) with 1,200 source sentences as inputs.The results show that STP can accurately find 5,073 unique erroneoustranslations in Google Translate and 5,100 unique erroneous translations inBing Microsoft Translator (400% more than state-of-the-art techniques), with64.5% and 65.4% precision, respectively. The reported erroneous translationsvary in types and more than 90% of them cannot be found by state-of-the-arttechniques. There are 9,393 erroneous translations unique to STP, which is711.9% more than state-of-the-art techniques. Moreover, STP is quite effectiveto detect translation errors for the original sentences with a recall reaching74.0%, improving state-of-the-art techniques by 55.1% on average.",Quanjun Zhang,2024/1/1,2024/1/1
1903.12282v1,An Empirical Study of Obsolete Answers on Stack Overflow,http://arxiv.org/abs/1903.12282v1,"Stack Overflow accumulates an enormous amount of software engineeringknowledge. However, as time passes, certain knowledge in answers may becomeobsolete. Such obsolete answers, if not identified or documented clearly, maymislead answer seekers and cause unexpected problems (e.g., using an out-datedsecurity protocol). In this paper, we investigate how the knowledge in answersbecomes obsolete and identify the characteristics of such obsolete answers. Wefind that: 1) More than half of the obsolete answers (58.4%) were probablyalready obsolete when they were first posted. 2) When an obsolete answer isobserved, only a small proportion (20.5%) of such answers are ever updated. 3)Answers to questions in certain tags (e.g., node.js, ajax, android, andobjective-c) are more likely to become obsolete. Our findings suggest thatStack Overflow should develop mechanisms to encourage the whole community tomaintain answers (to avoid obsolete answers) and answer seekers are encouragedto carefully go through all information (e.g., comments) in answer threads.",Haoxiang Zhang,2019/3/28,2019/3/28
2010.03165v3,Questions for Data Scientists in Software Engineering: A Replication,http://arxiv.org/abs/2010.03165v3,"In 2014, a Microsoft study investigated the sort of questions that datascience applied to software engineering should answer. This resulted in 145questions that developers considered relevant for data scientists to answer,thus providing a research agenda to the community. Fast forward to five years,no further studies investigated whether the questions from the softwareengineers at Microsoft hold for other software companies, includingsoftware-intensive companies with different primary focus (to which we refer assoftware-defined enterprises). Furthermore, it is not evident that the problemsidentified five years ago are still applicable, given the technologicaladvances in software engineering.",Hennie Huijgens,2020/10/7,2021/1/4
2306.11534v1,Software Engineers' Questions and Answers on Stack Exchange,http://arxiv.org/abs/2306.11534v1,"There exists a large number of research works analyzing questions and answerson the popular Stack Overflow website. However, other sub-sites of the StackExchange platform are studied rarely. In this paper, we analyze the questionsand answers on the Software Engineering Stack Exchange site that encompasses abroader set of areas, such as testing or software processes. Topics andquantities of the questions, historical trends, and the authors' sentiment wereanalyzed using downloaded datasets. We found that the asked questions are mostfrequently related to database systems, quality assurance, and agile softwaredevelopment. The most attractive topics were career and teamwork problems, andthe least attractive ones were network programming and software modeling.Historically, the topic of domain-driven design recorded the highest rise, andjobs and career the most significant fall. The number of new questions dropped,while the portion of unanswered ones increased.",Mat Sulr,2023/6/20,2023/6/20
2101.02830v2,Features that Predict the Acceptability of Java and JavaScript Answers on Stack Overflow,http://arxiv.org/abs/2101.02830v2,"Context: Stack Overflow is a popular community question and answer portalused by practitioners to solve problems during software development. Developerscan focus their attention on answers that have been accepted or where membershave recorded high votes in judging good answers when searching for help.However, the latter mechanism (votes) can be unreliable, and there is currentlyno way to differentiate between an answer that is likely to be accepted andthose that will not be accepted by looking at the answer's characteristics.Objective: In potentially providing a mechanism to identify acceptable answers,this study examines the features that distinguish an accepted answer from anunaccepted answer. Methods: We studied the Stack Overflow dataset by analyzingquestions and answers for the two most popular tags (Java and JavaScript). Ourdataset comprised 249,588 posts drawn from 2014-2016. We use random forest andneural network models to predict accepted answers, and study the features withthe highest predictive power in those two models. Results: Our findings revealthat the length of code in answers, reputation of users, similarity of the textbetween questions and answers, and the time lag between questions and answershave the highest predictive power for differentiating accepted and unacceptedanswers. Conclusion: Tools may leverage these findings in supporting developersand reducing the effort they must dedicate to searching for suitable answers onStack Overflow.",Osayande P. Omondiagbe,2021/1/8,2023/6/19
1903.09522v1,An empirical assessment of best-answer prediction models in technical Q&A sites,http://arxiv.org/abs/1903.09522v1,"Technical Q&A sites have become essential for software engineers as theyconstantly seek help from other experts to solve their work problems. Despitetheir success, many questions remain unresolved, sometimes because the askerdoes not acknowledge any helpful answer. In these cases, an information seekercan only browse all the answers within a question thread to assess theirquality as potential solutions. We approach this time-consuming problem as abinary-classification task where a best-answer prediction model is built toidentify the accepted answer among those within a resolved question thread, andthe candidate solutions to those questions that have received answers but arestill unresolved. In this paper, we report on a study aimed at assessing 26best-answer prediction models in two steps. First, we study how models performwhen predicting best answers in Stack Overflow, the most popular Q&A site forsoftware engineers. Then, we assess performance in a cross-platform settingwhere the prediction models are trained on Stack Overflow and tested on othertechnical Q&A sites. Our findings show that the choice of the classifier andautomated parameter tuning have a large impact on the prediction of the bestanswer. We also demonstrate that our approach to the best-answer predictionproblem is generalizable across technical Q&A sites. Finally, we providepractical recommendations to Q&A platform designers to curate and preserve thecrowdsourced knowledge shared through these sites.",Fabio Calefato,2019/3/22,2019/3/22
2101.03999v1,A Neural Question Answering System for Basic Questions about Subroutines,http://arxiv.org/abs/2101.03999v1,"A question answering (QA) system is a type of conversational AI thatgenerates natural language answers to questions posed by human users. QAsystems often form the backbone of interactive dialogue systems, and have beenstudied extensively for a wide variety of tasks ranging from restaurantrecommendations to medical diagnostics. Dramatic progress has been made inrecent years, especially from the use of encoder-decoder neural architecturestrained with big data input. In this paper, we take initial steps to bringingstate-of-the-art neural QA technologies to Software Engineering applications bydesigning a context-based QA system for basic questions about subroutines. Wecurate a training dataset of 10.9 million question/context/answer tuples basedon rules we extract from recent empirical studies. Then, we train a customneural QA model with this dataset and evaluate the model in a study withprofessional programmers. We demonstrate the strengths and weaknesses of thesystem, and lay the groundwork for its use in eventual dialogue systems forsoftware engineering.",Aakash Bansal,2021/1/11,2021/1/11
2302.04793v1,AI-based Question Answering Assistance for Analyzing Natural-language Requirements,http://arxiv.org/abs/2302.04793v1,"By virtue of being prevalently written in natural language (NL), requirementsare prone to various defects, e.g., inconsistency and incompleteness. As such,requirements are frequently subject to quality assurance processes. Theseprocesses, when carried out entirely manually, are tedious and may furtheroverlook important quality issues due to time and budget pressures. In thispaper, we propose QAssist -- a question-answering (QA) approach that providesautomated assistance to stakeholders, including requirements engineers, duringthe analysis of NL requirements. Posing a question and getting an instantanswer is beneficial in various quality-assurance scenarios, e.g.,incompleteness detection. Answering requirements-related questionsautomatically is challenging since the scope of the search for answers can gobeyond the given requirements specification. To that end, QAssist providessupport for mining external domain-knowledge resources. Our work is one of thefirst initiatives to bring together QA and external domain knowledge foraddressing requirements engineering challenges. We evaluate QAssist on adataset covering three application domains and containing a total of 387question-answer pairs. We experiment with state-of-the-art QA methods, basedprimarily on recent large-scale language models. In our empirical study,QAssist localizes the answer to a question to three passages within therequirements specification and within the external domain-knowledge resourcewith an average recall of 90.1% and 96.5%, respectively. QAssist extracts theactual answer to the posed question with an average accuracy of 84.2%.  Keywords: Natural-language Requirements, Question Answering (QA), LanguageModels, Natural Language Processing (NLP), Natural Language Generation (NLG),BERT, T5.",Saad Ezzini,2023/2/9,2023/2/9
1905.11366v1,Supporting Software Engineering Research and Education by Annotating Public Videos of Developers Programming,http://arxiv.org/abs/1905.11366v1,"Software engineering has long studied how software developers work, buildinga body of work which forms the foundation of many software engineering bestpractices, tools, and theories. Recently, some developers have begun recordingvideos of themselves engaged in programming tasks contributing to open sourceprojects, enabling them to share knowledge and socialize with other developers.We believe that these videos offer an important opportunity for both softwareengineering research and education. In this paper, we discuss the potential useof these videos as well as open questions for how to best enable thisenvisioned use. We propose creating a central repository of programming videos,enabling analyzing and annotating videos to illustrate specific behaviors ofinterest such as asking and answering questions, employing strategies, andsoftware engineering theories. Such a repository would offer an important newway in which both software engineering researchers and students can understandhow software developers work.",Abdulaziz Alaboudi,2019/5/9,2019/5/9
2109.08365v1,CodeQA: A Question Answering Dataset for Source Code Comprehension,http://arxiv.org/abs/2109.08365v1,"We propose CodeQA, a free-form question answering dataset for the purpose ofsource code comprehension: given a code snippet and a question, a textualanswer is required to be generated. CodeQA contains a Java dataset with 119,778question-answer pairs and a Python dataset with 70,085 question-answer pairs.To obtain natural and faithful questions and answers, we implement syntacticrules and semantic analysis to transform code comments into question-answerpairs. We present the construction process and conduct systematic analysis ofour dataset. Experiment results achieved by several neural baselines on ourdataset are shown and discussed. While research on question-answering andmachine reading comprehension develops rapidly, few prior work has drawnattention to code question answering. This new dataset can serve as a usefulresearch benchmark for source code comprehension.",Chenxiao Liu,2021/9/17,2021/9/17
1807.01850v1,An Insight into the Unresolved Questions at Stack Overflow,http://arxiv.org/abs/1807.01850v1,"For a significant number of questions at Stack Overflow, none of the postedanswers were accepted as solutions. Acceptance of an answer indicates that theanswer actually solves the discussed problem in the question, and the questionis answered sufficiently. In this paper, we investigate 3,956 such unresolvedquestions using an exploratory study where we analyze four important aspects ofthose questions, their answers and the corresponding users that partiallyexplain the observed scenario. We then propose a prediction model by employingfive metrics related to user behaviour, topics and popularity of question,which predicts if the best answer for a question at Stack Overflow might remainunaccepted or not. Experiments using 8,057 questions show that the model canpredict unresolved questions with 78.70% precision and 76.10% recall.",Mohammad Masudur Rahman,2018/7/5,2018/7/5
2203.14093v2,MQDD: Pre-training of Multimodal Question Duplicity Detection for Software Engineering Domain,http://arxiv.org/abs/2203.14093v2,"This work proposes a new pipeline for leveraging data collected on the StackOverflow website for pre-training a multimodal model for searching duplicateson question answering websites. Our multimodal model is trained on questiondescriptions and source codes in multiple programming languages. We design twonew learning objectives to improve duplicate detection capabilities. The resultof this work is a mature, fine-tuned Multimodal Question Duplicity Detection(MQDD) model, ready to be integrated into a Stack Overflow search system, whereit can help users find answers for already answered questions. Alongside theMQDD model, we release two datasets related to the software engineering domain.The first Stack Overflow Dataset (SOD) represents a massive corpus of pairedquestions and answers. The second Stack Overflow Duplicity Dataset (SODD)contains data for training duplicate detection models.",Jan Paek,2022/3/26,2022/3/29
1311.6876v1,Want a Good Answer? Ask a Good Question First!,http://arxiv.org/abs/1311.6876v1,"Community Question Answering (CQA) websites have become valuable repositorieswhich host a massive volume of human knowledge. To maximize the utility of suchknowledge, it is essential to evaluate the quality of an existing question oranswer, especially soon after it is posted on the CQA website.  In this paper, we study the problem of inferring the quality of questions andanswers through a case study of a software CQA (Stack Overflow). Our keyfinding is that the quality of an answer is strongly positively correlated withthat of its question. Armed with this observation, we propose a family ofalgorithms to jointly predict the quality of questions and answers, for bothquantifying numerical quality scores and differentiating the high-qualityquestions/answers from those of low quality. We conduct extensive experimentalevaluations to demonstrate the effectiveness and efficiency of our methods.",Yuan Yao,2013/11/27,2013/11/27
2306.07355v1,Are Software Updates Useless Against Advanced Persistent Threats?,http://arxiv.org/abs/2306.07355v1,"A dilemma worth Shakespeare's Hamlet is increasingly haunting companies andsecurity researchers: ``to update or not to update, this is the question``.From the perspective of recommended common practices by software vendors theanswer is unambiguous: you should keep your software up-to-date. But is commonsense always good sense? We argue it is not.",Fabio Massacci,2023/6/12,2023/6/12
2103.09423v1,Towards a question answering assistant for software development using a transformer-based language model,http://arxiv.org/abs/2103.09423v1,"Question answering platforms, such as Stack Overflow, have impactedsubstantially how developers search for solutions for their programmingproblems. The crowd knowledge content available from such platforms has alsobeen used to leverage software development tools. The recent advances onNatural Language Processing, specifically on more powerful language models,have demonstrated ability to enhance text understanding and generation. In thiscontext, we aim at investigating the factors that can influence on theapplication of such models for understanding source code related data andproduce more interactive and intelligent assistants for software development.In this preliminary study, we particularly investigate if a how-to questionfilter and the level of context in the question may impact the results of aquestion answering transformer-based model. We suggest that fine-tuning modelswith corpus based on how-to questions can impact positively in the model andmore contextualized questions also induce more objective answers.",Liliane do Nascimento Vale,2021/3/17,2021/3/17
2103.11386v1,Characterization and Prediction of Questions without Accepted Answers on Stack Overflow,http://arxiv.org/abs/2103.11386v1,"A fast and effective approach to obtain information regarding softwaredevelopment problems is to search them to find similar solved problems or postquestions on community question answering (CQA) websites. Solving codingproblems in a short time is important, so these CQAs have a considerable impacton the software development process. However, if developers do not get theirexpected answers, the websites will not be useful, and software developmenttime will increase. Stack Overflow is the most popular CQA concerningprogramming problems. According to its rules, the only sign that shows aquestion poser has achieved the desired answer is the user's acceptance. Inthis paper, we investigate unresolved questions, without accepted answers, onStack Overflow. The number of unresolved questions is increasing. As of August2019, 47% of Stack Overflow questions were unresolved. In this study, weanalyze the effectiveness of various features, including some novel features,to resolve a question. We do not use the features that contain information notpresent at the time of asking a question, such as answers. To evaluate ourfeatures, we deploy several predictive models trained on the features of 18million questions to predict whether a question will get an accepted answer ornot. The results of this study show a significant relationship between ourproposed features and getting accepted answers. Finally, we introduce an onlinetool that predicts whether a question will get an accepted answer or not.Currently, Stack Overflow's users do not receive any feedback on theirquestions before asking them, so they could carelessly ask unclear, unreadable,or inappropriately tagged questions. By using this tool, they can modify theirquestions and tags to check the different results of the tool and deliberatelyimprove their questions to get accepted answers.",Mohamad Yazdaninia,2021/3/21,2021/3/21
1905.06991v2,MSRBot: Using Bots to Answer Questions from Software Repositories,http://arxiv.org/abs/1905.06991v2,"Software repositories contain a plethora of useful information that can beused to enhance software projects. Prior work has leveraged repository data toimprove many aspects of the software development process, such as, help extractrequirement decisions, identify potentially defective code and improvemaintenance and evolution. However, in many cases, practitioners are not ableto fully benefit from software repositories due to the fact that they needspecial expertise and dedicated effort to mine their repositories.  Therefore, in this paper, we use bots to automate and ease the process ofextracting useful information from software repositories. Particularly, we layout an approach of how bots, layered on top of software repositories, can beused to answer some of the most common software development/maintenancequestions facing developers. We perform a preliminary study with 12participants to validate the effectiveness of the bot. Our findings indicatethat using bots achieves very promising results in terms of answer accuracy,speed and usefulness. Our work has the potential to transform the MSR field bysignificantly lowering the barrier to entry, making the extraction of usefulinformation from software repositories as easy as chatting with a bot.",Ahmad Abdellatif,2019/5/16,2020/3/18
2201.10090v1,Investigating Software Testability and Test cases Effectiveness,http://arxiv.org/abs/2201.10090v1,"Software measurement is an essential management tool to develop robust andmaintainable software systems. Software metrics can be used to control theinherent complexities in software design. To guarantee that the components ofthe software are inevitably testable, the testability attribute is used, whichis a sub-characteristics of the software's maintabilility as well as qualityassurance. This study investigates the relationship between static code andtest metrics and testability and test cases effectiveness. The study answersthree formulated research questions. The results of the analysis showed thatsize and complexity metrics are suitable for predicting the testability ofobject-oriented classes.",Mamdouh Alenezi,2022/1/25,2022/1/25
2210.15846v1,Technical Q&A Site Answer Recommendation via Question Boosting,http://arxiv.org/abs/2210.15846v1,"Software developers have heavily used online question and answer platforms toseek help to solve their technical problems. However, a major problem withthese technical Q&A sites is ""answer hungriness"" i.e., a large number ofquestions remain unanswered or unresolved, and users have to wait for a longtime or painstakingly go through the provided answers with various levels ofquality. To alleviate this time-consuming problem, we propose a novel DeepAnsneural network-based approach to identify the most relevant answer among a setof answer candidates. Our approach follows a three-stage process: questionboosting, label establishment, and answer recommendation. Given a post, wefirst generate a clarifying question as a way of question boosting. Weautomatically establish the positive, neutral+, neutral- and negative trainingsamples via label establishment. When it comes to answer recommendation, wesort answer candidates by the matching scores calculated by our neuralnetwork-based model. To evaluate the performance of our proposed model, weconducted a large scale evaluation on four datasets, collected from the realworld technical Q&A sites (i.e., Ask Ubuntu, Super User, Stack Overflow Pythonand Stack Overflow Java). Our experimental results show that our approachsignificantly outperforms several state-of-the-art baselines in automaticevaluation. We also conducted a user study with 50 solved/unanswered/unresolvedquestions. The user study results demonstrate that our approach is effective insolving the answer hungry problem by recommending the most relevant answersfrom historical archives.",Zhipeng Gao,2022/10/28,2022/10/28
1906.09179v1,Challenges for Verifying and Validating Scientific Software in Computational Materials Science,http://arxiv.org/abs/1906.09179v1,"Many fields of science rely on software systems to answer different researchquestions. For valid results researchers need to trust the results scientificsoftware produces, and consequently quality assurance is of utmost importance.In this paper we are investigating the impact of quality assurance in thedomain of computational materials science (CMS). Based on our experience inthis domain we formulate challenges for validation and verification ofscientific software and their results. Furthermore, we describe directions forfuture research that can potentially help dealing with these challenges.",Thomas Vogel,2019/6/21,2019/6/21
1905.02258v1,Toward Human-Like Summaries Generated from Heterogeneous Software Artefacts,http://arxiv.org/abs/1905.02258v1,"Automatic text summarisation has drawn considerable interest in the field ofsoftware engineering. It can improve the efficiency of software developers,enhance the quality of products, and ensure timely delivery. In this paper, wepresent our initial work towards automatically generating human-likemulti-document summaries from heterogeneous software artefacts. Our analysis ofthe text properties of 545 human-written summaries from 15 software engineeringprojects will ultimately guide heuristics searches in the automatic generationof human-like summaries.",Mahfouth Alghamdi,2019/5/6,2019/5/6
2105.05981v1,Assessing Semantic Frames to Support Program Comprehension Activities,http://arxiv.org/abs/2105.05981v1,"Software developers often rely on natural language text that appears insoftware engineering artifacts to access critical information as they build andwork on software systems. For example, developers access requirements documentsto understand what to build, comments in source code to understand designdecisions, answers to questions on Q&A sites to understand APIs, and so on. Toaid software developers in accessing and using this natural languageinformation, software engineering researchers often use techniques from naturallanguage processing. In this paper, we explore whether frame semantics, ageneral linguistic approach, which has been used on requirements text, can alsohelp address problems that occur when applying lexicon analysis basedtechniques to text associated with program comprehension activities. We assessthe applicability of generic semantic frame parsing for this purpose, and basedon the results, we propose SEFrame to tailor semantic frame parsing for programcomprehension uses. We evaluate the correctness and robustness of the approachfinding that SEFrame is correct in between 73% and 74% of the cases and that itcan parse text from a variety of software artifacts used to support programcomprehension. We describe how this approach could be used to enhance existingapproaches to identify meaning on intention from software engineering texts.",Arthur Marques,2021/5/12,2021/5/12
1809.00039v1,"Total Recall, Language Processing, and Software Engineering",http://arxiv.org/abs/1809.00039v1,"A broad class of software engineering problems can be generalized as the""total recall problem"". This short paper claims that identifying and exploringtotal recall language processing problems in software engineering is animportant task with wide applicability.  To make that case, we show that by applying and adapting the state of the artactive learning and text mining, solutions of the total recall problem, canhelp solve two important software engineering tasks: (a) supporting largeliterature reviews and (b) identifying software security vulnerabilities.Furthermore, we conjecture that (c) test case prioritization and (d) staticwarning identification can also be categorized as the total recall problem.  The widespread applicability of ""total recall"" to software engineeringsuggests that there exists some underlying framework that encompasses not justnatural language processing, but a wide range of important software engineeringtasks.",Zhe Yu,2018/8/31,2018/8/31
2107.07944v2,Satisfaction and Performance of Software Developers during Enforced Work from Home in the COVID-19 Pandemic,http://arxiv.org/abs/2107.07944v2,"Following the onset of the COVID-19 pandemic and subsequent lockdowns, thedaily lives of software engineers were heavily disrupted as they were abruptlyforced to work remotely from home. To better understand and contrast typicalworking days in this new reality with work in pre-pandemic times, we conductedone exploratory (N = 192) and one confirmatory study (N = 290) with softwareengineers recruited remotely. Specifically, we build on self-determinationtheory to evaluate whether and how specific activities are associated withsoftware engineers' satisfaction and productivity. To explore the subjectdomain, we first ran a two-wave longitudinal study. We found that the timesoftware engineers spent on specific activities (e.g., coding, bugfixing,helping others) while working from home was similar to pre-pandemic times.Also, the amount of time developers spent on each activity was unrelated totheir general well-being, perceived productivity, and other variables such asbasic needs. Our confirmatory study found that activity-specific variables(e.g., how much autonomy software engineers had during coding) do predictactivity satisfaction and productivity but not by activity-independentvariables such as general resilience or a good work-life balance.Interestingly, we found that satisfaction and autonomy were significantlyhigher when software engineers were helping others and lower when they werebugfixing. Finally, we discuss implications for software engineers, management,and researchers. In particular, active company policies to support developers'need for autonomy, relatedness, and competence appear particularly effective ina WFH context.",Daniel Russo,2021/7/16,2023/1/13
2308.11396v1,Towards an Understanding of Large Language Models in Software Engineering Tasks,http://arxiv.org/abs/2308.11396v1,"Large Language Models (LLMs) have drawn widespread attention and research dueto their astounding performance in tasks such as text generation and reasoning.Derivative products, like ChatGPT, have been extensively deployed and highlysought after. Meanwhile, the evaluation and optimization of LLMs in softwareengineering tasks, such as code generation, have become a research focus.However, there is still a lack of systematic research on the application andevaluation of LLMs in the field of software engineering. Therefore, this paperis the first to comprehensively investigate and collate the research andproducts combining LLMs with software engineering, aiming to answer twoquestions: (1) What are the current integrations of LLMs with softwareengineering? (2) Can LLMs effectively handle software engineering tasks? Tofind the answers, we have collected related literature as extensively aspossible from seven mainstream databases, and selected 123 papers for analysis.We have categorized these papers in detail and reviewed the current researchstatus of LLMs from the perspective of seven major software engineering tasks,hoping this will help researchers better grasp the research trends and addressthe issues when applying LLMs. Meanwhile, we have also organized and presentedpapers with evaluation content to reveal the performance and effectiveness ofLLMs in various software engineering tasks, providing guidance for researchersand developers to optimize.",Zibin Zheng,2023/8/22,2023/8/22
2305.09608v1,Data Augmentation for Conflict and Duplicate Detection in Software Engineering Sentence Pairs,http://arxiv.org/abs/2305.09608v1,"This paper explores the use of text data augmentation techniques to enhanceconflict and duplicate detection in software engineering tasks through sentencepair classification. The study adapts generic augmentation techniques such asshuffling, back translation, and paraphrasing and proposes new dataaugmentation techniques such as Noun-Verb Substitution, target-lemmareplacement and Actor-Action Substitution for software requirement texts. Acomprehensive empirical analysis is conducted on six software text datasets toidentify conflicts and duplicates among sentence pairs. The results demonstratethat data augmentation techniques have a significant impact on the performanceof all software pair text datasets. On the other hand, in cases where thedatasets are relatively balanced, the use of augmentation techniques may resultin a negative effect on the classification performance.",Garima Malik,2023/5/16,2023/5/16
2310.00960v1,A pragmatic workflow for research software engineering in computational science,http://arxiv.org/abs/2310.00960v1,"University research groups in Computational Science and Engineering (CSE)generally lack dedicated funding and personnel for Research SoftwareEngineering (RSE), which, combined with the pressure to maximize the number ofscientific publications, shifts the focus away from sustainable researchsoftware development and reproducible results. The neglect of RSE in CSE atUniversity research groups negatively impacts the scientific output: researchdata - including research software - related to a CSE publication cannot befound, reproduced, or re-used, different ideas are not combined easily into newideas, and published methods must very often be re-implemented to beinvestigated further. This slows down CSE research significantly, resulting inconsiderable losses in time and, consequentially, public funding.  We propose a RSE workflow for Computational Science and Engineering (CSE)that addresses these challenges, that improves the quality of research outputin CSE. Our workflow applies established software engineering practices adaptedfor CSE: software testing, result visualization, and periodical cross-linkingof software with reports/publications and data, timed by milestones in thescientific publication process. The workflow introduces minimal work overhead,crucial for university research groups, and delivers modular and testedsoftware linked to publications whose results can easily be reproduced. Wedefine research software quality from a perspective of a pragmatic researcher:the ability to quickly find the publication, data, and software related to apublished research idea, quickly reproduce results, understand or re-use a CSEmethod, and finally extend the method with new research ideas.",Tomislav Mari,2023/10/2,2023/10/2
2303.10439v2,Stop Words for Processing Software Engineering Documents: Do they Matter?,http://arxiv.org/abs/2303.10439v2,"Stop words, which are considered non-predictive, are often eliminated innatural language processing tasks. However, the definition of uninformativevocabulary is vague, so most algorithms use general knowledge-based stop liststo remove stop words. There is an ongoing debate among academics about theusefulness of stop word elimination, especially in domain-specific settings. Inthis work, we investigate the usefulness of stop word removal in a softwareengineering context. To do this, we replicate and experiment with threesoftware engineering research tools from related work. Additionally, weconstruct a corpus of software engineering domain-related text from 10,000Stack Overflow questions and identify 200 domain-specific stop words usingtraditional information-theoretic methods. Our results show that the use ofdomain-specific stop words significantly improved the performance of researchtools compared to the use of a general stop list and that 17 out of 19evaluation measures showed better performance.  Online appendix: https://zenodo.org/record/7865748",Yaohou Fan,2023/3/18,2023/6/12
2312.12933v1,Automated Testing for Text-to-Image Software,http://arxiv.org/abs/2312.12933v1,"Recently, creative generative artificial intelligence software has emerged asa pivotal assistant, enabling users to generate content and seek inspirationrapidly. Text-to-image (T2I) software, being one of the most widely used amongthem, is used to synthesize images with simple text input by engaging in across-modal process. However, despite substantial advancements in severalfields, T2I software often encounters defects and erroneous, including omittingfocal entities, low image realism, and mismatched text-image information. Thecross-modal nature of T2I software makes it challenging for traditional testingmethods to detect defects. Lacking test oracles further increases thecomplexity of testing. To address this deficiency, we propose ACTesting, anAutomated Cross-modal Testing Method of Text-to-Image software, the firsttesting method designed specifically for T2I software. We construct testsamples based on entities and relationship triples following the fundamentalprinciple of maintaining consistency in the semantic information to overcomethe cross-modal matching challenges. To address the issue of testing oraclescarcity, we first design the metamorphic relation for T2I software andimplement three types of mutation operators guided by adaptability density. Inthe experiment, we conduct ACTesting on four widely-used T2I software. Theresults show that ACTesting can generate error-revealing tests, reducing thetext-image consistency by up to 20% compared with the baseline. We also conductthe ablation study that effectively showcases the efficacy of each mutationoperator, based on the proposed metamorphic relation. The results demonstratethat ACTesting can identify abnormal behaviors of T2I software effectively.",Siqi Gu,2023/12/20,2023/12/20
2305.15642v2,Learning-Based Automatic Synthesis of Software Code and Configuration,http://arxiv.org/abs/2305.15642v2,"Increasing demands in software industry and scarcity of software engineersmotivates researchers and practitioners to automate the process of softwaregeneration and configuration. Large scale automatic software generation andconfiguration is a very complex and challenging task. In this proposal, we setout to investigate this problem by breaking down automatic software generationand configuration into two different tasks. In first task, we propose tosynthesize software automatically with input output specifications. This taskis further broken down into two sub-tasks. The first sub-task is aboutsynthesizing programs with a genetic algorithm which is driven by a neuralnetwork based fitness function trained with program traces and specifications.For the second sub-task, we formulate program synthesis as a continuousoptimization problem and synthesize programs with covariance matrix adaptionevolutionary strategy (a state-of-the-art continuous optimization method).Finally, for the second task, we propose to synthesize configurations of largescale software from different input files (e.g. software manuals,configurations files, online blogs, etc.) using a sequence-to-sequence deeplearning mechanism.",Shantanu Mandal,2023/5/25,2023/5/30
2310.20277v1,Towards a Structural Equation Model of Open Source Blockchain Software Health,http://arxiv.org/abs/2310.20277v1,"The widespread use of GitHub among software developers as a communal platformfor coordinating software development has led to an abundant supply of publiclyaccessible data. Ever since the inception of Bitcoin, blockchain teams haveincorporated the concept of open source code as a fundamental principle, thusmaking the majority of blockchain-based projects' code and version control dataavailable for analysis. We define health in open source software projects to bea combination of the concepts of sustainability, robustness, and nicheoccupation. Sustainability is further divided into interest and engagement.This work uses exploratory factor analysis to identify latent constructs thatare representative of general public interest or popularity in software, andsoftware robustness within open source blockchain projects. We find thatinterest is a combination of stars, forks, and text mentions in the GitHubrepository, while a second factor for robustness is composed of a criticalityscore, time since last updated, numerical rank, and geographic distribution.Cross validation of the dataset is carried out with good support for the model.A structural model of software health is proposed such that general interestpositively influences developer engagement, which, in turn, positively predictssoftware robustness. The implications of structural equation modelling in thecontext of software engineering and next steps are discussed.",Jeff Nijsse,2023/10/31,2023/10/31
1907.11481v2,Exploranative Code Quality Documents,http://arxiv.org/abs/1907.11481v2,"Good code quality is a prerequisite for efficiently developing maintainablesoftware. In this paper, we present a novel approach to generate exploranative(explanatory and exploratory) data-driven documents that report code quality inan interactive, exploratory environment. We employ a template-based naturallanguage generation method to create textual explanations about the codequality, dependent on data from software metrics. The interactive document isenriched by different kinds of visualization, including parallel coordinatesplots and scatterplots for data exploration and graphics embedded into text. Wedevise an interaction model that allows users to explore code quality withconsistent linking between text and visualizations; through integratedexplanatory text, users are taught background knowledge about code qualityaspects. Our approach to interactive documents was developed in a design studyprocess that included software engineering and visual analytics experts.Although the solution is specific to the software engineering scenario, wediscuss how the concept could generalize to multivariate data and reportlessons learned in a broader scope.",Haris Mumtaz,2019/7/26,2019/10/9
2004.14151v1,Human-Like Summaries from Heterogeneous and Time-Windowed Software Development Artefacts,http://arxiv.org/abs/2004.14151v1,"Automatic text summarisation has drawn considerable interest in the area ofsoftware engineering. It is challenging to summarise the activities related toa software project, (1) because of the volume and heterogeneity of involvedsoftware artefacts, and (2) because it is unclear what information a developerseeks in such a multi-document summary. We present the first framework forsummarising multi-document software artefacts containing heterogeneous datawithin a given time frame. To produce human-like summaries, we employ a rangeof iterative heuristics to minimise the cosine-similarity between texts andhigh-dimensional feature vectors. A first study shows that users find theautomatically generated summaries the most useful when they are generated usingword similarity and based on the eight most relevant software artefacts.",Mahfouth Alghamdi,2020/4/28,2020/4/28
2009.07237v2,A Survey on Automated Log Analysis for Reliability Engineering,http://arxiv.org/abs/2009.07237v2,"Logs are semi-structured text generated by logging statements in softwaresource code. In recent decades, software logs have become imperative in thereliability assurance mechanism of many software systems because they are oftenthe only data available that record software runtime information. As modernsoftware is evolving into a large scale, the volume of logs has increasedrapidly. To enable effective and efficient usage of modern software logs inreliability engineering, a number of studies have been conducted on automatedlog analysis. This survey presents a detailed overview of automated loganalysis research, including how to automate and assist the writing of loggingstatements, how to compress logs, how to parse logs into structured eventtemplates, and how to employ logs to detect anomalies, predict failures, andfacilitate diagnosis. Additionally, we survey work that releases open-sourcetoolkits and datasets. Based on the discussion of the recent advances, wepresent several promising future directions toward real-world andnext-generation automated log analysis.",Shilin He,2020/9/15,2021/6/1
2005.08309v1,"The Bourgeois Gentleman, Engineering and Formal Methods",http://arxiv.org/abs/2005.08309v1,"Industrial applications involving formal methods are still exceptions to thegeneral rule. Lack of understanding, employees without proper education,difficulty to integrate existing development cycles, no explicit requirementfrom the market, etc. are explanations often heard for not being more formal.This article reports some experience about a game changer that is going toseamlessly integrate formal methods into safety critical systems engineering.",Thierry Lecomte,2020/5/13,2020/5/13
1202.3335v1,An efficient high-quality hierarchical clustering algorithm for automatic inference of software architecture from the source code of a software system,http://arxiv.org/abs/1202.3335v1,"It is a high-quality algorithm for hierarchical clustering of large softwaresource code. This effectively allows to break the complexity of tens ofmillions lines of source code, so that a human software engineer can comprehenda software system at high level by means of looking at its architecturaldiagram that is reconstructed automatically from the source code of thesoftware system. The architectural diagram shows a tree of subsystems havingOOP classes in its leaves (in the other words, a nested softwaredecomposition). The tool reconstructs the missing(inconsistent/incomplete/inexistent) architectural documentation for a softwaresystem from its source code. This facilitates software maintenance: changerequests can be performed substantially faster. Simply speaking, this uniquetool allows to lift the comprehensible grain of object-oriented softwaresystems from OOP class-level to subsystem-level. It is estimated that acommercial tool, developed on the basis of this work, will reduce softwaremaintenance expenses 10 times on the current needs, and will allow to implementnext-generation software systems which are currently too complex to be withinthe range of human comprehension, therefore can't yet be designed orimplemented. Implemented prototype in Open Source:http://sourceforge.net/p/insoar/code-0/1/tree/",Sarge Rogatch,2012/2/15,2012/2/15
1508.00032v1,A Neuro-Fuzzy Model with SEER-SEM for Software Effort Estimation,http://arxiv.org/abs/1508.00032v1,"Software effort estimation is a critical part of software engineering.Although many techniques and algorithmic models have been developed andimplemented by practitioners, accurate software effort prediction is still achallenging endeavor. In order to address this issue, a novel soft computingframework was previously developed. Our study utilizes this novel framework todevelop an approach combining the neuro-fuzzy technique with the SystemEvaluation and Estimation of Resource - Software Estimation Model (SEER-SEM).Moreover, our study assesses the performance of the proposed model by designingand conducting evaluation with published industrial project data. Afteranalyzing the performance of our model in comparison to the SEER-SEM effortestimation model alone, the proposed model demonstrates the ability ofimproving the estimation accuracy, especially in its ability to reduce thelarge Mean Relative Error (MRE). Furthermore, the results of this researchindicate that the general neuro-fuzzy framework can work with variousalgorithmic models for improving the performance of software effort estimation.",Wei Lin Du,2015/7/31,2015/7/31
2312.05562v1,Chain-of-Thought in Neural Code Generation: From and For Lightweight Language Models,http://arxiv.org/abs/2312.05562v1,"Large Language Models (LLMs) have demonstrated remarkable potential in codegeneration. The integration of Chain of Thought (CoT) reasoning can furtherboost their performance. However, current CoT methods often require manualwriting or LLMs with over 100 billion parameters to generate, impeding theirapplicability in resource-constrained scenarios. In this study, we investigatelightweight Language Models (lLMs), which are defined to have fewer than 10billion parameters. Empirically, we find that most lLMs cannot generatehigh-quality CoTs when prompted by the few-shot method, but can take advantageof high-quality CoTs generated elsewhere to improve their performance in codegeneration. Based on these findings, we design a novel approach COTTON whichcan leverage lLMs to automatically generate CoTs for code generation. Wesynthesize new datasets and conduct extensive experiments on variousbenchmarks. The results show that the CoTs generated by COTTON outperform thebaselines in terms of automated and human evaluation metrics. In particular,the CoTs generated by COTTON boost various lLMs to achieve higher performancegains than those generated by LLMs such as ChatGLM (130B), and are competitivewith those generated by gpt-3.5-turbo (175B). Our study also showcases thepotential of lLMs in software engineering applications.",Guang Yang,2023/12/9,2023/12/9
1803.09427v1,Design Assurance Evaluation of Microcontrollers for safety critical Avionics,http://arxiv.org/abs/1803.09427v1,"Dealing with Commercial off-the-shelf (COTS) com- ponents is a daily businessfor avionic system manufacturers. They are necessary ingredients for hardwaredesigns, but are not built in accordance with the avionics consensus standardDO- 254 for Airborne Electronic Hardware (AEH) design. Especially for complexCOTS hardware components used in safety critical AEH, like MicrocontrollerUnits (MCUs), additional assurance activities have to be performed. All of themtogether shall form a convincing confident, that the hardware is safe in itsintended operation environment. The focus of DO-254 is one approach calledDesign Assurance (DA). Its aim is to reduce design errors by adherence ofprescribed process objectives for the entire design life cycle. The effort forcertain COTS assurance activities could be reduced if it is possible todemonstrate, that the COTS design process is based on similar effective designprocess guide- lines to minimize desgin errors. In the last years,semiconductor manufacturers released safety MCUs in compliance to the ISO 26262standard, dedicated for the development of functional safe automotive systems.These products are COTS components in the sense of avionics, but they are alsodeveloped according to a process that focuses on reduction of design errors. Inthis paper an evaluation is performed to figure out if the ISO 26262 prescribesa similar DA approach as the DO-254, in order to reduce the COTS assuranceeffort for coming avionic systems.",Andreas Schwierz,2018/3/26,2018/3/26
1608.06133v1,A Combined Dependability and Security Approach for Third Party Software in Space Systems,http://arxiv.org/abs/1608.06133v1,"Software components for on-board architectures in the space domain areincreasingly reliant on Commercial Off-The-Shelf (COTS), Open Source (OSS) orother third party software products. However, these software components oftenhave not been built with mission critical requirements in mind. Developmentproject teams incorporating these products have limited knowledge of or controlover the processes applied during the design, implementation, testing andmaintenance of selected COTS/OSS software products. These constraints generateuncertainty of potential software induced failures. Moreover, the lack ofinformation regarding security vulnerabilities increases the risks of theirusage, since their exploitation might lead to undesired behaviour of thesoftware and therefore to a system failure. The purpose of this paper is topresent a combined approach that takes into account reliability and securityenhancements for third party software, based on Time-Space Partitioning andMultiple Levels of Security.",David Escorial Rico,2016/8/22,2016/8/22
1202.2731v1,Risk Assessment Techniques and Survey Method for COTS Components,http://arxiv.org/abs/1202.2731v1,"The Rational Unified Process a software engineering process is gainingpopularity nowadays. RUP delivers best software practices for componentsoftware Development life cycle It supports component based softwaredevelopment. Risk is involved in every component development phase .neglectingthose risks sometimes hampers the software growth and leads to negativeoutcome. In Order to provide appropriate security and protection levels,identifying various risks is very vital. Therefore Risk identification plays avery crucial role in the component based software development This reportaddresses incorporation of component based software development cycle into RUPphases, assess several category of risk encountered in the component basedsoftware. It also entails a survey method to identify the risk factor andevaluating the overall severity of the component software development in termsof the risk. Formula for determining risk prevention cost and finding the riskprobability is also been included. The overall goal of the paper is to providea theoretical foundation that facilitates a good understanding of risk inrelation to componentbased system development",Rashmi Gupta,2012/2/13,2012/2/13
2103.03649v1,Fast Outage Analysis of Large-scale Production Clouds with Service Correlation Mining,http://arxiv.org/abs/2103.03649v1,"Cloud-based services are surging into popularity in recent years. However,outages, i.e., severe incidents that always impact multiple services, candramatically affect user experience and incur severe economic losses. Locatingthe root-cause service, i.e., the service that contains the root cause of theoutage, is a crucial step to mitigate the impact of the outage. In currentindustrial practice, this is generally performed in a bootstrap manner andlargely depends on human efforts: the service that directly causes the outageis identified first, and the suspected root cause is traced back manually fromservice to service during diagnosis until the actual root cause is found.Unfortunately, production cloud systems typically contain a large number ofinterdependent services. Such a manual root cause analysis is oftentime-consuming and labor-intensive. In this work, we propose COT, the firstoutage triage approach that considers the global view of service correlations.COT mines the correlations among services from outage diagnosis data. Afterlearning from historical outages, COT can infer the root cause of emerging onesaccurately. We implement COT and evaluate it on a real-world dataset containingone year of data collected from Microsoft Azure, one of the representativecloud computing platforms in the world. Our experimental results show that COTcan reach a triage accuracy of 82.1%~83.5%, which outperforms thestate-of-the-art triage approach by 28.0%~29.7%.",Yaohui Wang,2021/2/26,2021/2/26
2306.03971v1,A Review Of Progress for Component Based Software Cost Estimation From 1965 to 2023,http://arxiv.org/abs/2306.03971v1,"Component Based Software Engineering (CBSE) is used to develop software fromCommercial Off the Shelf Components (COTs) with minimum cost and time.Component Based Software Cost Estimation (CBSCE) is an importantpre-development activity for the successful planning and cost estimation ofComponents-Based Software Development (CBSD) that saves cost and time. Manyresearchers are putting their efforts to propose and then develop a CBSCEmodel. This motivates to review research work and history of CBSCE from 1965 to2023. The scope of this research also, to some extent, includes auxiliary thereview of all the research work done in the areas such as CBSE, CBSCE,Component Based Software Metrics, COTs, component based process models to coverall the areas of CBSD under CBSE either to answer or to provide pointers forthe answers to the questions of this area easily. Internet based searchmethodology has been used to review the available and published literature.This paper may also classify available literature of this area into its subareas such as component selection, quality with chronological contribution ofthe researchers and pictorial presentation of its history. Thus this researchpaper may serve as a common source of information for the concernedresearchers.",Muhammad Nadeem,2023/6/6,2023/6/6
1702.00125v1,"A Software Reuse Approach and Its Effect On Software Quality, An Empirical Study for The Software Industry",http://arxiv.org/abs/1702.00125v1,"Software reusability has become much interesting because of increased qualityand reduce cost. A good process of software reuse leads to enhance thereliability, productivity, quality and the reduction of time and cost. Currentreuse techniques focuses on the reuse of software artifact which grounded onanticipated functionality whereas, the non-functional (quality) aspect are alsoimportant. So, Software reusability used here to expand quality andproductivity of software. It improves overall quality of software in minimumenergy and time. Main objective of this study was to present a reuse approachthat discovered that how software reuse improves the quality in SoftwareIndustry. The V&V technique used for this purpose which is part of softwarequality management process, it checks the quality and correctness during thesoftware life cycle. A survey study conducted as QUESTIONAIR to find the impactof reuse approach on quality attributes which are requirement specification anddesign specification. Other quality enhancement techniques like ad hoc, CBSE,MBSE, Product line, COTS reuse checked on existing software industry. Resultsanalyzed with the help of MATLAB tool as it provides effective data management,wide range of options, better output organization, to check weather qualityenhancement technique is affected due to reusability and how quality willimprove.",Ahmed Mateen,2017/2/1,2017/2/1
2306.00757v1,AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code,http://arxiv.org/abs/2306.00757v1,"Control Flow Graphs (CFGs) are essential for visualizing, understanding andanalyzing program behavior. For statically-typed programming language likeJava, developers obtain CFGs by using bytecode-based methods for compilablecode and Abstract Syntax Tree (AST)-based methods for partially uncompilablecode. However, explicit syntax errors during AST construction and implicitsemantic errors caused by bad coding practices can lead to behavioral loss anddeviation of CFGs.To address the issue, we propose a novel approach thatleverages the error-tolerant and understanding ability of pre-trained LargeLanguage Models (LLMs) to generate CFGs. Our approach involves a Chain ofThought (CoT) with four steps: structure hierarchy extraction, nested codeblock extraction, CFG generation of nested code blocks, and fusion of allnested code blocks' CFGs. To address the limitations of the original CoT'ssingle-prompt approach (i.e., completing all steps in a single generativepass), which can result in an ``epic'' prompt with hard-to-control behavior anderror accumulation, we break down the CoT into an AI chain with explicitsub-steps. Each sub-step corresponds to a separate AI-unit, with an effectiveprompt assigned to each unit for interacting with LLMs to accomplish a specificpurpose.Our experiments confirmed that our method outperforms existing CFGtools in terms of node and edge coverage, especially for incomplete orerroneous code. We also conducted an ablation experiment and confirmed theeffectiveness of AI chain design principles: Hierarchical Task Breakdown, UnitComposition, and Mix of AI Units and Non-AI Units.Our work opens up newpossibilities for building foundational software engineering tools based onLLMs, as opposed to traditional program analysis methods.",Qing Huang,2023/6/1,2023/6/1
2306.00108v2,"Better patching using LLM prompting, via Self-Consistency",http://arxiv.org/abs/2306.00108v2,"Large Language models (LLMs) can be induced to solve non-trivial problemswith ""few-shot"" prompts including illustrative problem-solution examples. Nowif the few-shots also include ""chain of thought"" (CoT) explanations, which areof the form problem-explanation-solution, LLMs will generate a ""explained""solution, and perform even better. Recently an exciting, substantially bettertechnique, self-consistency [1] (S-C) has emerged, based on the intuition thatthere are many plausible explanations for the right solution; when the LLM issampled repeatedly to generate a pool of explanation-solution pairs, for agiven problem, the most frequently occurring solutions in the pool (ignoringthe explanations) tend to be even more likely to be correct! Unfortunately, theuse of this highly-performant S-C (or even CoT) approach in softwareengineering settings is hampered by the lack of explanations; most softwaredatasets lack explanations. In this paper, we describe an application of theS-C approach to program repair, using the commit log on the fix as theexplanation, only in the illustrative few-shots. We achieve state-of-the artresults, beating previous approaches to prompting-based program repair, on theMODIT dataset; we also find evidence suggesting that the correct commitmessages are helping the LLM learn to produce better patches.",Toufique Ahmed,2023/5/31,2023/8/16
2309.16120v1,Test-Case-Driven Programming Understanding in Large Language Models for Better Code Generation,http://arxiv.org/abs/2309.16120v1,"Code generation is to automatically generate source code conforming to agiven programming specification, which has received extensive attentionespecially with the development of large language models (LLMs). Due to theinherent difficulty of code generation, the code generated by LLMs may be alsonot aligned with the specification. To improve the perfor mance of LLMs in codegeneration, some Chain of Thought (CoT) techniques have been proposed to guideLLMs for programming understanding before code generation. However, they arestill hard to figure out complicated programming logic according to the(concise) specification, leadingto unsatisfactory code generation performance.In this work, we propose the first test-case-driven CoT technique, called TCoT,to further enhance the ability of LLMs in code generation. It understands theprogramming specification from the novel perspective of test cases, which isaligned with human practice by using examples to understand complicatedproblems. Due to the existence of the expected output specified in a test case,TCoT can instantly check the correctness of the programming understanding andthen refine it to be as correct as possible before code generation. In thisway, it is more likely to generate correct code. Our evaluation on 6 datasetsand 14 baselines demonstrates the effectiveness of TCoT. For example, TCoTimproves ChatGPT by 13.93%~69.44% in terms of Pass@1 (measuring the ratio ofprogramming problems for which the generated code passes all test cases), andoutperforms the existing CoT technique with the improvement of 12.14%~53.72% interms of Pass@1.",Zhao Tian,2023/9/28,2023/9/28
2010.02208v1,Robust Software Development for University-Built Satellites,http://arxiv.org/abs/2010.02208v1,"Satellites and other complex systems now become more and more softwaredependent. Even nanosatellites have complexity that can be compared toscientific instruments launched to Mars. COTS components and subsystems may nowbe purchased to support payload development. On the contrary, the software hasto be adapted to the new payload and, consequently, hardware architectureselected for the satellite. There is not a rigorous and robust way to designsoftware for CubeSats or small satellites yet. In this paper, we will brieflyreview some existing systems and present our approach, which based onBehaviour-Interaction-Priority (BIP) framework. We will describe our experiencein implementing fight software simulation and testing in the Swiss CubETHCubeSat project. We will conclude with lessons learned and future utilizationof BIP for hardware testing and simulation.",Anton B. Ivanov,2020/10/4,2020/10/4
2401.03065v1,"CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution",http://arxiv.org/abs/2401.03065v1,"We present CRUXEval (Code Reasoning, Understanding, and eXecutionEvaluation), a benchmark consisting of 800 Python functions (3-13 lines). Eachfunction comes with an input-output pair, leading to two natural tasks: inputprediction and output prediction. First, we propose a generic recipe forgenerating our execution benchmark which can be used to create future variationof the benchmark. Second, we evaluate twenty code models on our benchmark anddiscover that many recent high-scoring models on HumanEval do not show the sameimprovements on our benchmark. Third, we show that simple CoT and fine-tuningschemes can improve performance on our benchmark but remain far from solvingit. The best setup, GPT-4 with chain of thought (CoT), achieves a pass@1 of 75%and 81% on input and output prediction, respectively. In contrast, Code Llama34B achieves a pass@1 of 50% and 46% on input and output prediction,highlighting the gap between open and closed source models. As no model isclose to acing CRUXEval, we provide examples of consistent GPT-4 failures onsimple programs as a lens into its code reasoning capabilities and areas forimprovement.",Alex Gu,2024/1/5,2024/1/5
1412.0527v1,Automatic adaptor synthesis for protocol transformation,http://arxiv.org/abs/1412.0527v1,"Adaptation of software components is an important issue in Component BasedSoftware Engineering (CBSE). Building a system from reusable orCommercial-Off-The-Shelf (COTS) components introduces a set of issues, mainlyrelated to compatibility and communication aspects. Components may haveincompatible interaction behavior. Moreover it might be necessary to enhancethe current communication protocol to introduce more sophisticated interactionsamong components. We address these problems enhancing our architecturalapproach which allows for detection and recovery of integration mismatches bysynthesizing a suitable coordinator. Starting from the specification of thesystem to be assembled and from the specification of the needed protocolenhancements, our framework automatically derives, in a compositional way, theglue code for the set of components. The synthesized glue code avoidsinteraction mismatches and provides a protocol-enhanced version of the composedsystem.",Marco Autili,2014/12/1,2014/12/1
1804.05656v1,Assurance Benefits of ISO 26262 compliant Microcontrollers for safety-critical Avionics,http://arxiv.org/abs/1804.05656v1,The usage of complex Microcontroller Units (MCUs) in avionic systemsconstitutes a challenge in assuring their safety. They are not developedaccording to the development requirements accepted by the aerospace industry.These Commercial off-the-shelf (COTS) hardware components usually target otherdomains like the telecommunication branch. In the last years MCUs developed incompliance to the ISO 26262 have been released on the market for safety-relatedautomotive applications. The avionic assurance process could profit from thesesafety MCUs. In this paper we present evaluation results based on the currentassurance practice that demonstrates expected assurance activities benefit fromISO 26262 compliant MCUs.,Andreas Schwierz,2018/3/26,2018/3/26
2011.14914v1,Impacts of the Space Technology Evolution in the V\&V of Embedded Software-Intensive Systems,http://arxiv.org/abs/2011.14914v1,"CubeSat-based nanosatellites are composed of COTS components and rely on itsstructure and standardized interfaces. A challenge in the nanosatellitescontext is to adapt the V\&V (Verification and Validation) process to answer tothe increase importance of the embedded software, to reduce the artefacts to bedelivered aiming at cutting cost and time and still complying withinternational standards. This work presents an analysis of the strategy adoptedin a real nanosatellite for the development of the OBDH software embedded inNanosatC-BR2 mission. The goal is to discuss the impact that thestandardization of the structure and interfaces of the CubeSat impose on theV\&V process of the SiS and to highlight the challenges of ``New Space Age``for the use of existing V\&V techniques and methods.",Carlos Leandro Gomes Batista,2020/11/26,2020/11/26
1504.07504v2,Synthesis of correct adaptors for protocol enhancement in component-based systems,http://arxiv.org/abs/1504.07504v2,"Adaptation of software components is an important issue in Component BasedSoftware Engineering (CBSE). Building a system from reusable orCommercial-Off-The-Shelf (COTS) components introduces a set of problems, mainlyrelated to compatibility and communication aspects. On one hand, components mayhave incompatible interaction behavior. This might require to restrict thesystem's behavior to a subset of safe behaviors. On the other hand, it might benecessary to enhance the current communication protocol. This might require toaugment the system's behavior to introduce more sophisticated interactionsamong components. We address these problems by enhancing our architecturalapproach which allows for detection and recovery of incompatible interactionsby synthesizing a suitable coordinator. Taking into account the specificationof the system to be assembled and the specification of the protocolenhancements, our tool (called SYNTHESIS) automatically derives, in acompositional way, the glue code for the set of components. The synthesizedglue code implements a software coordinator which avoids incompatibleinteractions and provides a protocol-enhanced version of the composed system.By using an assume-guarantee technique, we are able to check, in acompositional way, if the protocol enhancement is consistent with respect tothe restrictions applied to assure the specified safe behaviors.",Marco Autili,2015/4/28,2015/5/4
2311.03033v1,Beyond Words: A Mathematical Framework for Interpreting Large Language Models,http://arxiv.org/abs/2311.03033v1,"Large language models (LLMs) are powerful AI tools that can generate andcomprehend natural language text and other complex information. However, thefield lacks a mathematical framework to systematically describe, compare andimprove LLMs. We propose Hex a framework that clarifies key terms and conceptsin LLM research, such as hallucinations, alignment, self-verification andchain-of-thought reasoning. The Hex framework offers a precise and consistentway to characterize LLMs, identify their strengths and weaknesses, andintegrate new findings. Using Hex, we differentiate chain-of-thought reasoningfrom chain-of-thought prompting and establish the conditions under which theyare equivalent. This distinction clarifies the basic assumptions behindchain-of-thought prompting and its implications for methods that use it, suchas self-verification and prompt programming.  Our goal is to provide a formal framework for LLMs that can help bothresearchers and practitioners explore new possibilities for generative AI. Wedo not claim to have a definitive solution, but rather a tool for opening upnew research avenues. We argue that our formal definitions and results arecrucial for advancing the discussion on how to build generative AI systems thatare safe, reliable, fair and robust, especially in domains like healthcare andsoftware engineering.",Javier Gonzlez,2023/11/6,2023/11/6
2312.14262v1,Exploring the intersection of Generative AI and Software Development,http://arxiv.org/abs/2312.14262v1,"In the ever-evolving landscape of Artificial Intelligence (AI), the synergybetween generative AI and Software Engineering emerges as a transformativefrontier. This whitepaper delves into the unexplored realm, elucidating howgenerative AI techniques can revolutionize software development. Spanning fromproject management to support and updates, we meticulously map the demands ofeach development stage and unveil the potential of generative AI in addressingthem. Techniques such as zero-shot prompting, self-consistency, and multimodalchain-of-thought are explored, showcasing their unique capabilities inenhancing generative AI models. The significance of vector embeddings, context,plugins, tools, and code assistants is underscored, emphasizing their role incapturing semantic information and amplifying generative AI capabilities.Looking ahead, this intersection promises to elevate productivity, improve codequality, and streamline the software development process. This whitepaperserves as a guide for stakeholders, urging discussions and experiments in theapplication of generative AI in Software Engineering, fostering innovation andcollaboration for a qualitative leap in the efficiency and effectiveness ofsoftware development.",Filipe Calegario,2023/12/21,2023/12/21
1810.01904v1,RPSE: Reification as Paradigm of Software Engineering,http://arxiv.org/abs/1810.01904v1,"The paper introduces RPSE, Reification as a Paradigm of Software Engineering,and enumerates the most important theoretical and practical problems of thedevelopment and application of this paradigm. Main thesis: Software engineeringis the reification (materialization of ideas) via the transformation of mentalmodels into code executed on computers . Within the proposed paradigm: 1.Allbasic processes of software engineering are concrete variants (implementations)of the process of constructing chains of mental and material models I1,I2,..In, M1, M2, ..Mm. The last most specific model in this chain is, as arule, program code. 2.The essence of software engineering is the constructionof such chains. 3.All main issues of optimizing the development, its cost, andquality can be reduced to the optimization of construction of the correspondingchain of models.",Viktor Sirotin,2018/10/3,2018/10/3
2312.01639v1,On the Effectiveness of Large Language Models in Domain-Specific Code Generation,http://arxiv.org/abs/2312.01639v1,"Large language models (LLMs) such as ChatGPT have shown remarkablecapabilities in code generation. Despite their great success, theireffectiveness within particular domains (e.g., web development) necessitatesfurther evaluation. In this study, we conduct an empirical study ofdomain-specific code generation with LLMs. We demonstrate that LLMs exhibitsub-optimal performance in generating domain-specific code, due to theirlimited proficiency in utilizing domain-specific libraries. We further observethat incorporating API knowledge as prompts can empower LLMs to generate moreprofessional code. Based on these findings, we further investigate how toefficiently incorporate API knowledge into the code generation process. Weexperiment with three strategies for incorporating domain knowledge, namely,external knowledge inquirer, chain-of-thought prompting, and chain-of-thoughtfine-tuning. We refer to these strategies as a new code generation approachcalled DomCoder. Experimental results show that all strategies of DomCoder leadto improvement in the effectiveness of domain-specific code generation undercertain settings. The results also show that there is still ample room forfurther improvement, based on which we suggest possible future works.",Meng Chen,2023/12/4,2023/12/4
2308.01191v3,Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey,http://arxiv.org/abs/2308.01191v3,"Code cloning, the duplication of code fragments, is common in softwaredevelopment. While some reuse aids productivity, excessive cloning hurtsmaintainability and introduces bugs. Hence, automatic code clone detection isvital. Meanwhile, large language models (LLMs) possess diverse code-relatedknowledge, making them versatile for various software engineering challenges.However, LLMs' performance in code clone detection is unclear and needs morestudy for accurate assessment. In this paper, we provide the firstcomprehensive evaluation of LLMs for clone detection, covering different clonetypes, languages, and prompts. We find advanced LLMs excel in detecting complexsemantic clones, surpassing existing methods. Adding intermediate reasoningsteps via chain-of-thought prompts noticeably enhances performance.Additionally, representing code as vector embeddings, especially with textencoders, effectively aids clone detection.Lastly, the ability of LLMs todetect code clones differs among various programming languages. Our studysuggests that LLMs have potential for clone detection due to their languagecapabilities, offering insights for developing robust LLM-based methods toenhance software engineering.",Shihan Dou,2023/8/2,2023/8/6
1802.06319v1,Consensus in Software Engineering: A Cognitive Mapping Study,http://arxiv.org/abs/1802.06319v1,"Background: Philosophers of science including Collins, Feyerabend, Kuhn andLatour have all emphasized the importance of consensus within scientificcommunities of practice. Consensus is important for maintaining legitimacy withoutsiders, orchestrating future research, developing educational curricula andagreeing industry standards. Low consensus contrastingly undermines a field'sreputation and hinders peer review. Aim: This paper aims to investigate thedegree of consensus within the software engineering academic communityconcerning members' implicit theories of software engineering. Method: Aconvenience sample of 60 software engineering researchers produced diagramsdescribing their personal understanding of causal relationships between coresoftware engineering constructs. The diagrams were then analyzed for patternsand clusters. Results: At least three schools of thought may be forming;however, their interpretation is unclear since they do not correspond to knowndivisions within the community (e.g. Agile vs. Plan-Driven methods).Furthermore, over one third of participants do not belong to any cluster.Conclusion: Although low consensus is common in social sciences, the rapid paceof innovation observed in software engineering suggests that high consensus isachievable given renewed commitment to empiricism and evidence-based practice.",Pontus Johnson,2018/2/18,2018/2/18
2210.05813v2,Software Supply Chain Attribute Integrity (SCAI),http://arxiv.org/abs/2210.05813v2,"The Software Supply Chain Attribute Integrity, or SCAI (pronounced ""sky""),specification proposes a data format for capturing functional attribute andintegrity information about software artifacts and their supply chain. SCAIdata can be associated with executable binaries, statically- ordynamically-linked libraries, software packages, container images, softwaretoolchains, and compute environments.  As such, SCAI is intended to be implemented as part of an existing softwaresupply chain attestation framework by software development tools or services(e.g., builders, CI/CD pipelines, software analysis tools) seeking to capturemore granular information about the attributes and behavior of the softwareartifacts they produce. That is, SCAI assumes that implementers will haveappropriate processes and tooling in place for capturing other types ofsoftware supply chain metadata, which can be extended to add support for SCAI.",Marcela S. Melara,2022/10/11,2023/5/26
1807.04072v2,Building a Sustainable Structure for Research Software Engineering Activities,http://arxiv.org/abs/1807.04072v2,"The profile of research software engineering has been greatly enhanced bydevelopments at institutions around the world to form groups and communitiesthat can support effective, sustainable development of research software. Weobserve, however, that there is still a long way to go to build a clearunderstanding about what approaches provide the best support for researchsoftware developers in different contexts, and how such understanding can beused to suggest more formal structures, models or frameworks that can help tofurther support the growth of research software engineering. This paper setsout some preliminary thoughts and proposes an initial high-level model based ondiscussions between the authors around the concept of a set of pillarsrepresenting key activities and processes that form the core structure of asuccessful research software engineering offering.",Jeremy Cohen,2018/7/11,2019/8/5
2312.05356v1,Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs,http://arxiv.org/abs/2312.05356v1,"Large Language Models are successfully adopted in software engineering,especially in code generation. Updating these models with new knowledge is veryexpensive, and is often required to fully realize their value. In this paper,we propose a novel and effective model editing approach, \textsc{MENT}, topatch LLMs in coding tasks. Based on the mechanism of generative LLMs,\textsc{MENT} enables model editing in next-token predictions, and furthersupports common coding tasks. \textsc{MENT} is effective, efficient, andreliable. It can correct a neural model by patching 1 or 2 neurons. As thepioneer work on neuron-level model editing of generative models, we formalizethe editing process and introduce the involved concepts. Besides, we alsointroduce new measures to evaluate its generalization ability, and build abenchmark for further study. Our approach is evaluated on three coding tasks,including API-seq recommendation, line-level code generation, andpseudocode-to-code transaction. It outperforms the state-of-the-art by asignificant margin on both effectiveness and efficiency measures. In addition,we demonstrate the usages of \textsc{MENT} for LLM reasoning in softwareengineering. By editing the LLM knowledge with \textsc{MENT}, the directly orindirectly dependent behaviors in the chain-of-thought change accordingly andautomatically.",Jian Gu,2023/12/8,2023/12/8
2305.14157v1,"Software supply chain: review of attacks, risk assessment strategies and security controls",http://arxiv.org/abs/2305.14157v1,"The software product is a source of cyber-attacks that target organizationsby using their software supply chain as a distribution vector. As the relianceof software projects on open-source or proprietary modules is increasingdrastically, SSC is becoming more and more critical and, therefore, hasattracted the interest of cyber attackers. While existing studies primarilyfocus on software supply chain attacks' prevention and detection methods, thereis a need for a broad overview of attacks and comprehensive risk assessment forsoftware supply chain security. This study conducts a systematic literaturereview to fill this gap. We analyze the most common software supply chainattacks by providing the latest trend of analyzed attacks, and we identify thesecurity risks for open-source and third-party software supply chains.Furthermore, this study introduces unique security controls to mitigateanalyzed cyber-attacks and risks by linking them with real-life securityincidence and attacks.",Betul Gokkaya,2023/5/23,2023/5/23
2309.14345v2,Bias Testing and Mitigation in LLM-based Code Generation,http://arxiv.org/abs/2309.14345v2,"Utilizing state-of-the-art Large Language Models (LLMs), automatic codegeneration models play a pivotal role in enhancing the productivity of softwaredevelopment procedures. As the adoption of LLMs becomes more widespread insoftware coding ecosystems, a pressing issue has emerged: does the generatedcode contain social bias and unfairness, such as those related to age, gender,and race? This issue concerns the integrity, fairness, and ethical foundationof software applications that depend on the code generated by these models, yetis under-explored in the literature. This paper presents a novel bias testingframework that is specifically designed for code generation tasks. Based onthis framework, we conduct an extensive evaluation of the bias in codegenerated by five state-of-the-art LLMs. Our findings reveal that 20.29% to44.93% code functions generated by the models under study are biased whenhandling bias sensitive tasks (i.e., tasks that involve sensitive attributessuch as age and gender). This indicates that the existing LLMs can be unfair incode generation, posing risks of unintended and harmful software behaviors. Tomitigate bias for code generation models, we evaluate five bias mitigationprompt strategies, i.e., utilizing bias testing results to refine the code(zero-shot), one-, few-shot, and two Chain-of-Thought (CoT) prompts. Ourevaluation results illustrate that these strategies are all effective inmitigating bias. Overall, one-shot and few-shot learning are the two mosteffective. For GPT-4, 80% to 90% code bias can be removed with one-shotlearning.",Dong Huang,2023/9/3,2024/1/9
1403.3928v1,A Bootstrap Theory: the SEMAT Kernel Itself as Runnable Software,http://arxiv.org/abs/1403.3928v1,"The SEMAT kernel is a thoroughly thought generic framework for SoftwareEngineering system development in practice. But one should be able to test itscharacteristics by means of a no less generic theory matching the SEMAT kernel.This paper claims that such a matching theory is attainable and describes itsmain principles. The conceptual starting point is the robustness of the Kernelalphas to variations in the nature of the software system, viz. to softwareautomation, distribution and self-evolution. From these and from observedKernel properties follows the proposed bootstrap principle: a software systemtheory should itself be a runnable software. Thus, the kernel alphas can beviewed as a top-level ontology, indeed the Essence of Software Engineering.Among the interesting consequences of this bootstrap theory, the observablesystem characteristics can now be formally tested. For instance, one can checkthe system completeness, viz. that software system modules fulfill each one ofthe system requirements.",Iaakov Exman,2014/3/16,2014/3/16
1309.1677v1,Toward a Research Software Security Maturity Model,http://arxiv.org/abs/1309.1677v1,"In its Vision and Strategy for Software for Science, Engineering, andEducation the NSF states that it will invest in activities that: ""Recognizethat software strategies must include the secure and reliable deployment andoperation of services, for example by campuses or national facilities orindustry, where identity, authentication, authorization and assurance arecrucial operational capabilities."" and ""Result in high-quality, usable, secure,vulnerability-free, sustainable, robust, well-tested, andmaintainable/evolvable software; and which promotes the sustainability of solidand useful on-going investments.""  Such statements evidence that security should indeed be a first-classconsideration of the software ecosystem. In this position paper, we share somethoughts related to research software security. Our thoughts are based on theobservation that security is not a binary, all-or-nothing attribute, but arange of practices and requirements depending on how the software is expectedto be deployed and used. We propose that the community leverage the concept ofa maturity model, and work to agree on a research software security maturitymodel. This model would categorize different sets of security needs of thedeployment community, and provide software developers a roadmap for advancingthe security maturity of their software. The intent of this paper is not toexpress such a comprehensive maturity model, but instead to start aconversation and set some initial requirements.",Randy Heiland,2013/9/6,2013/9/6
2305.08360v1,Improving ChatGPT Prompt for Code Generation,http://arxiv.org/abs/2305.08360v1,"Automated code generation can be a powerful technique for softwaredevelopment, significantly reducing developers' efforts and time required tocreate new code by generating it automatically based on requirements. Recently,OpenAI's language model ChatGPT has emerged as a powerful tool for generatinghuman-like responses to a wide range of textual inputs (i.e., prompts),including those related to code generation. However, the effectiveness ofChatGPT for code generation is not well understood, and the generationperformance could be heavily influenced by the choice of prompt. To answerthese questions, we conducted experiments using the CodeXGlue dataset toevaluate ChatGPT's capabilities for two code generation tasks, includingtext-to-code and code-to-code generation. We designed prompts by leveraging thechain-of-thought strategy with multi-step optimizations. Our results showedthat by carefully designing prompts to guide ChatGPT, the generationperformance can be improved substantially. We also analyzed the factors thatinfluenced the prompt design and provided insights that could guide futureresearch.",Chao Liu,2023/5/15,2023/5/15
2209.02930v2,Reflections on Software Failure Analysis,http://arxiv.org/abs/2209.02930v2,"Failure studies are important in revealing the root causes, behaviors, andlife cycle of defects in software systems. These studies either focus onunderstanding the characteristics of defects in specific classes of systems orthe characteristics of a specific type of defect in the systems it manifestsin. Failure studies have influenced various software engineering researchdirections, especially in the area of software evolution, defect detection, andprogram repair.  In this paper, we reflect on the conduct of failure studies in softwareengineering. We reviewed a sample of 52 failure study papers. We identifiedseveral recurring problems in these studies, some of which hinder the abilityof the engineering community to trust or replicate the results. Based on ourfindings, we suggest future research directions, including identifying andanalyzing failure causal chains, standardizing the conduct of failure studies,and tool support for faster defect analysis.",Paschal C. Amusuo,2022/9/7,2022/9/22
2302.13229v1,Artificial Intelligence Impact On The Labour Force -- Searching For The Analytical Skills Of The Future Software Engineers,http://arxiv.org/abs/2302.13229v1,"This systematic literature review aims to investigate the impact ofartificial intelligence (AI) on the labour force in software engineering, witha particular focus on the skills needed for future software engineers, theimpact of AI on the demand for software engineering skills, and the future ofwork for software engineers. The review identified 42 relevant publicationsthrough a comprehensive search strategy and analysed their findings. Theresults indicate that future software engineers will need to be competent inprogramming and have soft skills such as problem-solving and interpersonalcommunication. AI will have a significant impact on the software engineeringworkforce, with the potential to automate many jobs currently done by softwareengineers. The role of a software engineer is changing and will continue tochange in the future, with AI-assisted software development posing challengesfor the software engineering profession. The review suggests that the softwareengineering profession must adapt to the changing landscape to remain relevantand effective in the future.",Sabina-Cristiana Necula,2023/2/26,2023/2/26
1112.4016v1,The Study and Approach of Software Re-Engineering,http://arxiv.org/abs/1112.4016v1,"The nature of software re-engineering is to improve or transform existingsoftware so it can be understood, controlled and reused as new software. Needs,the necessity of re-engineering software has greatly increased. The systemsoftware has become obsolete no longer used in architecture, platform they'rerunning, stable and consistent they support the development and support needschange. Software re-engineering is vital to restore and reuse the thingsinherent in the existing software, put the cost of software maintenance to thelowest in the control and establish a basis for the development of software inthe future.",Phuc V. Nguyen,2011/12/17,2011/12/17
2301.08923v1,The Risk-Taking Software Engineer: A Framed Portrait,http://arxiv.org/abs/2301.08923v1,"Background: Risk-taking is prevalent in a host of activities performed bysoftware engineers on a daily basis, yet there is scant research on it. Aimsand Method: We study if software engineers' risk-taking is affected by framingeffects and by software engineers' personality. To this end, we perform asurvey experiment with 124 software engineers. Results: We find that framingsubstantially affects their risk-taking. None of the ""Big Five"" personalitytraits are related to risk-taking in software engineers after correcting formultiple testing. Conclusions: Software engineers and their managers must beaware of framing effects and account for them properly.",Lorenz Graf-Vlachy,2023/1/21,2023/1/21
1803.09823v1,The Impact of the Object-Oriented Software Evolution on Software Metrics: The Iris Approach,http://arxiv.org/abs/1803.09823v1,"The Object-Oriented (OO) software system evolves over the time to meet thenew requirements. Based on the initial release of software, the continuousmodification of software code leads to software evolution. Software needs toevolve over the time to meet the new user's requirements. Software companiesoften develop variant software of the original one depends on customers' needs.The main hypothesis of this paper states that the software when it evolves overthe time, its code continues to grow, change and become more complex. Thispaper proposes an automatic approach (Iris) to examine the proposed hypothesis.Originality of this approach is the exploiting of the software variants tostudy the impact of software evolution on the software metrics. This paperpresents the results of experiments conducted on three releases of drawingshapes software, sixteen releases of rhino software, eight releases of mobilemedia software and ten releases of ArgoUML software. Based on the extractedsoftware metrics, It has been found that Iris hypothesis is supported by thecomputed metrics.",Ra'Fat Al-Msie'deen,2018/3/15,2018/3/15
1202.0652v1,Agile Research,http://arxiv.org/abs/1202.0652v1,This paper discusses the application of agile software development methods insoftware-based research environments.,Hamish Cunningham,2012/2/3,2012/2/3
1403.4152v1,Quick Safari Through Software Design,http://arxiv.org/abs/1403.4152v1,This is a short tutorial about different software design methodologies.,Reza Rahimi,2014/3/17,2014/3/17
1209.0948v1,Teaching cloud computing: a software engineering perspective,http://arxiv.org/abs/1209.0948v1,This short papers discusses the issues of teaching cloud computing from asoftware engineering rather than a business perspective. It discusses whattopics might be covered in a senior course on cloud software engineering.,Ian Sommerville,2012/9/5,2012/9/5
1702.01715v3,Software Engineering at Google,http://arxiv.org/abs/1702.01715v3,We catalog and describe Google's key software engineering practices.,Fergus Henderson,2017/2/6,2020/1/30
2206.09303v2,The Framework For The Discipline Of Software Engineering in Connection to Information Technology Discipline,http://arxiv.org/abs/2206.09303v2,"This paper represents preliminary work in identifying the foundation for thediscipline of Software Engineering and discovering the links between thedomains of Software Engineering and Information Technology (IT). Our researchutilized IEEE Transactions on Software Engineering (IEEE-TSE), ACM Transactionson Software Engineering and Methodology (ACM-TOSEM), Automated SoftwareEngineering (ASE), the International Conference on Software Engineering(ICSE),and other related journal publication in the software engineering domain toaddress our research questions. We explored existing frameworks and describedthe need for software engineering as an academic discipline. We went further toclarify the distinction difference between Software Engineering and ComputerScience. Through this efforts we contribute to an understanding of how evidencefrom IT research can be used to improve Software Engineering as a discipline.",Jones Yeboah,2022/6/19,2022/10/27
2105.00272v1,Benchmarking as Empirical Standard in Software Engineering Research,http://arxiv.org/abs/2105.00272v1,"In empirical software engineering, benchmarks can be used for comparingdifferent methods, techniques and tools. However, the recent ACM SIGSOFTEmpirical Standards for Software Engineering Research do not include anexplicit checklist for benchmarking. In this paper, we discuss benchmarks forsoftware performance and scalability evaluation as example research areas insoftware engineering, relate benchmarks to some other empirical researchmethods, and discuss the requirements on benchmarks that may constitute thebasis for a checklist of a benchmarking standard for empirical softwareengineering research.",Wilhelm Hasselbring,2021/5/1,2021/5/1
2303.17271v1,What Practitioners Really Think About Continuous Software Engineering: A Taxonomy of Challenges,http://arxiv.org/abs/2303.17271v1,"The Continuous software engineering is a collaborative software developmentenvironment which offers the continues development and deployment of qualitysoftware project within short time. The Continuous software engineeringpractices are not yet mature enough, and the software organizations hesitate toadopt it. This study aims: (1) to explore the Continuous software engineeringchallenges by conducting systematic literature review (SLR) and to get theinsight of industry experts via questionnaire survey study; (2) to prioritizethe investigated challenges using fuzzy analytical hierarchy process (FAHP).The study findings provides the set of critical challenges faced by thesoftware organizations while adopting Continuous software engineering and aprioritization based taxonomy of the Continuous software engineeringchallenges. The application of FAHP is novel in this research area as itassists in addressing the vagueness of practitioners concerning the influencingfactors of Continuous software engineering. We believe that the finding of thisstudy will serve as a body of knowledge for real world practitioners andresearchers to revise and develop the new strategies for the successfulimplementation of Continuous software engineering practices in the softwareindustry.",Muhammad Zohaib,2023/3/30,2023/3/30
2102.08179v1,To get good student ratings should you only teach programming courses? Investigation and implications of student evaluations of teaching in a software engineering context,http://arxiv.org/abs/2102.08179v1,"Student evaluations of teaching (SET) are commonly used in universities forassessing teaching quality. However, previous literature shows that in softwareengineering students tend to rate certain topics higher than others: Inparticular students tend to value programming and software construction oversoftware design, software engineering models and methods, or soft skills. Wehypothesize that these biases also play a role in SET responses collected fromstudents. The objective of this study is to investigate how the topic of asoftware engineering course affects the SET metrics. We accomplish this byperforming multilevel regression analysis on SET data collected in a softwareengineering programme. We analyzed a total of 1295 student evaluations from 46university courses in a Finnish university. The results of the analysisverifies that the student course evaluations exhibit similar biases asdistinguished by previous software engineering education research. The type ofthe course can predict a higher SET rating. In our dataset, softwareconstruction and programming courses received higher SET ratings compared tocourses on software engineering processes, models, and methods.",Antti Knutas,2021/2/15,2021/2/15
2211.09034v1,Research Software Science: Expanding the Impact of Research Software Engineering,http://arxiv.org/abs/2211.09034v1,"Software plays a central role in scientific discovery. Improving how wedevelop and use software for research can have both broad and deep impacts on aspectrum of challenges and opportunities society faces today. The emergence ofResearch Software Engineer (RSE) as a role correlates with the growingcomplexity of scientific challenges and diversity of software team skills. Inthis paper, we describe research software science (RSS), an idea related toRSE, and particularly suited to research software teams. RSS promotes the useof scientific methodologies to explore and establish broadly applicableknowledge. Using RSS, we can pursue sustainable, repeatable, and reproduciblesoftware improvements that positively impact research software toward improvedscientific discovery.",Michael A. Heroux,2022/11/16,2022/11/16
1201.5735v1,Deconcentration of Attention: Addressing the Complexity of Software Engineering,http://arxiv.org/abs/1201.5735v1,"This article attempts to describe specific mental techniques that are relatedto resolving very complex tasks in software engineering. This subject may befamiliar to some software specialists to different extents; however, there iscurrently no common consensus and popular terminology for this subject area. Inthis article, the area is charted from a practical usability perspective.  This article also proposes to treat software engineering itself as researchon human thinking because software is meant to simulate thinking.",Igor Kusakov,2012/1/27,2012/1/27
1507.06897v1,A Business Maturity Model of Software Product Line Engineering,http://arxiv.org/abs/1507.06897v1,"In the recent past, software product line engineering has become one of themost promising practices in software industry with the potential tosubstantially increase the software development productivity. Software productline engineering approach spans the dimensions of business, architecture,software engineering process and organization. The increasing popularity ofsoftware product line engineering in the software industry necessitates aprocess maturity evaluation methodology. Accordingly, this paper presents abusiness maturity model of software product line, which is a methodology toevaluate the current maturity of the business dimension of a software productline in an organization. This model examines the coordination between productline engineering and the business aspects of software product line. Itevaluates the maturity of the business dimension of software product line as afunction of how a set of business practices are aligned with product lineengineering in an organization. Using the model presented in this paper, weconducted two case studies and reported the assessment results. This researchcontributes towards establishing a comprehensive and unified strategy for aprocess maturity evaluation of software product lines.",Faheem Ahmed,2015/7/24,2015/7/24
2304.07575v2,What Makes Good In-context Demonstrations for Code Intelligence Tasks with LLMs?,http://arxiv.org/abs/2304.07575v2,"Pre-trained models of source code have gained widespread popularity in manycode intelligence tasks. Recently, with the scaling of the model and corpussize, large language models have shown the ability of in-context learning(ICL). ICL employs task instructions and a few examples as demonstrations, andthen inputs the demonstrations to the language models for making predictions.This new learning paradigm is training-free and has shown impressiveperformance in various natural language processing and code intelligence tasks.However, the performance of ICL heavily relies on the quality ofdemonstrations, e.g., the selected examples. It is important to systematicallyinvestigate how to construct a good demonstration for code-related tasks. Inthis paper, we empirically explore the impact of three key factors on theperformance of ICL in code intelligence tasks: the selection, order, and numberof demonstration examples. We conduct extensive experiments on three codeintelligence tasks including code summarization, bug fixing, and programsynthesis. Our experimental results demonstrate that all the above threefactors dramatically impact the performance of ICL in code intelligence tasks.Additionally, we summarize our findings and provide takeaway suggestions on howto construct effective demonstrations, taking into account these threeperspectives. We also show that a carefully-designed demonstration based on ourfindings can lead to substantial improvements over widely-used demonstrationconstruction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%,175.96%, and 50.81% on code summarization, bug fixing, and program synthesis,respectively",Shuzheng Gao,2023/4/15,2023/8/8
2009.09295v1,Software Engineering Standards for Epidemiological Modeling,http://arxiv.org/abs/2009.09295v1,"There are many normative and technical questions involved in evaluating thequality of software used in epidemiological simulations. In this paper weanswer some of these questions and offer practical guidance to practitioners,funders, scientific journals, and consumers of epidemiological research. Theheart of our paper is a case study of the Imperial College London (ICL)COVID-19 simulator. We contend that epidemiological simulators should beengineered and evaluated within the framework of safety-critical standardsdeveloped by the consensus of the software engineering community forapplications such as automotive and aircraft control.",Jack K. Horner,2020/9/19,2020/9/19
2308.10462v2,Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models,http://arxiv.org/abs/2308.10462v2,"Large Language Models (LLMs) demonstrate impressive capabilities to generateaccurate code snippets given natural language intents in zero-shot, i.e.,without the need for specific fine-tuning. While prior studies have highlightedthe advantages of fine-tuning LLMs, this process incurs high computationalcosts, making it impractical in resource-scarce environments, particularly formodels with billions of parameters. To address these challenges, previousresearch explored In-Context Learning (ICL) as a strategy to guide the LLMgenerative process with task-specific prompt examples. However, ICL introducesinconveniences, such as the need for designing contextually relevant promptsand the absence of learning task-specific parameters, thereby limitingdownstream task performance. In this context, we foresee Parameter-EfficientFine-Tuning (PEFT) techniques as a promising approach to efficiently specializeLLMs to task-specific data while maintaining reasonable resource consumption.In this paper, we deliver a comprehensive study of PEFT techniques for LLMsunder the automated code generation scenario. Our comprehensive investigationof PEFT techniques for LLMs reveals their superiority and potential over ICLacross a diverse set of LLMs. Additionally, we demonstrate the extendedcapabilities of PEFT, showcasing its ability to learn from two distinctdatasets jointly without compromising performance. Furthermore, our studyhighlights the potential for tuning larger LLMs and significant reductions inmemory usage by combining PEFT with quantization. Therefore, this study opensopportunities for broader applications of PEFT in software engineeringscenarios. Our code is available athttps://github.com/martin-wey/peft-llm-code/.",Martin Weyssow,2023/8/21,2024/1/18
2310.09748v1,Large Language Model-Aware In-Context Learning for Code Generation,http://arxiv.org/abs/2310.09748v1,"Large language models (LLMs) have shown impressive in-context learning (ICL)ability in code generation. LLMs take a prompt consisting of requirement-codeexamples and a new requirement as input, and output new programs. Existingstudies have found that ICL is highly dominated by the examples and thus arisesresearch on example selection. However, existing approaches randomly selectexamples or only consider the textual similarity of requirements to retrieve,leading to sub-optimal performance. In this paper, we propose a novellearning-based selection approach named LAIL (LLM-Aware In-context Learning)for code generation. Given a candidate example, we exploit LLMs themselves toestimate it by considering the generation probabilities of ground-truthprograms given a requirement and the example. We then label candidate examplesas positive or negative through the probability feedback. Based on the labeleddata, we import a contrastive learning objective to train an effectiveretriever that acquires the preference of LLMs in code generation. We applyLAIL to three LLMs and evaluate it on three representative datasets (e.g.,MBJP, MBPP, and MBCPP). LATA outperforms the state-of-the-art baselines by11.58%, 6.89%, and 5.07% on CodeGen, and 4.38%, 2.85%, and 2.74% on GPT-3.5 interms of Pass@1, respectively.",Jia Li,2023/10/15,2023/10/15
2308.09890v1,Inductive-bias Learning: Generating Code Models with Large Language Model,http://arxiv.org/abs/2308.09890v1,"Large Language Models(LLMs) have been attracting attention due to a abilitycalled in-context learning(ICL). ICL, without updating the parameters of a LLM,it is possible to achieve highly accurate inference based on rules ``in thecontext'' by merely inputting a training data into the prompt. Although ICL isa developing field with many unanswered questions, LLMs themselves serves as ainference model, seemingly realizing inference without explicitly indicate``inductive bias''. On the other hand, a code generation is also a highlightedapplication of LLMs. The accuracy of code generation has dramatically improved,enabling even non-engineers to generate code to perform the desired tasks bycrafting appropriate prompts. In this paper, we propose a novel ``learning''method called an ``Inductive-Bias Learning (IBL)'', which combines thetechniques of ICL and code generation. An idea of IBL is straightforward. LikeICL, IBL inputs a training data into the prompt and outputs a code with anecessary structure for inference (we referred to as ``Code Model'') from a``contextual understanding''. Despite being a seemingly simple approach, IBLencompasses both a ``property of inference without explicit inductive bias''inherent in ICL and a ``readability and explainability'' of the codegeneration. Surprisingly, generated Code Models have been found to achievepredictive accuracy comparable to, and in some cases surpassing, ICL andrepresentative machine learning models. Our IBL code is open source:https://github.com/fuyu-quant/IBLM",Toma Tanaka,2023/8/19,2023/8/19
2310.01796v1,LLMParser: A LLM-based Log Parsing Framework,http://arxiv.org/abs/2310.01796v1,"The process of log parsing, which converts log messages into structuredformats, is a crucial step for various log analysis tasks. Although numerouslog parsers have been proposed, their effectiveness on complex log data isoften hindered due to reliance on human-made rules or learning-based modelswith limited training data. The recent rise of powerful large language models(LLMs) shows potential for log parsing due to their extensive pre-trainedknowledge related to code and logging. However, their accuracy is currentlylimited due to the lack of specialized log parsing capabilities. Additionally,the inconsistency of their answers and significant overhead obstruct thepractical implementation of LLM-based log parsing.  To tackle these challenges, we introduce LLMParser, the first practicalLLM-based log parsing framework. LLMParser enables accurate and robust logparsing by leveraging the in-context learning (ICL) capability of the LLM,employing a hierarchical candidate sampling algorithm, and selectinghigh-quality demonstrations. LLMParser also includes a novel adaptive parsingcache component to store and refine the templates generated by the LLM. Thisdesign aids in addressing the inefficiency of LLMs by rapid matching topreviously parsed log templates. LLMParser also adaptively updates thetemplates in the parsing cache to ensure consistent parsed results. Extensiveevaluation on large-scale public datasets demonstrates that LLMParser surpassesthe state-of-the-art methods. Furthermore, LLMParser significantly reduces thequery times to LLMs, achieving efficiency comparable to the most efficientbaseline, Drain.",Zhihan Jiang,2023/10/3,2023/10/3
2309.04663v2,FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning,http://arxiv.org/abs/2309.04663v2,"Learning paradigms for large language models (LLMs) currently tend to fallwithin either in-context learning (ICL) or full fine-tuning. Each of thesecomes with their own trade-offs based on available data, model size, computecost, ease-of-use, and final quality with neither solution performing wellacross-the-board. In this article, we first describe ICL and fine-tuningparadigms in a way that highlights their natural connections. Based on theseconnections, we propose a new learning paradigm called FIAT that fuses the bestof these paradigms together, enabling prompt-engineered instructions andchain-of-thought reasoning with the very largest models while also usingsimilar methods to perform parameter updates on a modestly-sized LLM withparameter-efficient tuning. We evaluate FIAT's effectiveness on a variety ofmultilingual tasks and observe that FIAT performs better than both ICL andfine-tuning at scales ranging from 100-10,000 training examples. We hope thatFIAT provides a practical way of harnessing the full potential of LLMs withoutneeding to make a hard choice between learning paradigms.",Xinyi Wang,2023/9/9,2023/9/12
2312.10771v1,kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning,http://arxiv.org/abs/2312.10771v1,"Task-Oriented Parsing (TOP) enables conversational assistants to interpretuser commands expressed in natural language, transforming them into structuredoutputs that combine elements of both natural language and intent/slot tags.Recently, Large Language Models (LLMs) have achieved impressive performance insynthesizing computer programs based on a natural language prompt, mitigatingthe gap between natural language and structured programs. Our paper focuses onharnessing the capabilities of LLMs for semantic parsing tasks, addressing thefollowing three key research questions: 1) How can LLMs be effectively utilizedfor semantic parsing tasks? 2) What defines an effective prompt? and 3) How canLLM overcome the length constraint and streamline prompt design by includingall examples as prompts? We introduce k Nearest Neighbor In-ContextLearning(kNN-ICL), which simplifies prompt engineering by allowing it to bebuilt on top of any design strategy while providing access to all demoexamples. Extensive experiments show that: 1)Simple ICL without kNN search canachieve a comparable performance with strong supervised models on the TOPtasks, and 2) kNN-ICL significantly improves the comprehension of complexrequests by seamlessly integrating ICL with a nearest-neighbor approach.Notably, this enhancement is achieved without the need for additional data orspecialized prompts.",Wenting Zhao,2023/12/17,2023/12/17
2311.09782v1,More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt Engineering,http://arxiv.org/abs/2311.09782v1,"While most existing works on LLM prompt-engineering focus only on how toselect a better set of data samples inside one single prompt input (In-ContextLearning or ICL), why can't we design and leverage multiple prompt inputstogether to further improve the LLM performance? In this work, we proposeIn-Context Sampling (ICS), a low-resource LLM prompt-engineering technique toproduce the most confident prediction results by optimizing the construction ofmultiple ICL prompt inputs. Extensive experiments with two SOTA LLMs (FlanT5-XLand Mistral-7B) on three NLI datasets (e-SNLI, Multi-NLI, and ANLI) illustratethat ICS can consistently enhance LLM's prediction performance and confidence.An ablation study suggests that a diversity-based ICS strategy may furtherimprove LLM's performance, which sheds light on a new yet promising futureresearch direction.",Bingsheng Yao,2023/11/16,2023/11/16
1912.03746v2,A Flipped Classroom Approach to Teaching Empirical Software Engineering,http://arxiv.org/abs/1912.03746v2,"Contribution: A flipped classroom approach to teaching empirical softwareengineering increases student learning by providing more time for activelearning in class. Background: There is a need for longitudinal studies of theflipped classroom approach in general. Although a few cross-sectional studiesshow that a flipped classroom approach can increase student learning byproviding more time for other in-class activities, such as active learning,such studies are also rare in the context of teaching software engineering.Intended outcomes: To assess the usefulness of a flipped classroom approach inteaching software engineering. Application design: The study was conducted atan international Master's program in Sweden, given in English, and partiallyreplicated at a university in Africa. Findings: The results suggest thatstudents' academic success, as measured by their exam grades, can be improvedby introducing a flipped classroom to teach software engineering topics, butthis may not extend to their subjective liking of the material, as measured bystudent evaluations. Furthermore, the effect of the change in teachingmethodology was not replicated when changing the teaching team.",Lucas Gren,2019/12/8,2019/12/14
2009.01521v2,Smoke Testing for Machine Learning: Simple Tests to Discover Severe Defects,http://arxiv.org/abs/2009.01521v2,"Machine learning is nowadays a standard technique for data analysis withinsoftware applications. Software engineers need quality assurance techniquesthat are suitable for these new kinds of systems. Within this article, wediscuss the question whether standard software testing techniques that havebeen part of textbooks since decades are also useful for the testing of machinelearning software. Concretely, we try to determine generic and simple smoketests that can be used to assert that basic functions can be executed withoutcrashing. We found that we can derive such tests using techniques similar toequivalence classes and boundary value analysis. Moreover, we found that theseconcepts can also be applied to hyperparameters, to further improve the qualityof the smoke tests. Even though our approach is almost trivial, we were able tofind bugs in all three machine learning libraries that we tested and severebugs in two of the three libraries. This demonstrates that common softwaretesting techniques are still valid in the age of machine learning and thatconsiderations how they can be adapted to this new context can help to find andprevent severe bugs, even in mature machine learning libraries.",Steffen Herbold,2020/9/3,2021/10/29
2208.00203v1,Adding Context to Source Code Representations for Deep Learning,http://arxiv.org/abs/2208.00203v1,"Deep learning models have been successfully applied to a variety of softwareengineering tasks, such as code classification, summarisation, and bug andvulnerability detection. In order to apply deep learning to these tasks, sourcecode needs to be represented in a format that is suitable for input into thedeep learning model. Most approaches to representing source code, such astokens, abstract syntax trees (ASTs), data flow graphs (DFGs), and control flowgraphs (CFGs) only focus on the code itself and do not take into accountadditional context that could be useful for deep learning models. In thispaper, we argue that it is beneficial for deep learning models to have accessto additional contextual information about the code being analysed. We presentpreliminary evidence that encoding context from the call hierarchy along withinformation from the code itself can improve the performance of astate-of-the-art deep learning model for two software engineering tasks. Weoutline our research agenda for adding further contextual information to sourcecode representations for deep learning.",Fuwei Tian,2022/7/30,2022/7/30
2112.11858v1,End to End Software Engineering Research,http://arxiv.org/abs/2112.11858v1,"End to end learning is machine learning starting in raw data and predicting adesired concept, with all steps done automatically. In software engineeringcontext, we see it as starting from the source code and predicting processmetrics. This framework can be used for predicting defects, code quality,productivity and more. End-to-end improves over features based machine learningby not requiring domain experts and being able to extract new knowledge. Wedescribe a dataset of 5M files from 15k projects constructed for this goal. Thedataset is constructed in a way that enables not only predicting concepts butalso investigating their causes.",Idan Amit,2021/12/22,2021/12/22
1811.12278v1,"Knowledge Management in Software Engineering: A Systematic Review of Studied Concepts, Findings and Research Methods Used",http://arxiv.org/abs/1811.12278v1,"Software engineering is knowledge-intensive work, and how to manage softwareengineering knowledge has received much attention. This systematic reviewidentifies empirical studies of knowledge management initiatives in softwareengineering, and discusses the concepts studied, the major findings, and theresearch methods used. Seven hundred and sixty-two articles were identified, ofwhich 68 were studies in an industry context. Of these, 29 were empiricalstudies and 39 reports of lessons learned. More than half of the empiricalstudies were case studies. The majority of empirical studies relate totechnocratic and behavioural aspects of knowledge management, while there arefew studies relating to economic, spatial and cartographic approaches. Afinding reported across multiple papers was the need to not focus exclusivelyon explicit knowledge, but also consider tacit knowledge. We also describeimplications for research and for practice.",Finn Olav Bjrnson,2018/11/29,2018/11/29
1412.4648v2,A Survey of Software Engineering Practices in Turkey (extended version),http://arxiv.org/abs/1412.4648v2,"Context: Understanding the types of software engineering practices andtechniques used in the industry is important. There is a wide spectrum in termsof the types and maturity of software engineering practices conducted in eachsoftware team and company. To characterize the type of software engineeringpractices conducted in software firms, a variety of surveys have been conductedin different countries and regions. Turkey has a vibrant software industry andit is important to characterize and understand the state of softwareengineering practices in this industry. Objective: Our objective is tocharacterize and grasp a high-level view on type of software engineeringpractices in the Turkish software industry. Among the software engineeringpractices that we have surveyed in this study are the followings: softwarerequirements, design, development, testing, maintenance, configurationmanagement, release planning and support practices. The current survey is themost comprehensive of its type ever conducted in the context of Turkishsoftware industry. Method: To achieve the above objective, we systematicallydesigned an online survey with 46 questions based on our past experience in theCanadian and Turkish contexts and using the Software Engineering Body ofKnowledge (SWEBOK). 202 practicing software engineers from the Turkish softwareindustry participated in the survey. We analyze and report in this paper theresults of the questions. Whenever possible, we also compare the trends andresults of our survey with the results of a similar 2010 survey conducted inthe Canadian software industry.",Vahid Garousi,2014/12/15,2014/12/16
2204.11039v1,Industry-Academia Research Collaboration in Software Engineering: The Certus Model,http://arxiv.org/abs/2204.11039v1,"Context: Research collaborations between software engineering industry andacademia can provide significant benefits to both sides, including improvedinnovation capacity for industry, and real-world environment for motivating andvalidating research ideas. However, building scalable and effective researchcollaborations in software engineering is known to be challenging. While suchchallenges can be varied and many, in this paper we focus on the challenges ofachieving participative knowledge creation supported by active dialog betweenindustry and academia and continuous commitment to joint problem solving.Objective: This paper aims to understand what are the elements of a successfulindustry-academia collaboration that enable the culture of participativeknowledge creation. Method: We conducted participant observation collectingqualitative data spanning 8 years of collaborative research between a softwareengineering research group on software V&V and the Norwegian IT sector. Thecollected data was analyzed and synthesized into a practical collaborationmodel, named the Certus Model. Results: The model is structured in sevenphases, describing activities from setting up research projects to theexploitation of research results. As such, the Certus model advances othercollaborations models from literature by delineating different phases coveringthe complete life cycle of participative research knowledge creation.Conclusion: The Certus model describes the elements of a research collaborationprocess between researchers and practitioners in software engineering, groundedon the principles of research knowledge co-creation and continuous commitmentto joint problem solving. The model can be applied and tested in other contextswhere it may be adapted to the local context through experimentation.",Dusica Marijan,2022/4/23,2022/4/23
2111.05327v1,An adaptive 3D virtual learning environment for training software developers in scrum,http://arxiv.org/abs/2111.05327v1,"Scrum is one of the most used frameworks for agile software developmentbecause of its potential improvements in productivity, quality, and clientsatisfaction. Academia has also focussed on teaching Scrum practices to preparestudents to face common software engineering challenges and facilitate theirinsertion in professional contexts. Furthermore, advances in learningtechnologies currently offer many virtual learning environments to enhancelearning in many ways. Their capability to consider the individual learnerpreferences has led a shift to more personalised training approaches, requiringthat the environments adapt themselves to the learner. We propose an adaptiveapproach for training developers in Scrum, including an adaptive virtuallearning environment based on Felder's learning style theory. Although stillpreliminary, our findings show that students who used the environment andreceived instruction matching their preferences obtained sightly higherlearning gains than students who received a different instruction than the onethey preferred. We also noticed less variability in the learning gains ofstudents who received instruction matching their preferences. The relevance ofthis work goes beyond the impact on learning gains since it describes howadaptive virtual learning environments can be used in the domain of SoftwareEngineering.",Ezequiel Scott,2021/11/9,2021/11/9
2205.02950v1,The Evolving Landscape of Software Performance Engineering,http://arxiv.org/abs/2205.02950v1,"Satisfactory software performance is essential for the adoption and thesuccess of a product. In organizations that follow traditional softwaredevelopment models (e.g., waterfall), Software Performance Engineering (SPE)involves time-consuming experimental modeling and performance testing outsidethe actual production environment. Such existing SPE methods, however, are notoptimized for environments utilizing Continuous Integration (CI) and ContinuousDelivery (CD) that result in high frequency and high volume of code changes. Wepresent a summary of lessons learned and propose improvements to the SPEprocess in the context of CI/CD. Our findings are based on SPE work on productsA and B conducted over 5 years at an online services company X. We find that(a) SPE has mainly become a post hoc activity based on data from the productionenvironment, (b) successful application of SPE techniques require frequentre-evaluation of priorities, and (c) engineers working on SPE require a broaderskill set than one traditionally possessed by engineers working on performance.",Gunnar Kudrjavets,2022/5/5,2022/5/5
2309.15606v1,From Misuse to Mastery: Enhancing Code Generation with Knowledge-Driven AI Chaining,http://arxiv.org/abs/2309.15606v1,"Large Language Models (LLMs) have shown promising results in automatic codegeneration by improving coding efficiency to a certain extent. However,generating high-quality and reliable code remains a formidable task because ofLLMs' lack of good programming practice, especially in exception handling. Inthis paper, we first conduct an empirical study and summarise three crucialchallenges of LLMs in exception handling, i.e., incomplete exception handling,incorrect exception handling and abuse of try-catch. We then try prompts withdifferent granularities to address such challenges, finding fine-grainedknowledge-driven prompts works best. Based on our empirical study, we propose anovel Knowledge-driven Prompt Chaining-based code generation approach, nameKPC, which decomposes code generation into an AI chain with iterativecheck-rewrite steps and chains fine-grained knowledge-driven prompts to assistLLMs in considering exception-handling specifications. We evaluate ourKPC-based approach with 3,079 code generation tasks extracted from the Javaofficial API documentation. Extensive experimental results demonstrate that theKPC-based approach has considerable potential to ameliorate the quality of codegenerated by LLMs. It achieves this through proficiently managing exceptionsand obtaining remarkable enhancements of 109.86% and 578.57% with staticevaluation methods, as well as a reduction of 18 runtime bugs in the sampleddataset with dynamic validation.",Xiaoxue Ren,2023/9/27,2023/9/27
2401.11361v1,Revolutionizing API Documentation through Summarization,http://arxiv.org/abs/2401.11361v1,"This study tackles the challenges associated with interpreting ApplicationProgramming Interface (API) documentation, an integral aspect of softwaredevelopment. Official API documentation, while essential, can be lengthy andchallenging to navigate, prompting developers to seek unofficial sources suchas Stack Overflow. Leveraging the vast user-generated content on StackOverflow, including code snippets and discussions, we employ BERTopic andextractive summarization to automatically generate concise and informative APIsummaries. These summaries encompass key insights like general usage, commondeveloper issues, and potential solutions, sourced from the wealth of knowledgeon Stack Overflow. Software developers evaluate these summaries forperformance, coherence, and interoperability, providing valuable feedback onthe practicality of our approach.",AmirHossein Naghshzan,2024/1/21,2024/1/21
2306.17077v1,RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot,http://arxiv.org/abs/2306.17077v1,"Performance bugs are non-functional bugs that can even manifest inwell-tested commercial products. Fixing these performance bugs is an importantyet challenging problem. In this work, we address this challenge and present anew approach called Retrieval-Augmented Prompt Generation (RAPGen). Given acode snippet with a performance issue, RAPGen first retrieves a promptinstruction from a pre-constructed knowledge-base of previous performance bugfixes and then generates a prompt using the retrieved instruction. It then usesthis prompt on a Large Language Model (such as Codex) in zero-shot to generatea fix. We compare our approach with the various prompt variations and state ofthe art methods in the task of performance bug fixing. Our evaluation showsthat RAPGen can generate performance improvement suggestions equivalent orbetter than a developer in ~60% of the cases, getting ~39% of them verbatim, inan expert-verified dataset of past performance changes made by C# developers.",Spandan Garg,2023/6/29,2023/6/29
2308.10576v2,Incorprating Prompt tuning for Commit classification with prior Knowledge,http://arxiv.org/abs/2308.10576v2,"Commit Classification(CC) is an important task in software maintenance sinceit helps software developers classify code changes into different typesaccording to their nature and purpose. This allows them to better understandhow their development efforts are progressing, identify areas where they needimprovement. However, existing methods are all discriminative models, usuallywith complex architectures that require additional output layers to produceclass label probabilities. Moreover, they require a large amount of labeleddata for fine-tuning, and it is difficult to learn effective classificationboundaries in the case of limited labeled data. To solve above problems, wepropose a generative framework that Incorporating prompt-tuning for commitclassification with prior knowledge (IPCK)https://github.com/AppleMax1992/IPCK, which simplifies the model structure andlearns features across different tasks. It can still reach the SOTA performancewith only limited samples. Firstly, we proposed a generative framework based onT5. This encoder-decoder construction method unifies different CC task into atext2text problem, which simplifies the structure of the model by not requiringan extra output layer. Second, instead of fine-tuning, we design anprompt-tuning solution which can be adopted in few-shot scenarios with onlylimit samples. Furthermore, we incorporate prior knowledge via an externalknowledge graph to map the probabilities of words into the final labels in thespeech machine step to improve performance in few-shot scenarios. Extensiveexperiments on two open available datasets show that our framework can solvethe CC problem simply but effectively in few-shot and zeroshot scenarios, whileimproving the adaptability of the model without requiring a large amount oftraining samples for fine-tuning.",Jiajun Tong,2023/8/21,2023/10/26
1703.00619v1,Reflections on Cyberethics Education for Millennial Software Engineers,http://arxiv.org/abs/1703.00619v1,"Software is a key component of solutions for 21st Century problems. Theseproblems are often ""wicked"", complex, and unpredictable. To provide the bestpossible solution, millennial software engineers must be prepared to makeethical decisions, thinking critically, and acting systematically. This realitydemands continuous changes in educational systems and curricula delivery, asmisjudgment might have serious social impact. This study aims to investigateand reflect on Software Engineering (SE) Programs, proposing a conceptualframework for analyzing cyberethics education and a set of suggestions on howto integrate it into the SE undergraduate curriculum.",Claudia de O. Melo,2017/3/2,2017/3/2
2111.08426v1,Formal Quantum Software Engineering: Introducing the Formal Methods of Software Engineering to Quantum Computing,http://arxiv.org/abs/2111.08426v1,"Quantum computing (QC) represents the future of computing systems, but thetools for reasoning about the quantum model of computation, in which the lawsobeyed are those on the quantum mechanical scale, are still a mix of linearalgebra and Dirac notation; two subjects more suitable for physicists, ratherthan computer scientists and software engineers. On this ground, we believe itis possible to provide a more intuitive approach to thinking and writing aboutquantum computing systems, in order to simplify the design of quantumalgorithms and the development of quantum software. In this paper, we move thefirst step in such direction, introducing a specification language as the toolto represent the operations of a quantum computer via axiomatic definitions, byadopting the same symbolisms and reasoning principles used by formal methods insoftware engineering. We name this approach formal quantum software engineering(F-QSE). This work assumes familiarity with the basic principles of quantummechanics (QM), with the use of Zed (Z) which is a formal language of softwareengineering (SE), and with the notation and techniques of first-order logic(FOL) and functional programming (FP).",Carmelo R. Cartiere,2021/11/14,2021/11/14
2201.01359v1,Software and Security Engineering in Digital Transformation,http://arxiv.org/abs/2201.01359v1,"Digital transformation is a hot topic in the current global environment as alarge number of organizations have been working to adopt digital solutions.Software engineering has also emerged to be a more important role as a largenumber of systems, either traditional or smart, are dependent on the softwarethat collects, store, and process data. The role of software engineers has alsobecome crucial in digital transformation. In this regard, this paper aims toexamine the trends of software engineering and the role of software engineersin digital transformation. In addition to this, this paper also examines theimportance of secure software development in digital transformation. It can beconcluded that software engineering is an integral part of digitaltransformation as all digital systems make use of software to perform theirfunctions efficiently. Software act as a bridge between digital systems andhumans to use the systems interactively and efficiently.",Mamdouh Alenezi,2021/12/16,2021/12/16
2010.04660v1,"Research, Develop, Deploy: Building a Full Spectrum Software Engineering and Research Department",http://arxiv.org/abs/2010.04660v1,"At Sandia National Laboratories, the Software Engineering and ResearchDepartment seeks to provide sustainable career pathways for research softwareengineers (RSEs). The conceptual model for our organization follows what wecall a Research, Develop, and Deploy (RDD) workflow pattern, enabling RSEs topartner with research and deployment specialists. We argue that thisinterdisciplinary model allows our department to act as an incubator and anaccelerator for impactful ideas. We describe these tactics and our experiencesas a RSE team in a scientific computing center.",Reed Milewicz,2020/10/9,2020/10/9
2106.12645v1,A Wizard of Oz Study Simulating API Usage Dialogues with a Virtual Assistant,http://arxiv.org/abs/2106.12645v1,"Virtual Assistant technology is rapidly proliferating to improve productivityin a variety of tasks. While several virtual assistants for everyday tasks arewell-known (e.g., Siri, Cortana, Alexa), assistants for specialty tasks such assoftware engineering are rarer. One key reason software engineering assistantsare rare is that very few experimental datasets are available and suitable fortraining the AI that is the bedrock of current virtual assistants. In thispaper, we present a set of Wizard of Oz experiments that we designed to build adataset for creating a virtual assistant. Our target is a hypothetical virtualassistant for helping programmers use APIs. In our experiments, we recruited 30professional programmers to complete programming tasks using two APIs. Theprogrammers interacted with a simulated virtual assistant for help - theprogrammers were not aware that the assistant was actually operated by humanexperts. We then annotated the dialogue acts in the corpus along fourdimensions: illocutionary intent, API information type(s), backward-facingfunction, and traceability to specific API components. We observed a diverserange of interactions that will facilitate the development of dialoguestrategies for virtual assistants for API usage.",Zachary Eberhart,2021/6/23,2021/6/23
1409.6587v1,Orchestration of Global Software Engineering Projects,http://arxiv.org/abs/1409.6587v1,"Global software engineering has become a fact in many companies due to realnecessity in practice. In contrast to co-located projects global projects facea number of additional software engineering challenges. Among them qualitymanagement has become much more difficult and schedule and budget overruns canbe observed more often. Compared to co-located projects global softwareengineering is even more challenging due to the need for integration ofdifferent cultures, different languages, and different time zones - acrosscompanies, and across countries. The diversity of development locations onseveral levels seriously endangers an effective and goal-oriented progress ofprojects. In this position paper we discuss reasons for global development,sketch settings for distribution and views of orchestration of dislocatedcompanies in a global project that can be seen as a ""virtual projectenvironment"". We also present a collection of questions, which we considerrelevant for global software engineering. The questions motivate furtherdiscussion to derive a research agenda in global software engineering.",Christian Bartelt,2014/9/22,2014/9/22
1303.1488v1,A Synthesis of Logical and Probabilistic Reasoning for Program Understanding and Debugging,http://arxiv.org/abs/1303.1488v1,"We describe the integration of logical and uncertain reasoning methods toidentify the likely source and location of software problems. To date, softwareengineers have had few tools for identifying the sources of error in complexsoftware packages. We describe a method for diagnosing software problemsthrough combining logical and uncertain reasoning analyses. Our preliminaryresults suggest that such methods can be of value in directing the attention ofsoftware engineers to paths of an algorithm that have the highest likelihood ofharboring a programming error.",Lisa J. Burnell,2013/3/6,2013/3/6
2303.16989v1,Applications of Causality and Causal Inference in Software Engineering,http://arxiv.org/abs/2303.16989v1,"Causal inference is a study of causal relationships between events and thestatistical study of inferring these relationships through interventions andother statistical techniques. Causal reasoning is any line of work towarddetermining causal relationships, including causal inference. This paperexplores the relationship between causal reasoning and various fields ofsoftware engineering. This paper aims to uncover which software engineeringfields are currently benefiting from the study of causal inference and causalreasoning, as well as which aspects of various problems are best addressedusing this methodology. With this information, this paper also aims to findfuture subjects and fields that would benefit from this form of reasoning andto provide that information to future researchers. This paper follows asystematic literature review, including; the formulation of a search query,inclusion and exclusion criteria of the search results, clarifying questionsanswered by the found literature, and synthesizing the results from theliterature review. Through close examination of the 45 found papers relevant tothe research questions, it was revealed that the majority of causal reasoningas related to software engineering is related to testing through root causelocalization. Furthermore, most causal reasoning is done informally through anexploratory process of forming a Causality Graph as opposed to strictstatistical analysis or introduction of interventions. Finally, causalreasoning is also used as a justification for many tools intended to make thesoftware more human-readable by providing additional causal information tologging processes or modeling languages.",Patrick Chadbourne,2023/3/29,2023/3/29
2309.07345v1,Unveiling the Life Cycle of User Feedback: Best Practices from Software Practitioners,http://arxiv.org/abs/2309.07345v1,"User feedback has grown in importance for organizations to improve softwareproducts. Prior studies focused primarily on feedback collection and reported ahigh-level overview of the processes, often overlooking how practitionersreason about, and act upon this feedback through a structured set ofactivities. In this work, we conducted an exploratory interview study with 40practitioners from 32 organizations of various sizes and in several domainssuch as e-commerce, analytics, and gaming. Our findings indicate thatorganizations leverage many different user feedback sources. Social mediaemerged as a key category of feedback that is increasingly critical for manyorganizations. We found that organizations actively engage in a number ofnon-trivial activities to curate and act on user feedback, depending on itssource. We synthesize these activities into a life cycle of managing userfeedback. We also report on the best practices for managing user feedback thatwe distilled from responses of practitioners who felt that their organizationeffectively understood and addressed their users' feedback. We presentactionable empirical results that organizations can leverage to increase theirunderstanding of user perception and behavior for better products thus reducinguser attrition.",Ze Shi Li,2023/9/13,2023/9/13
1806.05130v3,Detecting Speech Act Types in Developer Question/Answer Conversations During Bug Repair,http://arxiv.org/abs/1806.05130v3,"This paper targets the problem of speech act detection in conversations aboutbug repair. We conduct a ""Wizard of Oz"" experiment with 30 professionalprogrammers, in which the programmers fix bugs for two hours, and use asimulated virtual assistant for help. Then, we use an open coding manualannotation procedure to identify the speech act types in the conversations.Finally, we train and evaluate a supervised learning algorithm to automaticallydetect the speech act types in the conversations. In 30 two-hour conversations,we made 2459 annotations and uncovered 26 speech act types. Our automateddetection achieved 69% precision and 50% recall. The key application of thiswork is to advance the state of the art for virtual assistants in softwareengineering. Virtual assistant technology is growing rapidly, thoughapplications in software engineering are behind those in other areas, largelydue to a lack of relevant data and experiments. This paper targets this problemin the area of developer Q/A conversations about bug repair.",Andrew Wood,2018/6/13,2018/7/3
1704.00801v1,Need for a Soft Dimension,http://arxiv.org/abs/1704.00801v1,"It is impossible to separate the human factors from software engineeringexpertise during software development, because software is developed by peopleand for people. The intangible nature of software has made it a difficultproduct to successfully create, and an examination of the many reasons formajor software system failures show that the reasons for failures eventuallycome down to human issues. Software developers, immersed as they are in thetechnological aspect of the product, can quickly learn lessons fromtechnological failures and readily come up with solutions to avoid them in thefuture, yet they do not learn lessons from human aspects in softwareengineering. Dealing with human errors is much more difficult for developersand often this aspect is overlooked in the evaluation process as developersmove on to issues that they are more comfortable solving. A major reason forthis oversight is that software psychology (the softer side) has not developedas extensively.",Pradeep Waychal,2017/4/3,2017/4/3
1405.1505v1,System Software: Concepts and Approach,http://arxiv.org/abs/1405.1505v1,"In software industry a large number of projects continue to fail due to nontechnical issue such as communication gap,requirements and poor executive. Theauthors identify the reasons for which are available for software developmentlife cycles fall short of dealing with them. They also proposed the systemdevelopment for software development life cycle. In this paper, the concept ofsystem development, SDLC is further explored and a number of concepts arediscussed in this regard.",Dr. Manju Kaushik,2014/5/7,2014/5/7
2303.12913v1,What do Transgender Software Professionals say about a Career in the Software Industry?,http://arxiv.org/abs/2303.12913v1,"Diversity is an essential aspect of software development because technologyinfluences almost every aspect of modern society, and if the software industrylacks diversity, software products might unintentionally constrain groups ofindividuals instead of promoting an equalitarian experience to all. In thisstudy, we investigate the perspectives of transgender software professionalsabout a career in software engineering as one of the aspects of diversity inthe software industry. Our findings demonstrate that, on the one hand, transpeople choose careers in software engineering for two primary reasons: a) eventhough software development environments are not exempt from discrimination,the software industry is safer than other industries for transgenders; b) transpeople occasionally have to deal with gender dysphoria, anxiety, and fear ofjudgment, and the work flexibility offered by software companies allow them tocope with these issues more efficiently.",Ronnie de Souza Santos,2023/3/22,2023/3/22
2304.13294v1,Systems Modeling for novice engineers to comprehend software products better,http://arxiv.org/abs/2304.13294v1,"One of the key challenges for a novice engineer in a product company is tocomprehend the product sufficiently and quickly. It can take anywhere from sixmonths to several years for them to attain mastery but they need to startdelivering results much before. SaaS (Software-as-a-Service) products havesophisticated system architecture which adds to the time and effort ofunderstanding them. On the other hand, time available to new hires for productunderstanding continues to be short and getting shorter, given the pressure todeliver more in less time. Constructivist theory views learning as a personalprocess in which the learner constructs new knowledge for themselves. Buildingand refining a mental model is the key way in which they learn, similar to howthe brain operates. This paper presents an approach to improve systemcomprehension process by using a system model that a) acts as a transitionalobject to aid and refine the mental model of the learner, and b) captures thecurrent understanding of the dynamics of the software system in a way that canbe reasoned with and simulated.  We have adapted discrete systems modeling techniques and used a transitionsystem as a lightweight modeling language. Such a model can be used by noviceengineers during their product ramp-up phase to build a model of the softwaresystem that captures their knowledge of the system and aid their mental model.The paper also presents a learning approach in which the learners create andrefine these models iteratively using the available and newly uncoveredknowledge about the software system. We hypothesize that by leveraging thismodeling language and approach, novice engineers can reduce the time it takesthem to achieve desired proficiency level of system comprehension. This paperpresents early ideas on this language and approach.",Mrityunjay Kumar,2023/4/26,2023/4/26
1901.01819v1,A Call to Promote Soft Skills in Software Engineering,http://arxiv.org/abs/1901.01819v1,"We have been thinking about other aspects of software engineering for manyyears; the missing link in engineering software is the soft skills set,essential in the software development process. Although soft skills are amongthe most important aspects in the creation of software, they are oftenoverlooked by educators and practitioners. One of the main reasons for theoversight is that soft skills are usually related to social and personalityfactors, i.e., teamwork, motivation, commitment, leadership, multi-culturalism,emotions, interpersonal skills, etc. This editorial is a manifesto declaringthe importance of soft skills in software engineering with the intention todraw professionals attention to these topics. We have approached this issue bymentioning what we know about the field, what we believe to be evident, andwhich topics need further investigation. Important references to back up ourclaims are also included. Software engineers take pride in the depth of theirtechnical expertise, which separates them from the crowd. But, what makes agood software engineer? First, it is the technical knowledge of relevantmethodologies and techniques (i.e. hard skills), as well as the skillsnecessary for applying that knowledge in practice. Second, but nonethelessimportant, it is a set of soft skills, in particular collaboration,communication, problem-solving and similar interpersonal and critical thinkingskills that are expected from software engineering professionals. In otherwords, software engineers need both hard and soft skills in order to besuccessful at the workplace.",Luiz Fernando Capretz,2018/12/12,2018/12/12
2302.07229v1,Moving on from the software engineers' gambit: an approach to support the defense of software effort estimates,http://arxiv.org/abs/2302.07229v1,"Pressure for higher productivity and faster delivery is increasinglypervading software organizations. This can lead software engineers to act likechess players playing a gambit -- making sacrifices of their technically soundestimates, thus submitting their teams to time pressure. In turn, time pressurecan have varied detrimental effects, such as poor product quality and emotionaldistress, decreasing productivity, which leads to more time pressure anddelays: a hard-to-stop vicious cycle. This reveals a need for moving on fromthe more passive strategy of yielding to pressure to a more active one ofdefending software estimates. Therefore, we propose an approach to supportsoftware estimators in acquiring knowledge on how to carry out such defense, byintroducing negotiation principles encapsulated in a set of defense lenses,presented through a digital simulation. We evaluated the proposed approachthrough a controlled experiment with software practitioners from differentcompanies. We collected data on participants' attitudes, subjective norms,perceived behavioral control, and intentions to perform the defense of theirestimates in light of the Theory of Planned Behavior. We employed a frequentistand a bayesian approach to data analysis. Results show improved scores amongexperimental group participants after engaging with the digital simulation andlearning about the lenses. They were also more inclined to choose a defenseaction when facing pressure scenarios than a control group exposed to questionsto reflect on the reasons and outcomes of pressure over estimates. Qualitativeevidence reveals that practitioners perceived the set of lenses as useful intheir current work environments. Collectively, these results show theeffectiveness of the proposed approach and its perceived relevance for theindustry, despite the low amount of time required to engage with it.",Patrcia Matsubara,2023/2/14,2023/2/14
1306.2414v1,Action Research Can Swing the Balance in Experimental Software Engineering,http://arxiv.org/abs/1306.2414v1,"In general, professionals still ignore scientific evidence in place of expertopinions in most of their decision-making. For this reason, it is still commonto see the adoption of new software technologies in the field without anyscientific basis or well-grounded criteria, but on the opinions of experts.Experimental Software Engineering is of paramount importance to provide thefoundations to understand the limits and applicability of softwaretechnologies. The need to better observe and understand the practice ofSoftware Engineering leads us to look for alternative experimental approachesto support our studies. Different research strategies can be used to exploredifferent Software Engineering practices. Action Research can be seen as onealternative to intensify the conducting of important experimental studies withresults of great value while investigating the Software Engineering practicesin depth. In this paper, a discussion on the use of Action Research in SoftwareEngineering is presented. Aiming at better explaining the application of ActionResearch, an experimental study (in vivo) on the investigation of thesubjective decisions of software developers, concerned with the refactoring ofsource code to improve source code quality in a distributed softwaredevelopment context is depicted. In addition, some guidance on how toaccomplish an Action Research study in Software Engineering supplement thediscussions.",Paulo Sergio Medeiros dos Santos,2013/6/11,2013/6/11
2204.11083v1,Blockchain-Oriented Software Variant Forks: A Preliminary Study,http://arxiv.org/abs/2204.11083v1,"In collaborative social development platforms such as GitHub, forking arepository is a common activity. A variant fork wants to split the developmentfrom the original repository and grow towards a different direction. In thispreliminary exploratory research, we analyze the possible reasons for creatinga variant fork in blockchain-oriented software. By collecting repositories inGitHub, we created a dataset with repositories and their variants, from whichwe manually analyzed 86 variants. Based on the variants we studied, the mainreason to create a variant in blockchain-oriented software is to support adifferent blockchain platform (65%).",Henrique Rocha,2022/4/23,2022/4/23
2311.18450v3,Lessons from Building StackSpot AI: A Contextualized AI Coding Assistant,http://arxiv.org/abs/2311.18450v3,"With their exceptional natural language processing capabilities, tools basedon Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly becomeindispensable resources in the software developer's toolkit. While recentstudies suggest the potential productivity gains these tools can unlock, usersstill encounter drawbacks, such as generic or incorrect answers. Additionally,the pursuit of improved responses often leads to extensive prompt engineeringefforts, diverting valuable time from writing code that delivers actual value.To address these challenges, a new breed of tools, built atop LLMs, isemerging. These tools aim to mitigate drawbacks by employing techniques likefine-tuning or enriching user prompts with contextualized information.  In this paper, we delve into the lessons learned by a software developmentteam venturing into the creation of such a contextualized LLM-basedapplication, using retrieval-based techniques, called CodeBuddy. Over afour-month period, the team, despite lacking prior professional experience inLLM-based applications, built the product from scratch. Following the initialproduct release, we engaged with the development team responsible for the codegenerative components. Through interviews and analysis of the application'sissue tracker, we uncover various intriguing challenges that teams working onLLM-based applications might encounter. For instance, we found three main groupof lessons: LLM-based lessons, User-based lessons, and Technical lessons. Byunderstanding these lessons, software development teams could become betterprepared to build LLM-based applications.",Gustavo Pinto,2023/11/30,2024/1/4
2303.05771v1,Automating Method Naming with Context-Aware Prompt-Tuning,http://arxiv.org/abs/2303.05771v1,"Method names are crucial to program comprehension and maintenance. Recently,many approaches have been proposed to automatically recommend method names anddetect inconsistent names. Despite promising, their results are stillsub-optimal considering the three following drawbacks: 1) These models aremostly trained from scratch, learning two different objectives simultaneously.The misalignment between two objectives will negatively affect trainingefficiency and model performance. 2) The enclosing class context is not fullyexploited, making it difficult to learn the abstract function of the method. 3)Current method name consistency checking methods follow a generate-then-compareprocess, which restricts the accuracy as they highly rely on the quality ofgenerated names and face difficulty measuring the semantic consistency.  In this paper, we propose an approach named AUMENA to AUtomate MEthod NAmingtasks with context-aware prompt-tuning. Unlike existing deep learning basedapproaches, our model first learns the contextualized representation(i.e.,class attributes) of PL and NL through the pre-training model, then fullyexploits the capacity and knowledge of large language model with prompt-tuningto precisely detect inconsistent method names and recommend more accuratenames. To better identify semantically consistent names, we model the methodname consistency checking task as a two-class classification problem, avoidingthe limitation of previous similarity-based consistency checking approaches.The experimental results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7%on four datasets of method name recommendation, surpassing the state-of-the-artbaseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively. And our approach scores80.8% accuracy on method name consistency checking, reaching an 5.5%outperformance. All data and trained models are publicly available.",Jie Zhu,2023/3/10,2023/3/10
2307.08177v3,Using an LLM to Help With Code Understanding,http://arxiv.org/abs/2307.08177v3,"Understanding code is challenging, especially when working in new and complexdevelopment environments. Code comments and documentation can help, but aretypically scarce or hard to navigate. Large language models (LLMs) arerevolutionizing the process of writing code. Can they do the same for helpingunderstand it? In this study, we provide a first investigation of an LLM-basedconversational UI built directly in the IDE that is geared towards codeunderstanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with fourhigh-level requests without the user having to write explicit prompts: toexplain a highlighted section of code, provide details of API calls used in thecode, explain key domain-specific terms, and provide usage examples for an API.The plugin also allows for open-ended prompts, which are automaticallycontextualized to the LLM with the program being edited. We evaluate thissystem in a user study with 32 participants, which confirms that using ourplugin can aid task completion more than web search. We additionally provide athorough analysis of the ways developers use, and perceive the usefulness of,our system, among others finding that the usage and benefits differ betweenstudents and professionals. We conclude that in-IDE prompt-less interactionwith LLMs is a promising future direction for tool builders.",Daye Nam,2023/7/17,2024/1/16
1407.6100v1,A framework for contextual information retrieval from the WWW,http://arxiv.org/abs/1407.6100v1,"Search engines are the most commonly used type of tool for finding relevantinformation on the Internet. However, today's search engines are far fromperfect. Typical search queries are short, often one or two words, and can beambiguous therefore returning inappropriate results. Contextual informationretrieval (CIR) is a critical technique for these search engines to facilitatequeries and return relevant information. Despite its importance, littleprogress has been made in CIR due to the difficulty of capturing andrepresenting contextual information about users. Numerous contextualinformation retrieval approaches exist today, but to the best of our knowledgenone of them offer a similar service to the one proposed in this paper.  This paper proposes an alternative framework for contextual informationretrieval from the WWW. The framework aims to improve query results (or makesearch results more relevant) by constructing a contextual profile based on auser's behaviour, their preferences, and a shared knowledge base, and usingthis information in the search engine framework to find and return relevantinformation.",Dilip K. Limbu,2014/7/23,2014/7/23
2305.18584v1,Coeditor: Leveraging Contextual Changes for Multi-round Code Auto-editing,http://arxiv.org/abs/2305.18584v1,"Developers often dedicate significant time to maintaining and refactoringexisting code. However, most prior work on generative models for code focusessolely on creating new code, neglecting the unique requirements of editingexisting code. In this work, we explore a multi-round code auto-editingsetting, aiming to predict edits to a code region based on recent changeswithin the same codebase. Our model, Coeditor, is a fine-tuned CodeT5 modelwith enhancements specifically designed for code editing tasks. We encode codechanges using a line diff format and employ static analysis to form largecustomized model contexts, ensuring appropriate information for prediction. Wecollect a code editing dataset from the commit histories of 1650 open-sourcePython projects for training and evaluation. In a simplified single-round,single-edit task, Coeditor significantly outperforms the best code completionapproach -- nearly doubling its exact-match accuracy, despite using a muchsmaller model -- demonstrating the benefits of incorporating editing historyfor code completion. In a multi-round, multi-edit setting, we observesubstantial gains by iteratively prompting the model with additional useredits. We open-source our code, data, and model weights to encourage futureresearch and release a VSCode extension powered by our model for interactiveusage.",Jiayi Wei,2023/5/29,2023/5/29
2310.03659v1,Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures,http://arxiv.org/abs/2310.03659v1,"Large language models (LLMs) have revolutionized the field of artificialintelligence, endowing it with sophisticated language understanding andgeneration capabilities. However, when faced with more complex andinterconnected tasks that demand a profound and iterative thought process, LLMsreveal their inherent limitations. Autonomous LLM-powered multi-agent systemsrepresent a strategic response to these challenges. Such systems strive forautonomously tackling user-prompted goals by decomposing them into manageabletasks and orchestrating their execution and result synthesis through acollective of specialized intelligent agents. Equipped with LLM-poweredreasoning capabilities, these agents harness the cognitive synergy ofcollaborating with their peers, enhanced by leveraging contextual resourcessuch as tools and datasets. While these architectures hold promising potentialin amplifying AI capabilities, striking the right balance between differentlevels of autonomy and alignment remains the crucial challenge for theireffective operation. This paper proposes a comprehensive multi-dimensionaltaxonomy, engineered to analyze how autonomous LLM-powered multi-agent systemsbalance the dynamic interplay between autonomy and alignment across variousaspects inherent to architectural viewpoints such as goal-driven taskmanagement, agent composition, multi-agent collaboration, and contextinteraction. It also includes a domain-ontology model specifying fundamentalarchitectural concepts. Our taxonomy aims to empower researchers, engineers,and AI practitioners to systematically analyze the architectural dynamics andbalancing strategies employed by these increasingly prevalent AI systems. Theexploratory taxonomic classification of selected representative LLM-poweredmulti-agent systems illustrates its practical utility and reveals potential forfuture research and development.",Thorsten Hndler,2023/10/5,2023/10/5
2309.03914v1,DevGPT: Studying Developer-ChatGPT Conversations,http://arxiv.org/abs/2309.03914v1,"The emergence of large language models (LLMs) such as ChatGPT has disruptedthe landscape of software development. Many studies are investigating thequality of responses generated by ChatGPT, the efficacy of various promptingtechniques, and its comparative performance in programming contests, to name afew examples. Yet, we know very little about how ChatGPT is actually used bysoftware developers. What questions do developers present to ChatGPT? What arethe dynamics of these interactions? What is the backdrop against which theseconversations are held, and how do the conversations feedback into theartifacts of their work? To close this gap, we introduce DevGPT, a curateddataset which encompasses 17,913 prompts and ChatGPT's responses including11,751 code snippets, coupled with the corresponding software developmentartifacts -- ranging from source code, commits, issues, pull requests, todiscussions and Hacker News threads -- to enable the analysis of the contextand implications of these developer interactions with ChatGPT.",Tao Xiao,2023/8/31,2023/8/31
2301.03987v1,API Entity and Relation Joint Extraction from Text via Dynamic Prompt-tuned Language Model,http://arxiv.org/abs/2301.03987v1,"Extraction of Application Programming Interfaces (APIs) and their semanticrelations from unstructured text (e.g., Stack Overflow) is a fundamental workfor software engineering tasks (e.g., API recommendation). However, existingapproaches are rule-based and sequence-labeling based. They must manuallyenumerate the rules or label data for a wide range of sentence patterns, whichinvolves a significant amount of labor overhead and is exacerbated bymorphological and common-word ambiguity. In contrast to matching or labelingAPI entities and relations, this paper formulates heterogeneous API extractionand API relation extraction task as a sequence-to-sequence generation task, andproposes AERJE, an API entity-relation joint extraction model based on thelarge pre-trained language model. After training on a small number of ambiguousbut correctly labeled data, AERJE builds a multi-task architecture thatextracts API entities and relations from unstructured text using dynamicprompts. We systematically evaluate AERJE on a set of long and ambiguoussentences from Stack Overflow. The experimental results show that AERJEachieves high accuracy and discrimination ability in API entity-relation jointextraction, even with zero or few-shot fine-tuning.",Qing Huang,2023/1/10,2023/1/10
2308.03921v1,Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts,http://arxiv.org/abs/2308.03921v1,"Creative coding tasks are often exploratory in nature. When producing digitalartwork, artists usually begin with a high-level semantic construct such as a""stained glass filter"" and programmatically implement it by varying codeparameters such as shape, color, lines, and opacity to produce visuallyappealing results. Based on interviews with artists, it can be effortful totranslate semantic constructs to program syntax, and current programming toolsdon't lend well to rapid creative exploration. To address these challenges, weintroduce Spellburst, a large language model (LLM) powered creative-codingenvironment. Spellburst provides (1) a node-based interface that allows artiststo create generative art and explore variations through branching and mergingoperations, (2) expressive prompt-based interactions to engage in semanticprogramming, and (3) dynamic prompt-driven interfaces and direct code editingto seamlessly switch between semantic and syntactic exploration. Our evaluationwith artists demonstrates Spellburst's potential to enhance creative codingpractices and inform the design of computational creativity tools that bridgesemantic and syntactic spaces.",Tyler Angert,2023/8/7,2023/8/7
2309.07026v1,APICom: Automatic API Completion via Prompt Learning and Adversarial Training-based Data Augmentation,http://arxiv.org/abs/2309.07026v1,"Based on developer needs and usage scenarios, API (Application ProgrammingInterface) recommendation is the process of assisting developers in finding therequired API among numerous candidate APIs. Previous studies mainly modeled APIrecommendation as the recommendation task, which can recommend multiplecandidate APIs for the given query, and developers may not yet be able to findwhat they need. Motivated by the neural machine translation research domain, wecan model this problem as the generation task, which aims to directly generatethe required API for the developer query. After our preliminary investigation,we find the performance of this intuitive approach is not promising. The reasonis that there exists an error when generating the prefixes of the API. However,developers may know certain API prefix information during actual development inmost cases. Therefore, we model this problem as the automatic completion taskand propose a novel approach APICom based on prompt learning, which cangenerate API related to the query according to the prompts (i.e., API prefixinformation). Moreover, the effectiveness of APICom highly depends on thequality of the training dataset. In this study, we further design a novelgradient-based adversarial training method {\atpart} for data augmentation,which can improve the normalized stability when generating adversarialexamples. To evaluate the effectiveness of APICom, we consider a corpus of 33kdeveloper queries and corresponding APIs. Compared with the state-of-the-artbaselines, our experimental results show that APICom can outperform allbaselines by at least 40.02\%, 13.20\%, and 16.31\% in terms of the performancemeasures EM@1, MRR, and MAP. Finally, our ablation studies confirm theeffectiveness of our component setting (such as our designed adversarialtraining method, our used pre-trained model, and prompt learning) in APICom.",Yafeng Gu,2023/9/13,2023/9/13
2303.07546v1,Constrained Adversarial Learning and its applicability to Automated Software Testing: a systematic review,http://arxiv.org/abs/2303.07546v1,"Every novel technology adds hidden vulnerabilities ready to be exploited by agrowing number of cyber-attacks. Automated software testing can be a promisingsolution to quickly analyze thousands of lines of code by generating andslightly modifying function-specific testing data to encounter a multitude ofvulnerabilities and attack vectors. This process draws similarities to theconstrained adversarial examples generated by adversarial learning methods, sothere could be significant benefits to the integration of these methods inautomated testing tools. Therefore, this systematic review is focused on thecurrent state-of-the-art of constrained data generation methods applied foradversarial learning and software testing, aiming to guide researchers anddevelopers to enhance testing tools with adversarial learning methods andimprove the resilience and robustness of their digital systems. The foundconstrained data generation applications for adversarial machine learning weresystematized, and the advantages and limitations of approaches specific forsoftware testing were thoroughly analyzed, identifying research gaps andopportunities to improve testing tools with adversarial attack methods.",Joo Vitorino,2023/3/14,2023/3/14
2302.12173v2,Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection,http://arxiv.org/abs/2302.12173v2,"Large Language Models (LLMs) are increasingly being integrated into variousapplications. The functionalities of recent LLMs can be flexibly modulated vianatural language prompts. This renders them susceptible to targeted adversarialprompting, e.g., Prompt Injection (PI) attacks enable attackers to overrideoriginal instructions and employed controls. So far, it was assumed that theuser is directly prompting the LLM. But, what if it is not the user prompting?We argue that LLM-Integrated Applications blur the line between data andinstructions. We reveal new attack vectors, using Indirect Prompt Injection,that enable adversaries to remotely (without a direct interface) exploitLLM-integrated applications by strategically injecting prompts into data likelyto be retrieved. We derive a comprehensive taxonomy from a computer securityperspective to systematically investigate impacts and vulnerabilities,including data theft, worming, information ecosystem contamination, and othernovel security risks. We demonstrate our attacks' practical viability againstboth real-world systems, such as Bing's GPT-4 powered Chat and code-completionengines, and synthetic applications built on GPT-4. We show how processingretrieved prompts can act as arbitrary code execution, manipulate theapplication's functionality, and control how and if other APIs are called.Despite the increasing integration and reliance on LLMs, effective mitigationsof these emerging threats are currently lacking. By raising awareness of thesevulnerabilities and providing key insights into their implications, we aim topromote the safe and responsible deployment of these powerful models and thedevelopment of robust defenses that protect users and systems from potentialattacks.",Kai Greshake,2023/2/23,2023/5/5
2204.03649v2,Unsupervised Prompt Learning for Vision-Language Models,http://arxiv.org/abs/2204.03649v2,"Contrastive vision-language models like CLIP have shown great progress intransfer learning. In the inference stage, the proper text description, alsoknown as prompt, needs to be carefully designed to correctly classify the givenimages. In order to avoid laborious prompt engineering, recent works such asCoOp, CLIP-Adapter and Tip-Adapter propose to adapt vision-language models fordownstream image recognition tasks on a small set of labeled data. Thoughpromising improvements are achieved, requiring labeled data from the targetdatasets may restrict the scalability. In this paper, we explore a differentscenario, in which the labels of the target datasets are unprovided, and wepresent an unsupervised prompt learning (UPL) approach to avoid promptengineering while simultaneously improving transfer performance of CLIP-likevision-language models. As far as we know, UPL is the first work to introduceunsupervised learning into prompt learning. Experimentally, our UPL outperformsoriginal CLIP with prompt engineering on ImageNet as well as other 10 datasets.An enhanced version of UPL is even competitive with the 8-shot CoOp and the8-shot TIP-Adapter on most datasets. Code and models are available athttps://github.com/tonyhuang2022/UPL.",Tony Huang,2022/4/7,2022/8/22
2310.00032v2,"Pretrain, Prompt, and Transfer: Evolving Digital Twins for Time-to-Event Analysis in Cyber-physical Systems",http://arxiv.org/abs/2310.00032v2,"Cyber-Physical Systems (CPSs), e.g., elevator systems and autonomous drivingsystems, are progressively permeating our everyday lives. To ensure theirsafety, various analyses need to be conducted, such as anomaly detection andtime-to-event analysis (the focus of this paper). Recently, it has been widelyaccepted that digital Twins (DTs) can serve as an efficient method to aid inthe development, maintenance, and safe and secure operation of CPSs. However,CPSs frequently evolve, e.g., with new or updated functionalities, which demandtheir corresponding DTs be co-evolved, i.e., in synchronization with the CPSs.To that end, we propose a novel method, named PPT, utilizing anuncertainty-aware transfer learning for DT evolution. Specifically, we firstpretrain PPT with a pretraining dataset to acquire generic knowledge about theCPSs, followed by adapting it to a specific CPS with the help of prompt tuning.Results highlight that PPT is effective in time-to-event analysis in bothelevator and ADSs case studies, on average, outperforming a baseline method by7.31 and 12.58 in terms of Huber loss, respectively. The experiment resultsalso affirm the effectiveness of transfer learning, prompt tuning anduncertainty quantification in terms of reducing Huber loss by at least 21.32,3.14 and 4.08, respectively, in both case studies.",Qinghua Xu,2023/9/29,2023/10/3
2307.01446v1,On Conditional and Compositional Language Model Differentiable Prompting,http://arxiv.org/abs/2307.01446v1,"Prompts have been shown to be an effective method to adapt a frozenPretrained Language Model (PLM) to perform well on downstream tasks. Promptscan be represented by a human-engineered word sequence or by a learnedcontinuous embedding. In this work, we investigate conditional andcompositional differentiable prompting. We propose a new model, PromptProduction System (PRopS), which learns to transform task instructions or inputmetadata, into continuous prompts that elicit task-specific outputs from thePLM. Our model uses a modular network structure based on our neural formulationof Production Systems, which allows the model to learn discrete rules -- neuralfunctions that learn to specialize in transforming particular prompt inputpatterns, making it suitable for compositional transfer learning and few-shotlearning. We present extensive empirical and theoretical analysis and show thatPRopS consistently surpasses other PLM adaptation techniques, and oftenimproves upon fully fine-tuned models, on compositional generalization tasks,controllable summarization and multilingual translation, while needing fewertrainable parameters.",Jonathan Pilault,2023/7/4,2023/7/4
2309.01189v1,LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection,http://arxiv.org/abs/2309.01189v1,"The increasing volume of log data produced by software-intensive systemsmakes it impractical to analyze them manually. Many deep learning-based methodshave been proposed for log-based anomaly detection. These methods face severalchallenges such as high-dimensional and noisy log data, class imbalance,generalization, and model interpretability. Recently, ChatGPT has shownpromising results in various domains. However, there is still a lack of studyon the application of ChatGPT for log-based anomaly detection. In this work, weproposed LogGPT, a log-based anomaly detection framework based on ChatGPT. Byleveraging the ChatGPT's language interpretation capabilities, LogGPT aims toexplore the transferability of knowledge from large-scale corpora to log-basedanomaly detection. We conduct experiments to evaluate the performance of LogGPTand compare it with three deep learning-based methods on BGL and Spiritdatasets. LogGPT shows promising results and has good interpretability. Thisstudy provides preliminary insights into prompt-based models, such as ChatGPT,for the log-based anomaly detection task.",Jiaxing Qi,2023/9/3,2023/9/3
2312.03724v1,DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer,http://arxiv.org/abs/2312.03724v1,"Large Language Models (LLMs) have emerged as dominant tools for varioustasks, particularly when tailored for a specific target by prompt tuning.Nevertheless, concerns surrounding data privacy present obstacles due to thetuned prompts' dependency on sensitive private information. A practicalsolution is to host a local LLM and optimize a soft prompt privately usingdata. Yet, hosting a local model becomes problematic when model ownership isprotected. Alternative methods, like sending data to the model's provider fortraining, intensify these privacy issues facing an untrusted provider. In thispaper, we present a novel solution called Differentially-Private Offsite PromptTuning (DP-OPT) to address this challenge. Our approach involves tuning adiscrete prompt on the client side and then applying it to the desired cloudmodels. We demonstrate that prompts suggested by LLMs themselves can betransferred without compromising performance significantly. To ensure that theprompts do not leak private information, we introduce the first private promptgeneration mechanism, by a differentially-private (DP) ensemble of in-contextlearning with private demonstrations. With DP-OPT, generatingprivacy-preserving prompts by Vicuna-7b can yield competitive performancecompared to non-private in-context learning on GPT3.5 or local private prompttuning. Codes are available at https://github.com/VITA-Group/DP-OPT .",Junyuan Hong,2023/11/27,2023/11/27
2311.14708v1,Large Language Model-Driven Classroom Flipping: Empowering Student-Centric Peer Questioning with Flipped Interaction,http://arxiv.org/abs/2311.14708v1,"Reciprocal questioning is essential for effective teaching and learning,fostering active engagement and deeper understanding through collaborativeinteractions, especially in large classrooms. Can large language model (LLM),such as OpenAI's GPT (Generative Pre-trained Transformer) series, assist inthis? This paper investigates a pedagogical approach of classroom flippingbased on flipped interaction in LLMs. Flipped interaction involves usinglanguage models to prioritize generating questions instead of answers toprompts. We demonstrate how traditional classroom flipping techniques,including Peer Instruction and Just-in-Time Teaching (JiTT), can be enhancedthrough flipped interaction techniques, creating student-centric questions forhybrid teaching. In particular, we propose a workflow to integrate promptengineering with clicker and JiTT quizzes by a poll-prompt-quiz routine and aquiz-prompt-discuss routine to empower students to self-regulate their learningcapacity and enable teachers to swiftly personalize training pathways. Wedevelop an LLM-driven chatbot software that digitizes various elements ofclassroom flipping and facilitates the assessment of students using theseroutines to deliver peer-generated questions. We have applied our LLM-drivenchatbot software for teaching both undergraduate and graduate students from2020 to 2022, effectively useful for bridging the gap between teachers andstudents in remote teaching during the COVID-19 pandemic years. In particular,LLM-driven classroom flipping can be particularly beneficial in large classsettings to optimize teaching pace and enable engaging classroom experiences.",Chee Wei Tan,2023/11/14,2023/11/14
2212.05113v1,Automatically Generating CS Learning Materials with Large Language Models,http://arxiv.org/abs/2212.05113v1,"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 andCodex, now enable software developers to generate code based on a naturallanguage prompt. Within computer science education, researchers are exploringthe potential for LLMs to generate code explanations and programmingassignments using carefully crafted prompts. These advances may enable studentsto interact with code in new ways while helping instructors scale theirlearning materials. However, LLMs also introduce new implications for academicintegrity, curriculum design, and software engineering careers. This workshopwill demonstrate the capabilities of LLMs to help attendees evaluate whetherand how LLMs might be integrated into their pedagogy and research. We will alsoengage attendees in brainstorming to consider how LLMs will impact our field.",Stephen MacNeil,2022/12/9,2022/12/9
1009.2787v1,Teaching Spreadsheets: Curriculum Design Principles,http://arxiv.org/abs/1009.2787v1,"EuSpRIG concerns direct researchers to revisit spreadsheet education, takinginto account error auditing tools, checklists, and good practices. This paperaims at elaborating principles to design a spreadsheet curriculum. It mainlyfocuses on two important issues. Firstly, it is necessary to establish thespreadsheet invariants to be taught, especially those concerning errors andgood practices. Secondly, it is important to take into account the learners'ICT experience, and to encourage them to attitudes that foster self-learning.We suggest key principles for spreadsheet teaching, and we illustrate them withteaching guidelines.",Francoise Tort,2010/9/14,2010/9/14
1107.3785v1,Teaching Introductory Electrical Engineering Course to CS Students in a Russian University,http://arxiv.org/abs/1107.3785v1,"This article is about the author's experience with developing and teaching anintroductory electrical engineering course for students of Faculty (department)of Information Technology of a Russian university. The curriculum of thisdepartment conforms to typical computer science curricula of US engineeringschools with a noticeable omission of comparable electrical engineeringcourses. When developing the course, I did my best to pay attention to learningpreferences of the department's student body. I also hoped to contribute to adegree to meeting labor market demands for developers of electrical engineeringCAD software. As for inspiration, I was enchanted with ideas of the Mead &Conway revolution, albeit indirectly related to my enterprise.",Vladimir Vasilich Tregub,2011/7/19,2011/7/19
2302.03287v3,ChatGPT and Software Testing Education: Promises & Perils,http://arxiv.org/abs/2302.03287v3,"Over the past decade, predictive language modeling for code has proven to bea valuable tool for enabling new forms of automation for developers. Morerecently, we have seen the advent of general purpose ""large language models"",based on neural transformer architectures, that have been trained on massivedatasets of human written text spanning code and natural language. However,despite the demonstrated representational power of such models, interactingwith them has historically been constrained to specific task settings, limitingtheir general applicability. Many of these limitations were recently overcomewith the introduction of ChatGPT, a language model created by OpenAI andtrained to operate as a conversational agent, enabling it to answer questionsand respond to a wide variety of commands from end users. The introduction ofmodels, such as ChatGPT, has already spurred fervent discussion from educators,ranging from fear that students could use these AI tools to circumventlearning, to excitement about the new types of learning opportunities that theymight unlock. However, given the nascent nature of these tools, we currentlylack fundamental knowledge related to how well they perform in differenteducational settings, and the potential promise (or danger) that they mightpose to traditional forms of instruction. As such, in this paper, we examinehow well ChatGPT performs when tasked with answering common questions in apopular software testing curriculum. Our findings indicate that ChatGPT canprovide correct or partially correct answers in 55.6% of cases, provide corrector partially correct explanations of answers in 53.0% of cases, and thatprompting the tool in a shared question context leads to a marginally higherrate of correct responses. Based on these findings, we discuss the potentialpromises and perils related to the use of ChatGPT by students and instructors.",Sajed Jalil,2023/2/7,2023/3/11
2309.15995v1,Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems,http://arxiv.org/abs/2309.15995v1,"Anomaly detection is critical to ensure the security of cyber-physicalsystems (CPS). However, due to the increasing complexity of attacks and CPSthemselves, anomaly detection in CPS is becoming more and more challenging. Inour previous work, we proposed a digital twin-based anomaly detection method,called ATTAIN, which takes advantage of both historical and real-time data ofCPS. However, such data vary significantly in terms of difficulty. Therefore,similar to human learning processes, deep learning models (e.g., ATTAIN) canbenefit from an easy-to-difficult curriculum. To this end, in this paper, wepresent a novel approach, named digitaL twin-based Anomaly deTecTion wIthCurriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculumlearning to optimize its learning paradigm. LATTICE attributes each sample witha difficulty score, before being fed into a training scheduler. The trainingscheduler samples batches of training data based on these difficulty scoressuch that learning from easy to difficult data can be performed. To evaluateLATTICE, we use five publicly available datasets collected from five real-worldCPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-artanomaly detectors. Evaluation results show that LATTICE outperforms the threebaselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also,on average, reduces the training time of ATTAIN by 4.2% on the five datasetsand is on par with the baselines in terms of detection delay time.",Qinghua Xu,2023/9/27,2023/9/27
1407.4186v1,Bridging the Research-Practice Gap in Requirements Engineering through Effective Teaching and Peer Learning,http://arxiv.org/abs/1407.4186v1,"In this paper, we introduce the concept of the research practice gap as it isperceived in the field of software requirements engineering. An analysis ofthis gap has shown that two key causes for the research-practice gap are lackof effective communication and the relatively light coverage of requirementsengineering material in University programmes. We discuss the design anddelivery of a Masters course in Software Requirements Engineering (SRE) that isdesigned to overcome some of the issues that have caused the research-practicegap. By encouraging students to share their experiences in a peer learningenvironment, we aim to improve shared understanding between students (many ofwhom are current industry practitioners) and researchers (including academicstaff members) to improve the potential for effective collaborations, whilstsimultaneously developing the requirements engineering skill sets of theenrolled students. Feedback from students in the course is discussed anddirections for the future development of the curriculum and learning strategiesare given.",Andrew M. Connor,2014/7/16,2014/7/16
1703.02944v1,"""Tell me and I forget, teach me and I may remember, involve me and I learn"": changing the approach of teaching Computer Organization",http://arxiv.org/abs/1703.02944v1,Millennials are arriving to university sometimes uncomfortable with themethods of some courses. Ideas that worked with previous generations ofstudents begin to fail when digital natives receive paper and pencil as tools.Courses must update from old paper-based methods to hands-on and computerizedversions. The present work discusses about this update and comments on oneimplementation in the course Computer Organization of the Computer Sciencecurriculum at Universidad de Buenos Aires. It also includes some metrics thatshow the effectiveness of the changes in attracting and engaging the digitalgeneration.,Matas Lopez-Rosenfeld,2017/3/8,2017/3/8
1401.5111v1,"The Art of Software Design, a Video Game for Learning Software Design Principles",http://arxiv.org/abs/1401.5111v1,"This paper introduces our gamification of a part of our software designcurriculum. Based on typical design principles a motivating learning game isdeveloped to train students in software design. We use Bloom's taxonomy todetermine learning objectives. We keep the player engaged with direct feedbackin a challenging level based game with increasing complexity. Players canevaluate their design actions with the help of the visualisation of control anddata flows. The main learning objective: applying design principles, fits thegame's main activity. This supports the learning by doing approach oflecturers. A user test indicates possible learning effects and a playable game.",Dave R. Stikkolorum,2014/1/20,2014/1/20
2312.10557v1,Improving Environment Robustness of Deep Reinforcement Learning Approaches for Autonomous Racing Using Bayesian Optimization-based Curriculum Learning,http://arxiv.org/abs/2312.10557v1,"Deep reinforcement learning (RL) approaches have been broadly applied to alarge number of robotics tasks, such as robot manipulation and autonomousdriving. However, an open problem in deep RL is learning policies that arerobust to variations in the environment, which is an important condition forsuch systems to be deployed into real-world, unstructured settings. Curriculumlearning is one approach that has been applied to improve generalizationperformance in both supervised and reinforcement learning domains, butselecting the appropriate curriculum to achieve robustness can be auser-intensive process. In our work, we show that performing probabilisticinference of the underlying curriculum-reward function using BayesianOptimization can be a promising technique for finding a robust curriculum. Wedemonstrate that a curriculum found with Bayesian optimization can outperform avanilla deep RL agent and a hand-engineered curriculum in the domain ofautonomous racing with obstacle avoidance. Our code is available athttps://github.com/PRISHIta123/Curriculum_RL_for_Driving.",Rohan Banerjee,2023/12/16,2023/12/16
1905.07193v1,MaMiC: Macro and Micro Curriculum for Robotic Reinforcement Learning,http://arxiv.org/abs/1905.07193v1,"Shaping in humans and animals has been shown to be a powerful tool forlearning complex tasks as compared to learning in a randomized fashion. Thismakes the problem less complex and enables one to solve the easier sub task athand first. Generating a curriculum for such guided learning involvessubjecting the agent to easier goals first, and then gradually increasing theirdifficulty. This paper takes a similar direction and proposes a dual curriculumscheme for solving robotic manipulation tasks with sparse rewards, calledMaMiC. It includes a macro curriculum scheme which divides the task intomultiple sub-tasks followed by a micro curriculum scheme which enables theagent to learn between such discovered sub-tasks. We show how combining macroand micro curriculum strategies help in overcoming major exploratoryconstraints considered in robot manipulation tasks without having to engineerany complex rewards. We also illustrate the meaning of the individual curriculaand how they can be used independently based on the task. The performance ofsuch a dual curriculum scheme is analyzed on the Fetch environments.",Manan Tomar,2019/5/17,2019/5/17
2307.07846v1,AIOptimizer -- A reinforcement learning-based software performance optimisation prototype for cost minimisation,http://arxiv.org/abs/2307.07846v1,"This research article introduces AIOptimizer, a prototype for a softwareperformance optimisation tool based on cost reduction. AIOptimizer uses arecommendation system driven by reinforcement learning to improve softwaresystem efficiency and affordability. The paper highlights AIOptimizer's designfactors, such as accuracy, adaptability, scalability, and user-friendliness. Toprovide effective and user-centric performance optimisation solutions, itemphasises the use of a modular design, data gathering techniques, continuouslearning, and resilient integration. The article also investigates AIOptimizerfeatures such as fault identification, cost optimisation recommendations,efficiency prediction, and cooperation. Furthermore, it explores severalsoftware development life cycle models and introduces AIOptimizer uses areinforcement learning-based recommendation engine for cost optimisation. Thepurpose of this research study is to highlight AIOptimizer as a prototype thatuses advanced optimisation techniques and smart recommendation systems tocontinually enhance software performance and save expenses. The researchfocuses on various software development life cycle models, such as theWaterfall model, Iterative model, Spiral model, V-Model, Big Bang model andAgile Model. Each model has advantages and disadvantages, and their usefulnessis determined by the project's specifications and characteristics. TheAIOptimizer tool is a theoretical prototype for such software performanceoptimizers.",Noopur Zambare,2023/7/15,2023/7/15
2012.14178v2,Experiential Learning Approach for Software Engineering Courses at Higher Education Level,http://arxiv.org/abs/2012.14178v2,"Background: Software project management activities help to introduce softwareprocess models in Software Engineering courses. However, these activitiesshould be adequately aligned with the learning outcomes and support student'sprogression.  Objective: Present and evaluate an approach to help students acquiretheoretical and practical knowledge and experience real-world softwareprojects' challenges. The approach combines a serious game and adesign-implement task in which students develop a controlled-scale softwaresystem.  Method: To evaluate our approach, we analyzed the students' perceptionscollected through an online survey, their project plans, and their finalreports using thematic analysis.  Results: Results suggest that the approach promotes knowledge acquisition,enables students' progression, reinforces theoretical concepts, and is properlyaligned with the course's learning outcomes.  Conclusion: The approach seems to help to introduce software process modelsin Software Engineering courses. Our experience can also be inspiring foreducators willing to apply our approach in similar courses.",Javier Gonzalez-Huerta,2020/12/28,2021/1/20
2309.14391v1,An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems,http://arxiv.org/abs/2309.14391v1,"Deep Reinforcement Learning (Deep RL) is increasingly used to cope with theopen-world assumption in service-oriented systems. Deep RL was successfullyapplied to problems such as dynamic service composition, job scheduling, andoffloading, as well as service adaptation. While Deep RL offers many benefits,understanding the decision-making of Deep RL is challenging because its learneddecision-making policy essentially appears as a black box. Yet, understandingthe decision-making of Deep RL is key to help service developers performdebugging, support service providers to comply with relevant legal frameworks,and facilitate service users to build trust. We introduce Chat4XAI tofacilitate the understanding of the decision-making of Deep RL by providingnatural-language explanations. Compared with visual explanations, the reportedbenefits of natural-language explanations include better understandability fornon-technical users, increased user acceptance and trust, as well as moreefficient explanations. Chat4XAI leverages modern AI chatbot technology anddedicated prompt engineering. Compared to earlier work on natural-languageexplanations using classical software-based dialogue systems, using an AIchatbot eliminates the need for eliciting and defining potential questions andanswers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT APIand evaluate the fidelity and stability of its explanations using an adaptiveservice exemplar.",Andreas Metzger,2023/9/25,2023/9/25
2009.13265v1,Deep Reinforcement Learning for Process Synthesis,http://arxiv.org/abs/2009.13265v1,"This paper demonstrates the application of reinforcement learning (RL) toprocess synthesis by presenting Distillation Gym, a set of RL environments inwhich an RL agent is tasked with designing a distillation train, given a userdefined multi-component feed stream. Distillation Gym interfaces with a processsimulator (COCO and ChemSep) to simulate the environment. A demonstration oftwo distillation problem examples are discussed in this paper (a Benzene,Toluene, P-xylene separation problem and a hydrocarbon separation problem), inwhich a deep RL agent is successfully able to learn within Distillation Gym toproduce reasonable designs. Finally, this paper proposes the creation ofChemical Engineering Gym, an all-purpose reinforcement learning softwaretoolkit for chemical engineering process synthesis.",Laurence Illing Midgley,2020/9/23,2020/9/23
2201.12602v1,DeepRNG: Towards Deep Reinforcement Learning-Assisted Generative Testing of Software,http://arxiv.org/abs/2201.12602v1,"Although machine learning (ML) has been successful in automating varioussoftware engineering needs, software testing still remains a highly challengingtopic. In this paper, we aim to improve the generative testing of software bydirectly augmenting the random number generator (RNG) with a deep reinforcementlearning (RL) agent using an efficient, automatically extractable staterepresentation of the software under test. Using the Cosmos SDK as the testbed,we show that the proposed DeepRNG framework provides a statisticallysignificant improvement to the testing of the highly complex software librarywith over 350,000 lines of code. The source code of the DeepRNG framework ispublicly available online.",Chuan-Yung Tsai,2022/1/29,2022/1/29
1910.13356v1,"Real-time Timepix3 data clustering, visualization and classification with a new Clusterer framework",http://arxiv.org/abs/1910.13356v1,"With the next-generation Timepix3 hybrid pixel detector, new possibilitiesand challenges have arisen. The Timepix3 segments active sensor area of 1.98$cm^2$ into a square matrix of 256 x 256 pixels. In each pixel, the Time ofArrival (ToA, with a time binning of 1.56 $ns$) and Time over Threshold (ToT,energy) are measured simultaneously in a data-driven, i.e. self-triggered,read-out scheme. This contribution presents a framework for data acquisition,real-time clustering, visualization, classification and data saving. All ofthese tasks can be performed online, directly from multiple readouts throughUDP protocol. Clusters are reconstructed on a pixel-by-pixel decision from thestream of not-necessarily chronologically sorted pixel data. To achieve quickspatial pixel-to-cluster matching, non-trivial data structures (quadtree) areutilized. Furthermore, parallelism (i.e multi-threaded architecture) is used tofurther improve the performance of the framework. Such real-time clusteringoffers the advantages of online filtering and classification of events.Versatility of the software is ensured by supporting all major operatingsystems (macOS, Windows and Linux) with both graphical and command-lineinterfaces. The performance of the real-time clustering and applied filtrationmethods are demonstrated using data from the Timepix3 network installed in theATLAS and MoEDAL experiments at CERN.",Luk Meduna,2019/10/29,2019/10/29
1912.08122v2,Estimating the maximum gravitational mass of nonrotating neutron stars from the GW170817/GRB 170817A/AT2017gfo observation,http://arxiv.org/abs/1912.08122v2,"Assuming that the differential rotation of the massive neutron star (NS)formed in the double NS (DNS) mergers has been effectively terminated by themagnetic braking and a uniform rotation has been subsequently established(i.e., a supramassive NS is formed), we analytically derive in this work anapproximated expression for the critical total gravitational mass ($M_{\rmtot,c}$) to form supramassive NS (SMNS) in the DNS mergers, benefited from someequation of state (EoS) insensitive relationships. The maximum gravitationalmass of the nonrotating NSs ($M_{\rm TOV}$) as well as the dimensionlessangular momentum of the remnant ($j$) play the dominant roles in modifying$M_{\rm tot,c}$, while the radius and mass differences of the premerger NSs donot. The GW170817/GRB 170817A/AT2017gfo observations have provided so far thebest opportunity to quantitatively evaluate $M_{\rm TOV}$. Supposing thecentral engine for GRB 170817A is a black hole quickly formed in the collapseof an SMNS, we find $M_{\rm TOV}=2.13^{+0.09}_{-0.08}M_\odot$ (68.3%credibility interval, including also the uncertainties of the EoS insensitiverelationships), which is consistent with the constraints set by current NS massmeasurements.",Dong-Sheng Shao,2019/12/17,2020/3/30
2105.08887v1,Dialogue Disentanglement in Software Engineering: How Far are We?,http://arxiv.org/abs/2105.08887v1,"Despite the valuable information contained in software chat messages,disentangling them into distinct conversations is an essential prerequisite forany in-depth analyses that utilize this information. To provide a betterunderstanding of the current state-of-the-art, we evaluate five popular dialogdisentanglement approaches on software-related chat. We find that existingapproaches do not perform well on disentangling software-related dialogs thatdiscuss technical and complex topics. Further investigation on how well theexisting disentanglement measures reflect human satisfaction shows thatexisting measures cannot correctly indicate human satisfaction ondisentanglement results. Therefore, in this paper, we introduce and evaluate anovel measure, named DLD. Using results of human satisfaction, we furthersummarize four most frequently appeared bad disentanglement cases onsoftware-related chat to insight future improvements. These cases include (i)ignoring interaction patterns; (ii) ignoring contextual information; (iii)mixing up topics; and (iv) ignoring user relationships. We believe that ourfindings provide valuable insights on the effectiveness of existing dialogdisentanglement approaches and these findings would promote a betterapplication of dialog disentanglement in software engineering.",Ziyou Jiang,2021/5/19,2021/5/19
1803.09529v1,Poster: Communication in Open-Source Projects--End of the E-mail Era?,http://arxiv.org/abs/1803.09529v1,"Communication is essential in software engineering. Especially in distributedopen-source teams, communication needs to be supported by channels includingmailing lists, forums, issue trackers, and chat systems. Yet, we do not have aclear understanding of which communication channels stakeholders in open-sourceprojects use. In this study, we fill the knowledge gap by investigating astatistically representative sample of 400 GitHub projects. We discover theused communication channels by regular expressions on project data. We showthat (1) half of the GitHub projects use observable communication channels; (2)GitHub Issues, e-mail addresses, and the modern chat system Gitter are the mostcommon channels; (3) mailing lists are only in place five and have a lowermarket share than all modern chat systems combined.",Verena Kfer,2018/3/26,2018/3/26
2204.09368v1,BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats,http://arxiv.org/abs/2204.09368v1,"In community-based software development, developers frequently rely onlive-chatting to discuss emergent bugs/errors they encounter in dailydevelopment tasks. However, it remains a challenging task to accurately recordsuch knowledge due to the noisy nature of interleaved dialogs in live chatdata. In this paper, we first formulate the task of identifying andsynthesizing bug reports from community live chats, and propose a novelapproach, named BugListener, to address the challenges. Specifically,BugListener automates three sub-tasks: 1) Disentangle the dialogs from massivechat logs by using a Feed-Forward neural network; 2) Identify the bug-reportdialogs from separated dialogs by modeling the original dialog to thegraph-structured dialog and leveraging the graph neural network to learn thecontextual information; 3) Synthesize the bug reports by utilizing the TextCNNmodel and Transfer Learning network to classify the sentences into threegroups: observed behaviors (OB), expected behaviors (EB), and steps toreproduce the bug (SR). BugListener is evaluated on six open source projects.The results show that: for bug report identification, BugListener achieves theaverage F1 of 74.21%, improving the best baseline by 10.37%; and for bug reportsynthesis task, BugListener could classify the OB, EB, and SR sentences withthe F1 of 67.37%, 87.14%, and 65.03%, improving the best baselines by 7.21%,7.38%, 5.30%, respectively. A human evaluation also confirms the effectivenessof BugListener in generating relevant and accurate bug reports. Thesedemonstrate the significant potential of applying BugListener incommunity-based software development, for promoting bug discovery and qualityimprovement.",Lin Shi,2022/4/20,2022/4/20
2107.05823v1,A First Look at Developers' Live Chat on Gitter,http://arxiv.org/abs/2107.05823v1,"Modern communication platforms such as Gitter and Slack play an increasinglycritical role in supporting software teamwork, especially in open sourcedevelopment.Conversations on such platforms often contain intensive, valuableinformation that may be used for better understanding OSS developercommunication and collaboration. However, little work has been done in thisregard. To bridge the gap, this paper reports a first comprehensive empiricalstudy on developers' live chat, investigating when they interact, whatcommunity structures look like, which topics are discussed, and how theyinteract. We manually analyze 749 dialogs in the first phase, followed by anautomated analysis of over 173K dialogs in the second phase. We find thatdevelopers tend to converse more often on weekdays, especially on Wednesdaysand Thursdays (UTC), that there are three common community structures observed,that developers tend to discuss topics such as API usages and errors, and thatsix dialog interaction patterns are identified in the live chat communities.Based on the findings, we provide recommendations for individual developers andOSS communities, highlight desired features for platform vendors, and shedlight on future research directions. We believe that the findings and insightswill enable a better understanding of developers' live chat, pave the way forother researchers, as well as a better utilization and mining of knowledgeembedded in the massive chat history.",Lin Shi,2021/7/13,2021/7/13
2005.13969v2,An Empirical Study of Bots in Software Development -- Characteristics and Challenges from a Practitioner's Perspective,http://arxiv.org/abs/2005.13969v2,"Software engineering bots - automated tools that handle tedious tasks - areincreasingly used by industrial and open source projects to improve developerproductivity. Current research in this area is held back by a lack of consensusof what software engineering bots (DevBots) actually are, what characteristicsdistinguish them from other tools, and what benefits and challenges areassociated with DevBot usage. In this paper we report on a mixed-methodempirical study of DevBot usage in industrial practice. We report on findingsfrom interviewing 21 and surveying a total of 111 developers. We identify threedifferent personas among DevBot users (focusing on autonomy, chat interfaces,and ""smartness""), each with different definitions of what a DevBot is, whydevelopers use them, and what they struggle with. We conclude that futureDevBot research should situate their work within our framework, to clearlyidentify what type of bot the work targets, and what advantages practitionerscan expect. Further, we find that there currently is a lack of general purpose""smart"" bots that go beyond simple automation tools or chat interfaces. This isproblematic, as we have seen that such bots, if available, can have atransformative effect on the projects that use them.",Linda Erlenhov,2020/5/28,2020/10/29
2109.07055v1,ISPY: Automatic Issue-Solution Pair Extraction from Community Live Chats,http://arxiv.org/abs/2109.07055v1,"Collaborative live chats are gaining popularity as a developmentcommunication tool. In community live chatting, developers are likely to postissues they encountered (e.g., setup issues and compile issues), and otherdevelopers respond with possible solutions. Therefore, community live chatscontain rich sets of information for reported issues and their correspondingsolutions, which can be quite useful for knowledge sharing and future reuse ifextracted and restored in time. However, it remains challenging to accuratelymine such knowledge due to the noisy nature of interleaved dialogs in live chatdata. In this paper, we first formulate the problem of issue-solution pairextraction from developer live chat data, and propose an automated approach,named ISPY, based on natural language processing and deep learning techniqueswith customized enhancements, to address the problem. Specifically, ISPYautomates three tasks: 1) Disentangle live chat logs, employing a feedforwardneural network to disentangle a conversation history into separate dialogsautomatically; 2) Detect dialogs discussing issues, using a novel convolutionalneural network (CNN), which consists of a BERT-based utterance embedding layer,a context-aware dialog embedding layer, and an output layer; 3) Extractappropriate utterances and combine them as corresponding solutions, based onthe same CNN structure but with different feeding inputs. To evaluate ISPY, wecompare it with six baselines, utilizing a dataset with 750 dialogs including171 issue-solution pairs and evaluate ISPY from eight open source communities.The results show that, for issue-detection, our approach achieves the F1 of76%, and outperforms all baselines by 30%. Our approach achieves the F1 of 63%for solution-extraction and outperforms the baselines by 20%.",Lin Shi,2021/9/15,2021/9/15
2009.09824v1,Identifying the Mood of a Software Development Team by Analyzing Text-Based Communication in Chats with Machine Learning,http://arxiv.org/abs/2009.09824v1,"Software development encompasses many collaborative tasks in which usuallyseveral persons are involved. Close collaboration and the synchronization ofdifferent members of the development team require effective communication. Oneestablished communication channel are meetings which are, however, often not aseffective as expected. Several approaches already focused on the analysis ofmeetings to determine the reasons for inefficiency and dissatisfying meetingoutcomes. In addition to meetings, text-based communication channels such aschats and e-mails are frequently used in development teams. Communication viathese channels requires a similar appropriate behavior as in meetings toachieve a satisfying and expedient collaboration. However, these channels havenot yet been extensively examined in research. In this paper, we present anapproach for analyzing interpersonal behavior in text-based communicationconcerning the conversational tone, the familiarity of sender and receiver, thesender's emotionality, and the appropriateness of the used language. Weevaluate our approach in an industrial case study based on 1947 messages sentin a group chat in Zulip over 5.5 months. Using our approach, it was possibleto automatically classify written sentences as positive, neutral, or negativewith an average accuracy of 62.97% compared to human ratings. Despite thiscoarse-grained classification, it is possible to gain an overall picture of theadequacy of the textual communication and tendencies in the group mood.",Jil Klnder,2020/9/21,2020/9/21
2305.16837v1,ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks,http://arxiv.org/abs/2305.16837v1,"ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched byOpenAI on November 30, 2022. OpenAI's GPT-3 family of large language modelsserve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervisedand reinforcement learning techniques and has received widespread attention forits articulate responses across diverse domains of knowledge. In this study, weexplore how ChatGPT can be used to help with common software engineering tasks.Many of the ubiquitous tasks covering the breadth of software engineering suchas ambiguity resolution in software requirements, method name suggestion, testcase prioritization, code review, log summarization can potentially beperformed using ChatGPT. In this study, we explore fifteen common softwareengineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answerswith the respective state of the art outputs (where available) and/or humanexpert ground truth. Our experiments suggest that for many tasks, ChatGPT doesperform credibly and the response from it is detailed and often better than thehuman expert output or the state of the art output. However, for a few othertasks, ChatGPT in its present form provides incorrect answers and hence is notsuited for such tasks.",Giriprasad Sridhara,2023/5/26,2023/5/26
1808.05409v2,Using Experience Sampling to link Software Repositories with Emotions and Work Well-Being,http://arxiv.org/abs/1808.05409v2,"Background: The experience sampling method studies everyday experiences ofhumans in natural environments. In psychology it has been used to study therelationships between work well-being and productivity. To our best knowledge,daily experience sampling has not been previously used in software engineering.Aims: Our aim is to identify links between software developers self-reportedaffective states and work well-being and measures obtained from softwarerepositories. Method: We perform an experience sampling study in a softwarecompany for a period of eight months, we use logistic regression to link thewell-being measures with development activities, i.e. number of commits andchat messages. Results: We find several significant relationships betweenquestionnaire variables and software repository variables. To our surpriserelationship between hurry and number of commits is negative, meaning moreperceived hurry is linked with a smaller number of commits. We also find anegative relationship between social interaction and hindered work well-being.Conclusions: The negative link between commits and hurry is counter-intuitiveand goes against previous lab-experiments in software engineering that showincreased efficiency under time pressure. Overall, our work is an initial stepin using experience sampling in software engineering and validating theories onwork well-being from other fields in the domain of software engineering.",Miikka Kuutila,2018/8/16,2018/9/4
2111.04507v1,Ontology-based question answering over corporate structured data,http://arxiv.org/abs/2111.04507v1,"Ontology-based approach to the Natural Language Understanding (NLU)processing allows to improve questions answering quality in dialogue systems.We describe our NLU engine architecture and evaluate its implementation. Theengine transforms user input into the SPARQL SELECT, ASK or INSERT query to theknowledge graph provided by the ontology-based data virtualization platform.The transformation is based on the lexical level of the knowledge graph builtaccording to the Ontolex ontology. The described approach can be applied forgraph data population tasks and to the question answering systemsimplementation, including chat bots. We describe the dialogue engine for a chatbot which can keep the conversation context and ask clarifying questions,simulating some aspects of the human logical thinking. Our approach usesgraph-based algorithms to avoid gathering datasets, required in the neuralnets-based approaches, and provide better explainability of our models. Usingquestion answering engine in conjunction with data virtualization layer overthe corporate data sources allows extracting facts from the structured data tobe used in conversation.",Sergey Gorshkov,2021/11/8,2021/11/8
1806.03513v1,Improving the Reliability of Mobility Applications,http://arxiv.org/abs/1806.03513v1,"The Android platform was introduced by Google in 2008 as an operating systemfor mobile devices. Android's SDK provides a wide support for programming andextensive examples and documentation. Reliability is an increasing concern forSmart Phone applications since they often feature personal information anddata. Therefore, techniques and tools for checking the correct behavior of appsare required. This paper shows how the Event-B method can be used to reason andto verify the design of Android apps and how this can be used to documentimplementation decisions. Our approach consists in modeling the corefunctionality of the app in Event-B and using the evidence shown by the ProofObligations generated to reason about the design and the implementation of theapp. Although we do not propose a novel approach, we prove that heavyweightFormal Methods (FMs) techniques with Event-B can effectively be used to supportthe development of correct Android apps. We present a case study in which wedesign the core functionality of WhatsApp in Event-B, we encode it over threemachine refinements modeling basic functionality (chatting, deleting content,forwarding content, deleting a chat session, etc.), read and unread status ofchat sessions, and implementation details, respectively. We report and discusson underlying challenges in the design and implementation of the corefunctionality.",Nstor Catao,2018/6/9,2018/6/9
2311.00272v1,ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation,http://arxiv.org/abs/2311.00272v1,"Large language models have shown good performances in generating code to meethuman requirements. However, human requirements expressed in natural languagescan be vague, incomplete, and ambiguous, leading large language models tomisunderstand human requirements and make mistakes. Worse, it is difficult fora human user to refine the requirement. To help human users refine theirrequirements and improve large language models' code generation performances,we propose ChatCoder: a method to refine the requirements via chatting withlarge language models. We design a chat scheme in which the large languagemodels will guide the human users to refine their expression of requirements tobe more precise, unambiguous, and complete than before. Experiments show thatChatCoder has improved existing large language models' performance by a largemargin. Besides, ChatCoder has the advantage over refine-based methods and LLMsfine-tuned via human response.",Zejun Wang,2023/11/1,2023/11/1
2307.07924v4,Communicative Agents for Software Development,http://arxiv.org/abs/2307.07924v4,"Software engineering is a domain characterized by intricate decision-makingprocesses, often relying on nuanced intuition and consultation. Recentadvancements in deep learning have started to revolutionize softwareengineering practices through elaborate designs implemented at various stagesof software development. In this paper, we present an innovative paradigm thatleverages large language models (LLMs) throughout the entire softwaredevelopment process, streamlining and unifying key processes through naturallanguage communication, thereby eliminating the need for specialized models ateach phase. At the core of this paradigm lies ChatDev, a virtual chat-poweredsoftware development company that mirrors the established waterfall model,meticulously dividing the development process into four distinct chronologicalstages: designing, coding, testing, and documenting. Each stage engages a teamof ""software agents"", such as programmers, code reviewers, and test engineers,fostering collaborative dialogue and facilitating a seamless workflow. The chatchain acts as a facilitator, breaking down each stage into atomic subtasks.This enables dual roles, allowing for proposing and validating solutionsthrough context-aware communication, leading to efficient resolution ofspecific subtasks. The instrumental analysis of ChatDev highlights itsremarkable efficacy in software generation, enabling the completion of theentire software development process in under seven minutes at a cost of lessthan one dollar. It not only identifies and alleviates potentialvulnerabilities but also rectifies potential hallucinations while maintainingcommendable efficiency and cost-effectiveness. The potential of ChatDev unveilsfresh possibilities for integrating LLMs into the realm of softwaredevelopment. Our code is available at https://github.com/OpenBMB/ChatDev.",Chen Qian,2023/7/16,2023/12/19
1204.4224v3,Software Mutational Robustness,http://arxiv.org/abs/1204.4224v3,"Neutral landscapes and mutational robustness are believed to be importantenablers of evolvability in biology. We apply these concepts to software,defining mutational robustness to be the fraction of random mutations thatleave a program's behavior unchanged. Test cases are used to measure programbehavior and mutation operators are taken from genetic programming. Althoughsoftware is often viewed as brittle, with small changes leading to catastrophicchanges in behavior, our results show surprising robustness in the face ofrandom software mutations.  The paper describes empirical studies of the mutational robustness of 22programs, including 14 production software projects, the Siemens benchmarks,and 4 specially constructed programs. We find that over 30% of random mutationsare neutral with respect to their test suite. The results hold across allclasses of programs, for mutations at both the source code and assemblyinstruction levels, across various programming languages, and are only weaklyrelated to test suite coverage. We conclude that mutational robustness is aninherent property of software, and that neutral variants (i.e., those that passthe test suite) often fulfill the program's original purpose or specification.  Based on these results, we conjecture that neutral mutations can be leveragedas a mechanism for generating software diversity. We demonstrate this idea bygenerating a population of neutral program variants and showing that thevariants automatically repair unknown bugs with high probability. Neutrallandscapes also provide a partial explanation for recent results that useevolutionary computation to automatically repair software bugs.",Eric Schulte,2012/4/18,2013/6/27
2104.13100v4,Shellcode_IA32: A Dataset for Automatic Shellcode Generation,http://arxiv.org/abs/2104.13100v4,"We take the first step to address the task of automatically generatingshellcodes, i.e., small pieces of code used as a payload in the exploitation ofa software vulnerability, starting from natural language comments. We assembleand release a novel dataset (Shellcode_IA32), consisting of challenging butcommon assembly instructions with their natural language descriptions. Weexperiment with standard methods in neural machine translation (NMT) toestablish baseline performance levels on this task.",Pietro Liguori,2021/4/27,2022/3/18
2401.07565v1,Call graph discovery in binary programs from unknown instruction set architectures,http://arxiv.org/abs/2401.07565v1,"This study addresses the challenge of reverse engineering binaries fromunknown instruction set architectures, a complex task with potentialimplications for software maintenance and cyber-security. We focus on the tasksof detecting candidate call and return opcodes for automatic extraction of callgraphs in order to simplify the reverse engineering process. Empirical testingon a small dataset of binary files from different architectures demonstratesthat the approach can accurately detect specific opcodes under conditions ofnoisy data. The method lays the groundwork for a valuable tool for reverseengineering where the reverse engineer has minimal a priori knowledge of theunderlying instruction set architecture.",Hvard Pettersen,2024/1/15,2024/1/15
1204.0221v1,MyProLang - My Programming Language: A Template-Driven Automatic Natural Programming Language,http://arxiv.org/abs/1204.0221v1,"Modern computer programming languages are governed by complex syntacticrules. They are unlike natural languages; they require extensive manual workand a significant amount of learning and practicing for an individual to becomeskilled at and to write correct programs. Computer programming is a difficult,complicated, unfamiliar, non-automated, and a challenging discipline foreveryone; especially, for students, new programmers and end-users. This paperproposes a new programming language and an environment for writing computerapplications based on source-code generation. It is mainly a template-drivenautomatic natural imperative programming language called MyProLang. Itharnesses GUI templates to generate proprietary natural language source-code,instead of having computer programmers write the code manually. MyProLang is ablend of five elements. A proprietary natural programming language withunsophisticated grammatical rules and expressive syntax; automation templatesthat automate the generation of instructions and thereby minimizing thelearning and training time; an NLG engine to generate natural instructions; asource-to-source compiler that analyzes, parses, and build executables; and anergonomic IDE that houses diverse functions whose role is to simplify thesoftware development process. MyProLang is expected to make programming open toeveryone including students, programmers and end-users. In that sense, anyonecan start programming systematically, in an automated manner and in naturallanguage; without wasting time in learning how to formulate instructions andarrange expressions, without putting up with unfamiliar structures and symbols,and without being annoyed by syntax errors. In the long run, this increases theproductivity, quality and time-to-market in software development.",Youssef Bassil,2012/4/1,2012/4/1
2106.14332v1,A Case Study of LLVM-Based Analysis for Optimizing SIMD Code Generation,http://arxiv.org/abs/2106.14332v1,"This paper presents a methodology for using LLVM-based tools to tune theDCA++ (dynamical clusterapproximation) application that targets the new ARMA64FX processor. The goal is to describethe changes required for the newarchitecture and generate efficient single instruction/multiple data(SIMD)instructions that target the new Scalable Vector Extension instruction set.During manualtuning, the authors used the LLVM tools to improve codeparallelization by using OpenMP SIMD,refactored the code and appliedtransformation that enabled SIMD optimizations, and ensured thatthe correctlibraries were used to achieve optimal performance. By applying these codechanges, codespeed was increased by 1.98X and 78 GFlops were achieved on theA64FX processor. The authorsaim to automatize parts of the efforts in theOpenMP Advisor tool, which is built on top of existingand newly introduced LLVMtooling.",Joseph Huber,2021/6/27,2021/6/27
1809.00912v2,Automated Instruction Stream Throughput Prediction for Intel and AMD Microarchitectures,http://arxiv.org/abs/1809.00912v2,"An accurate prediction of scheduling and execution of instruction streams isa necessary prerequisite for predicting the in-core performance behavior ofthroughput-bound loop kernels on out-of-order processor architectures. Suchpredictions are an indispensable component of analytical performance models,such as the Roofline and the Execution-Cache-Memory (ECM) model, and allow adeep understanding of the performance-relevant interactions between hardwarearchitecture and loop code. We present the Open Source Architecture CodeAnalyzer (OSACA), a static analysis tool for predicting the execution time ofsequential loops comprising x86 instructions under the assumption of aninfinite first-level cache and perfect out-of-order scheduling. We show theprocess of building a machine model from available documentation andsemi-automatic benchmarking, and carry it out for the latest Intel Skylake andAMD Zen micro-architectures. To validate the constructed models, we apply themto several assembly kernels and compare runtime predictions with actualmeasurements. Finally we give an outlook on how the method may be generalizedto new architectures.",Jan Laukemann,2018/9/4,2018/10/10
0909.5012v1,IRPF90: a programming environment for high performance computing,http://arxiv.org/abs/0909.5012v1,"IRPF90 is a Fortran programming environment which helps the development oflarge Fortran codes. In Fortran programs, the programmer has to focus on theorder of the instructions: before using a variable, the programmer has to besure that it has already been computed in all possible situations. For largecodes, it is common source of error. In IRPF90 most of the order ofinstructions is handled by the pre-processor, and an automatic mechanismguarantees that every entity is built before being used. This mechanism relieson the {needs/needed by} relations between the entities, which are builtautomatically. Codes written with IRPF90 execute often faster than Fortranprograms, are faster to write and easier to maintain.",Anthony Scemama,2009/9/28,2009/9/28
2312.14898v1,Enriching Automatic Test Case Generation by Extracting Relevant Test Inputs from Bug Reports,http://arxiv.org/abs/2312.14898v1,"The quality of a software is highly dependent on the quality of the tests itis submitted to. Writing tests for bug detection is thus essential. However, itis time-consuming when done manually. Automating test cases generation hastherefore been an exciting research area in the software engineering community.Most approaches have been focused on generating unit tests. Unfortunately,current efforts often do not lead to the generation of relevant inputs, whichlimits the efficiency of automatically generated tests. Towards improving therelevance of test inputs, we present \name, a technique for exploring bugreports to identify input values that can be fed to automatic test generationtools. In this work, we investigate the performance of using inputs extractedfrom bug reports with \name to generate test cases with Evosuite. Theevaluation is performed on the Defects4J benchmark. For Defects4J projects, ourstudy has shown that \name successfully extracted 68.68\% of relevant inputswhen using regular expression in its approach versus 50.21\% relevant inputswithout regular expression. Further, our study has shown the potential toimprove the Line and Instruction Coverage across all projects. Overall, wesuccessfully collected relevant inputs that led to the detection of 45 bugsthat were previously undetected by the baseline.",Wendkuni C. Oudraogo,2023/12/22,2023/12/22
2106.01115v1,Efficient and Expressive Bytecode-Level Instrumentation for Java Programs,http://arxiv.org/abs/2106.01115v1,"We present an efficient and expressive tool for the instrumentation of Javaprograms at the bytecode-level. BISM (Bytecode-Level Instrumentation forSoftware Monitoring) is a light-weight Java bytecode instrumentation tool thatfeatures an expressive high-level control-flow-aware instrumentation language.The language is inspired by the aspect-oriented programming paradigm inmodularizing instrumentation into separate transformers, that encapsulatejoinpoint selection and advice inlining. BISM allows capturing joinpointsranging from bytecode instructions to methods execution and providescomprehensive static and dynamic context information. It runs in twoinstrumentation modes: build-time and load-time. BISM also provides a mechanismto compose transformers and automatically detect their collision in the baseprogram. Transformers in a composition can control the visibility of theiradvice and other instructions from the base program. We show several exampleapplications for BISM and demonstrate its effectiveness using threeexperiments: a security scenario, a financial transaction system, and a generalruntime verification case. The results show that BISM instrumentation incurslow runtime and memory overheads.",Chukri Soueidi,2021/6/2,2021/6/2
2312.14187v3,WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation,http://arxiv.org/abs/2312.14187v3,"Recent work demonstrates that, after being fine-tuned on a high-qualityinstruction dataset, the resulting model can obtain impressive capabilities toaddress a wide range of tasks. However, existing methods for instruction datageneration often produce duplicate data and are not controllable enough on dataquality. In this paper, we extend the generalization of instruction tuning byclassifying the instruction data to 4 code-related tasks and propose aLLM-based Generator-Discriminator data process framework to generate diverse,high-quality instruction data from open source code. Hence, we introduceCodeOcean, a dataset comprising 20,000 instruction instances across 4 universalcode-related tasks,which is aimed at augmenting the effectiveness ofinstruction tuning and improving the generalization ability of fine-tunedmodel. Subsequently, we present WaveCoder, a fine-tuned Code LLM withWidespread And Versatile Enhanced instruction tuning. This model isspecifically designed for enhancing instruction tuning of Code Language Models(LLMs). Our experiments demonstrate that Wavecoder models outperform otheropen-source models in terms of generalization ability across differentcode-related tasks at the same level of fine-tuning scale. Moreover, Wavecoderexhibits high efficiency in previous code generation tasks. This paper thusoffers a significant contribution to the field of instruction data generationand fine-tuning models, providing new insights and tools for enhancingperformance in code-related tasks.",Zhaojian Yu,2023/12/20,2024/1/11
1401.0972v1,BEval: A Plug-in to Extend Atelier B with Current Verification Technologies,http://arxiv.org/abs/1401.0972v1,"This paper presents BEval, an extension of Atelier B to improve automation inthe verification activities in the B method or Event-B. It combines a tool formanaging and verifying software projects (Atelier B) and a modelchecker/animator (ProB) so that the verification conditions generated in theformer are evaluated with the latter. In our experiments, the two mainverification strategies (manual and automatic) showed significant improvementas ProB's evaluator proves complementary to Atelier B built-in provers. Weconducted experiments with the B model of a micro-controller instruction set;several verification conditions, that we were not able to dischargeautomatically or manually with AtelierB's provers, were automatically verifiedusing BEval.",Valrio Medeiros Jr.,2014/1/6,2014/1/6
2310.20329v1,InstructCoder: Empowering Language Models for Code Editing,http://arxiv.org/abs/2310.20329v1,"Code editing encompasses a variety of pragmatic tasks that developers dealwith daily. Despite its relevance and practical usefulness, automatic codeediting remains an underexplored area in the evolution of deep learning models,partly due to data scarcity. In this work, we explore the use of large languagemodels (LLMs) to edit code based on user instructions, covering a broad rangeof implicit tasks such as comment insertion, code optimization, and coderefactoring. To facilitate this, we introduce InstructCoder, the first datasetdesigned to adapt LLMs for general-purpose code editing, containinghighdiversity code-editing tasks. It consists of over 114,000instruction-input-output triplets and covers multiple distinct code editingscenarios. The dataset is systematically expanded through an iterative processthat commences with code editing data sourced from GitHub commits as seedtasks. Seed and generated tasks are used subsequently to prompt ChatGPT formore task data. Our experiments demonstrate that open-source LLMs fine-tuned onInstructCoder can edit code correctly based on users' instructions most of thetime, exhibiting unprecedented code-editing performance levels. Such resultssuggest that proficient instruction-finetuning can lead to significantamelioration in code editing abilities. The dataset and the source code areavailable at https://github.com/qishenghu/CodeInstruct.",Qisheng Hu,2023/10/31,2023/10/31
1609.00999v1,Automatic Generation of Vectorized Montgomery Algorithm,http://arxiv.org/abs/1609.00999v1,"Modular arithmetic is widely used in crytography and symbolic computation.This paper presents a vectorized Montgomery algorithm for modularmultiplication, the key to fast modular arithmetic, that fully utilizes theSIMD instructions. We further show how the vectorized algorithm can beautomatically generated by the {\SPIRAL} system, as part of the effort forautomatic generation of a modular polynomial multiplication library.",Lingchuan Meng,2016/9/4,2016/9/4
1109.4351v1,Designing a CPU model: from a pseudo-formal document to fast code,http://arxiv.org/abs/1109.4351v1,"For validating low level embedded software, engineers use simulators thattake the real binary as input. Like the real hardware, these full-systemsimulators are organized as a set of components. The main component is the CPUsimulator (ISS), because it is the usual bottleneck for the simulation speed,and its development is a long and repetitive task. Previous work showed that anISS can be generated from an Architecture Description Language (ADL). In thework reported in this paper, we generate a CPU simulator directly from thepseudo-formal descriptions of the reference manual. For each instruction, weextract the information describing its behavior, its binary encoding, and itsassembly syntax. Next, after automatically applying many optimizations on theextracted information, we generate a SystemC/TLM ISS. We also generate testsfor the decoder and a formal specification in Coq. Experiments show that thegenerated ISS is as fast and stable as our previous hand-written ISS.",Frdric Blanqui,2011/9/20,2011/9/20
2308.13319v1,COCO: Testing Code Generation Systems via Concretized Instructions,http://arxiv.org/abs/2308.13319v1,"Code generation systems have been extensively developed in recent years togenerate source code based on natural language instructions. However, despitetheir advancements, these systems still face robustness issues where evenslightly different instructions can result in significantly different codesemantics. Robustness is critical for code generation systems, as it can havesignificant impacts on software development, software quality, and trust in thegenerated code. Although existing testing techniques for general text-to-textsoftware can detect some robustness issues, they are limited in effectivenessdue to ignoring the characteristics of code generation systems. In this work,we propose a novel technique COCO to test the robustness of code generationsystems. It exploits the usage scenario of code generation systems to make theoriginal programming instruction more concrete by incorporating features knownto be contained in the original code. A robust system should maintain codesemantics for the concretized instruction, and COCO detects robustnessinconsistencies when it does not. We evaluated COCO on eight advanced codegeneration systems, including commercial tools such as Copilot and ChatGPT,using two widely-used datasets. Our results demonstrate the effectiveness ofCOCO in testing the robustness of code generation systems, outperforming twotechniques adopted from general text-to-text software testing by 466.66% and104.02%, respectively. Furthermore, concretized instructions generated by COCOcan help reduce robustness inconsistencies by 18.35% to 53.91% throughfine-tuning.",Ming Yan,2023/8/25,2023/8/25
2108.07117v1,A Program Synthesis Approach for Adding Architectural Tactics to An Existing Code Base,http://arxiv.org/abs/2108.07117v1,"Automatically constructing a program based on given specifications has beenstudied for decades. Despite the advances in the field of Program Synthesis,the current approaches still synthesize a block of code snippet and leave thetask of reusing it in an existing code base to program developers. Due to itsprogram-wide effects, synthesizing an architectural tactic and reusing it in aprogram is even more challenging. Architectural tactics need to be synthesizedbased on the context of different locations of the program, broken down tosmaller pieces, and added to corresponding locations in the code. Moreover,each piece needs to establish correct data- and control-dependencies to itssurrounding environment as well as to the other synthesized pieces. This is anerror-prone and challenging task, especially for novice program developers. Inthis paper, we introduce a novel program synthesis approach that synthesizesarchitectural tactics and adds them to an existing code base.",Ali Shokri,2021/8/16,2021/8/16
1611.07624v1,Developing a Practical Reactive Synthesis Tool: Experience and Lessons Learned,http://arxiv.org/abs/1611.07624v1,"We summarise our experience developing and using Termite, the first reactivesynthesis tool intended for use by software development practitioners. Weidentify the main barriers to making reactive synthesis accessible to softwaredevelopers and describe the key features of Termite designed to overcome thesebarriers, including an imperative C-like specification language, an interactivesource-level debugger, and a user-guided code generator. Based on ourexperience applying Termite to synthesising real-world reactive software, weidentify several caveats of the practical use of the reactive synthesistechnology. We hope that these findings will help define the agenda for futureresearch on practical reactive synthesis.",Leonid Ryzhyk,2016/11/23,2016/11/23
2102.01687v1,Report of the Workshop on Program Synthesis for Scientific Computing,http://arxiv.org/abs/2102.01687v1,"Program synthesis is an active research field in academia, national labs, andindustry. Yet, work directly applicable to scientific computing, while havingsome impressive successes, has been limited. This report reviews the relevantareas of program synthesis work for scientific computing, discusses successesto date, and outlines opportunities for future work. This report is the resultof the Workshop on Program Synthesis for Scientific Computing was heldvirtually on August 4-5 2020 (https://prog-synth-science.github.io/2020/).",Hal Finkel,2021/2/2,2021/2/2
1304.5661v1,On Integrating Deductive Synthesis and Verification Systems,http://arxiv.org/abs/1304.5661v1,"We describe techniques for synthesis and verification of recursive functionalprograms over unbounded domains. Our techniques build on top of an algorithmfor satisfiability modulo recursive functions, a framework for deductivesynthesis, and complete synthesis procedures for algebraic data types. Wepresent new counterexample-guided algorithms for constructing verifiedprograms. We have implemented these algorithms in an integrated environment forinteractive verification and synthesis from relational specifications. Oursystem was able to synthesize a number of useful recursive functions thatmanipulate unbounded numbers and data structures.",Etienne Kneuss,2013/4/20,2013/4/20
2311.10117v1,Automatic Engineering of Long Prompts,http://arxiv.org/abs/2311.10117v1,"Large language models (LLMs) have demonstrated remarkable capabilities insolving complex open-domain tasks, guided by comprehensive instructions anddemonstrations provided in the form of prompts. However, these prompts can belengthy, often comprising hundreds of lines and thousands of tokens, and theirdesign often requires considerable human effort. Recent research has exploredautomatic prompt engineering for short prompts, typically consisting of one ora few sentences. However, the automatic design of long prompts remains achallenging problem due to its immense search space. In this paper, weinvestigate the performance of greedy algorithms and genetic algorithms forautomatic long prompt engineering. We demonstrate that a simple greedy approachwith beam search outperforms other methods in terms of search efficiency.Moreover, we introduce two novel techniques that utilize search history toenhance the effectiveness of LLM-based mutation in our search algorithm. Ourresults show that the proposed automatic long prompt engineering algorithmachieves an average of 9.2% accuracy gain on eight tasks in Big Bench Hard,highlighting the significance of automating prompt designs to fully harness thecapabilities of LLMs.",Cho-Jui Hsieh,2023/11/16,2023/11/16
2302.06235v2,A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models,http://arxiv.org/abs/2302.06235v2,"Contrastively trained text-image models have the remarkable ability toperform zero-shot classification, that is, classifying previously unseen imagesinto categories that the model has never been explicitly trained to identify.However, these zero-shot classifiers need prompt engineering to achieve highaccuracy. Prompt engineering typically requires hand-crafting a set of promptsfor individual downstream tasks. In this work, we aim to automate this promptengineering and improve zero-shot accuracy through prompt ensembling. Inparticular, we ask ""Given a large pool of prompts, can we automatically scorethe prompts and ensemble those that are most suitable for a particulardownstream dataset, without needing access to labeled validation data?"". Wedemonstrate that this is possible. In doing so, we identify several pathologiesin a naive prompt scoring method where the score can be easily overconfidentdue to biases in pre-training and test data, and we propose a novel promptscoring method that corrects for the biases. Using our proposed scoring methodto create a weighted average prompt ensemble, our method outperforms equalaverage ensemble, as well as hand-crafted prompts, on ImageNet, 4 of itsvariants, and 11 fine-grained classification benchmarks, all while being fullyautomatic, optimization-free, and not requiring access to labeled validationdata.",James Urquhart Allingham,2023/2/13,2023/7/15
2311.12229v1,NeuroPrompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation,http://arxiv.org/abs/2311.12229v1,"Despite impressive recent advances in text-to-image diffusion models,obtaining high-quality images often requires prompt engineering by humans whohave developed expertise in using them. In this work, we present NeuroPrompts,an adaptive framework that automatically enhances a user's prompt to improvethe quality of generations produced by text-to-image models. Our frameworkutilizes constrained text decoding with a pre-trained language model that hasbeen adapted to generate prompts similar to those produced by human promptengineers. This approach enables higher-quality text-to-image generations andprovides user control over stylistic features via constraint set specification.We demonstrate the utility of our framework by creating an interactiveapplication for prompt enhancement and image generation using Stable Diffusion.Additionally, we conduct experiments utilizing a large dataset ofhuman-engineered prompts for text-to-image generation and show that ourapproach automatically produces enhanced prompts that result in superior imagequality. We make our code, a screencast video demo and a live demo instance ofNeuroPrompts publicly available.",Shachar Rosenman,2023/11/20,2023/11/20
2203.11364v1,An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels,http://arxiv.org/abs/2203.11364v1,"Pre-trained language models derive substantial linguistic and factualknowledge from the massive corpora on which they are trained, and promptengineering seeks to align these models to specific tasks. Unfortunately,existing prompt engineering methods require significant amounts of labeleddata, access to model parameters, or both. We introduce a new method forselecting prompt templates \textit{without labeled examples} and\textit{without direct access to the model}. Specifically, over a set ofcandidate templates, we choose the template that maximizes the mutualinformation between the input and the corresponding model output. Across 8datasets representing 7 distinct NLP tasks, we show that when a template hashigh mutual information, it also has high accuracy on the task. On the largestmodel, selecting prompts with our method gets 90\% of the way from the averageprompt accuracy to the best prompt accuracy and requires no ground truthlabels.",Taylor Sorensen,2022/3/21,2022/3/21
2309.09128v2,ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing,http://arxiv.org/abs/2309.09128v2,"Evaluating outputs of large language models (LLMs) is challenging, requiringmaking -- and making sense of -- many responses. Yet tools that go beyond basicprompting tend to require knowledge of programming APIs, focus on narrowdomains, or are closed-source. We present ChainForge, an open-source visualtoolkit for prompt engineering and on-demand hypothesis testing of textgeneration LLMs. ChainForge provides a graphical interface for comparison ofresponses across models and prompt variations. Our system was designed tosupport three tasks: model selection, prompt template design, and hypothesistesting (e.g., auditing). We released ChainForge early in its development anditerated on its design with academics and online users. Through in-lab andinterview studies, we find that a range of people could use ChainForge toinvestigate hypotheses that matter to them, including in real-world settings.We identify three modes of prompt engineering and LLM hypothesis testing:opportunistic exploration, limited evaluation, and iterative refinement.",Ian Arawjo,2023/9/17,2023/12/20
2203.01543v2,QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition,http://arxiv.org/abs/2203.01543v2,"Recently, prompt-based learning for pre-trained language models has succeededin few-shot Named Entity Recognition (NER) by exploiting prompts as taskguidance to increase label efficiency. However, previous prompt-based methodsfor few-shot NER have limitations such as a higher computational complexity,poor zero-shot ability, requiring manual prompt engineering, or lack of promptrobustness. In this work, we address these shortcomings by proposing a newprompt-based learning NER method with Question Answering (QA), called QaNER.Our approach includes 1) a refined strategy for converting NER problems intothe QA formulation; 2) NER prompt generation for QA models; 3) prompt-basedtuning with QA models on a few annotated NER examples; 4) zero-shot NER byprompting the QA model. Comparing the proposed approach with previous methods,QaNER is faster at inference, insensitive to the prompt quality, and robust tohyper-parameters, as well as demonstrating significantly better low-resourceperformance and zero-shot capability.",Andy T. Liu,2022/3/3,2022/3/4
2312.12416v1,Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models,http://arxiv.org/abs/2312.12416v1,"The quality of the prompts provided to text-to-image diffusion modelsdetermines how faithful the generated content is to the user's intent, oftenrequiring `prompt engineering'. To harness visual concepts from target imageswithout prompt engineering, current approaches largely rely on embeddinginversion by optimizing and then mapping them to pseudo-tokens. However,working with such high-dimensional vector representations is challengingbecause they lack semantics and interpretability, and only allow simple vectoroperations when using them. Instead, this work focuses on inverting thediffusion model to obtain interpretable language prompts directly. Thechallenge of doing this lies in the fact that the resulting optimizationproblem is fundamentally discrete and the space of prompts is exponentiallylarge; this makes using standard optimization techniques, such as stochasticgradient descent, difficult. To this end, we utilize a delayed projectionscheme to optimize for prompts representative of the vocabulary space in themodel. Further, we leverage the findings that different timesteps of thediffusion process cater to different levels of detail in an image. The later,noisy, timesteps of the forward diffusion process correspond to the semanticinformation, and therefore, prompt inversion in this range provides tokensrepresentative of the image semantics. We show that our approach can identifysemantically interpretable and meaningful prompts for a target image which canbe used to synthesize diverse images with similar content. We furtherillustrate the application of the optimized prompts in evolutionary imagegeneration and concept removal.",Shweta Mahajan,2023/12/19,2023/12/19
2208.07852v1,Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models,http://arxiv.org/abs/2208.07852v1,"State-of-the-art neural language models can now be used to solve ad-hoclanguage tasks through zero-shot prompting without the need for supervisedtraining. This approach has gained popularity in recent years, and researchershave demonstrated prompts that achieve strong accuracy on specific NLP tasks.However, finding a prompt for new tasks requires experimentation. Differentprompt templates with different wording choices lead to significant accuracydifferences. PromptIDE allows users to experiment with prompt variations,visualize prompt performance, and iteratively optimize prompts. We developed aworkflow that allows users to first focus on model feedback using small databefore moving on to a large data regime that allows empirical grounding ofpromising prompts using quantitative measures of the task. The tool then allowseasy deployment of the newly created ad-hoc models. We demonstrate the utilityof PromptIDE (demo at http://prompt.vizhub.ai) and our workflow using severalreal-world use cases.",Hendrik Strobelt,2022/8/16,2022/8/16
2209.07511v1,Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models,http://arxiv.org/abs/2209.07511v1,"Pre-trained vision-language models (e.g., CLIP) have shown promisingzero-shot generalization in many downstream tasks with properly designed textprompts. Instead of relying on hand-engineered prompts, recent works learnprompts using the training data from downstream tasks. While effective,training on domain-specific data reduces a model's generalization capability tounseen new domains. In this work, we propose test-time prompt tuning (TPT), amethod that can learn adaptive prompts on the fly with a single test sample.For image classification, TPT optimizes the prompt by minimizing the entropywith confidence selection so that the model has consistent predictions acrossdifferent augmented views of each test sample. In evaluating generalization tonatural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIPby 3.6% on average, surpassing previous prompt tuning approaches that requireadditional task-specific training data. In evaluating cross-datasetgeneralization with unseen categories, TPT performs on par with thestate-of-the-art approaches that use additional training data. Project page:https://azshue.github.io/TPT.",Manli Shu,2022/9/15,2022/9/15
2303.17780v3,AceCoder: Utilizing Existing Code to Enhance Code Generation,http://arxiv.org/abs/2303.17780v3,"Large Language Models (LLMs) have shown great success in code generation.LLMs take as the input a prompt and output the code. A key question is how tomake prompts (i.e., Prompting Techniques). Existing prompting techniques aredesigned for natural language generation and have low accuracy in codegeneration.  In this paper, we propose a new prompting technique named AceCoder. Ourmotivation is that code generation meets two unique challenges (i.e.,requirement understanding and code implementation). AceCoder contains two novelmechanisms (i.e., guided code generation and example retrieval) to solve thesechallenges. (1) Guided code generation asks LLMs first to analyze requirementsand output an intermediate preliminary (e.g., test cases). The preliminary isused to clarify requirements and tell LLMs ""what to write"". (2) Exampleretrieval selects similar programs as examples in prompts, which provide lotsof relevant content (e.g., algorithms, APIs) and teach LLMs ""how to write"". Weapply AceCoder to three LLMs (e.g., Codex) and evaluate it on three publicbenchmarks using the Pass@k. Results show that AceCoder can significantlyimprove the performance of LLMs on code generation. (1) In terms of Pass@1,AceCoder outperforms the state-of-the-art baseline by up to 56.4% in MBPP,70.7% in MBJP, and 88.4% in MBJSP. (2) AceCoder is effective in LLMs withdifferent sizes (i.e., 6B to 13B) and different languages (i.e., Python, Java,and JavaScript). (3) Human evaluation shows human developers prefer programsfrom AceCoder.",Jia Li,2023/3/31,2023/9/7
2208.11640v3,Repair Is Nearly Generation: Multilingual Program Repair with LLMs,http://arxiv.org/abs/2208.11640v3,"Most programmers make mistakes when writing code. Some of these mistakes aresmall and require few edits to the original program -- a class of errorsrecently termed last mile mistakes. These errors break the flow for experienceddevelopers and can stump novice programmers. Existing automated repairtechniques targeting this class of errors are language-specific and do noteasily carry over to new languages. Transferring symbolic approaches requiressubstantial engineering and neural approaches require data and retraining. Weintroduce RING, a multilingual repair engine powered by a large language modeltrained on code (LLMC) such as Codex. Such a multilingual engine enables aflipped model for programming assistance, one where the programmer writes codeand the AI assistance suggests fixes, compared to traditional code suggestiontechnology. Taking inspiration from the way programmers manually fix bugs, weshow that a prompt-based strategy that conceptualizes repair as localization,transformation, and candidate ranking, can successfully repair programs inmultiple languages with minimal effort. We present the first results for such amultilingual repair engine by evaluating on 6 different languages and comparingperformance to language-specific repair engines. We show that RING canoutperform language-specific repair engines for three of these languages.",Harshit Joshi,2022/8/24,2022/12/5
2401.12178v1,In-Context Learning for Extreme Multi-Label Classification,http://arxiv.org/abs/2401.12178v1,"Multi-label classification problems with thousands of classes are hard tosolve with in-context learning alone, as language models (LMs) might lack priorknowledge about the precise classes or how to assign them, and it is generallyinfeasible to demonstrate every class in a prompt. We propose a generalprogram, $\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactionsbetween LMs and retrievers to efficiently tackle such problems. We implementthis program using the $\texttt{DSPy}$ programming model, which specifiesin-context systems in a declarative manner, and use $\texttt{DSPy}$ optimizersto tune it towards specific datasets by bootstrapping only tens of few-shotexamples. Our primary extreme classification program, optimized separately foreach task, attains state-of-the-art results across three benchmarks (HOUSE,TECH, TECHWOLF). We apply the same program to a benchmark with vastly differentcharacteristics and attain competitive performance as well (BioDEX). Unlikeprior work, our proposed solution requires no finetuning, is easily applicableto new tasks, alleviates prompt engineering, and requires only tens of labeledexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.",Karel D'Oosterlinck,2024/1/22,2024/1/22
2401.08500v1,Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering,http://arxiv.org/abs/2401.08500v1,"Code generation problems differ from common natural language problems - theyrequire matching the exact syntax of the target language, identifying happypaths and edge cases, paying attention to numerous small details in the problemspec, and addressing other code-specific issues and requirements. Hence, manyof the optimizations and tricks that have been successful in natural languagegeneration may not be effective for code tasks. In this work, we propose a newapproach to code generation by LLMs, which we call AlphaCodium - a test-based,multi-stage, code-oriented iterative flow, that improves the performances ofLLMs on code problems. We tested AlphaCodium on a challenging code generationdataset called CodeContests, which includes competitive programming problemsfrom platforms such as Codeforces. The proposed flow consistently andsignificantly improves results. On the validation set, for example, GPT-4accuracy (pass@5) increased from 19% with a single well-designed direct promptto 44% with the AlphaCodium flow. Many of the principles and best practicesacquired in this work, we believe, are broadly applicable to general codegeneration tasks. Full implementation is available at:https://github.com/Codium-ai/AlphaCodium",Tal Ridnik,2024/1/16,2024/1/16
2204.00166v1,Making Pre-trained Language Models End-to-end Few-shot Learners with Contrastive Prompt Tuning,http://arxiv.org/abs/2204.00166v1,"Pre-trained Language Models (PLMs) have achieved remarkable performance forvarious language understanding tasks in IR systems, which require thefine-tuning process based on labeled training data. For low-resource scenarios,prompt-based learning for PLMs exploits prompts as task guidance and turnsdownstream tasks into masked language problems for effective few-shotfine-tuning. In most existing approaches, the high performance of prompt-basedlearning heavily relies on handcrafted prompts and verbalizers, which may limitthe application of such approaches in real-world scenarios. To solve thisissue, we present CP-Tuning, the first end-to-end Contrastive Prompt Tuningframework for fine-tuning PLMs without any manual engineering of task-specificprompts and verbalizers. It is integrated with the task-invariant continuousprompt encoding technique with fully trainable prompt parameters. We furtherpropose the pair-wise cost-sensitive contrastive learning procedure to optimizethe model in order to achieve verbalizer-free class mapping and enhance thetask-invariance of prompts. It explicitly learns to distinguish differentclasses and makes the decision boundary smoother by assigning different coststo easy and hard cases. Experiments over a variety of language understandingtasks used in IR systems and different PLMs show that CP-Tuning outperformsstate-of-the-art methods.",Ziyun Xu,2022/4/1,2022/4/1
2310.18358v1,A Communication Theory Perspective on Prompting Engineering Methods for Large Language Models,http://arxiv.org/abs/2310.18358v1,"The springing up of Large Language Models (LLMs) has shifted the communityfrom single-task-orientated natural language processing (NLP) research to aholistic end-to-end multi-task learning paradigm. Along this line of researchendeavors in the area, LLM-based prompting methods have attracted muchattention, partially due to the technological advantages brought by promptengineering (PE) as well as the underlying NLP principles disclosed by variousprompting methods. Traditional supervised learning usually requires training amodel based on labeled data and then making predictions. In contrast, PEmethods directly use the powerful capabilities of existing LLMs (i.e., GPT-3and GPT-4) via composing appropriate prompts, especially under few-shot orzero-shot scenarios. Facing the abundance of studies related to the promptingand the ever-evolving nature of this field, this article aims to (i) illustratea novel perspective to review existing PE methods, within the well-establishedcommunication theory framework; (ii) facilitate a better/deeper understandingof developing trends of existing PE methods used in four typical tasks; (iii)shed light on promising research directions for future PE methods.",Yuanfeng Song,2023/10/24,2023/10/24
2310.03957v1,Understanding prompt engineering may not require rethinking generalization,http://arxiv.org/abs/2310.03957v1,"Zero-shot learning in prompted vision-language models, the practice ofcrafting prompts to build classifiers without an explicit training process, hasachieved impressive performance in many settings. This success presents aseemingly surprising observation: these methods suffer relatively little fromoverfitting, i.e., when a prompt is manually engineered to achieve low error ona given training set (thus rendering the method no longer actually zero-shot),the approach still performs well on held-out test data. In this paper, we showthat we can explain such performance well via recourse to classical PAC-Bayesbounds. Specifically, we show that the discrete nature of prompts, combinedwith a PAC-Bayes prior given by a language model, results in generalizationbounds that are remarkably tight by the standards of the literature: forinstance, the generalization bound of an ImageNet classifier is often within afew percentage points of the true test error. We demonstrate empirically thatthis holds for existing handcrafted prompts and prompts generated throughsimple greedy search. Furthermore, the resulting bound is well-suited for modelselection: the models with the best bound typically also have the best testperformance. This work thus provides a possible justification for thewidespread practice of prompt engineering, even if it seems that such methodscould potentially overfit the training data.",Victor Akinwande,2023/10/6,2023/10/6
2103.04433v1,Teaching Model-based Requirements Engineering to Industry Professionals: An Experience Report,http://arxiv.org/abs/2103.04433v1,"The use of conceptual models to foster requirements engineering has beenproposed and evaluated as beneficial for several decades. For instance,goal-oriented requirements engineering or the specification of scenarios arecommonly done using conceptual models. Bringing such model-based requirementsengineering approaches into industrial practice typically requires industrialtraining. In this paper, we report lessons learned from a training program forteaching industry professionals model-based requirements engineering.Particularly, we as educators and learners report experiences from designingthe training program, conducting the actual training, and applying theinstructed material in our day-to-day work. From these findings we provideguidelines for educators designing requirements engineering courses forindustry professionals.",Marian Daun,2021/3/7,2021/3/7
1711.09092v1,What If People Learn Requirements Over Time? A Rough Introduction to Requirements Economics,http://arxiv.org/abs/1711.09092v1,"The overall objective of Requirements Engineering is to specify, in asystematic way, a system that satisfies the expectations of its stakeholders.Despite tremendous effort in the field, recent studies demonstrate this isobjective is not always achieved. In this paper, we discuss one particularlychallenging factor to Requirements Engineering projects, namely the change ofrequirements. We proposes a rough discussion of how learning and time explainrequirements changes, how it can be introduced as a key variable in theformulation of the Requirements Engineering Problem, and how this induces costsfor a requirements engineering project. This leads to a new discipline ofrequirements economics.",Corentin Burnay,2017/11/24,2017/11/24
2010.14212v1,Renovating Requirements Engineering: First Thoughts to Shape Requirements Engineering as a Profession,http://arxiv.org/abs/2010.14212v1,"Legacy software systems typically include vital data for organizations thatuse them and should thus to be regularly maintained. Ideally, organizationsshould rely on Requirements Engineers to understand and manage changes ofstakeholder needs and system constraints. However, due to time and costpressure, and with a heavy focus on implementation, organizations often chooseto forgo Requirements Engineers and rather focus on ad-hoc bug fixing andmaintenance. This position paper discusses what Requirements Engineers couldpossibly learn from other similar roles to become crucial for the evolution oflegacy systems. Particularly, we compare the roles of Requirements Engineers(according to IREB), Building Architects (according to the German regulations),and Product Owners (according to ""The Scrum-Guide""). We discuss overlaps alongfour dimensions: liability, self-portrayal, core activities, and artifacts.Finally we draw insights from these related fields to foster the concept of aRequirements Engineer as a distinguished profession.",Yen Dieu Pham,2020/10/26,2020/10/26
2210.00859v1,Requirements Engineering for Machine Learning: A Review and Reflection,http://arxiv.org/abs/2210.00859v1,"Today, many industrial processes are undergoing digital transformation, whichoften requires the integration of well-understood domain models andstate-of-the-art machine learning technology in business processes. However,requirements elicitation and design decision making about when, where and howto embed various domain models and end-to-end machine learning techniquesproperly into a given business workflow requires further exploration. Thispaper aims to provide an overview of the requirements engineering process formachine learning applications in terms of cross domain collaborations. We firstreview the literature on requirements engineering for machine learning, andthen go through the collaborative requirements analysis process step-by-step.An example case of industrial data-driven intelligence applications is alsodiscussed in relation to the aforementioned steps.",Zhongyi Pei,2022/10/3,2022/10/3
1904.00001v2,Engineering problems in machine learning systems,http://arxiv.org/abs/1904.00001v2,"Fatal accidents are a major issue hindering the wide acceptance ofsafety-critical systems that employ machine learning and deep learning models,such as automated driving vehicles. In order to use machine learning in asafety-critical system, it is necessary to demonstrate the safety and securityof the system through engineering processes. However, thus far, no such widelyaccepted engineering concepts or frameworks have been established for thesesystems. The key to using a machine learning model in a deductively engineeredsystem is decomposing the data-driven training of machine learning models intorequirement, design, and verification, particularly for machine learning modelsused in safety-critical systems. Simultaneously, open problems and relevanttechnical fields are not organized in a manner that enables researchers toselect a theme and work on it. In this study, we identify, classify, andexplore the open problems in engineering (safety-critical) machine learningsystems --- that is, in terms of requirement, design, and verification ofmachine learning models and systems --- as well as discuss related works andresearch directions, using automated driving vehicles as an example. Ourresults show that machine learning models are characterized by a lack ofrequirements specification, lack of design specification, lack ofinterpretability, and lack of robustness. We also perform a gap analysis on aconventional system quality standard SQuARE with the characteristics of machinelearning models to study quality models for machine learning systems. We findthat a lack of requirements specification and lack of robustness have thegreatest impact on conventional quality models.",Hiroshi Kuwajima,2019/4/1,2019/8/22
2307.05584v1,Code Generation for Machine Learning using Model-Driven Engineering and SysML,http://arxiv.org/abs/2307.05584v1,"Data-driven engineering refers to systematic data collection and processingusing machine learning to improve engineering systems. Currently, theimplementation of data-driven engineering relies on fundamental data scienceand software engineering skills. At the same time, model-based engineering isgaining relevance for the engineering of complex systems. In previous work, amodel-based engineering approach integrating the formalization of machinelearning tasks using the general-purpose modeling language SysML is presented.However, formalized machine learning tasks still require the implementation ina specialized programming languages like Python. Therefore, this work aims tofacilitate the implementation of data-driven engineering in practice byextending the previous work of formalizing machine learning tasks byintegrating model transformation to generate executable code. The methodfocuses on the modifiability and maintainability of the model transformation sothat extensions and changes to the code generation can be integrated withoutrequiring modifications to the code generator. The presented method isevaluated for feasibility in a case study to predict weather forecasts. Basedthereon, quality attributes of model transformations are assessed anddiscussed. Results demonstrate the flexibility and the simplicity of the methodreducing efforts for implementation. Further, the work builds a theoreticalbasis for standardizing data-driven engineering implementation in practice.",Simon Raedler,2023/7/10,2023/7/10
2107.00821v2,An Experience Report on Machine Learning Reproducibility: Guidance for Practitioners and TensorFlow Model Garden Contributors,http://arxiv.org/abs/2107.00821v2,"Machine learning techniques are becoming a fundamental tool for scientificand engineering progress. These techniques are applied in contexts as diverseas astronomy and spam filtering. However, correctly applying these techniquesrequires careful engineering. Much attention has been paid to the technicalpotential; relatively little attention has been paid to the softwareengineering process required to bring research-based machine learningtechniques into practical utility. Technology companies have supported theengineering community through machine learning frameworks such as TensorFLowand PyTorch, but the details of how to engineer complex machine learning modelsin these frameworks have remained hidden.  To promote best practices within the engineering community, academicinstitutions and Google have partnered to launch a Special Interest Group onMachine Learning Models (SIGMODELS) whose goal is to develop exemplaryimplementations of prominent machine learning models in community locationssuch as the TensorFlow Model Garden (TFMG). The purpose of this report is todefine a process for reproducing a state-of-the-art machine learning model at alevel of quality suitable for inclusion in the TFMG. We define the engineeringprocess and elaborate on each step, from paper analysis to model release. Wereport on our experiences implementing the YOLO model family with a team of 26student researchers, share the tools we developed, and describe the lessons welearned along the way.",Vishnu Banna,2021/7/2,2021/7/29
2006.11108v1,A Reinforcement Learning Approach for Transient Control of Liquid Rocket Engines,http://arxiv.org/abs/2006.11108v1,"Nowadays, liquid rocket engines use closed-loop control at most near steadyoperating conditions. The control of the transient phases is traditionallyperformed in open-loop due to highly nonlinear system dynamics. This situationis unsatisfactory, in particular for reusable engines. The open-loop controlsystem cannot provide optimal engine performance due to external disturbancesor the degeneration of engine components over time. In this paper, we study adeep reinforcement learning approach for optimal control of a genericgas-generator engine's continuous start-up phase. It is shown that the learnedpolicy can reach different steady-state operating points and convincingly adaptto changing system parameters. A quantitative comparison with carefully tunedopen-loop sequences and PID controllers is included. The deep reinforcementlearning controller achieves the highest performance and requires only minimalcomputational effort to calculate the control action, which is a big advantageover approaches that require online optimization, such as model predictivecontrol. control.",Gnther Waxenegger-Wilfing,2020/6/19,2020/6/19
1908.11791v1,Requirements Engineering Challenges in Building AI-Based Complex Systems,http://arxiv.org/abs/1908.11791v1,"This paper identifies and tackles the challenges of the requirementsengineering discipline when applied to development of AI-based complex systems.Due to their complex behaviour, there is an immanent need for a tailoreddevelopment process for such systems. However, there is still no widely usedand specifically tailored process in place to effectively and efficiently dealwith requirements suitable for specifying a software solution that uses machinelearning. By analysing the related work from software engineering andartificial intelligence fields, potential contributions have been recognizedfrom agent-based software engineering and goal-oriented requirementsengineering research, as well as examples from large product developmentcompanies. The challenges have been discussed, with proposals given how andwhen to tackle them. RE4AI taxonomy has also been outlined, to inform thetailoring of development process.",Hrvoje Belani,2019/8/30,2019/8/30
1908.04674v1,Requirements Engineering for Machine Learning: Perspectives from Data Scientists,http://arxiv.org/abs/1908.04674v1,"Machine learning (ML) is used increasingly in real-world applications. Inthis paper, we describe our ongoing endeavor to define characteristics andchallenges unique to Requirements Engineering (RE) for ML-based systems. As afirst step, we interviewed four data scientists to understand how ML expertsapproach elicitation, specification, and assurance of requirements andexpectations. The results show that changes in the development paradigm, i.e.,from coding to training, also demands changes in RE. We conclude thatdevelopment of ML systems demands requirements engineers to: (1) understand MLperformance measures to state good functional requirements, (2) be aware of newquality requirements such as explainability, freedom from discrimination, orspecific legal requirements, and (3) integrate ML specifics in the RE process.Our study provides a first contribution towards an RE methodology for MLsystems.",Andreas Vogelsang,2019/8/13,2019/8/13
1807.11454v1,Automating Requirements Traceability: Two Decades of Learning from KDD,http://arxiv.org/abs/1807.11454v1,"This paper summarizes our experience with using Knowledge Discovery in Data(KDD) methodology for automated requirements tracing, and discusses ourinsights.",Alex Dekhtyar,2018/7/30,2018/7/30
1707.01927v1,Let's hear it from RETTA: A Requirements Elicitation Tool for TrAffic management systems,http://arxiv.org/abs/1707.01927v1,"The area of Traffic Management (TM) is characterized by uncertainty,complexity, and imprecision. The complexity of software systems in the TMdomain which contributes to a more challenging Requirements Engineering (RE)job mainly stems from the diversity of stakeholders and complexity ofrequirements elicitation in this domain. This work brings an interactivesolution for exploring functional and non-functional requirements ofsoftware-reliant systems in the area of traffic management. We prototyped theRETTA tool which leverages the wisdom of the crowd and combines it with machinelearning approaches such as Natural Language Processing and Naive Bayes to helpwith the requirements elicitation and classification task in the TM domain.This bridges the gap among stakeholders from both areas of software developmentand transportation engineering. The RETTA prototype is mainly designed forrequirements engineers and software developers in the area of TM and can beused on Android-based devices.",Mohammad Noaeen,2017/7/6,2017/7/6
1909.09929v1,MaLTESE: Large-Scale Simulation-Driven Machine Learning for Transient Driving Cycles,http://arxiv.org/abs/1909.09929v1,"Optimal engine operation during a transient driving cycle is the key toachieving greater fuel economy, engine efficiency, and reduced emissions. Inorder to achieve continuously optimal engine operation, engine calibrationmethods use a combination of static correlations obtained from dynamometertests for steady-state operating points and road and/or track performance data.As the parameter space of control variables, design variable constraints, andobjective functions increases, the cost and duration for optimal calibrationbecome prohibitively large. In order to reduce the number of dynamometer testsrequired for calibrating modern engines, a large-scale simulation-drivenmachine learning approach is presented in this work. A parallel, fast, robust,physics-based reduced-order engine simulator is used to obtain performance andemission characteristics of engines over a wide range of control parametersunder various transient driving conditions (drive cycles). We scale thesimulation up to 3,906 nodes of the Theta supercomputer at the ArgonneLeadership Computing Facility to generate data required to train a machinelearning model. The trained model is then used to predict various engineparameters of interest. Our results show that a deep-neural-network-basedsurrogate model achieves high accuracy for various engine parameters such asexhaust temperature, exhaust pressure, nitric oxide, and engine torque. Oncetrained, the deep-neural-network-based surrogate model is fast for inference:it requires about 16 micro sec for predicting the engine performance andemissions for a single design configuration compared with about 0.5 s perconfiguration with the engine simulator. Moreover, we demonstrate that transferlearning and retraining can be leveraged to incrementally retrain the surrogatemodel to cope with new configurations that fall outside the training dataspace.",Shashi M. Aithal,2019/9/22,2019/9/22
1707.02358v1,What Works Better? A Study of Classifying Requirements,http://arxiv.org/abs/1707.02358v1,"Classifying requirements into functional requirements (FR) and non-functionalones (NFR) is an important task in requirements engineering. However, automatedclassification of requirements written in natural language is notstraightforward, due to the variability of natural language and the absence ofa controlled vocabulary. This paper investigates how automated classificationof requirements into FR and NFR can be improved and how well several machinelearning approaches work in this context. We contribute an approach forpreprocessing requirements that standardizes and normalizes requirements beforeapplying classification algorithms. Further, we report on how well severalexisting machine learning methods perform for automated classification of NFRsinto sub-categories such as usability, availability, or performance. Our studyis performed on 625 requirements provided by the OpenScience tera-PROMISErepository. We found that our preprocessing improved the performance of anexisting classification method. We further found significant differences in theperformance of approaches such as Latent Dirichlet Allocation, Biterm TopicModeling, or Naive Bayes for the sub-classification of NFRs.",Zahra Shakeri Hossein Abad,2017/7/7,2017/7/7
2211.09084v1,Technical Report on Neural Language Models and Few-Shot Learning for Systematic Requirements Processing in MDSE,http://arxiv.org/abs/2211.09084v1,"Systems engineering, in particular in the automotive domain, needs to copewith the massively increasing numbers of requirements that arise during thedevelopment process. To guarantee a high product quality and make sure thatfunctional safety standards such as ISO26262 are fulfilled, the exploitation ofpotentials of model-driven systems engineering in the form of automaticanalyses, consistency checks, and tracing mechanisms is indispensable. However,the language in which requirements are written, and the tools needed to operateon them, are highly individual and require domain-specific tailoring. Thishinders automated processing of requirements as well as the linking ofrequirements to models. Introducing formal requirement notations in existingprojects leads to the challenge of translating masses of requirements andprocess changes on the one hand and to the necessity of the correspondingtraining for the requirements engineers.  In this paper, based on the analysis of an open-source set of automotiverequirements, we derive domain-specific language constructs helping us to avoidambiguities in requirements and increase the level of formality. The maincontribution is the adoption and evaluation of few-shot learning with largepretrained language models for the automated translation of informalrequirements to structured languages such as a requirement DSL. We show thatsupport sets of less than ten translation examples can suffice to few-shottrain a language model to incorporate keywords and implement syntactic rulesinto informal natural language requirements.",Vincent Bertram,2022/11/16,2022/11/16
2105.07771v1,Deep Learning Models in Software Requirements Engineering,http://arxiv.org/abs/2105.07771v1,"Requirements elicitation is an important phase of any software project: theerrors in requirements are more expensive to fix than the errors introduced atlater stages of software life cycle. Nevertheless, many projects do not devotesufficient time to requirements. Automated requirements generation can improvethe quality of software projects. In this article we have accomplished thefirst step of the research on this topic: we have applied the vanilla sentenceautoencoder to the sentence generation task and evaluated its performance. Thegenerated sentences are not plausible English and contain only a few meaningfulwords. We believe that applying the model to a larger dataset may producesignificantly better results. Further research is needed to improve the qualityof generated data.",Maria Naumcheva,2021/5/17,2021/5/17
2203.15510v1,Achieving Guidance in Applied Machine Learning through Software Engineering Techniques,http://arxiv.org/abs/2203.15510v1,"Development of machine learning (ML) applications is hard. Producingsuccessful applications requires, among others, being deeply familiar with avariety of complex and quickly evolving application programming interfaces(APIs). It is therefore critical to understand what prevents developers fromlearning these APIs, using them properly at development time, and understandingwhat went wrong when it comes to debugging. We look at the (lack of) guidancethat currently used development environments and ML APIs provide to developersof ML applications, contrast these with software engineering best practices,and identify gaps in the current state of the art. We show that current MLtools fall short of fulfilling some basic software engineering gold standardsand point out ways in which software engineering concepts, tools and techniquesneed to be extended and adapted to match the special needs of ML applicationdevelopment. Our findings point out ample opportunities for research onML-specific software engineering.",Lars Reimann,2022/3/29,2022/3/29
1102.4178v1,Mixed-Variable Requirements Roadmaps and their Role in the Requirements Engineering of Adaptive Systems,http://arxiv.org/abs/1102.4178v1,"The requirements roadmap concept is introduced as a solution to the problemof the requirements engineering of adaptive systems. The concept requires a newgeneral definition of the requirements problem which allows for quantitative(numeric) variables, together with qualitative (binary boolean) propositionalvariables, and distinguishes monitored from controlled variables for use incontrol loops. We study the consequences of these changes, and argue that therequirements roadmap concept bridges the gap between current generaldefinitions of the requirements problem and its notion of solution, and theresearch into the relaxation of requirements, the evaluation of their partialsatisfaction, and the monitoring and control of requirements, all topics ofparticular interest in the engineering of requirements for adaptive systems[Cheng et al. 2009]. From the theoretical perspective, we show clearly andformally the fundamental differences between more traditional conception ofrequirements engineering (e.g., Zave & Jackson [1997]) and the requirementsengineering of adaptive systems (from Fickas & Feather [1995], over Letier &van Lamsweerde [2004], and up to Whittle et al. [2010] and the most recentresearch). From the engineering perspective, we define a proto-framework forearly requirements engineering of adaptive systems, which illustrates thefeatures needed in future requirements frameworks for this class of systems.",Ivan Jureta,2011/2/21,2011/2/21
1508.01954v1,Ordering Interrogative Questions for Effective Requirements Engineering: The W6H Pattern,http://arxiv.org/abs/1508.01954v1,"Requirements elicitation and requirements analysis are important practices ofRequirements Engineering. Elicitation techniques, such as interviews andquestionnaires, rely on formulating interrogative questions and asking these ina proper order to maximize the accuracy of the information being gathered.Information gathered during requirements elicitation then has to beinterpreted, analyzed, and validated. Requirements analysis involves analyzingthe problem and solutions spaces. In this paper, we describe a method toformulate interrogative questions for effective requirements elicitation basedon the lexical and semantic principles of the English language interrogatives,and propose a pattern to organize stakeholder viewpoint concerns for betterrequirements analysis. This helps requirements engineer thoroughly describeproblem and solutions spaces.  Most of the previous requirements elicitation studies included six out of theseven English language interrogatives 'what', 'where', 'when', 'who', 'why',and 'how' (denoted by W5H) and did not propose any order in the interrogatives.We show that extending the set of six interrogatives with 'which' (denoted byW6H) improves the generation and formulation of questions for requirementselicitation and facilitates better requirements analysis via arrangingstakeholder views. We discuss the interdependencies among interrogatives (forrequirements engineer to consider while eliciting the requirements) and suggestan order for the set of W6H interrogatives. The proposed W6H-based reusablepattern also aids requirements engineer in organizing viewpoint concerns ofstakeholders, making this pattern an effective tool for requirements analysis.",Mujahid Sultan,2015/8/8,2015/8/8
2209.01993v1,Aspects of Modelling Requirements in Very-Large Agile Systems Engineering,http://arxiv.org/abs/2209.01993v1,"Using models for requirements engineering (RE) is uncommon in systemsengineering, despite the widespread use of model-based engineering in general.One reason for this lack of use is that formal models do not match well thetrend to move towards agile developing methods. While there exists work thatinvestigates challenges in the adoption of requirements modeling and agilemethods in systems engineering, there is a lack of work studying successfulapproaches of using requirements modelling in agile systems engineering. Toaddress this gap, we conducted a case study investigating the application ofrequirements models at Ericsson AB, a Swedish telecommunications company. Westudied a department using requirements models to bridge agile development andplan-driven development aspects. We find that models are used to understand howrequirements relate to each other, and to keep track with the product'sevolution. To cope with the effort to maintain models over time, studyparticipants suggest to rely on text-based notations that bring the modelscloser to developers and allow integration into existing software developmentworkflows. This results in tool trade-offs, e.g., losing the possibility tocontrol diagram layout.",Grischa Liebel,2022/9/5,2022/9/5
1907.10887v1,Towards an Holistic Definition of Requirements Debt,http://arxiv.org/abs/1907.10887v1,"When not appropriately managed, technical debt is considered to have negativeeffects on the long term success of a software project. However, how the debtmetaphor applies to requirements engineering in general, and to requirementsengineering activities in particular, is not well understood. Grounded in theexisting literature, we present a holistic definition of requirements debtwhich include debt incurred during the identification, formalization, andimplementation of requirements. We outline future assessment to validate andfurther refine our proposed definition. This conceptualization is the firststep towards a requirements debt monitoring framework to support stakeholdersdecisions, such as when to incur and eventually pay back requirements debt, andat what costs",Valentina Lenarduzzi,2019/7/25,2019/7/25
2011.10975v1,Modular Moose: A new generation software reverse engineering environment,http://arxiv.org/abs/2011.10975v1,"Advanced reverse engineering tools are required to cope with the complexityof software systems and the specific requirements of numerous different tasks(re-architecturing, migration, evolution). Consequently, reverse engineeringtools should adapt to a wide range of situations. Yet, because they require alarge infrastructure investment, being able to reuse these tools is key. Mooseis a reverse engineering environment answering these requirements. While Moosestarted as a research project 20 years ago, it is also used in industrialprojects, exposing itself to all these difficulties. In this paper we presentModMoose, the new version of Moose. ModMoose revolves around a new meta-model,modular and extensible; a new toolset of generic tools (query module,visualization engine, ...); and an open architecture supporting thesynchronization and interaction of tools per task. With ModMoose, tooldevelopers can develop specific meta-models by reusing existing elementaryconcepts, and dedicated reverse engineering tools that can interact with theexisting ones.",Nicolas Anquetil,2020/11/22,2020/11/22
2312.06986v1,Automatic extraction of cause-effect-relations from requirements artifacts,http://arxiv.org/abs/2312.06986v1,"Background: The detection and extraction of causality from natural languagesentences have shown great potential in various fields of application. Thefield of requirements engineering is eligible for multiple reasons: (1)requirements artifacts are primarily written in natural language, (2) causalsentences convey essential context about the subject of requirements, and (3)extracted and formalized causality relations are usable for a (semi-)automatictranslation into further artifacts, such as test cases. Objective: We aim atunderstanding the value of interactive causality extraction based on syntacticcriteria for the context of requirements engineering. Method: We developed aprototype of a system for automatic causality extraction and evaluate it byapplying it to a set of publicly available requirements artifacts, determiningwhether the automatic extraction reduces the manual effort of requirementsformalization. Result: During the evaluation we analyzed 4457 natural languagesentences from 18 requirements documents, 558 of which were causal (12.52%).The best evaluation of a requirements document provided an automatic extractionof 48.57% cause-effect graphs on average, which demonstrates the feasibility ofthe approach. Limitation: The feasibility of the approach has been proven intheory but lacks exploration of being scaled up for practical use. Evaluatingthe applicability of the automatic causality extraction for a requirementsengineer is left for future research. Conclusion: A syntactic approach forcausality extraction is viable for the context of requirements engineering andcan aid a pipeline towards an automatic generation of further artifacts fromrequirements artifacts.",Julian Frattini,2023/12/12,2023/12/12
1505.00904v1,Code Generator Composition for Model-Driven Engineering of Robotics Component & Connector Systems,http://arxiv.org/abs/1505.00904v1,"Engineering software for robotics applications requires multidomain andapplication-specific solutions. Model-driven engineering and modeling languageintegration provide means for developing specialized, yet reusable models ofrobotics software architectures. Code generators transform these platformindependent models into executable code specific to robotic platforms.Generative software engineering for multidomain applications requires not onlythe integration of modeling languages but also the integration of validationmechanisms and code generators. In this paper we sketch a conceptual model forcode generator composition and show an instantiation of this model in theMontiArc- Automaton framework. MontiArcAutomaton allows modeling softwarearchitectures as component and connector models with different componentbehavior modeling languages. Effective means for code generator integration area necessity for the post hoc integration of applicationspecific languages inmodel-based robotics software engineering.",Jan Oliver Ringert,2015/5/5,2015/5/5
2110.12594v2,Developing a Meta-suggestion Engine for Search Queries,http://arxiv.org/abs/2110.12594v2,"Typically, search engines provide query suggestions to assist users in thesearch process. Query suggestions are very important for improving users searchexperience. However, most query suggestions are based on the user's searchlogs, and they can be influenced by infrequently searched queries. Depending onthe user's query, query suggestions can be ineffective in global search enginesbut effective in a domestic search engine. Conversely, it can be effective inglobal engines and weak in domestic engines. In addition, log-based querysuggestions require many search logs, which makes them difficult to constructoutside of a large search engine. Some search engines do not provide querysuggestions, making searches difficult for users. These query suggestionvulnerabilities degrade the user's search experience. In this study, we developa meta-suggestion, a new query suggestion scheme. Similar to meta-searches,meta-suggestions retrieves candidate queries of suggestions from other searchengines. Meta-suggestions generate suggestions by reranking the aggregatedcandidate queries. We develop a meta-suggestion engine (MSE) browser extensionthat generates meta-suggestions. It can provide query suggestions for anywebpage and does not require a search log. Comparing our meta-suggestions tomajor search engines such as Google, showed a 17% performance improvement onnormalized discounted cumulative gain (NDCG) and a 31% improvement onprecision. If more detailed factors, such as user preferences are discoveredthrough continued research, it is expected that user searches will greatlyimprove. An enhanced user search experience is possible if factors, such asuser preference, are examined in future work.",Seungmin Kim,2021/10/25,2022/5/11
2310.08234v1,CiRA: An Open-Source Python Package for Automated Generation of Test Case Descriptions from Natural Language Requirements,http://arxiv.org/abs/2310.08234v1,"Deriving acceptance tests from high-level, natural language requirements thatachieve full coverage is a major manual challenge at the interface betweenrequirements engineering and testing. Conditional requirements (e.g., ""If A orB then C."") imply causal relationships which - when extracted - allow togenerate these acceptance tests automatically. This paper presents a tool fromthe CiRA (Causality In Requirements Artifacts) initiative, which automaticallyprocesses conditional natural language requirements and generates a minimal setof test case descriptions achieving full coverage. We evaluate the tool on apublicly available data set of 61 requirements from the requirementsspecification of the German Corona-Warn-App. The tool infers the correct testvariables in 84.5% and correct variable configurations in 92.3% of all cases,which corroborates the feasibility of our approach.",Julian Frattini,2023/10/12,2023/10/12
cs/0503003v1,An Objectives-Driven Process for Selecting Methods to Support Requirements Engineering Activities,http://arxiv.org/abs/cs/0503003v1,"This paper presents a framework that guides the requirements engineer in theimplementation and execution of an effective requirements generation process.We achieve this goal by providing a well-defined requirements engineering modeland a criteria based process for optimizing method selection for attendantactivities. Our model, unlike other models, addresses the complete requirementsgeneration process and consists of activities defined at more adequate levelsof abstraction. Additionally, activity objectives are identified and explicitlystated - not implied as in the current models. Activity objectives are crucialas they drive the selection of methods for each activity. Our model alsoincorporates a unique approach to verification and validation that enhancesquality and reduces the cost of generating requirements. To assist in theselection of methods, we have mapped commonly used methods to activities basedon their objectives. In addition, we have identified method selection criteriaand prescribed a reduced set of methods that optimize these criteria for eachactivity defined by our requirements generation process. Thus, the definedapproach assists in the task of selecting methods by using selection criteriato reduce a large collection of potential methods to a smaller, manageable set.The model and the set of methods, taken together, provide the much neededguidance for the effective implementation and execution of the requirementsgeneration process.",Lester Lobo,2005/3/2,2005/3/2
2004.01770v1,Software Engineering For Automated Game Design,http://arxiv.org/abs/2004.01770v1,"As we develop more assistive and automated game design systems, the questionof how these systems should be integrated into game development workflows, andhow much adaptation may be required, becomes increasingly important. In thispaper we explore the impact of software engineering decisions on the ability ofan automated game design system to understand a game's codebase, generate newgame code, and evaluate its work. We argue that a new approach to softwareengineering may be required in order for game developers to fully benefit fromautomated game designers.",Michael Cook,2020/4/3,2020/4/3
2208.13421v1,Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering,http://arxiv.org/abs/2208.13421v1,"There is an increasing interest in research on the combination of AItechniques and methods with MDE. However, there is a gap between AI and MDEpractices, as well as between researchers and practitioners. This paper tacklesthis gap by reporting on industrial requirements in this field. In the AIDOaRtresearch project, practitioners and researchers collaborate on AI-augmentedautomation supporting modeling, coding, testing, monitoring, and continuousdevelopment in cyber-physical systems. The project specifically lies at theintersection of industry and academia collaboration with several industrial usecases. Through a process of elicitation and refinement, 78 high-levelrequirements were defined, and generalized into 30 generic requirements by theAIDOaRt partners. The main contribution of this paper is the set of genericrequirements from the project for enhancing the development of cyber-physicalsystems with artificial intelligence, DevOps, and model-driven engineering,identifying the hot spots of industry needs in the interactions of MDE and AI.Future work will refine, implement and evaluate solutions toward theserequirements in industry contexts.",Johan Bergelin,2022/8/29,2022/8/29
2206.08530v1,GDsmith: Detecting Bugs in Graph Database Engines,http://arxiv.org/abs/2206.08530v1,"Graph database engines stand out in the era of big data for their efficiencyof modeling and processing linked data. There is a strong need of testing graphdatabase engines. However, random testing, the most practical way of automatedtest generation, faces the challenges of semantic validity, non-empty result,and behavior diversity to detect bugs in graph database engines. To addressthese challenges, in this paper, we propose GDsmith, the first black-boxapproach for testing graph database engines. It ensures that each randomlygenerated Cypher query satisfies the semantic requirements via skeletongeneration and completion. GDsmith includes our technique to increase theprobability of producing Cypher queries that return non-empty results byleveraging three types of structural mutation strategies. GDsmith also includesour technique to improve the behavior diversity of the generated Cypher queriesby selecting property keys according to their previous frequencies whengenerating new queries. Our evaluation results demonstrate that GDsmith iseffective and efficient for automated query generation and substantiallyoutperforms the baseline. GDsmith successfully detects 27 previously unknownbugs on the released versions of three popular open-source graph databaseengines and receive positive feedback from their developers.",Wei Lin,2022/6/17,2022/6/17
2304.02702v1,"Human Error Management in Requirements Engineering: Should We Fix the People, the Processes, or the Environment?",http://arxiv.org/abs/2304.02702v1,"Context: Software development is human-centric and vulnerable to human error.Human errors are errors in the human thought process. To ensure softwarequality, practitioners must understand how to manage these human errors.Organizations often change the requirements engineering process to preventhuman errors from occurring or to mitigate the harm caused when those errors dooccur. While there are studies on human error management in other disciplines,research on the prevention and mitigation of human errors in softwareengineering, and requirements engineering specifically, are limited. Thesoftware engineering studies do not provide strong results about the types ofchanges that are most effective in requirements engineering. Objective: Thegoal of this paper is to develop a taxonomy of human error prevention andmitigation strategies based on data from requirements engineeringprofessionals. Method: We performed a qualitative analysis of two practitionersurveys on requirements engineering practices to identify and classifystrategies for the prevention and mitigation of human errors. Results: Weorganized the human error management strategies into a taxonomy based onwhether they primarily affect People, Processes, or the Environment. Insideeach high-level category, we further organized the strategies into low-levelclasses. More than 50% of the reported strategies require a change in Process,23% require a change in Environment, 21% require a change in People, with theremaining 5% too ambiguous to classify. In addition, more than 50\% of thestrategies focus on Management activities. Conclusions: The Human ErrorManagement Taxonomy provides a systematic classification and organization ofstrategies for prevention and mitigation of human errors in requirementsengineering. This systematic organization provides a foundation upon whichresearch can build.",Sweta Mahaju,2023/4/5,2023/4/5
2311.11547v1,"Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT",http://arxiv.org/abs/2311.11547v1,"Context and motivation: Recently, Large Language Models (LLMs) like ChatGPThave demonstrated remarkable proficiency in various Natural Language Processing(NLP) tasks. Their application in Requirements Engineering (RE), especially inrequirements classification, has gained increasing interest. Question/problem:In our research, we conducted an extensive empirical evaluation of ChatGPTmodels including text-davinci-003, gpt-3.5-turbo, and gpt-4 in both zero-shotand few-shot settings for requirements classification. The question arises asto how these models compare to traditional classification methods, specificallySupport Vector Machine (SVM) and Long Short-Term Memory (LSTM). Principalideas/results: Based on five diverse datasets, our results show that ChatGPTconsistently outperforms LSTM, and while ChatGPT is more effective than SVM inclassifying functional requirements (FR), SVM is better in classifyingnon-functional requirements (NFR). Our results also show that contrary to ourexpectations, the few-shot setting does not always lead to enhancedperformance; in most instances, it was found to be suboptimal. Contribution:Our findings underscore the potential of LLMs in the RE domain, suggesting thatthey could play a pivotal role in future software engineering processes,particularly as tools to enhance requirements classification.",Abdelkarim El-Hajjami,2023/11/20,2023/11/20
2401.06948v1,Fast and Accurate Zero-Training Classification for Tabular Engineering Data,http://arxiv.org/abs/2401.06948v1,"In engineering design, navigating complex decision-making landscapes demandsa thorough exploration of the design, performance, and constraint spaces, oftenimpeded by resource-intensive simulations. Data-driven methods can mitigatethis challenge by harnessing historical data to delineate feasible domains,accelerate optimization, or evaluate designs. However, the implementation ofthese methods usually demands machine-learning expertise and multiple trials tochoose the right method and hyperparameters. This makes them less accessiblefor numerous engineering situations. Additionally, there is an inherenttrade-off between training speed and accuracy, with faster methods sometimescompromising precision. In our paper, we demonstrate that a recently releasedgeneral-purpose transformer-based classification model, TabPFN, is both fastand accurate. Notably, it requires no dataset-specific training to assess newtabular data. TabPFN is a Prior-Data Fitted Network, which undergoes a one-timeoffline training across a broad spectrum of synthetic datasets and performsin-context learning. We evaluated TabPFN's efficacy across eight engineeringdesign classification problems, contrasting it with seven other algorithms,including a state-of-the-art AutoML method. For these classificationchallenges, TabPFN consistently outperforms in speed and accuracy. It is alsothe most data-efficient and provides the added advantage of beingdifferentiable and giving uncertainty estimates. Our findings advocate for thepotential of pre-trained models that learn from synthetic data and require nodomain-specific tuning to make data-driven engineering design accessible to abroader community and open ways to efficient general-purpose models validacross applications. Furthermore, we share a benchmark problem set forevaluating new classification algorithms in engineering design.",Cyril Picard,2024/1/13,2024/1/13
2302.04723v2,Zero-Shot Learning for Requirements Classification: An Exploratory Study,http://arxiv.org/abs/2302.04723v2,"Context: Requirements engineering researchers have been experimenting withmachine learning and deep learning approaches for a range of RE tasks, such asrequirements classification, requirements tracing, ambiguity detection, andmodelling. However, most of today's ML/DL approaches are based on supervisedlearning techniques, meaning that they need to be trained using a large amountof task-specific labelled training data. This constraint poses an enormouschallenge to RE researchers, as the lack of labelled data makes it difficultfor them to fully exploit the benefit of advanced ML/DL technologies.Objective: This paper addresses this problem by showing how a zero-shotlearning approach can be used for requirements classification without using anylabelled training data. We focus on the classification task because many REtasks can be framed as classification problems. Method: The ZSL approach usedin our study employs contextual word-embeddings and transformer-based languagemodels. We demonstrate this approach through a series of experiments to performthree classification tasks: (1)FR/NFR: classification functional requirementsvs non-functional requirements; (2)NFR: identification of NFR classes;(3)Security: classification of security vs non-security requirements. Results:The study shows that the ZSL approach achieves an F1 score of 0.66 for theFR/NFR task. For the NFR task, the approach yields F1~0.72-0.80, consideringthe most frequent classes. For the Security task, F1~0.66. All of theaforementioned F1 scores are achieved with zero-training efforts. Conclusion:This study demonstrates the potential of ZSL for requirements classification.An important implication is that it is possible to have very little or notraining data to perform classification tasks. The proposed approach thuscontributes to the solution of the long-standing problem of data shortage inRE.",Waad Alhoshan,2023/2/9,2023/3/15
1601.03528v1,"A Taxonomy for Tools, Processes and Languages in Automotive Software Engineering",http://arxiv.org/abs/1601.03528v1,"Within the growing domain of software engineering in the automotive sector,the number of used tools, processes, methods and languages has increaseddistinctly in the past years. To be able to choose proper methods forparticular development use cases, factors like the intended use, key-featuresand possible limitations have to be evaluated. This requires a taxonomy thataids the decision making. An analysis of the main existing taxonomies revealedtwo major deficiencies: the lack of the automotive focus and the limitation toparticular engineering method types. To face this, a graphical taxonomy isproposed based on two well-established engineering approaches and enriched withadditional classification information. It provides a self-evident and-explanatory overview and comparison technique for engineering methods in theautomotive domain. The taxonomy is applied to common automotive engineeringmethods. The resulting diagram classifies each method and enables the reader toselect appropriate solutions for given project requirements.",Florian Bock,2016/1/14,2016/1/14
2302.05266v1,On the Applicability of Explainable Artificial Intelligence for Software Requirement Analysis,http://arxiv.org/abs/2302.05266v1,"The applications of Artificial Intelligence (AI) methods especially machinelearning techniques have increased in recent years. Classification algorithmshave been successfully applied to different problems such as requirementclassification. Although these algorithms have good performance, most of themcannot explain how they make a decision. Explainable Artificial Intelligence(XAI) is a set of new techniques that explain the predictions of machinelearning algorithms. In this work, the applicability of XAI for softwarerequirement classification is studied. An explainable software requirementclassifier is presented using the LIME algorithm. The explainability of theproposed method is studied by applying it to the PROMISE software requirementdataset. The results show that XAI can help the analyst or requirementspecifier to better understand why a specific requirement is classified asfunctional or non-functional. The important keywords for such decisions areidentified and analyzed in detail. The experimental study shows that the XAIcan be used to help analysts and requirement specifiers to better understandthe predictions of the classifiers for categorizing software requirements.Also, the effect of the XAI on feature reduction is analyzed. The resultsshowed that the XAI model has a positive role in feature analysis.",Behnaz Jamasb,2023/2/10,2023/2/10
1009.4964v1,Text Classification using Artificial Intelligence,http://arxiv.org/abs/1009.4964v1,"Text classification is the process of classifying documents into predefinedcategories based on their content. It is the automated assignment of naturallanguage texts to predefined categories. Text classification is the primaryrequirement of text retrieval systems, which retrieve texts in response to auser query, and text understanding systems, which transform text in some waysuch as producing summaries, answering questions or extracting data. Existingsupervised learning algorithms for classifying text need sufficient documentsto learn accurately. This paper presents a new algorithm for textclassification using artificial intelligence technique that requires fewerdocuments for training. Instead of using words, word relation i.e. associationrules from these words is used to derive feature set from pre-classified textdocuments. The concept of na\""ive Bayes classifier is then used on derivedfeatures and finally only a single concept of genetic algorithm has been addedfor final classification. A system based on the proposed algorithm has beenimplemented and tested. The experimental results show that the proposed systemworks as a successful text classifier.",S. M. Kamruzzaman,2010/9/25,2010/9/25
2310.01395v1,Requirements' Characteristics: How do they Impact on Project Budget in a Systems Engineering Context?,http://arxiv.org/abs/2310.01395v1,"Background: Requirements engineering is of a principal importance whenstarting a new project. However, the number of the requirements involved in asingle project can reach up to thousands. Controlling and assuring the qualityof natural language requirements (NLRs), in these quantities, is challenging.Aims: In a field study, we investigated with the Swedish Transportation Agency(STA) to what extent the characteristics of requirements had an influence onchange requests and budget changes in the project. Method: We choose thefollowing models to characterize system requirements formulated in naturallanguage: Concern-based Model of Requirements (CMR), Requirements AbstractionsModel (RAM) and Software-Hardware model (SHM). The classification of the NLRswas conducted by the three authors. The robust statistical measure Fleiss'Kappa was used to verify the reliability of the results. We used descriptivestatistics, contingency tables, results from the Chi-Square test of associationalong with post hoc tests. Finally, a multivariate statistical technique,Correspondence analysis was used in order to provide a means of displaying aset of requirements in two-dimensional graphical form. Results: The resultsshowed that software requirements are associated with less budget cost thanhardware requirements. Moreover, software requirements tend to stay open for alonger period indicating that they are ""harder"" to handle. Finally, the morediscussion or interaction on a change request can lower the actual estimatedchange request cost. Conclusions: The results lead us to a need to furtherinvestigate the reasons why the software requirements are treated differentlyfrom the hardware requirements, interview the project managers, understandbetter the way those requirements are formulated and propose effective ways ofSoftware management.",Panagiota Chatzipetrou,2023/10/2,2023/10/2
2104.05861v3,Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews,http://arxiv.org/abs/2104.05861v3,"Context: Mobile app reviews written by users on app stores or social mediaare significant resources for app developers.Analyzing app reviews have provedto be useful for many areas of software engineering (e.g., requirementengineering, testing). Automatic classification of app reviews requiresextensive efforts to manually curate a labeled dataset. When the classificationpurpose changes (e.g. identifying bugs versus usability issues or sentiment),new datasets should be labeled, which prevents the extensibility of thedeveloped models for new desired classes/tasks in practice. Recent pre-trainedneural language models (PTM) are trained on large corpora in an unsupervisedmanner and have found success in solving similar Natural Language Processingproblems. However, the applicability of PTMs is not explored for app reviewclassification Objective: We investigate the benefits of PTMs for app reviewclassification compared to the existing models, as well as the transferabilityof PTMs in multiple settings. Method: We empirically study the accuracy andtime efficiency of PTMs compared to prior approaches using six datasets fromliterature. In addition, we investigate the performance of the PTMs trained onapp reviews (i.e. domain-specific PTMs) . We set up different studies toevaluate PTMs in multiple settings: binary vs. multi-class classification,zero-shot classification (when new labels are introduced to the model),multi-task setting, and classification of reviews from different resources. Thedatasets are manually labeled app review datasets from Google Play Store, AppleApp Store, and Twitter data. In all cases, Micro and Macro Precision, Recall,and F1-scores will be used and we will report the time required for trainingand prediction with the models.",Mohammad Abdul Hadi,2021/4/12,2022/4/6
1804.02956v1,Towards Reproducible Research: Automatic Classification of Empirical Requirements Engineering Papers,http://arxiv.org/abs/1804.02956v1,"Research must be reproducible in order to make an impact on science and tocontribute to the body of knowledge in our field. Yet studies have shown that70% of research from academic labs cannot be reproduced. In softwareengineering, and more specifically requirements engineering (RE), reproducibleresearch is rare, with datasets not always available or methods not fullydescribed. This lack of reproducible research hinders progress, withresearchers having to replicate an experiment from scratch. A researcherstarting out in RE has to sift through conference papers, finding ones that areempirical, then must look through the data available from the empirical paper(if any) to make a preliminary determination if the paper can be reproduced.This paper addresses two parts of that problem, identifying RE papers andidentifying empirical papers within the RE papers. Recent RE and empiricalconference papers were used to learn features and to build an automaticclassifier to identify RE and empirical papers. We introduce the EmpiricalRequirements Research Classifier (ERRC) method, which uses natural languageprocessing and machine learning to perform supervised classification ofconference papers. We compare our method to a baseline keyword-based approach.To evaluate our approach, we examine sets of papers from the IEEE RequirementsEngineering conference and the IEEE International Symposium on Software Testingand Analysis. We found that the ERRC method performed better than the baselinemethod in all but a few cases.",Clinton Woodson,2018/4/9,2018/4/9
2107.03783v1,Use of Affective Visual Information for Summarization of Human-Centric Videos,http://arxiv.org/abs/2107.03783v1,"Increasing volume of user-generated human-centric video content and theirapplications, such as video retrieval and browsing, require compactrepresentations that are addressed by the video summarization literature.Current supervised studies formulate video summarization as asequence-to-sequence learning problem and the existing solutions often neglectthe surge of human-centric view, which inherently contains affective content.In this study, we investigate the affective-information enriched supervisedvideo summarization task for human-centric videos. First, we train a visualinput-driven state-of-the-art continuous emotion recognition model (CER-NET) onthe RECOLA dataset to estimate emotional attributes. Then, we integrate theestimated emotional attributes and the high-level representations from theCER-NET with the visual information to define the proposed affective videosummarization architectures (AVSUM). In addition, we investigate the use ofattention to improve the AVSUM architectures and propose two new architecturesbased on temporal attention (TA-AVSUM) and spatial attention (SA-AVSUM). Weconduct video summarization experiments on the TvSum database. The proposedAVSUM-GRU architecture with an early fusion of high level GRU embeddings andthe temporal attention based TA-AVSUM architecture attain competitive videosummarization performances by bringing strong performance improvements for thehuman-centric videos compared to the state-of-the-art in terms of F-score andself-defined face recall metrics.",Berkay Kpr,2021/7/8,2021/7/8
2310.09411v1,Surveying the Landscape of Text Summarization with Deep Learning: A Comprehensive Review,http://arxiv.org/abs/2310.09411v1,"In recent years, deep learning has revolutionized natural language processing(NLP) by enabling the development of models that can learn complexrepresentations of language data, leading to significant improvements inperformance across a wide range of NLP tasks. Deep learning models for NLPtypically use large amounts of data to train deep neural networks, allowingthem to learn the patterns and relationships in language data. This is incontrast to traditional NLP approaches, which rely on hand-engineered featuresand rules to perform NLP tasks. The ability of deep neural networks to learnhierarchical representations of language data, handle variable-length inputsequences, and perform well on large datasets makes them well-suited for NLPapplications. Driven by the exponential growth of textual data and theincreasing demand for condensed, coherent, and informative summaries, textsummarization has been a critical research area in the field of NLP. Applyingdeep learning to text summarization refers to the use of deep neural networksto perform text summarization tasks. In this survey, we begin with a review offashionable text summarization tasks in recent years, including extractive,abstractive, multi-document, and so on. Next, we discuss most deeplearning-based models and their experimental results on these tasks. The paperalso covers datasets and data representation for summarization tasks. Finally,we delve into the opportunities and challenges associated with summarizationtasks and their corresponding methodologies, aiming to inspire future researchefforts to advance the field further. A goal of our survey is to explain howthese methods differ in their requirements as understanding them is essentialfor choosing a technique suited for a specific setting.",Guanghua Wang,2023/10/13,2023/10/13
2301.13479v1,Archive TimeLine Summarization (ATLS): Conceptual Framework for Timeline Generation over Historical Document Collections,http://arxiv.org/abs/2301.13479v1,"Archive collections are nowadays mostly available through search enginesinterfaces, which allow a user to retrieve documents by issuing queries. Thestudy of these collections may be, however, impaired by some aspects of searchengines, such as the overwhelming number of documents returned or the lack ofcontextual knowledge provided. New methods that could work independently or incombination with search engines are then required to access these collections.In this position paper, we propose to extend TimeLine Summarization (TLS)methods on archive collections to assist in their studies. We provide anoverview of existing TLS methods and we describe a conceptual framework for anArchive TimeLine Summarization (ATLS) system, which aims to generateinformative, readable and interpretable timelines.",Nicolas Gutehrl,2023/1/31,2023/1/31
2305.14808v1,SAGA: Summarization-Guided Assert Statement Generation,http://arxiv.org/abs/2305.14808v1,"Generating meaningful assert statements is one of the key challenges inautomated test case generation, which requires understanding the intendedfunctionality of the tested code. Recently, deep learning-based models haveshown promise in improving the performance of assert statement generation.However, existing models only rely on the test prefixes along with theircorresponding focal methods, yet ignore the developer-written summarization.Based on our observations, the summarization contents usually express theintended program behavior or contain parameters that will appear directly inthe assert statement. Such information will help existing models address theircurrent inability to accurately predict assert statements. This paper presentsa novel summarization-guided approach for automatically generating assertstatements. To derive generic representations for natural language (i.e.,summarization) and programming language (i.e., test prefixes and focalmethods), we leverage a pre-trained language model as the referencearchitecture and fine-tune it on the task of assert statement generation. Tothe best of our knowledge, the proposed approach makes the first attempt toleverage the summarization of focal methods as the guidance for making thegenerated assert statements more accurate. We demonstrate the effectiveness ofour approach on two real-world datasets when compared with state-of-the-artmodels.",Yuwei Zhang,2023/5/24,2023/5/24
1904.00805v1,A Convolutional Neural Network for Language-Agnostic Source Code Summarization,http://arxiv.org/abs/1904.00805v1,"Descriptive comments play a crucial role in the software engineering process.They decrease development time, enable better bug detection, and facilitate thereuse of previously written code. However, comments are commonly the last of asoftware developer's priorities and are thus either insufficient or missingentirely. Automatic source code summarization may therefore have the ability tosignificantly improve the software development process. We introduce a novelencoder-decoder model that summarizes source code, effectively writing acomment to describe the code's functionality. We make two primary innovationsbeyond current source code summarization models. First, our encoder is fullylanguage-agnostic and requires no complex input preprocessing. Second, ourdecoder has an open vocabulary, enabling it to predict any word, even ones notseen in training. We demonstrate results comparable to state-of-the-art methodson a single-language data set and provide the first results on a data setconsisting of multiple programming languages.",Jessica Moore,2019/3/29,2019/3/29
2201.05222v2,Assemble Foundation Models for Automatic Code Summarization,http://arxiv.org/abs/2201.05222v2,"Automatic code summarization is beneficial to daily software developmentsince it could help reduce the requirement of manual writing. Currently,artificial intelligence is undergoing a paradigm shift. The foundation modelspretrained on massive data and finetuned to downstream tasks surpass speciallycustomized models. This trend inspired us to consider reusing foundation modelsinstead of learning from scratch. Thereby, we propose a flexible and robustapproach for automatic code summarization, based on neural models. We assembleavailable foundation models, such as CodeBERT and GPT-2, into a single neuralmodel named AdaMo. Moreover, we utilize Gaussian noise as the simulation ofcontextual information to optimize the latent representation. Furthermore, weintroduce two adaptive schemes from the perspective of knowledge transfer,namely continuous pretraining and intermediate finetuning, and designintermediate stage tasks for general sequence-to-sequence learning. Finally, weevaluate AdaMo against a benchmark dataset for code summarization, by comparingit with state-of-the-art models.",Jian Gu,2022/1/13,2022/3/11
2210.11843v1,Low-Resources Project-Specific Code Summarization,http://arxiv.org/abs/2210.11843v1,"Code summarization generates brief natural language descriptions of sourcecode pieces, which can assist developers in understanding code and reducedocumentation workload. Recent neural models on code summarization are trainedand evaluated on large-scale multi-project datasets consisting of independentcode-summary pairs. Despite the technical advances, their effectiveness on aspecific project is rarely explored. In practical scenarios, however,developers are more concerned with generating high-quality summaries for theirworking projects. And these projects may not maintain sufficient documentation,hence having few historical code-summary pairs. To this end, we investigatelow-resource project-specific code summarization, a novel task more consistentwith the developers' requirements. To better characterize project-specificknowledge with limited training samples, we propose a meta transfer learningmethod by incorporating a lightweight fine-tuning mechanism into ameta-learning framework. Experimental results on nine real-world projectsverify the superiority of our method over alternative ones and reveal how theproject-specific knowledge is learned.",Rui Xie,2022/10/21,2022/10/21
2308.07429v1,Semantic Similarity Loss for Neural Source Code Summarization,http://arxiv.org/abs/2308.07429v1,"This paper presents an improved loss function for neural source codesummarization. Code summarization is the task of writing natural languagedescriptions of source code. Neural code summarization refers to automatedtechniques for generating these descriptions using neural networks. Almost allcurrent approaches involve neural networks as either standalone models or aspart of a pretrained large language models e.g., GPT, Codex, LLaMA. Yet almostall also use a categorical cross-entropy (CCE) loss function for networkoptimization. Two problems with CCE are that 1) it computes loss over each wordprediction one-at-a-time, rather than evaluating a whole sentence, and 2) itrequires a perfect prediction, leaving no room for partial credit for synonyms.We propose and evaluate a loss function to alleviate this problem. In essence,we propose to use a semantic similarity metric to calculate loss over the wholeoutput sentence prediction per training batch, rather than just loss for eachword. We also propose to combine our loss with traditional CCE for each word,which streamlines the training process compared to baselines. We evaluate ourapproach over several baselines and report an improvement in the vast majorityof conditions.",Chia-Yi Su,2023/8/14,2023/8/14
2303.16178v1,Label Smoothing Improves Neural Source Code Summarization,http://arxiv.org/abs/2303.16178v1,"Label smoothing is a regularization technique for neural networks. Normallyneural models are trained to an output distribution that is a vector with asingle 1 for the correct prediction, and 0 for all other elements. Labelsmoothing converts the correct prediction location to something slightly lessthan 1, then distributes the remainder to the other elements such that they areslightly greater than 0. A conceptual explanation behind label smoothing isthat it helps prevent a neural model from becoming ""overconfident"" by forcingit to consider alternatives, even if only slightly. Label smoothing has beenshown to help several areas of language generation, yet typically requiresconsiderable tuning and testing to achieve the optimal results. This tuning andtesting has not been reported for neural source code summarization - a growingresearch area in software engineering that seeks to generate natural languagedescriptions of source code behavior. In this paper, we demonstrate the effectof label smoothing on several baselines in neural code summarization, andconduct an experiment to find good parameters for label smoothing and makerecommendations for its use.",Sakib Haque,2023/3/28,2023/3/28
1704.00421v1,Review on Requirements Modeling and Analysis for Self-Adaptive Systems: A Ten-Year Perspective,http://arxiv.org/abs/1704.00421v1,"Context: Over the last decade, software researchers and engineers havedeveloped a vast body of methodologies and technologies in requirementsengineering for self-adaptive systems. Although existing studies have exploredvarious aspects of this field, no systematic study has been performed onsummarizing modeling methods and corresponding requirements activities.Objective: This study summarizes the state-of-the-art research trends, detailsthe modeling methods and corresponding requirements activities, identifiesrelevant quality attributes and application domains and assesses the quality ofeach study. Method: We perform a systematic literature review underpinned by arigorously established and reviewed protocol. To ensure the quality of thestudy, we choose 21 highly regarded publication venues and 8 popular digitallibraries. In addition, we apply text mining to derive search strings and useKappa coefficient to mitigate disagreements of researchers. Results: Weselected 109 papers during the period of 2003-2013 and presented the researchdistributions over various kinds of factors. We extracted 29 modeling methodswhich are classified into 8 categories and identified 14 requirementsactivities which are classified into 4 requirements timelines. We captured 8concerned software quality attributes based on the ISO 9126 standard and 12application domains. Conclusion: The frequency of application of modelingmethods varies greatly. Enterprise models were more widely used while behaviormodels were more rigorously evaluated. Requirements-driven runtime adaptationwas the most frequently studied requirements activity. Activities at runtimewere conveyed with more details. Finally, we draw other conclusions bydiscussing how well modeling dimensions were considered in these modelingmethods and how well assurance dimensions were conveyed in requirementsactivities.",Zhuoqun Yang,2017/4/3,2017/4/3
2311.09735v1,GEO: Generative Engine Optimization,http://arxiv.org/abs/2311.09735v1,"The advent of large language models (LLMs) has ushered in a new paradigm ofsearch engines that use generative models to gather and summarize informationto answer user queries. This emerging technology, which we formalize under theunified framework of Generative Engines (GEs), has the potential to generateaccurate and personalized responses, and is rapidly replacing traditionalsearch engines like Google and Bing. Generative Engines typically satisfyqueries by synthesizing information from multiple sources and summarizing themwith the help of LLMs. While this shift significantly improves \textit{user}utility and \textit{generative search engine} traffic, it results in a hugechallenge for the third stakeholder -- website and content creators. Given theblack-box and fast-moving nature of Generative Engines, content creators havelittle to no control over when and how their content is displayed. Withgenerative engines here to stay, the right tools should be provided to ensurethat creator economy is not severely disadvantaged. To address this, weintroduce Generative Engine Optimization (GEO), a novel paradigm to aid contentcreators in improving the visibility of their content in Generative Engineresponses through a black-box optimization framework for optimizing anddefining visibility metrics. We facilitate systematic evaluation in this newparadigm by introducing GEO-bench, a benchmark of diverse user queries acrossmultiple domains, coupled with sources required to answer these queries.Through rigorous evaluation, we show that GEO can boost visibility by up to40\% in generative engine responses. Moreover, we show the efficacy of thesestrategies varies across domains, underscoring the need for domain-specificmethods. Our work opens a new frontier in the field of information discoverysystems, with profound implications for generative engines and contentcreators.",Pranjal Aggarwal,2023/11/16,2023/11/16
1202.1718v1,A transformation approach for collaboration based requirement models,http://arxiv.org/abs/1202.1718v1,"Distributed software engineering is widely recognized as a complex task.Among the inherent complexities is the process of obtaining a system designfrom its global requirement specification. This paper deals with suchtransformation process and suggests an approach to derive the behavior of agiven system components, in the form of distributed Finite State Machines, fromthe global system requirements, in the form of an augmented UML ActivityDiagrams notation. The process of the suggested approach is summarized in threesteps: the definition of the appropriate source Meta-Model (requirementsMeta-Model), the definition of the target Design Meta-Model and the definitionof the rules to govern the transformation during the derivation process. Thederivation process transforms the global system requirements described as UMLdiagram activities (extended with collaborations) to system roles behaviorsrepresented as UML finite state machines. The approach is implemented usingAtlas Transformation Language (ATL).",Ahmed Harbouche,2012/2/8,2012/2/8
1704.00420v1,A Thematic Study of Requirements Modeling and Analysis for Self-Adaptive Systems,http://arxiv.org/abs/1704.00420v1,"Over the last decade, researchers and engineers have developed a vast body ofmethodologies and technologies in requirements engineering for self-adaptivesystems. Although existing studies have explored various aspects of this topic,few of them have categorized and summarized these areas of research inrequire-ments modeling and analysis. This study aims to investigate theresearch themes based on the utilized modeling methods and RE activities. Weconduct a thematic study in the systematic literature review. The results arederived by synthesizing the extracted data with statistical methods. This paperprovides an updated review of the research literature, enabling researchers andpractitioners to better understand the research themes in these areas andidentify research gaps which need to be further studied.",Zhuoqun Yang,2017/4/3,2017/4/3
1201.2304v1,Query sensitive comparative summarization of search results using concept based segmentation,http://arxiv.org/abs/1201.2304v1,Query sensitive summarization aims at providing the users with the summary ofthe contents of single or multiple web pages based on the search query. Thispaper proposes a novel idea of generating a comparative summary from a set ofURLs from the search result. User selects a set of web page links from thesearch result produced by search engine. Comparative summary of these selectedweb sites is generated. This method makes use of HTML DOM tree structure ofthese web pages. HTML documents are segmented into set of concept blocks.Sentence score of each concept block is computed with respect to the query andfeature keywords. The important sentences from the concept blocks of differentweb pages are extracted to compose the comparative summary on the fly. Thissystem reduces the time and effort required for the user to browse various websites to compare the information. The comparative summary of the contents wouldhelp the users in quick decision making.,P. Chitra,2012/1/11,2012/1/11
astro-ph/0309752v1,Dynamo-Driven Outflows in Pre-Planetary Nebulae,http://arxiv.org/abs/astro-ph/0309752v1,"The plethora of asymmetric planetary nebulae and the curiously high momentaof pre-planetary nebula outflows suggest that rotational energy is extractedfrom the engines. Magneto-rotational outflows driven by dynamos might beoperating therein. I summarize scenarios involving (a) an isolated AGB star and(b) a binary. The efficacy of (a) requires re-establishing differentialrotation over the AGB star's lifetime, whereas (b) delivers the angularmomentum at the end of the AGB phase when needed, and may involve turbulentdisks. Both can produce fields that drive outflows of the required mechanicalluminosity and momentum, though weak points and open questions require furtherstudy.",Eric G. Blackman,2003/9/28,2003/9/28
2306.11823v1,EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only,http://arxiv.org/abs/2306.11823v1,"This paper presents EvolveMT for efficiently combining multiple machinetranslation (MT) engines. The proposed system selects the output from a singleengine for each segment by utilizing online learning techniques to predict themost suitable system for every translation request. A neural quality estimationmetric supervises the method without requiring reference translations. Theonline learning capability of this system allows for dynamic adaptation toalterations in the domain or machine translation engines, thereby obviating thenecessity for additional training. EvolveMT selects a subset of translationengines to be called based on the source sentence features. The degree ofexploration is configurable according to the desired quality-cost trade-off.Results from custom datasets demonstrate that EvolveMT achieves similartranslation accuracy at a lower cost than selecting the best translation ofeach segment from all translations using an MT quality estimator. To ourknowledge, EvolveMT is the first meta MT system that adapts itself afterdeployment to incoming translation requests from the production environmentwithout needing costly retraining on human feedback.",Kamer Ali Yuksel,2023/6/20,2023/6/20
2305.03873v1,"Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages",http://arxiv.org/abs/2305.03873v1,"In many humanitarian scenarios, translation into severely low resourcelanguages often does not require a universal translation engine, but adedicated text-specific translation engine. For example, healthcare records,hygienic procedures, government communication, emergency procedures andreligious texts are all limited texts. While generic translation engines forall languages do not exist, translation of multilingually known limited textsinto new, endangered languages may be possible and reduce human translationeffort. We attempt to leverage translation resources from many rich resourcelanguages to efficiently produce best possible translation quality for a wellknown text, which is available in multiple languages, in a new, severely lowresource language. We examine two approaches: 1. best selection of seedsentences to jump start translations in a new language in view of bestgeneralization to the remainder of a larger targeted text(s), and 2. we adaptlarge general multilingual translation engines from many other languages tofocus on a specific text in a new, unknown language. We find that adaptinglarge pretrained multilingual models to the domain/text first and then to theseverely low resource language works best. If we also select a best set of seedsentences, we can improve average chrF performance on new test languages from abaseline of 21.9 to 50.7, while reducing the number of seed sentences to onlyaround 1,000 in the new, unknown language.",Zhong Zhou,2023/5/5,2023/5/5
1210.5517v1,Design of English-Hindi Translation Memory for Efficient Translation,http://arxiv.org/abs/1210.5517v1,"Developing parallel corpora is an important and a difficult activity forMachine Translation. This requires manual annotation by Human Translators.Translating same text again is a useless activity. There are tools available toimplement this for European Languages, but no such tool is available for IndianLanguages. In this paper we present a tool for Indian Languages which not onlyprovides automatic translations of the previously available translation butalso provides multiple translations, in cases where a sentence has multipletranslations, in ranked list of suggestive translations for a sentence.Moreover this tool also lets translators have global and local saving optionsof their work, so that they may share it with others, which further lightensthe task.",Nisheeth Joshi,2012/10/19,2012/10/19
1301.6678v1,An Application of Uncertain Reasoning to Requirements Engineering,http://arxiv.org/abs/1301.6678v1,"This paper examines the use of Bayesian Networks to tackle one of the tougherproblems in requirements engineering, translating user requirements into systemrequirements. The approach taken is to model domain knowledge as BayesianNetwork fragments that are glued together to form a complete view of the domainspecific system requirements. User requirements are introduced as evidence andthe propagation of belief is used to determine what are the appropriate systemrequirements as indicated by user requirements. This concept has beendemonstrated in the development of a system specification and the results arepresented here.",Philip S. Barry,2013/1/23,2013/1/23
1807.02340v2,Testing Untestable Neural Machine Translation: An Industrial Case,http://arxiv.org/abs/1807.02340v2,"Neural Machine Translation (NMT) has been widely adopted recently due to itsadvantages compared with the traditional Statistical Machine Translation (SMT).However, an NMT system still often produces translation failures due to thecomplexity of natural language and sophistication in designing neural networks.While in-house black-box system testing based on reference translations (i.e.,examples of valid translations) has been a common practice for NMT qualityassurance, an increasingly critical industrial practice, named in-vivo testing,exposes unseen types or instances of translation failures when real users areusing a deployed industrial NMT system. To fill the gap of lacking test oraclefor in-vivo testing of an NMT system, in this paper, we propose a new approachfor automatically identifying translation failures, without requiring referencetranslations for a translation task; our approach can directly serve as a testoracle for in-vivo testing. Our approach focuses on properties of naturallanguage translation that can be checked systematically and uses informationfrom both the test inputs (i.e., the texts to be translated) and the testoutputs (i.e., the translations under inspection) of the NMT system. Ourevaluation conducted on real-world datasets shows that our approach caneffectively detect targeted property violations as translation failures. Ourexperiences on deploying our approach in both production and developmentenvironments of WeChat (a messenger app with over one billion monthly activeusers) demonstrate high effectiveness of our approach along with high industryimpact.",Wujie Zheng,2018/7/6,2018/10/3
2312.04068v1,Making Translators Privacy-aware on the User's Side,http://arxiv.org/abs/2312.04068v1,"We propose PRISM to enable users of machine translation systems to preservethe privacy of data on their own initiative. There is a growing demand to applymachine translation systems to data that require privacy protection. Whileseveral machine translation engines claim to prioritize privacy, the extent andspecifics of such protection are largely ambiguous. First, there is often alack of clarity on how and to what degree the data is protected. Even ifservice providers believe they have sufficient safeguards in place,sophisticated adversaries might still extract sensitive information. Second,vulnerabilities may exist outside of these protective measures, such as withincommunication channels, potentially leading to data leakage. As a result, usersare hesitant to utilize machine translation engines for data demanding highlevels of privacy protection, thereby missing out on their benefits. PRISMresolves this problem. Instead of relying on the translation service to keepdata safe, PRISM provides the means to protect data on the user's side. Thisapproach ensures that even machine translation engines with inadequate privacymeasures can be used securely. For platforms already equipped with privacysafeguards, PRISM acts as an additional protection layer, reinforcing theirsecurity furthermore. PRISM adds these privacy features without significantlycompromising translation accuracy. Our experiments demonstrate theeffectiveness of PRISM using real-world translators, T5 and ChatGPT(GPT-3.5-turbo), and the datasets with two languages. PRISM effectivelybalances privacy protection with translation accuracy.",Ryoma Sato,2023/12/7,2023/12/7
1909.05362v1,Problems with automating translation of movie/TV show subtitles,http://arxiv.org/abs/1909.05362v1,"We present 27 problems encountered in automating the translation of movie/TVshow subtitles. We categorize each problem in one of the three categories viz.problems directly related to textual translation, problems related to subtitlecreation guidelines, and problems due to adaptability of machine translation(MT) engines. We also present the findings of a translation quality evaluationexperiment where we share the frequency of 16 key problems. We show that thesystems working at the frontiers of Natural Language Processing do not performwell for subtitles and require some post-processing solutions for redressal ofthese problems",Prabhakar Gupta,2019/9/4,2019/9/4
2103.12797v1,RPT: Effective and Efficient Retrieval of Program Translations from Big Code,http://arxiv.org/abs/2103.12797v1,"Program translation is a growing demand in software engineering. Manualprogram translation requires programming expertise in source and targetlanguage. One way to automate this process is to make use of the big data ofprograms, i.e., Big Code. In particular, one can search for programtranslations in Big Code. However, existing code retrieval techniques are notdesigned for cross-language code retrieval. Other data-driven approachesrequire human efforts in constructing cross-language parallel datasets to traintranslation models. In this paper, we present RPT, a novel code translationretrieval system. We propose a lightweight but informative programrepresentation, which can be generalized to all imperative PLs. Furthermore, wepresent our index structure and hierarchical filtering mechanism for efficientcode retrieval from a Big Code database.",Binger Chen,2021/3/23,2021/3/23
1807.07149v1,A Hand-Held Multimedia Translation and Interpretation System with Application to Diet Management,http://arxiv.org/abs/1807.07149v1,"We propose a network independent, hand-held system to translate anddisambiguate foreign restaurant menu items in real-time. The system is based onthe use of a portable multimedia device, such as a smartphones or a PDA. Anaccurate and fast translation is obtained using a Machine Translation engineand a context-specific corpora to which we apply two pre-processing steps,called translation standardization and $n$-gram consolidation. The phrase-tablegenerated is orders of magnitude lighter than the ones commonly used in marketapplications, thus making translations computationally less expensive, anddecreasing the battery usage. Translation ambiguities are mitigated usingmultimedia information including images of dishes and ingredients, along withingredient lists. We implemented a prototype of our system on an iPod TouchSecond Generation for English speakers traveling in Spain. Our tests indicatethat our translation method yields higher accuracy than translation enginessuch as Google Translate, and does so almost instantaneously. The memoryrequirements of the application, including the database of images, are alsowell within the limits of the device. By combining it with a database ofnutritional information, our proposed system can be used to help individualswho follow a medical diet maintain this diet while traveling.",Albert Parra,2018/7/17,2018/7/17
1311.5836v1,Automatic Ranking of MT Outputs using Approximations,http://arxiv.org/abs/1311.5836v1,"Since long, research on machine translation has been ongoing. Still, we donot get good translations from MT engines so developed. Manual ranking of theseoutputs tends to be very time consuming and expensive. Identifying which one isbetter or worse than the others is a very taxing task. In this paper, we showan approach which can provide automatic ranks to MT outputs (translations)taken from different MT Engines and which is based on N-gram approximations. Weprovide a solution where no human intervention is required for ranking systems.Further we also show the evaluations of our results which show equivalentresults as that of human ranking.",Pooja Gupta,2013/11/22,2013/11/22
2007.07825v1,Intelligent requirements engineering from natural language and their chaining toward CAD models,http://arxiv.org/abs/2007.07825v1,"This paper assumes that design language plays an important role in howdesigners design and on the creativity of designers. Designers use and developmodels as an aid to thinking, a focus for discussion and decision-making and ameans of evaluating the reliability of the proposals. This paper proposes anintelligent method for requirements engineering from natural language and theirchaining toward CAD models. The transition from linguistic analysis to therepresentation of engineering requirements consists of the translation of thesyntactic structure into semantic form represented by conceptual graphs. Basedon the isomorphism between conceptual graphs and predicate logic, a formallanguage of the specification is proposed. The outcome of this language ischained and translated in Computer Aided Three-Dimensional InteractiveApplication (CATIA) models. The tool (EGEON: Engineering desiGn sEmanticselabOration and applicatioN) is developed to represent the semantic network ofengineering requirements. A case study on the design of a car door hinge ispresented to illustrates the proposed method.",Alain-Jrme Fougres,2020/7/14,2020/7/14
2305.15314v1,Towards Fine-Grained Localization of Privacy Behaviors,http://arxiv.org/abs/2305.15314v1,"Mobile applications are required to give privacy notices to users when theycollect or share personal information. Creating consistent and concise privacynotices can be a challenging task for developers. Previous work has attemptedto help developers create privacy notices through a questionnaire or predefinedtemplates. In this paper, we propose a novel approach and a framework, calledPriGen, that extends these prior work. PriGen uses static analysis to identifyAndroid applications' code segments that process sensitive information (i.e.permission-requiring code segments) and then leverages a Neural MachineTranslation model to translate them into privacy captions. We present theinitial evaluation of our translation task for ~300,000 code segments.",Vijayanta Jain,2023/5/24,2023/5/24
2310.13362v1,Towards General Error Diagnosis via Behavioral Testing in Machine Translation,http://arxiv.org/abs/2310.13362v1,"Behavioral testing offers a crucial means of diagnosing linguistic errors andassessing capabilities of NLP models. However, applying behavioral testing tomachine translation (MT) systems is challenging as it generally requires humanefforts to craft references for evaluating the translation quality of suchsystems on newly generated test cases. Existing works in behavioral testing ofMT systems circumvent this by evaluating translation quality withoutreferences, but this restricts diagnosis to specific types of errors, such asincorrect translation of single numeric or currency words. In order to diagnosegeneral errors, this paper proposes a new Bilingual Translation Pair Generationbased Behavior Testing (BTPGBT) framework for conducting behavioral testing ofMT systems. The core idea of BTPGBT is to employ a novel bilingual translationpair generation (BTPG) approach that automates the construction of high-qualitytest cases and their pseudoreferences. Experimental results on various MTsystems demonstrate that BTPGBT could provide comprehensive and accuratebehavioral testing results for general error diagnosis, which further leads toseveral insightful findings. Our code and data are available at https://github.com/wujunjie1998/BTPGBT.",Junjie Wu,2023/10/20,2023/10/20
2109.10294v4,DeepSTL -- From English Requirements to Signal Temporal Logic,http://arxiv.org/abs/2109.10294v4,"Formal methods provide very powerful tools and techniques for the design andanalysis of complex systems. Their practical application remains howeverlimited, due to the widely accepted belief that formal methods requireextensive expertise and a steep learning curve. Writing correct formalspecifications in form of logical formulas is still considered to be adifficult and error prone task.  In this paper we propose DeepSTL, a tool and technique for the translation ofinformal requirements, given as free English sentences, into Signal TemporalLogic (STL), a formal specification language for cyber-physical systems, usedboth by academia and advanced research labs in industry. A major challenge todevise such a translator is the lack of publicly available informalrequirements and formal specifications. We propose a two-step workflow toaddress this challenge. We first design a grammar-based generation technique ofsynthetic data, where each output is a random STL formula and its associatedset of possible English translations. In the second step, we use astate-of-the-art transformer-based neural translation technique, to train anaccurate attentional translator of English to STL. The experimental resultsshow high translation quality for patterns of English requirements that havebeen well trained, making this workflow promising to be extended for processingmore complex translation tasks.",Jie He,2021/9/21,2022/3/24
2006.09001v1,RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real,http://arxiv.org/abs/2006.09001v1,"Deep neural network based reinforcement learning (RL) can learn appropriatevisual representations for complex tasks like vision-based robotic graspingwithout the need for manually engineering or prior learning a perceptionsystem. However, data for RL is collected via running an agent in the desiredenvironment, and for applications like robotics, running a robot in the realworld may be extremely costly and time consuming. Simulated training offers anappealing alternative, but ensuring that policies trained in simulation cantransfer effectively into the real world requires additional machinery.Simulations may not match reality, and typically bridging thesimulation-to-reality gap requires domain knowledge and task-specificengineering. We can automate this process by employing generative models totranslate simulated images into realistic ones. However, this sort oftranslation is typically task-agnostic, in that the translated images may notpreserve all features that are relevant to the task. In this paper, weintroduce the RL-scene consistency loss for image translation, which ensuresthat the translation operation is invariant with respect to the Q-valuesassociated with the image. This allows us to learn a task-aware translation.Incorporating this loss into unsupervised domain translation, we obtainRL-CycleGAN, a new approach for simulation-to-real-world transfer forreinforcement learning. In evaluations of RL-CycleGAN on two vision-basedrobotics grasping tasks, we show that RL-CycleGAN offers a substantialimprovement over a number of prior methods for sim-to-real transfer, attainingexcellent real-world performance with only a modest number of real-worldobservations.",Kanishka Rao,2020/6/16,2020/6/16
1803.06643v1,The Web as a Knowledge-base for Answering Complex Questions,http://arxiv.org/abs/1803.06643v1,"Answering complex questions is a time-consuming activity for humans thatrequires reasoning and integration of information. Recent work on readingcomprehension made headway in answering simple questions, but tackling complexquestions is still an ongoing research challenge. Conversely, semantic parsershave been successful at handling compositionality, but only when theinformation resides in a target knowledge-base. In this paper, we present anovel framework for answering broad and complex questions, assuming answeringsimple questions is possible using a search engine and a reading comprehensionmodel. We propose to decompose complex questions into a sequence of simplequestions, and compute the final answer from the sequence of answers. Toillustrate the viability of our approach, we create a new dataset of complexquestions, ComplexWebQuestions, and present a model that decomposes questionsand interacts with the web to compute an answer. We empirically demonstratethat question decomposition improves performance from 20.8 precision@1 to 27.5precision@1 on this new dataset.",Alon Talmor,2018/3/18,2018/3/18
2212.10003v2,(QA)$^2$: Question Answering with Questionable Assumptions,http://arxiv.org/abs/2212.10003v2,"Naturally occurring information-seeking questions often contain questionableassumptions -- assumptions that are false or unverifiable. Questions containingquestionable assumptions are challenging because they require a distinct answerstrategy that deviates from typical answers for information-seeking questions.For instance, the question ""When did Marie Curie discover Uranium?"" cannot beanswered as a typical ""when"" question without addressing the false assumption""Marie Curie discovered Uranium"". In this work, we propose (QA)$^2$ (QuestionAnswering with Questionable Assumptions), an open-domain evaluation datasetconsisting of naturally occurring search engine queries that may or may notcontain questionable assumptions. To be successful on (QA)$^2$, systems must beable to detect questionable assumptions and also be able to produce adequateresponses for both typical information-seeking questions and ones withquestionable assumptions. Through human rater acceptability on end-to-end QAwith (QA)$^2$, we find that current models do struggle with handlingquestionable assumptions, leaving substantial headroom for progress.",Najoung Kim,2022/12/20,2023/8/29
2206.10233v1,COREQQA -- A COmpliance REQuirements Understanding using Question Answering Tool,http://arxiv.org/abs/2206.10233v1,"We introduce COREQQA, a tool for assisting requirements engineers inacquiring a better understanding of compliance requirements by means ofautomated Question Answering. Extracting compliance-related requirements bymanually navigating through a legal document is both time-consuming anderror-prone. COREQQA enables requirements engineers to pose questions innatural language about a compliance-related topic given some legal document,e.g., asking about data breach. The tool then automatically navigates throughthe legal document and returns to the requirements engineer a list of textpassages containing the possible answers to the input question. For betterreadability, the tool also highlights the likely answers in these passages. Theengineer can then use this output for specifying compliance requirements.COREQQA is developed using advanced large-scale language models from BERT'sfamily. COREQQA has been evaluated on four legal documents. The results of thisevaluation are briefly presented in the paper. The tool is publicly availableon Zenodo (DOI: 10.5281/zenodo.6653514).",Sallam Abualhaija,2022/6/21,2022/6/21
2104.08727v2,GooAQ: Open Question Answering with Diverse Answer Types,http://arxiv.org/abs/2104.08727v2,"While day-to-day questions come with a variety of answer types, the currentquestion-answering (QA) literature has failed to adequately address the answerdiversity of questions. To this end, we present GooAQ, a large-scale datasetwith a variety of answer types. This dataset contains over 5 million questionsand 3 million answers collected from Google. GooAQ questions are collectedsemi-automatically from the Google search engine using its autocompletefeature. This results in naturalistic questions of practical interest that arenonetheless short and expressed using simple language. GooAQ answers are minedfrom Google's responses to our collected questions, specifically from theanswer boxes in the search results. This yields a rich space of answer types,containing both textual answers (short and long) as well as more structuredones such as collections. We benchmarkT5 models on GooAQ and observe that: (a)in line with recent work, LM's strong performance on GooAQ's short-answerquestions heavily benefit from annotated data; however, (b) their quality ingenerating coherent and accurate responses for questions requiring longresponses (such as 'how' and 'why' questions) is less reliant on observingannotated data and mainly supported by their pre-training. We release GooAQ tofacilitate further research on improving QA with diverse response types.",Daniel Khashabi,2021/4/18,2021/9/10
1712.09827v1,A Syntactic Approach to Domain-Specific Automatic Question Generation,http://arxiv.org/abs/1712.09827v1,"Factoid questions are questions that require short fact-based answers.Automatic generation (AQG) of factoid questions from a given text cancontribute to educational activities, interactive question answering systems,search engines, and other applications. The goal of our research is to generatefactoid source-question-answer triplets based on a specific domain. We proposea four-component pipeline, which obtains as input a training corpus ofdomain-specific documents, along with a set of declarative sentences from thesame domain, and generates as output a set of factoid questions that refer tothe source sentences but are slightly different from them, so that aquestion-answering system or a person can be asked a question that requires adeeper understanding and knowledge than a simple word-matching. Contrary toexisting domain-specific AQG systems that utilize the template-based approachto question generation, we propose to transform each source sentence into a setof questions by applying a series of domain-independent rules (asyntactic-based approach). Our pipeline was evaluated in the domain of cybersecurity using a series of experiments on each component of the pipelineseparately and on the end-to-end system. The proposed approach generated ahigher percentage of acceptable questions than a prior state-of-the-art AQGsystem.",Guy Danon,2017/12/28,2017/12/28
2012.05818v1,Bew: Towards Answering Business-Entity-Related Web Questions,http://arxiv.org/abs/2012.05818v1,"We present BewQA, a system specifically designed to answer a class ofquestions that we call Bew questions. Bew questions are related tobusinesses/services such as restaurants, hotels, and movie theaters; forexample, ""Until what time is happy hour?"". These questions are challenging toanswer because the answers are found in open-domain Web, are present in shortsentences without surrounding context, and are dynamic since the webpageinformation can be updated frequently. Under these conditions, existing QAsystems perform poorly. We present a practical approach, called BewQA, that cananswer Bew queries by mining a template of the business-related webpages andusing the template to guide the search. We show how we can extract the templateautomatically by leveraging aggregator websites that aggregate informationabout business entities in a domain (e.g., restaurants). We answer a givenquestion by identifying the section from the extracted template that is mostlikely to contain the answer. By doing so we can extract the answers even whenthe answer span does not have sufficient context. Importantly, BewQA does notrequire any training. We crowdsource a new dataset of 1066 Bew questions andground-truth answers in the restaurant domain. Compared to state-of-the-art QAmodels, BewQA has a 27 percent point improvement in F1 score. Compared to acommercial search engine, BewQA answered correctly 29% more Bew questions.",Qingqing Cao,2020/12/10,2020/12/10
1803.08896v1,Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering,http://arxiv.org/abs/1803.08896v1,"Many vision and language tasks require commonsense reasoning beyonddata-driven image and natural language processing. Here we adopt VisualQuestion Answering (VQA) as an example task, where a system is expected toanswer a question in natural language about an image. Current state-of-the-artsystems attempted to solve the task using deep neural architectures andachieved promising performance. However, the resulting systems are generallyopaque and they struggle in understanding questions for which extra knowledgeis required. In this paper, we present an explicit reasoning layer on top of aset of penultimate neural network based systems. The reasoning layer enablesreasoning and answering questions where additional knowledge is required, andat the same time provides an interpretable interface to the end users.Specifically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) basedengine to reason over a basket of inputs: visual relations, the semantic parseof the question, and background ontological knowledge from word2vec andConceptNet. Experimental analysis of the answers and the key evidentialpredicates generated on the VQA dataset validate our approach.",Somak Aditya,2018/3/23,2018/3/23
1810.03918v1,Answer Extraction in Question Answering using Structure Features and Dependency Principles,http://arxiv.org/abs/1810.03918v1,"Question Answering (QA) research is a significant and challenging task inNatural Language Processing. QA aims to extract an exact answer from a relevanttext snippet or a document. The motivation behind QA research is the need ofuser who is using state-of-the-art search engines. The user expects an exactanswer rather than a list of documents that probably contain the answer. Inthis paper, for a successful answer extraction from relevant documents severalefficient features and relations are required to extract. The features includevarious lexical, syntactic, semantic and structural features. The proposedstructural features are extracted from the dependency features of the questionand supported document. Experimental results show that structural featuresimprove the accuracy of answer extraction when combined with the basic featuresand designed using dependency principles. Proposed structural features use newdesign principles which extract the long-distance relations. This addition is apossible reason behind the improvement in overall answer extraction accuracy.",Lokesh Kumar Sharma,2018/10/9,2018/10/9
1709.08165v1,A Model for Enhancing Human Behaviour with Security Questions: A Theoretical Perspective,http://arxiv.org/abs/1709.08165v1,"Security questions are one of the mechanisms used to recover passwords.Strong answers to security questions (i.e. high entropy) are hard for attackersto guess or obtain using social engineering techniques (e.g. monitoring ofsocial networking profiles), but at the same time are difficult to remember.Instead, weak answers to security questions (i.e. low entropy) are easy toremember, which makes them more vulnerable to cyber-attacks. Convenience leadsusers to use the same answers to security questions on multiple accounts, whichexposes these accounts to numerous cyber-threats. Hence, current securityquestions implementations rarely achieve the required security and memorabilityrequirements. This research study is the first step in the development of amodel which investigates the determinants that influence users' behaviouralintentions through motivation to select strong and memorable answers tosecurity questions. This research also provides design recommendations fornovel security questions mechanisms.",Nicholas Micallef,2017/9/24,2017/9/24
1808.09492v5,Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering,http://arxiv.org/abs/1808.09492v5,"Open-domain question answering remains a challenging task as it requiresmodels that are capable of understanding questions and answers, collectinguseful information, and reasoning over evidence. Previous work typicallyformulates this task as a reading comprehension or entailment problem givenevidence retrieved from search engines. However, existing techniques struggleto retrieve indirectly related evidence when no directly related evidence isprovided, especially for complex questions where it is hard to parse preciselywhat the question asks. In this paper we propose a retriever-reader model thatlearns to attend on essential terms during the question answering process. Webuild (1) an essential term selector which first identifies the most importantwords in a question, then reformulates the query and searches for relatedevidence; and (2) an enhanced reader that distinguishes between essential termsand distracting words to predict the answer. We evaluate our model on multipleopen-domain multiple-choice QA datasets, notably performing at the level of thestate-of-the-art on the AI2 Reasoning Challenge (ARC) dataset.",Jianmo Ni,2018/8/28,2019/5/9
cond-mat/0409175v1,"Questions, relevance and relative entropy",http://arxiv.org/abs/cond-mat/0409175v1,"What is a question? According to Cox a question can be identified with theset of assertions that constitute possible answers. In this paper we propose adifferent approach that combines the notion that questions are requests forinformation with the notion that probability distributions representuncertainties resulting from lack of information. This suggests that to eachprobability distribution one can naturally associate that particular questionwhich requests the information that is missing and vice-versa. We propose torepresent questions q by probability distributions Next we consider howquestions relate to each other: to what extent is finding the answer to onequestion relevant to answering another? A natural measure of relevance isderived by requiring that it satisfy three desirable features (three axioms).We find that the relevance of a question q to another question Q turns out tobe the relative entropy S[q,Q] of the corresponding distributions. Anapplication to statistical physics is briefly considered.",Ariel Caticha,2004/9/8,2004/9/8
2306.11174v1,Evaluating Privacy Questions From Stack Overflow: Can ChatGPT Compete?,http://arxiv.org/abs/2306.11174v1,"Stack Overflow and other similar forums are used commonly by developers toseek answers for their software development as well as privacy-relatedconcerns. Recently, ChatGPT has been used as an alternative to generate code orproduce responses to developers' questions. In this paper, we aim to understanddevelopers' privacy challenges by evaluating the types of privacy-relatedquestions asked on Stack Overflow. We then conduct a comparative analysisbetween the accepted responses given by Stack Overflow users and the responsesproduced by ChatGPT for those extracted questions to identify if ChatGPT couldserve as a viable alternative. Our results show that most privacy-relatedquestions are related to choice/consent, aggregation, and identification.Furthermore, our findings illustrate that ChatGPT generates similarly correctresponses for about 56% of questions, while for the rest of the responses, theanswers from Stack Overflow are slightly more accurate than ChatGPT.",Zack Delile,2023/6/19,2023/6/19
2310.18983v1,DCQA: Document-Level Chart Question Answering towards Complex Reasoning and Common-Sense Understanding,http://arxiv.org/abs/2310.18983v1,"Visually-situated languages such as charts and plots are omnipresent inreal-world documents. These graphical depictions are human-readable and areoften analyzed in visually-rich documents to address a variety of questionsthat necessitate complex reasoning and common-sense responses. Despite thegrowing number of datasets that aim to answer questions over charts, most onlyaddress this task in isolation, without considering the broader context ofdocument-level question answering. Moreover, such datasets lack adequatecommon-sense reasoning information in their questions. In this work, weintroduce a novel task named document-level chart question answering (DCQA).The goal of this task is to conduct document-level question answering,extracting charts or plots in the document via document layout analysis (DLA)first and subsequently performing chart question answering (CQA). The newlydeveloped benchmark dataset comprises 50,010 synthetic documents integratingcharts in a wide range of styles (6 styles in contrast to 3 for PlotQA andChartQA) and includes 699,051 questions that demand a high degree of reasoningability and common-sense understanding. Besides, we present the development ofa potent question-answer generation engine that employs table data, a richcolor set, and basic question templates to produce a vast array of reasoningquestion-answer pairs automatically. Based on DCQA, we devise an OCR-freetransformer for document-level chart-oriented understanding, capable of DLA andanswering complex reasoning and common-sense questions over charts in anOCR-free manner. Our DCQA dataset is expected to foster research onunderstanding visualizations in documents, especially for scenarios thatrequire complex reasoning for charts in the visually-rich document. Weimplement and evaluate a set of baselines, and our proposed method achievescomparable results.",Anran Wu,2023/10/29,2023/10/29
2303.01903v3,Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering,http://arxiv.org/abs/2303.01903v3,"Knowledge-based visual question answering (VQA) requires external knowledgebeyond the image to answer the question. Early studies retrieve requiredknowledge from explicit knowledge bases (KBs), which often introducesirrelevant information to the question, hence restricting the performance oftheir models. Recent works have resorted to using a powerful large languagemodel (LLM) as an implicit knowledge engine to acquire the necessary knowledgefor answering. Despite the encouraging results achieved by these methods, weargue that they have not fully activated the capacity of the blind LLM as theprovided textual input is insufficient to depict the required visualinformation to answer the question. In this paper, we present Prophet -- aconceptually simple, flexible, and general framework designed to prompt LLMwith answer heuristics for knowledge-based VQA. Specifically, we first train avanilla VQA model on a specific knowledge-based VQA dataset without externalknowledge. After that, we extract two types of complementary answer heuristicsfrom the VQA model: answer candidates and answer-aware examples. Finally, thetwo types of answer heuristics are jointly encoded into a formatted prompt tofacilitate the LLM's understanding of both the image and question, thusgenerating a more accurate answer. By incorporating the state-of-the-art LLMGPT-3, Prophet significantly outperforms existing state-of-the-art methods onfour challenging knowledge-based VQA datasets. To demonstrate the generality ofour approach, we instantiate Prophet with the combinations of different VQAmodels (i.e., both discriminative and generative ones) and different LLMs(i.e., both commercial and open-source ones).",Zhou Yu,2023/3/3,2023/12/14
2204.09036v1,Write a Line: Tests with Answer Templates and String Completion Hints for Self-Learning in a CS1 Course,http://arxiv.org/abs/2204.09036v1,"One of the important scaffolding tasks in programming learning is writing aline of code performing the necessary action. This allows students to practiceskills in a playground with instant feedback before writing more complexprograms and increases their proficiency when solving programming problems.However, answers in the form of program code have high variability. Among thepossible approaches to grading and providing feedback, we chose templatematching. This paper reports the results of using regular-expression-basedquestions with string completion hints in a CS1 course for 4 years with 497students. The evaluation results show that Perl-compatible regular expressionsprovide good precision and recall (more than 99\%) when used for questionsrequiring writing a single line of code while being able to providestring-completion feedback regardless of how wrong the initial student's answeris. After introducing formative quizzes with string-completion hints to thecourse, the number of questions that teachers and teaching assistants receivedabout questions in the formative quizzes dropped considerably: most of thetraining question attempts resulted in finding the correct answer without helpfrom the teaching staff. However, some of the students use formative quizzesjust to learn correct answers without actually trying to answer the questions.",Oleg Sychev,2022/4/19,2022/4/19
1907.04149v1,Answer Extraction for Why Arabic Questions Answering Systems: EWAQ,http://arxiv.org/abs/1907.04149v1,"With the increasing amount of web information, questions answering systemsbecomes very important to allow users to access to direct answers for theirrequests. This paper presents an Arabic Questions Answering Systems based onentailment metrics. The type of questions which this paper focuses on is whyquestions. There are many reasons lead us to develop this system: generally,the lack of Arabic Questions Answering Systems and scarcity Arabic QuestionsAnswering Systems which focus on why questions. The goal of the proposed systemin this research is to extract answers from re-ranked retrieved passages whichare retrieved by search engines. This system extracts the answer only to whyquestions. This system is called by EWAQ: Entailment based Why Arabic QuestionsAnswering. Each answer is scored with entailment metrics and ranked accordingto their scores in order to determine the most possible correct answer. EWAQ iscompared with search engines: yahoo, google and ask.com, the well-establishedweb-based Questions Answering systems, using manual test set. In EWAQexperiments, it is showed that the accuracy is increased by implementing thetextual entailment in re-raking the retrieved relevant passages by searchengines and deciding the correct answer. The obtained results show that usingentailment based similarity can help significantly to tackle the why AnswerExtraction module in Arabic language.",Fatima T. AL-Khawaldeh,2019/7/4,2019/7/4
1403.0541v1,"Representing, reasoning and answering questions about biological pathways - various applications",http://arxiv.org/abs/1403.0541v1,"Biological organisms are composed of numerous interconnected biochemicalprocesses. Diseases occur when normal functionality of these processes isdisrupted. Thus, understanding these biochemical processes and theirinterrelationships is a primary task in biomedical research and a prerequisitefor diagnosing diseases, and drug development. Scientists studying theseprocesses have identified various pathways responsible for drug metabolism, andsignal transduction, etc.  Newer techniques and speed improvements have resulted in deeper knowledgeabout these pathways, resulting in refined models that tend to be large andcomplex, making it difficult for a person to remember all aspects of it. Thus,computer models are needed to analyze them. We want to build such a system thatallows modeling of biological systems and pathways in such a way that we cananswer questions about them.  Many existing models focus on structural and/or factoid questions, usingsurface-level knowledge that does not require understanding the underlyingmodel. We believe these are not the kind of questions that a biologist may asksomeone to test their understanding of the biological processes. We want oursystem to answer the kind of questions a biologist may ask. Such questionsappear in early college level text books.  Thus the main goal of our thesis is to develop a system that allows us toencode knowledge about biological pathways and answer such questions about themdemonstrating understanding of the pathway. To that end, we develop a languagethat will allow posing such questions and illustrate the utility of ourframework with various applications in the biological domain. We use someexisting tools with modifications to accomplish our goal.  Finally, we apply our system to real world applications by extracting pathwayknowledge from text and answering questions related to drug development.",Saadat Anwar,2014/3/3,2014/3/3
2306.06233v1,Boosting GUI Prototyping with Diffusion Models,http://arxiv.org/abs/2306.06233v1,"GUI (graphical user interface) prototyping is a widely-used technique inrequirements engineering for gathering and refining requirements, reducingdevelopment risks and increasing stakeholder engagement. However, GUIprototyping can be a time-consuming and costly process. In recent years, deeplearning models such as Stable Diffusion have emerged as a powerfultext-to-image tool capable of generating detailed images based on text prompts.In this paper, we propose UI-Diffuser, an approach that leverages StableDiffusion to generate mobile UIs through simple textual descriptions and UIcomponents. Preliminary results show that UI-Diffuser provides an efficient andcost-effective way to generate mobile GUI designs while reducing the need forextensive prototyping efforts. This approach has the potential to significantlyimprove the speed and efficiency of GUI prototyping in requirementsengineering.",Jialiang Wei,2023/6/9,2023/6/9
1107.3297v1,Semantic annotation of requirements for automatic UML class diagram generation,http://arxiv.org/abs/1107.3297v1,"The increasing complexity of software engineering requires effective methodsand tools to support requirements analysts' activities. While much of acompany's knowledge can be found in text repositories, current contentmanagement systems have limited capabilities for structuring and interpretingdocuments. In this context, we propose a tool for transforming text documentsdescribing users' requirements to an UML model. The presented tool uses NaturalLanguage Processing (NLP) and semantic rules to generate an UML class diagram.The main contribution of our tool is to provide assistance to designersfacilitating the transition from a textual description of user requirements totheir UML diagrams based on GATE (General Architecture of Text) by formulatingnecessary rules that generate new semantic annotations.",Soumaya Amdouni,2011/7/17,2011/7/17
1412.1842v1,Reading Text in the Wild with Convolutional Neural Networks,http://arxiv.org/abs/1412.1842v1,"In this work we present an end-to-end system for text spotting -- localisingand recognising text in natural scene images -- and text based image retrieval.This system is based on a region proposal mechanism for detection and deepconvolutional neural networks for recognition. Our pipeline uses a novelcombination of complementary proposal generation techniques to ensure highrecall, and a fast subsequent filtering stage for improving precision. For therecognition and ranking of proposals, we train very large convolutional neuralnetworks to perform word recognition on the whole proposal region at the sametime, departing from the character classifier based systems of the past. Thesenetworks are trained solely on data produced by a synthetic text generationengine, requiring no human labelled data.  Analysing the stages of our pipeline, we show state-of-the-art performancethroughout. We perform rigorous experiments across a number of standardend-to-end text spotting benchmarks and text-based image retrieval datasets,showing a large improvement over all previous methods. Finally, we demonstratea real-world application of our text spotting system to allow thousands ofhours of news footage to be instantly searchable via a text query.",Max Jaderberg,2014/12/4,2014/12/4
cs/0102002v1,On the Automated Classification of Web Sites,http://arxiv.org/abs/cs/0102002v1,"In this paper we discuss several issues related to automated textclassification of web sites. We analyze the nature of web content and metadatain relation to requirements for text features. We find that HTML metatags are agood source of text features, but are not in wide use despite their role insearch engine rankings. We present an approach for targeted spidering includingmetadata extraction and opportunistic crawling of specific semantic hyperlinks.We describe a system for automatically classifying web sites into industrycategories and present performance results based on different combinations oftext features and training data. This system can serve as the basis for ageneralized framework for automated metadata creation.",John M. Pierre,2001/2/1,2001/2/1
2112.08493v1,StyleMC: Multi-Channel Based Fast Text-Guided Image Generation and Manipulation,http://arxiv.org/abs/2112.08493v1,"Discovering meaningful directions in the latent space of GANs to manipulatesemantic attributes typically requires large amounts of labeled data. Recentwork aims to overcome this limitation by leveraging the power of ContrastiveLanguage-Image Pre-training (CLIP), a joint text-image model. While promising,these methods require several hours of preprocessing or training to achieve thedesired manipulations. In this paper, we present StyleMC, a fast and efficientmethod for text-driven image generation and manipulation. StyleMC uses aCLIP-based loss and an identity loss to manipulate images via a single textprompt without significantly affecting other attributes. Unlike prior work,StyleMC requires only a few seconds of training per text prompt to find stableglobal directions, does not require prompt engineering and can be used with anypre-trained StyleGAN2 model. We demonstrate the effectiveness of our method andcompare it to state-of-the-art methods. Our code can be found athttp://catlab-team.github.io/stylemc.",Umut Kocasari,2021/12/15,2021/12/15
1812.11270v1,Weakly-Supervised Hierarchical Text Classification,http://arxiv.org/abs/1812.11270v1,"Hierarchical text classification, which aims to classify text documents intoa given hierarchy, is an important task in many real-world applications.Recently, deep neural models are gaining increasing popularity for textclassification due to their expressive power and minimum requirement forfeature engineering. However, applying deep neural networks for hierarchicaltext classification remains challenging, because they heavily rely on a largeamount of training data and meanwhile cannot easily determine appropriatelevels of documents in the hierarchical setting. In this paper, we propose aweakly-supervised neural method for hierarchical text classification. Ourmethod does not require a large amount of training data but requires onlyeasy-to-provide weak supervision signals such as a few class-related documentsor keywords. Our method effectively leverages such weak supervision signals togenerate pseudo documents for model pre-training, and then performsself-training on real unlabeled data to iteratively refine the model. Duringthe training process, our model features a hierarchical neural structure, whichmimics the given hierarchy and is capable of determining the proper levels fordocuments with a blocking mechanism. Experiments on three datasets fromdifferent domains demonstrate the efficacy of our method compared with acomprehensive set of baselines.",Yu Meng,2018/12/29,2018/12/29
2104.11493v3,Stroke-Based Scene Text Erasing Using Synthetic Data for Training,http://arxiv.org/abs/2104.11493v3,"Scene text erasing, which replaces text regions with reasonable content innatural images, has drawn significant attention in the computer visioncommunity in recent years. There are two potential subtasks in scene texterasing: text detection and image inpainting. Both subtasks requireconsiderable data to achieve better performance; however, the lack of alarge-scale real-world scene-text removal dataset does not allow existingmethods to realize their potential. To compensate for the lack of pairwisereal-world data, we made considerable use of synthetic text after additionalenhancement and subsequently trained our model only on the dataset generated bythe improved synthetic text engine. Our proposed network contains a stroke maskprediction module and background inpainting module that can extract the textstroke as a relatively small hole from the cropped text image to maintain morebackground content for better inpainting results. This model can partiallyerase text instances in a scene image with a bounding box or work with anexisting scene-text detector for automatic scene text erasing. The experimentalresults from the qualitative and quantitative evaluation on the SCUT-Syn,ICDAR2013, and SCUT-EnsText datasets demonstrate that our method significantlyoutperforms existing state-of-the-art methods even when they are trained onreal-world data.",Zhengmi Tang,2021/4/23,2021/12/3
1809.01478v2,Weakly-Supervised Neural Text Classification,http://arxiv.org/abs/1809.01478v2,"Deep neural networks are gaining increasing popularity for the classic textclassification task, due to their strong expressive power and less requirementfor feature engineering. Despite such attractiveness, neural textclassification models suffer from the lack of training data in many real-worldapplications. Although many semi-supervised and weakly-supervised textclassification models exist, they cannot be easily applied to deep neuralmodels and meanwhile support limited supervision types. In this paper, wepropose a weakly-supervised method that addresses the lack of training data inneural text classification. Our method consists of two modules: (1) apseudo-document generator that leverages seed information to generatepseudo-labeled documents for model pre-training, and (2) a self-training modulethat bootstraps on real unlabeled data for model refinement. Our method has theflexibility to handle different types of weak supervision and can be easilyintegrated into existing deep neural models for text classification. We haveperformed extensive experiments on three real-world datasets from differentdomains. The results demonstrate that our proposed method achieves inspiringperformance without requiring excessive training data and outperforms baselinemethods significantly.",Yu Meng,2018/9/2,2018/9/12
1403.1939v1,Extraction of Core Contents from Web Pages,http://arxiv.org/abs/1403.1939v1,"The information available on web pages mostly contains semi-structured textdocuments which are represented either in XML, or HTML, or XHTML format thatlacks formatted document structure. The document does not discriminate betweenthe text and the schema that represent the text. Also the amount of structureused to represent the text depends on the purpose and size of text document. Nosemantic is applied to semi-structured documents. This requires extracting corecontents of text document to analyse words or sentences to generate usefulknowledge. This paper discusses several techniques and approaches useful forextracting core content from semi-structured text documents and their meritsand demerits",Sandeep Sirsat,2014/3/8,2014/3/8
2111.13327v2,Traditional Chinese Synthetic Datasets Verified with Labeled Data for Scene Text Recognition,http://arxiv.org/abs/2111.13327v2,"Scene text recognition (STR) has been widely studied in academia andindustry. Training a text recognition model often requires a large amount oflabeled data, but data labeling can be difficult, expensive, or time-consuming,especially for Traditional Chinese text recognition. To the best of ourknowledge, public datasets for Traditional Chinese text recognition arelacking. This paper presents a framework for a Traditional Chinese syntheticdata engine which aims to improve text recognition model performance. Wegenerated over 20 million synthetic data and collected over 7,000 manuallylabeled data TC-STR 7k-word as the benchmark. Experimental results show that atext recognition model can achieve much better accuracy either by training fromscratch with our generated synthetic data or by further fine-tuning with TC-STR7k-word.",Yi-Chang Chen,2021/11/26,2022/8/7
2312.06355v2,Linguistic and Structural Basis of Engineering Design Knowledge,http://arxiv.org/abs/2312.06355v2,"Artefact descriptions are the primary carriers of engineering designknowledge that is both an outcome and a driver of the design process. While anartefact could be described in different connotations, the design processrequires a description to embody engineering design knowledge, which isexpressed in the text through intricate placement of entities andrelationships. As large-language models learn from all kinds of text merely asa sequence of characters/tokens, these are yet to generate text that embodiesexplicit engineering design facts. Existing ontological design theories areless likely to guide the large-language models whose applications are currentlylimited to ideation and learning purposes. In this article, we explicateengineering design knowledge as knowledge graphs from a large sample of 33,881patent documents. We examine the constituents of these knowledge graphs tounderstand the linguistic and structural basis of engineering design knowledge.In terms of linguistic basis, we observe that entities and relationships couldbe generalised to 64 and 24 linguistic syntaxes. While relationships mainlycapture attributes ('of'), structure ('in', 'with'), purpose ('to', 'for'),hierarchy ('include'), exemplification ('such as'), and behaviour ('to','from'), the hierarchical relationships could specifically be identified using75 unique syntaxes. To understand the structural basis, we draw inspirationfrom various studies on biological/ecological networks and discover motifs frompatent knowledge graphs. We identify four 3-node and four 4-node patterns thatcould further be converged and simplified into sequence [->...->], aggregation[->...<-], and hierarchy [<-...->]. Expected to guide large-language modelbased design tools, we propose few regulatory precepts for concretisingabstract entities and relationships within subgraphs, while explicatinghierarchical structures.",L. Siddharth,2023/12/11,2024/1/16
1304.3879v1,Automatic case acquisition from texts for process-oriented case-based reasoning,http://arxiv.org/abs/1304.3879v1,"This paper introduces a method for the automatic acquisition of a rich caserepresentation from free text for process-oriented case-based reasoning. Caseengineering is among the most complicated and costly tasks in implementing acase-based reasoning system. This is especially so for process-orientedcase-based reasoning, where more expressive case representations are generallyused and, in our opinion, actually required for satisfactory case adaptation.In this context, the ability to acquire cases automatically from proceduraltexts is a major step forward in order to reason on processes. We thereforedetail a methodology that makes case acquisition from processes described asfree text possible, with special attention given to assembly instruction texts.This methodology extends the techniques we used to extract actions from cookingrecipes. We argue that techniques taken from natural language processing arerequired for this task, and that they give satisfactory results. An evaluationbased on our implemented prototype extracting workflows from recipe texts isprovided.",Valmi Dufour-Lussier,2013/4/14,2013/4/14
2308.06721v1,IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models,http://arxiv.org/abs/2308.06721v1,"Recent years have witnessed the strong power of large text-to-image diffusionmodels for the impressive generative capability to create high-fidelity images.However, it is very tricky to generate desired images using only text prompt asit often involves complex prompt engineering. An alternative to text prompt isimage prompt, as the saying goes: ""an image is worth a thousand words"".Although existing methods of direct fine-tuning from pretrained models areeffective, they require large computing resources and are not compatible withother base models, text prompt, and structural controls. In this paper, wepresent IP-Adapter, an effective and lightweight adapter to achieve imageprompt capability for the pretrained text-to-image diffusion models. The keydesign of our IP-Adapter is decoupled cross-attention mechanism that separatescross-attention layers for text features and image features. Despite thesimplicity of our method, an IP-Adapter with only 22M parameters can achievecomparable or even better performance to a fully fine-tuned image prompt model.As we freeze the pretrained diffusion model, the proposed IP-Adapter can begeneralized not only to other custom models fine-tuned from the same basemodel, but also to controllable generation using existing controllable tools.With the benefit of the decoupled cross-attention strategy, the image promptcan also work well with the text prompt to achieve multimodal image generation.The project page is available at \url{https://ip-adapter.github.io}.",Hu Ye,2023/8/13,2023/8/13
2207.08143v4,Can large language models reason about medical questions?,http://arxiv.org/abs/2207.08143v4,"Although large language models (LLMs) often produce impressive outputs, itremains unclear how they perform in real-world scenarios requiring strongreasoning skills and expert domain knowledge. We set out to investigate whetherclose- and open-source models (GPT-3.5, LLama-2, etc.) can be applied to answerand reason about difficult real-world-based questions. We focus on threepopular medical benchmarks (MedQA-USMLE, MedMCQA, and PubMedQA) and multipleprompting scenarios: Chain-of-Thought (CoT, think step-by-step), few-shot andretrieval augmentation. Based on an expert annotation of the generated CoTs, wefound that InstructGPT can often read, reason and recall expert knowledge.Last, by leveraging advances in prompt engineering (few-shot and ensemblemethods), we demonstrated that GPT-3.5 not only yields calibrated predictivedistributions, but also reaches the passing score on three datasets:MedQA-USMLE 60.2%, MedMCQA 62.7% and PubMedQA 78.2%. Open-source models areclosing the gap: Llama-2 70B also passed the MedQA-USMLE with 62.5% accuracy.",Valentin Livin,2022/7/17,2023/12/24
2101.03696v1,A Cooperative Dynamic Task Assignment Framework for COTSBot AUVs,http://arxiv.org/abs/2101.03696v1,"This paper presents a cooperative dynamic task assignment framework for acertain class of Autonomous Underwater Vehicles (AUVs) employed to controloutbreak of Crown-Of-Thorns Starfish (COTS) in Australia's Great Barrier Reef.The problem of monitoring and controlling the COTS is transcribed into aconstrained task assignment problem in which eradicating clusters of COTS, bythe injection system of COTSbot AUVs, is considered as a task. A probabilisticmap of the operating environment including seabed terrain, clusters of COTS,and coastlines is constructed. Then, a novel heuristic algorithm calledHeuristic Fleet Cooperation (HFC) is developed to provide a cooperativeinjection of the COTSbot AUVs to the maximum possible COTS in an assignedmission time. Extensive simulation studies together with quantitativeperformance analysis are conducted to demonstrate the effectiveness androbustness of the proposed cooperative task assignment algorithm in eradicatingthe COTS in the Great Barrier Reef.",Amin Abbasi,2021/1/11,2021/1/11
2307.09163v1,Generative Type Inference for Python,http://arxiv.org/abs/2307.09163v1,"Python is a popular dynamic programming language, evidenced by its ranking asthe second most commonly used language on GitHub. However, its dynamic typesystem can lead to potential type errors, leading researchers to exploreautomatic type inference approaches for Python programs. The rule-based typeinference approaches can ensure the accuracy of predicted variable types, butthey suffer from low coverage problems. Supervised type inference approaches,while feature-agnostic, require large, high-quality annotated datasets and arelimited to pre-defined types. As zero-shot approaches, the cloze-styleapproaches reformulate the type inference problem into a fill-in-the-blankproblem. However, their performance is limited.  This paper introduces TypeGen, a few-shot generative type inference approachthat incorporates static domain knowledge from static analysis. TypeGen createschain-of-thought (COT) prompts by translating the type inference steps ofstatic analysis into prompts based on the type dependency graphs (TDGs),enabling language models to learn from how static analysis infers types. Bycombining COT prompts with code slices and type hints, TypeGen constructsexample prompts from human annotations. TypeGen only requires very fewannotated examples to teach language models to generate similar COT prompts viain-context learning. Moreover, TypeGen enhances the interpretability of resultsthrough the use of the input-explanation-output strategy. Experiments show thatTypeGen outperforms the best baseline Type4Py by 10.0% for argument typeprediction and 22.5% in return value type prediction in terms of top-1 ExactMatch by using only five examples. Furthermore, TypeGen achieves substantialimprovements of 27% to 84% compared to the zero-shot performance of largelanguage models with parameter sizes ranging from 1.3B to 175B in terms oftop-1 Exact Match.",Yun Peng,2023/7/18,2023/7/18
2210.03493v1,Automatic Chain of Thought Prompting in Large Language Models,http://arxiv.org/abs/2210.03493v1,"Large language models (LLMs) can perform complex reasoning by generatingintermediate reasoning steps. Providing these steps for promptingdemonstrations is called chain-of-thought (CoT) prompting. CoT prompting hastwo major paradigms. One leverages a simple prompt like ""Let's think step bystep"" to facilitate step-by-step thinking before answering a question. Theother uses a few manual demonstrations one by one, each composed of a questionand a reasoning chain that leads to an answer. The superior performance of thesecond paradigm hinges on the hand-crafting of task-specific demonstrations oneby one. We show that such manual efforts may be eliminated by leveraging LLMswith the ""Let's think step by step"" prompt to generate reasoning chains fordemonstrations one by one, i.e., let's think not just step by step, but alsoone by one. However, these generated chains often come with mistakes. Tomitigate the effect of such mistakes, we find that diversity matters forautomatically constructing demonstrations. We propose an automatic CoTprompting method: Auto-CoT. It samples questions with diversity and generatesreasoning chains to construct demonstrations. On ten public benchmark reasoningtasks with GPT-3, Auto-CoT consistently matches or exceeds the performance ofthe CoT paradigm that requires manual designs of demonstrations. Code isavailable at https://github.com/amazon-research/auto-cot",Zhuosheng Zhang,2022/10/7,2022/10/7
2310.13552v2,Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning,http://arxiv.org/abs/2310.13552v2,"In open-domain question-answering (ODQA), most existing questions requiresingle-hop reasoning on commonsense. To further extend this task, we officiallyintroduce open-domain multi-hop reasoning (ODMR) by answering multi-hopquestions with explicit reasoning steps in open-domain setting. Recently, largelanguage models (LLMs) have found significant utility in facilitating ODQAwithout external corpus. Furthermore, chain-of-thought (CoT) prompting booststhe reasoning capability of LLMs to a greater extent with manual or automatedparadigms. However, existing automated methods lack of quality assurance, whilemanual approaches suffer from limited scalability and poor diversity, hinderingthe capabilities of LLMs. In this paper, we propose Self-promptedChain-of-Thought (SP-CoT), an automated framework to mass-produce high qualityCoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generationpipeline of high quality ODMR datasets, an adaptive sampler for in-context CoTselection and self-prompted inference via in-context learning. Extensiveexperiments on four multi-hop question-answering benchmarks show that ourproposed SP-CoT not only significantly surpasses the previous SOTA methods onlarge-scale (175B) LLMs, but also nearly doubles the zero-shot performance ofsmall-scale (13B) LLMs. Further analysis reveals the remarkable capability ofSP-CoT to elicit direct and concise intermediate reasoning steps by recalling$\sim$50\% of intermediate answers on MuSiQue-Ans dataset.",Jinyuan Wang,2023/10/20,2023/10/23
2310.11721v1,Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding,http://arxiv.org/abs/2310.11721v1,"Chain-of-Thought (CoT) is a technique that guides Large Language Models(LLMs) to decompose complex tasks into multi-step reasoning throughintermediate steps in natural language form. Briefly, CoT enables LLMs to thinkstep by step. However, although many Natural Language Understanding (NLU) tasksalso require thinking step by step, LLMs perform less well than small-scaleMasked Language Models (MLMs). To migrate CoT from LLMs to MLMs, we proposeChain-of-Thought Tuning (CoTT), a two-step reasoning framework based on prompttuning, to implement step-by-step thinking for MLMs on NLU tasks. From theperspective of CoT, CoTT's two-step framework enables MLMs to implement taskdecomposition; CoTT's prompt tuning allows intermediate steps to be used innatural language form. Thereby, the success of CoT can be extended to NLU tasksthrough MLMs. To verify the effectiveness of CoTT, we conduct experiments ontwo NLU tasks: hierarchical classification and relation extraction, and theresults show that CoTT outperforms baselines and achieves state-of-the-artperformance.",Caoyun Fan,2023/10/18,2023/10/18
2310.18127v1,"Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models",http://arxiv.org/abs/2310.18127v1,"Large language models (LLMs) demonstrate their promise in tacklingcomplicated practical challenges by combining action-based policies with chainof thought (CoT) reasoning. Having high-quality prompts on hand, however, isvital to the framework's effectiveness. Currently, these prompts arehandcrafted utilizing extensive human labor, resulting in CoT policies thatfrequently fail to generalize. Human intervention is also required in order todevelop grounding functions that ensure low-level controllers appropriatelyprocess CoT reasoning. In this paper, we take the first step towards a fullyintegrated end-to-end framework for task-solving in real settings employingcomplicated reasoning. To that purpose, we offer a new leader-follower bilevelframework capable of learning to ask relevant questions (prompts) andsubsequently undertaking reasoning to guide the learning of actions to beperformed in an environment. A good prompt should make introspective revisionsbased on historical findings, leading the CoT to consider the anticipatedgoals. A prompt-generator policy has its own aim in our system, allowing it toadapt to the action policy and automatically root the CoT process towardsoutputs that lead to decisive, high-performing actions. Meanwhile, the actionpolicy is learning how to use the CoT outputs to take specific actions. Ourempirical data reveal that our system outperforms leading methods in agentlearning benchmarks such as Overcooked and FourRoom.",Xue Yan,2023/10/27,2023/10/27
1910.00948v1,Reverse Engineering x86 Processor Microcode,http://arxiv.org/abs/1910.00948v1,"Microcode is an abstraction layer on top of the physical components of a CPUand present in most general-purpose CPUs today. In addition to facilitatecomplex and vast instruction sets, it also provides an update mechanism thatallows CPUs to be patched in-place without requiring any special hardware.While it is well-known that CPUs are regularly updated with this mechanism,very little is known about its inner workings given that microcode and theupdate mechanism are proprietary and have not been throughly analyzed yet.  In this paper, we reverse engineer the microcode semantics and inner workingsof its update mechanism of conventional COTS CPUs on the example of AMD's K8and K10 microarchitectures. Furthermore, we demonstrate how to develop custommicrocode updates. We describe the microcode semantics and additionally presenta set of microprograms that demonstrate the possibilities offered by thistechnology. To this end, our microprograms range from CPU-assistedinstrumentation to microcoded Trojans that can even be reached from within aweb browser and enable remote code execution and cryptographic implementationattacks.",Philipp Koppe,2019/10/1,2019/10/1
2312.03748v1,Applying Large Language Models and Chain-of-Thought for Automatic Scoring,http://arxiv.org/abs/2312.03748v1,"This study investigates the application of large language models (LLMs),specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT)in the automaticscoring of student-written responses to science assessments. We focused onovercoming the challenges of accessibility, technical complexity, and lack ofexplainability that have previously limited the use of automatic assessmenttools among researchers and educators. We used a testing dataset comprising sixassessment tasks (three binomial and three trinomial) with 1,650 studentresponses. We employed six prompt engineering strategies, combining zero-shotor few-shot learning with CoT, either alone or alongside item stem and scoringrubrics. Results indicated that few-shot (acc = .67) outperformed zero-shotlearning (acc = .60), with 12.6\% increase. CoT, when used without item stemand scoring rubrics, did not significantly affect scoring accuracy (acc = .60).However, CoT prompting paired with contextual item stems and rubrics proved tobe a significant contributor to scoring accuracy (13.44\% increase forzero-shot; 3.7\% increase for few-shot). Using a novel approach PPEAS, we founda more balanced accuracy across different proficiency categories, highlightingthe importance of domain-specific reasoning in enhancing the effectiveness ofLLMs in scoring tasks. Additionally, we also found that GPT-4 demonstratedsuperior performance over GPT-3.5 in various scoring tasks, showing 8.64\%difference. The study revealed that the single-call strategy with GPT-4,particularly using greedy sampling, outperformed other approaches, includingensemble voting strategies. This study demonstrates the potential of LLMs infacilitating automatic scoring, emphasizing that CoT enhances accuracy,particularly when used with item stem and scoring rubrics.",Gyeong-Geon Lee,2023/11/30,2023/11/30
2312.01398v1,Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal Stakeholder's Perspective,http://arxiv.org/abs/2312.01398v1,"Commercial contracts are known to be a valuable source for derivingproject-specific requirements. However, contract negotiations mainly occuramong the legal counsel of the parties involved. The participation of non-legalstakeholders, including requirement analysts, engineers, and solutionarchitects, whose primary responsibility lies in ensuring the seamlessimplementation of contractual terms, is often indirect and inadequate.Consequently, a significant number of sentences in contractual clauses, thoughlegally accurate, can appear unfair from an implementation perspective tonon-legal stakeholders. This perception poses a problem since requirementsindicated in the clauses are obligatory and can involve punitive measures andpenalties if not implemented as committed in the contract. Therefore, theidentification of potentially unfair clauses in contracts becomes crucial. Inthis work, we conduct an empirical study to analyze the perspectives ofdifferent stakeholders regarding contractual fairness. We then investigate theability of Pre-trained Language Models (PLMs) to identify unfairness incontractual sentences by comparing chain of thought prompting andsemi-supervised fine-tuning approaches. Using BERT-based fine-tuning, weachieved an accuracy of 84% on a dataset consisting of proprietary contracts.It outperformed chain of thought prompting using Vicuna-13B by a margin of 9%.",Anmol Singhal,2023/12/3,2023/12/3
2309.03667v2,Exploring an LM to generate Prolog Predicates from Mathematics Questions,http://arxiv.org/abs/2309.03667v2,"Recently, there has been a surge in interest in NLP driven by ChatGPT.ChatGPT, a transformer-based generative language model of substantial scale,exhibits versatility in performing various tasks based on natural language.Nevertheless, large language models often exhibit poor performance in solvingmathematics questions that require reasoning. Prior research has demonstratedthe effectiveness of chain-of-thought prompting in enhancing reasoningcapabilities. Now, we aim to investigate whether fine-tuning a model for thegeneration of Prolog codes, a logic language, and subsequently passing thesecodes to a compiler can further improve accuracy. Consequently, we employchain-of-thought to fine-tune LLaMA7B as a baseline model and develop otherfine-tuned LLaMA7B models for the generation of Prolog code, Prolog code +chain-of-thought, and chain-of-thought + Prolog code, respectively. The resultsreveal that the Prolog generation model surpasses the baseline in performance,while the combination generation models do not yield significant improvements.The Prolog corpus based on GSM8K and the correspondingly finetuned Prologgeneration model based on LLaMA7B are released to the research community.",Xiaocheng Yang,2023/9/7,2023/9/8
2305.10601v2,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,http://arxiv.org/abs/2305.10601v2,"Language models are increasingly being deployed for general problem solvingacross a wide range of tasks, but are still confined to token-level,left-to-right decision-making processes during inference. This means they canfall short in tasks that require exploration, strategic lookahead, or whereinitial decisions play a pivotal role. To surmount these challenges, weintroduce a new framework for language model inference, Tree of Thoughts (ToT),which generalizes over the popular Chain of Thought approach to promptinglanguage models, and enables exploration over coherent units of text (thoughts)that serve as intermediate steps toward problem solving. ToT allows LMs toperform deliberate decision making by considering multiple different reasoningpaths and self-evaluating choices to decide the next course of action, as wellas looking ahead or backtracking when necessary to make global choices. Ourexperiments show that ToT significantly enhances language models'problem-solving abilities on three novel tasks requiring non-trivial planningor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, inGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% oftasks, our method achieved a success rate of 74%. Code repo with all prompts:https://github.com/princeton-nlp/tree-of-thought-llm.",Shunyu Yao,2023/5/17,2023/12/3
2210.03350v3,Measuring and Narrowing the Compositionality Gap in Language Models,http://arxiv.org/abs/2210.03350v3,"We investigate the ability of language models to perform compositionalreasoning tasks where the overall solution depends on correctly composing theanswers to sub-problems. We measure how often models can correctly answer allsub-problems but not generate the overall solution, a ratio we call thecompositionality gap. We evaluate this ratio by asking multi-hop questions withanswers that require composing multiple facts unlikely to have been observedtogether during pretraining. In the GPT-3 family of models, as model sizeincreases we show that the single-hop question answering performance improvesfaster than the multi-hop performance does, therefore the compositionality gapdoes not decrease. This surprising result suggests that while more powerfulmodels memorize and recall more factual knowledge, they show no correspondingimprovement in their ability to perform this kind of compositional reasoning.  We then demonstrate how elicitive prompting (such as chain of thought)narrows the compositionality gap by reasoning explicitly. We present a newmethod, self-ask, that further improves on chain of thought. In our method, themodel explicitly asks itself (and answers) follow-up questions before answeringthe initial question. We finally show that self-ask's structured prompting letsus easily plug in a search engine to answer the follow-up questions, whichadditionally improves accuracy.",Ofir Press,2022/10/7,2023/10/17
2304.07919v2,Chain of Thought Prompt Tuning in Vision Language Models,http://arxiv.org/abs/2304.07919v2,"Language-Image Pre-training has demonstrated promising results on zero-shotand few-shot downstream tasks by prompting visual models with natural languageprompts. However, most recent studies only use a single prompt for tuning,neglecting the inherent step-to-step cognitive reasoning process that humansconduct in complex task settings, for example, when processing images fromunfamiliar domains. Chain of Thought is a simple and effective approximation tohuman reasoning process and has been proven useful for natural languageprocessing (NLP) tasks. Based on this cognitive intuition, we believe thatconducting effective reasoning is also an important problem in visual tasks,and a chain of thought could be a solution to this problem. In this work, wepropose a novel chain of thought prompt tuning for vision-language modeling.Extensive experiments show that our method not only generalizes better in imageclassification tasks, has greater transferability beyond a single dataset, andhas stronger domain generalization performance, but also performs much betterin imagetext retrieval and visual question answering, which require morereasoning capabilities. We are the first to successfully adapt chain-of-thoughtprompting that combines visual and textual embeddings. We will release ourcodes",Jiaxin Ge,2023/4/16,2023/6/17
2312.13848v1,Reducing Hallucinations: Enhancing VQA for Flood Disaster Damage Assessment with Visual Contexts,http://arxiv.org/abs/2312.13848v1,"The zero-shot performance of visual question answering (VQA) models reliesheavily on prompts. For example, a zero-shot VQA for disaster scenarios couldleverage well-designed Chain of Thought (CoT) prompts to stimulate the model'spotential. However, using CoT prompts has some problems, such as causing anincorrect answer in the end due to the hallucination in the thought process. Inthis paper, we propose a zero-shot VQA named Flood Disaster VQA with Two-StagePrompt (VQA-TSP). The model generates the thought process in the first stageand then uses the thought process to generate the final answer in the secondstage. In particular, visual context is added in the second stage to relievethe hallucination problem that exists in the thought process. Experimentalresults show that our method exceeds the performance of state-of-the-artzero-shot VQA models for flood disaster scenarios in total. Our study providesa research basis for improving the performance of CoT-based zero-shot VQA.",Yimin Sun,2023/12/21,2023/12/21
2401.04398v2,Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding,http://arxiv.org/abs/2401.04398v2,"Table-based reasoning with large language models (LLMs) is a promisingdirection to tackle many table understanding tasks, such as table-basedquestion answering and fact verification. Compared with generic reasoning,table-based reasoning requires the extraction of underlying semantics from bothfree-form questions and semi-structured tabular data. Chain-of-Thought and itssimilar approaches incorporate the reasoning chain in the form of textualcontext, but it is still an open question how to effectively leverage tabulardata in the reasoning chain. We propose the Chain-of-Table framework, wheretabular data is explicitly used in the reasoning chain as a proxy forintermediate thoughts. Specifically, we guide LLMs using in-context learning toiteratively generate operations and update the table to represent a tabularreasoning chain. LLMs can therefore dynamically plan the next operation basedon the results of the previous ones. This continuous evolution of the tableforms a chain, showing the reasoning process for a given tabular problem. Thechain carries structured information of the intermediate results, enabling moreaccurate and reliable predictions. Chain-of-Table achieves new state-of-the-artperformance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLMchoices.",Zilong Wang,2024/1/9,2024/1/19
2304.03087v1,Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media,http://arxiv.org/abs/2304.03087v1,"Stance detection predicts attitudes towards targets in texts and has gainedattention with the rise of social media. Traditional approaches includeconventional machine learning, early deep neural networks, and pre-trainedfine-tuning models. However, with the evolution of very large pre-trainedlanguage models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods facedeployment challenges. The parameter-free Chain-of-Thought (CoT) approach, notrequiring backpropagation training, has emerged as a promising alternative.This paper examines CoT's effectiveness in stance detection tasks,demonstrating its superior accuracy and discussing associated challenges.",Bowen Zhang,2023/4/6,2023/4/6
1903.06979v1,A Principal-Agent Model of Systems Engineering Processes with Application to Satellite Design,http://arxiv.org/abs/1903.06979v1,"We present a principal-agent model of a one-shot, shallow, systemsengineering process. The process is one-shot in the sense that decisions aremade during one time step and that they are final. The term shallow refers to aone-layer hierarchy of the process. Specifically, we assume that the systemsengineer has already decomposed the problem in subsystems, and that eachsubsystem is assigned to a different subsystem engineer. Each subsystemengineer works independently to maximize their own expected payoff. The goal ofthe systems engineer is to maximize the system-level payoff by incentivizingthe subsystem engineers. We restrict our attention to requirement-basedsystem-level payoffs, i.e., the systems engineer makes a profit only if all thedesign requirements are met. We illustrate the model using the design of anEarth-orbiting satellite system where the systems engineer determines theoptimum incentive structures and requirements for two subsystems: thepropulsion subsystem and the power subsystem. The model enables the analysis ofa systems engineer's decisions about optimal passed-down requirements andincentives for sub-system engineers under different levels of task difficultyand associated costs. Sample results, for the case of risk-neutral systems andsubsystems engineers, show that it is not always in the best interest of thesystems engineer to pass down the true requirements. As expected, the modelpredicts that for small to moderate task uncertainties the optimal requirementsare higher than the true ones, effectively eliminating the probability offailure for the systems engineer. In contrast, the model predicts that forlarge task uncertainties the optimal requirements should be smaller than thetrue ones in order to lure the subsystem engineers into participation.",Salar Safarkhani,2019/3/16,2019/3/16
1002.3711v1,Theory of Regulatory Compliance for Requirements Engineering,http://arxiv.org/abs/1002.3711v1,"Regulatory compliance is increasingly being addressed in the practice ofrequirements engineering as a main stream concern. This paper points out a gapin the theoretical foundations of regulatory compliance, and presents a theorythat states (i) what it means for requirements to be compliant, (ii) thecompliance problem, i.e., the problem that the engineer should resolve in orderto verify whether requirements are compliant, and (iii) testable hypotheses(predictions) about how compliance of requirements is verified. The theory isinstantiated by presenting a requirements engineering framework that implementsits principles, and is exemplified on a real-world case study.",Ivan Jureta,2010/2/19,2010/2/19
1305.3853v2,Analysing the Assumed Benefits of Software Requirements,http://arxiv.org/abs/1305.3853v2,"Often during the requirements engineering (RE) process, the value of arequirement is assessed, e.g., in requirement prioritisation, release planning,and trade-off analysis. In order to support these activities, this researchevaluates Goal Oriented Requirements Engineering (GORE) methods for thedescription of a requirement's value. Specifically, we investigate thegoal-to-goal contribution relationship for its ability to demonstrate the valueof a requirement, and propose that it is enriched with concepts such ascorrelation, confidence, and utility.",Richard Ellis-Braithwaite,2013/5/16,2013/6/13
2207.04698v1,Numerical computing in engineering mathematics,http://arxiv.org/abs/2207.04698v1,"The rapid advances in technology over the last decade have significantlyaltered the nature of engineering knowledge and skills required in the modernindustries. In response to the changing professional requirements, engineeringinstitutions have updated their curriculum and pedagogical practices. However,most of the changes in the curriculum have been focused on the core engineeringcourses without much consideration for the auxiliary courses in mathematics andsciences. In this paper, we aim to propose a new, augmented mathematicscurriculum aimed at meeting the requirements of the modern, technology-basedengineering workplace. The proposed updates require minimal resources and canbe seamlessly integrated into the existing curriculum.",Firuz Kamalov,2022/7/11,2022/7/11
1303.5950v1,High Quality Requirement Engineering and Applying Priority Based Tools for QoS Standardization in Web Service Architecture,http://arxiv.org/abs/1303.5950v1,Even though there are more development to improving the Quality of Serviceand requirement engineering in web services yet there is a big scarcity for itsrelated standardization in day to day progress leading to vast needs in itsarea. Also in web service environment it always has been a big challenge toraise the standard of Quality of Service in requirement engineering analysis.,C. Dinesh,2013/3/24,2013/3/24
1811.03482v1,A holistic look at requirements engineering practices in the gaming industry,http://arxiv.org/abs/1811.03482v1,In this work we present an account of the status of requirements engineeringin the gaming industry. Recent papers in the area were surveyed.Characterizations of the gaming industry were deliberated upon by portrayingits relations with the market industry. Some research directions in the area ofrequirements engineering in the gaming industry were also mentioned.,Aftab Hussain,2018/11/8,2018/11/8
1404.7260v1,Refinement-Based Specification: Requirements and Architecture,http://arxiv.org/abs/1404.7260v1,This paper presents the methodology for the system requirements andarchitecture w.r.t. their decomposition and refinement. It also introducesideas of refinement layers and of refinement-based verification.,Maria Spichkova,2014/4/29,2014/4/29
2305.16091v1,Emotions in Requirements Engineering: A Systematic Mapping Study,http://arxiv.org/abs/2305.16091v1,"The purpose of requirements engineering (RE) is to make sure that theexpectations and needs of the stakeholders of a software system are met.Emotional needs can be captured as emotional requirements that represent howthe end user should feel when using the system. Differently from functional andquality (non-functional) requirements, emotional requirements have receivedrelatively less attention from the RE community. This study is motivated by theneed to explore and map the literature on emotional requirements. The studyapplies the systematic mapping study technique for surveying and analyzing theavailable literature to identify the most relevant publications on emotionalrequirements. We identified 34 publications that address a wide spectrum ofpractices concerned with engineering emotional requirements. The identifiedpublications were analyzed with respect to the application domains, instrumentsused for eliciting and artefacts used for representing emotional requirements,and the state of the practice in emotion-related requirements engineering. Thisanalysis serves to identify research gaps and research directions inengineering emotional requirements. To the best of the knowledge by theauthors, no other similar study has been conducted on emotional requirements.",Tahira Iqbal,2023/5/25,2023/5/25
2110.03952v1,A Framework for Aspectual Requirements Validation: An Experimental Study,http://arxiv.org/abs/2110.03952v1,"Requirements engineering is a discipline of software engineering that isconcerned with the identification and handling of user and system requirements.Aspect-Oriented Requirements Engineering (AORE) extends the existingrequirements engineering approaches to cope with the issue of tangling andscattering resulted from crosscutting concerns. Crosscutting concerns areconsidered as potential aspects and can lead to the phenomena tyranny of thedominant decomposition. Requirements-level aspects are responsible forproducing scattered and tangled descriptions of requirements in therequirements document. Validation of requirements artefacts is an essentialtask in software development. This task ensures that requirements are correctand valid in terms of completeness and consistency, hence, reducing thedevelopment cost, maintenance and establish an approximately correct estimateof effort and completion time of the project. In this paper, we present avalidation framework to validate the aspectual requirements and thecrosscutting relationship of concerns that are resulted from the requirementsengineering phase. The proposed framework comprises a high-level and low-levelvalidation to implement on software requirements specification (SRS). Thehigh-level validation validates the concerns with stakeholders, whereas thelow-level validation validates the aspectual requirement by requirementsengineers and analysts using a checklist. The approach has been evaluated usingan experimental study on two AORE approaches. The approaches areviewpoint-based called AORE with ArCaDe and lexical analysis based on Theme/Docapproach. The results obtained from the study demonstrate that the proposedframework is an effective validation model for AORE artefacts.",Abdelsalam M. Maatuk,2021/10/8,2021/10/8
1410.6902v1,Applying Agile Requirements Engineering Approach for Re-engineering & Changes in existing Brownfield Adaptive Systems,http://arxiv.org/abs/1410.6902v1,Requirements Engineering (RE) is a key activity in the development ofsoftware systems and is concerned with the identification of the goals ofstakeholders and their elaboration into precise statements of desired servicesand behavior. The research describes an Agile Requirements Engineering approachfor re-engineering & changes in existing Brownfield adaptive system. Theapproach has few modifications that can be used as a part of SCRUM developmentprocess for re-engineering & changes. The approach illustrates there-engineering & changes requirements through introduction of GAP analysis &requirements structuring & prioritization by creating AS-IS & TO-BE models with80 / 20 rule. An attempt to close the gap between requirements engineering &agile methods in form of this approach is provided for practicalimplementation.,Abdullah Masood,2014/10/25,2014/10/25
1712.00061v2,Agile Software Engineering and Systems Engineering at SKA Scale,http://arxiv.org/abs/1712.00061v2,"Systems Engineering (SE) is the set of processes and documentation requiredfor successfully realising large-scale engineering projects, but the classicalapproach is not a good fit for software-intensive projects, especially when theneeds of the different stakeholders are not fully known from the beginning, andrequirement priorities might change. The SKA is the ultimate software-enabledtelescope, with enormous amounts of computing hardware and software required toperform its data reduction. We give an overview of the system and softwareengineering processes in the SKA1 development, and the tension betweenclassical and agile SE.",Juande Santander-Vela,2017/11/30,2017/12/4
1304.0116v1,The Illusion of Requirements in Software Development,http://arxiv.org/abs/1304.0116v1,"It is widely accepted that understanding system requirements is important forsoftware development project success. However, this paper presents two novelchallenges to the requirements concept. First, where many plausible approachesto achieving a goal are evident, there may be insufficient overlap betweenapproaches to form requirements. Second, while all plausible approaches mayhave sufficient overlap to state requirements, we cannot know that unless allapproaches are identified and we are sure that none have been missed. Thissuggest that many, if not most, software projects may have too few requirementsdrive the design process, and that analysts may misrepresent design decisionsas requirements to compensate.",Paul Ralph,2013/3/30,2013/3/30
2211.06189v2,An initial Theory to Understand and Manage Requirements Engineering Debt in Practice,http://arxiv.org/abs/2211.06189v2,"Context: Advances in technical debt research demonstrate the benefits ofapplying the financial debt metaphor to support decision-making in softwaredevelopment activities. Although decision-making during requirementsengineering has significant consequences, the debt metaphor in requirementsengineering is inadequately explored. Objective: We aim to conceptualize howthe debt metaphor applies to requirements engineering by organizing conceptsrelated to practitioners' understanding and managing of requirementsengineering debt (RED). Method: We conducted two in-depth expert interviews toidentify key requirements engineering debt concepts and construct a surveyinstrument. We surveyed 69 practitioners worldwide regarding their perceptionof the concepts and developed an initial analytical theory. Results: We proposea RED theory that aligns key concepts from technical debt research butemphasizes the specific nature of requirements engineering. In particular, thetheory consists of 23 falsifiable propositions derived from the literature, theinterviews, and survey results. Conclusions: The concepts of requirementsengineering debt are perceived to be similar to their technical debtcounterpart. Nevertheless, measuring and tracking requirements engineering debtare immature in practice. Our proposed theory serves as the first guide towardfurther research in this area.",Julian Frattini,2022/11/11,2023/3/8
2303.02913v1,OpenICL: An Open-Source Framework for In-context Learning,http://arxiv.org/abs/2303.02913v1,"In recent years, In-context Learning (ICL) has gained increasing attentionand emerged as the new paradigm for large language model (LLM) evaluation.Unlike traditional fine-tuning methods, ICL instead adapts the pre-trainedmodels to unseen tasks without any parameter updates. However, theimplementation of ICL is sophisticated due to the diverse retrieval andinference methods involved, as well as the varying pre-processing requirementsfor different models, datasets, and tasks. A unified and flexible framework forICL is urgently needed to ease the implementation of the aforementionedcomponents. To facilitate ICL research, we introduce OpenICL, an open-sourcetoolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highlyflexible architecture that users can easily combine different components tosuit their needs. It also provides various state-of-the-art retrieval andinference methods to streamline the process of adapting ICL to cutting-edgeresearch. The effectiveness of OpenICL has been validated on a wide range ofNLP tasks, including classification, QA, machine translation, and semanticparsing. As a side-product, we found OpenICL to be an efficient yet robust toolfor LLMs evaluation. OpenICL is released athttps://github.com/Shark-NLP/OpenICL",Zhenyu Wu,2023/3/6,2023/3/6
2310.12477v1,An Exploration of In-Context Learning for Speech Language Model,http://arxiv.org/abs/2310.12477v1,"Ever since the development of GPT-3 in the natural language processing (NLP)field, in-context learning (ICL) has played an important role in utilizinglarge language models (LLMs). By presenting the LM utterance-labeldemonstrations at the input, the LM can accomplish few-shot learning withoutrelying on gradient descent or requiring explicit modification of itsparameters. This enables the LM to learn and adapt in a black-box manner.Despite the success of ICL in NLP, little work is exploring the possibility ofICL in speech processing. This study proposes the first exploration of ICL witha speech LM without text supervision. We first show that the current speech LMdoes not have the ICL capability. With the proposed warmup training, the speechLM can, therefore, perform ICL on unseen tasks. In this work, we verify thefeasibility of ICL for speech LM on speech classification tasks.",Ming-Hao Hsu,2023/10/19,2023/10/19
2401.02543v1,Evidence for a redshifted excess in the intracluster light fractions of merging clusters at $z\sim 0.8$,http://arxiv.org/abs/2401.02543v1,"The intracluster light (ICL) fraction is a well-known indicator of thedynamical activity in intermediate-redshift clusters. Merging clusters in theredshift interval $0.18<z<0.56$ have a distinctive peak in the ICL fractionsmeasured between $\sim 3800-4800$ \AA. In this work, we analyze twohigher-redshift, clearly merging clusters, ACT-CLJ0102-49151 and CLJ0152.7-1357, at $z>0.8$, using the HST optical and infrared images obtained bythe RELICS survey. We report the presence of a similar peak in the ICLfractions, although wider and redshifted to the wavelength interval $\sim5200-7300$ \AA. The fact that this excess in the ICL fractions is found atlonger wavelengths can be explained by an assorted mixture of stellarpopulations in the ICL, direct inheritance of an ICL that was mainly formed bymajor galaxy mergers with the BCG at $z>1$ and whose production isinstantaneously burst by the merging event. The ubiquity of the ICL fractionmerging signature across cosmic time enhances the ICL as a highly reliable andpowerful probe to determine the dynamical stage of galaxy clusters, which iscrucial for cluster-based cosmological inferences that require relaxation ofthe sample.",Yolanda Jimnez-Teja,2024/1/4,2024/1/4
2101.03835v1,"DAWIS, a Detection Algorithm with Wavelets for Intracluster light Studies",http://arxiv.org/abs/2101.03835v1,"Large amounts of deep optical images will be available in the near future,allowing statistically significant studies of low surface brightness structuressuch as intracluster light (ICL) in galaxy clusters. The detection of thesestructures requires efficient algorithms dedicated to this task, wheretraditional methods suffer difficulties. We present our new Detection Algorithmwith Wavelets for Intracluster light Studies (DAWIS), developed and optimisedfor the detection of low surface brightness sources in images, in particular(but not limited to) ICL. DAWIS follows a multiresolution vision based onwavelet representation to detect sources, embedded in an iterative procedurecalled synthesis-by-analysis approach to restore the complete unmasked lightdistribution of these sources with very good quality. The algorithm is built sosources can be classified based on criteria depending on the analysis goal; wedisplay in this work the case of ICL detection and the measurement of ICLfractions. We test the efficiency of DAWIS on 270 mock images of galaxyclusters with various ICL profiles and compare its efficiency to moretraditional ICL detection methods such as the surface brightness thresholdmethod. We also run DAWIS on a real galaxy cluster image, and compare theoutput to results obtained with previous multiscale analysis algorithms. Wefind in simulations that in average DAWIS is able to disentangle galaxy lightfrom ICL more efficiently, and to detect a greater quantity of ICL flux due tothe way it handles sky background noise. We also show that the ICL fraction, ametric used on a regular basis to characterise ICL, is subject to severalmeasurement biases both on galaxies and ICL fluxes. In the real galaxy clusterimage, DAWIS detects a faint and extended source with an absolute magnitude twoorders brighter than previous multiscale methods.",A. Ellien,2021/1/11,2021/1/11
2307.09032v1,Isotonic Conditional Laws,http://arxiv.org/abs/2307.09032v1,"We introduce Isotonic Conditional Laws (ICL) which extend the classicalnotion of conditional laws by the additional requirement that there exists anisotonic relationship between the random variable of interest and theconditioning random object. We show existence and uniqueness of ICL building onconditional expectations given $\sigma$-lattices. ICL corresponds to aclassical conditional law if and only if the latter is already isotonic. ICL ismotivated from a statistical point of view by showing that ICL emergesequivalently as the minimizer of an expected score where the scoring rule maybe taken from a large class comprising the Continuous Ranked Probability Score(CRPS). Furthermore, ICL is calibrated in the sense that it is invariant tocertain conditioning operations, and the corresponding event probabilities andquantiles are simultaneously optimal with respect to all relevant scoringfunctions. We will develop a new notion of general conditional functionalsgiven $\sigma$-lattices which is of independent interest.",Sebastian Arnold,2023/7/18,2023/7/18
0906.1185v1,Tidal Streams of Intracluster Light,http://arxiv.org/abs/0906.1185v1,"Using N-body simulations, we have modeled the production and evolution ofsubstructures in the intracluster light (ICL) of a simulated galaxy cluster. Weuse a density-based definition of ICL, where ICL consists of luminous particleswhich are at low densities, to identify ICL particles and track theirevolution. We have implemented a friends-of-friends-type clustering algorithmwhich finds groups of particles correlated in both position and velocity spaceto identify substructures in the ICL, hereafter referred to as ``streams''. Wefind that ~40% of the cluster's ICL is generated in the form of these massive(M > 7.0x10^8 Msun), dynamically cold streams. The fraction of the ICLgenerated in streams is greater early in the cluster's evolution, when galaxiesare interacting in the group environment, than later in its evolution when themassive cluster potential has been assembled. The production of streamsrequires the strong tidal fields associated with close interactions betweenpairs of galaxies, and is usually associated with merging pairs of galaxies, orfast, close encounters with the cluster's central galaxy. Once streams areformed, they begin to decay as they are disrupted by the tidal field of thecluster. We find that streams have decay timescales which are ~1.5 times theirdynamical time in the cluster.",Craig S. Rudick,2009/6/5,2009/6/5
2005.13763v2,On the Mass Distribution of the Intra-Cluster Light in Galaxy Groups and Clusters,http://arxiv.org/abs/2005.13763v2,"We take advantage of a semi-analytic model with a state-of-art implementationof the formation of the intra-cluster light (ICL) to study the massdistribution of the ICL in galaxy groups and clusters, at different redshifts.We assume the ICL to follow a NFW profile with a different concentration,linked to that of the dark matter by the relation $c_{ICL}=\gamma c_{DM}$,where the parameter $\gamma$ is set to reproduce the observed relation betweenthe stellar mass in the brightest cluster galaxy (BCG) and ICL in the innermost100 kpc and the halo mass ($M^*_{100}-M_{500}$), at $z=0$. The model is thentested against several theoretical and observational results, from the presenttime to $z\sim1.5$. Our analysis shows that the fraction of stellar mass in theBCG and ICL within the innermost 100 kpc is an increasing function of redshift,parameter $\gamma$, and a decreasing function of the halo mass. The value of$\gamma$ required to match the observed $M^*_{100}-M_{500}$ is $\gamma=3$ at$z=0$, but there are hints that it might be a function of redshift and halomass. This result indicates that the distribution of the ICL is moreconcentrated than the dark matter one, but less concentrated than previouslyfound by other studies. We suggest that a modified version of the NFW is a gooddescription of the distribution of the diffuse light in groups and clusters,which makes the ICL a reliable tracer of the dark matter, in good agreementwith recent observational findings.",Emanuele Contini,2020/5/28,2020/8/21
2305.13016v2,Iterative Forward Tuning Boosts In-context Learning in Language Models,http://arxiv.org/abs/2305.13016v2,"Large language models (LLMs) have exhibited an emergent in-context learning(ICL) ability. However, the ICL models that can solve ordinary cases are hardlyextended to solve more complex tasks by processing the demonstration examplesonce. This single-turn ICL is incoordinate with the decision making process ofhumans by learning from analogy. In this paper, we propose an effective andefficient two-stage framework to boost ICL in LLMs by exploiting a dual formbetween Transformer attention and gradient descent-based optimization.Concretely, we divide the ICL process into ""Deep-Thinking"" and inferencestages. The ""Deep-Thinking"" stage performs iterative forward optimization ofdemonstrations, which is expected to boost the reasoning abilities of LLMs attest time by ""thinking"" demonstrations multiple times. It produces accumulatedmeta-gradients by manipulating the Key-Value matrices in the self-attentionmodules of the Transformer. Then, the inference stage only takes the test queryas input without concatenating demonstrations and applies the learnedmeta-gradients through attention for output prediction. In this way,demonstrations are not required during the inference stage since they arealready learned and stored in the definitive meta-gradients. LLMs can beeffectively and efficiently adapted to downstream tasks. Extensive experimentson ten classification and multiple-choice datasets show that our methodachieves substantially better performance than standard ICL in terms of bothaccuracy and efficiency.",Jiaxi Yang,2023/5/22,2023/5/30
2310.05797v2,Are Large Language Models Post Hoc Explainers?,http://arxiv.org/abs/2310.05797v2,"Large Language Models (LLMs) are increasingly used as powerful tools for aplethora of natural language processing (NLP) applications. A recentinnovation, in-context learning (ICL), enables LLMs to learn new tasks bysupplying a few examples in the prompt during inference time, therebyeliminating the need for model fine-tuning. While LLMs have been utilized inseveral applications, their applicability in explaining the behavior of othermodels remains relatively unexplored. Despite the growing number of newexplanation techniques, many require white-box access to the model and/or arecomputationally expensive, highlighting a need for next-generation post hocexplainers. In this work, we present the first framework to study theeffectiveness of LLMs in explaining other predictive models. More specifically,we propose a novel framework encompassing multiple prompting strategies: i)Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL,and iv) Explanation-based ICL, with varying levels of information about theunderlying ML model and the local neighborhood of the test sample. We conductextensive experiments with real-world benchmark datasets to demonstrate thatLLM-generated explanations perform on par with state-of-the-art post hocexplainers using their ability to leverage ICL examples and their internalknowledge in generating model explanations. On average, across four datasetsand two ML models, we observe that LLMs identify the most important featurewith 72.19% accuracy, opening up new frontiers in explainable artificialintelligence (XAI) to explore LLM-based explanation frameworks.",Nicholas Kroeger,2023/10/9,2023/10/10
1311.1921v3,Diffuse optical intracluster light as a measure of stellar tidal stripping: the cluster CL0024+17 at $z\sim $0.4 observed at LBT,http://arxiv.org/abs/1311.1921v3,"We have evaluated the diffuse intracluster light (ICL) in the central core ofthe galaxy cluster CL0024+17 at $z\sim 0.4$ observed with the prime focuscamera (LBC) at LBT. The measure required an accurate removal of the galaxieslight within $\sim 200$ kpc from the center. The residual background intensityhas then been integrated in circular apertures to derive the average ICLintensity profile. The latter shows an approximate exponential decline asexpected from theoretical cold dark matter models. The radial profile of theICL over the galaxies intensity ratio (ICL fraction) is increasing withdecreasing radius but near the cluster center it starts to bend and thendecreases where the overlap of the halos of the brightest cluster galaxiesbecomes dominant. Theoretical expectations in a simplified CDM scenario showthat the ICL fraction profile can be estimated from the stripped over galaxystellar mass ratio in the cluster. It is possible to show that the latterquantity is almost independent of the properties of the individual hostgalaxies but mainly depends on the average cluster properties. The predictedICL fraction profile is thus very sensitive to the assumed CDM profile, totalmass and concentration parameter of the cluster. Adopting values very similarto those derived from the most recent lensing analysis in CL0024+17 we find agood agreement with the observed ICL fraction profile. The galaxy counts in thecluster core have then been compared with that derived from composite clustersamples in larger volumes, up to the clusters virial radius. The galaxy countsin the CL0024+17 core appear flatter and the amount of bending respect to theaverage cluster galaxy counts imply a loss of total emissivity in broadagreement with the measured ICL fraction.",E. Giallongo,2013/11/8,2013/12/18
1211.3210v2,Fast estimation of the ICL criterion for change-point detection problems with applications to Next-Generation Sequencing data,http://arxiv.org/abs/1211.3210v2,"In this paper, we consider the Integrated Completed Likelihood (ICL) as auseful criterion for estimating the number of changes in the underlyingdistribution of data in problems where detecting the precise location of thesechanges is the main goal. The exact computation of the ICL requires O(Kn2)operations (with K the number of segments and n the number of data-points)which is prohibitive in many practical situations with large sequences of data.We describe a framework to estimate the ICL with O(Kn) complexity. Our approachis general in the sense that it can accommodate any given model distribution.We checked the run-time and validity of our approach on simulated data anddemonstrate its good performance when analyzing real Next-Generation Sequencing(NGS) data using a negative binomial model.",Alice Cleynen,2012/11/14,2013/7/1
1301.4265v1,Theory and synthesis of bilayer graphene intercalated with ICl and IBr for low power device applications,http://arxiv.org/abs/1301.4265v1,"Graphene intercalation materials are potentially promising for theimplementation of the ultra-low power, excitonic-condensate-based BilayerpseudoSpin Field-Effect Transistor (BiSFET) concept, as well as other noveldevice concepts requiring a graphene interlayer dielectric. Using densityfunctional theory (DFT) we study the structural and electronic properties ofbilayer graphene intercalated with iodine monochloride (ICl) and iodinemonobromide (IBr). We determine the structural configuration of ICl and IBrgraphene intercalation compounds (GICs). We also conduct an in-depthexploration of inter-layer electronic coupling, using \textit{ab initio}calculations. The presence of intercalants dopes the graphene layer. It alsoreduces, but does not eliminate, the electronic coupling between graphenelayers, which may enable BiSFET operation. In addition, we present experimentalresults for ICl-GIC synthesis and characterization.",Priyamvada Jadaun,2013/1/17,2013/1/17
2310.20046v1,Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection,http://arxiv.org/abs/2310.20046v1,"Large Language Models (LLMs) can adapt to new tasks via in-context learning(ICL). ICL is efficient as it does not require any parameter updates to thetrained LLM, but only few annotated examples as input for the LLM. In thiswork, we investigate an active learning approach for ICL, where there is alimited budget for annotating examples. We propose a model-adaptiveoptimization-free algorithm, termed AdaICL, which identifies examples that themodel is uncertain about, and performs semantic diversity-based exampleselection. Diversity-based sampling improves overall effectiveness, whileuncertainty sampling improves budget efficiency and helps the LLM learn newinformation. Moreover, AdaICL poses its sampling strategy as a Maximum Coverageproblem, that dynamically adapts based on the model's feedback and can beapproximately solved via greedy algorithms. Extensive experiments on ninedatasets and seven LLMs show that AdaICL improves performance by 4.4% accuracypoints over SOTA (7.7% relative improvement), is up to 3x more budget-efficientthan performing annotations uniformly at random, while it outperforms SOTA with2x fewer ICL examples.",Costas Mavromatis,2023/10/30,2023/10/30
2311.03319v1,DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase,http://arxiv.org/abs/2311.03319v1,"In-Context Learning (ICL) combined with pre-trained large language models hasachieved promising results on various NLP tasks. However, ICL requireshigh-quality annotated demonstrations which might not be available inreal-world scenarios. To overcome this limitation, we propose \textbf{D}ata\textbf{A}ugmentation for \textbf{I}n-Context \textbf{L}earning(\textbf{DAIL}). DAIL leverages the intuition that large language models aremore familiar with the content generated by themselves. It first utilizes thelanguage model to generate paraphrases of the test sample and employs majorityvoting to determine the final result based on individual predictions. Ourextensive empirical evaluation shows that DAIL outperforms the standard ICLmethod and other ensemble-based methods in the low-resource scenario.Additionally, we explore the use of voting consistency as a confidence score ofthe model when the logits of predictions are inaccessible. We believe our workwill stimulate further research on ICL in low-resource settings.",Dawei Li,2023/11/6,2023/11/6
2311.09606v1,GistScore: Learning Better Representations for In-Context Example Selection with Gist Bottlenecks,http://arxiv.org/abs/2311.09606v1,"Large language models (LLMs) have the ability to perform in-context learning(ICL) of new tasks by conditioning on prompts comprising a few task examples.This work studies the problem of selecting the best examples given a candidatepool to improve ICL performance on given a test input. Existing approacheseither require training with feedback from a much larger LLM or arecomputationally expensive. We propose a novel metric, GistScore, based onExample Gisting, a novel approach for training example retrievers for ICL usingan attention bottleneck via Gisting, a recent technique for compressing taskinstructions. To tradeoff performance with ease of use, we experiment with bothfine-tuning gist models on each dataset and multi-task training a single modelon a large collection of datasets. On 21 diverse datasets spanning 9 tasks, weshow that our fine-tuned models get state-of-the-art ICL performance with 20%absolute average gain over off-the-shelf retrievers and 7% over the best priormethods. Our multi-task model generalizes well out-of-the-box to new taskcategories, datasets, and prompt templates with retrieval speeds that areconsistently thousands of times faster than the best prior training-freemethod.",Shivanshu Gupta,2023/11/16,2023/11/16
2112.04251v2,FRETting about Requirements: Formalised Requirements for an Aircraft Engine Controller,http://arxiv.org/abs/2112.04251v2,"[Context & motivation] Eliciting requirements that are detailed and logicalenough to be amenable to formal verification is a difficult task. Multipletools exist for requirements elicitation and some of these also supportformalisation of requirements in a way that is useful for formal methods.[Question/problem] This paper reports on our experience of using the FRETalongside our industrial partner. The use case that we investigate is anaircraft engine controller. In this context, we evaluate the use of FRET tobridge the communication gap between formal methods experts and aerospaceindustry specialists. [Principal ideas/results] We describe our journey fromambiguous, natural-language requirements to concise, formalised FRETrequirements. We include our analysis of the formalised requirements from theperspective of patterns, translation into other formal methods and therelationship between parent-child requirements in this set. We also provideinsight into lessons learned throughout this process and identify futureimprovements to FRET. [Contribution] Previous experience reports have beenpublished by the FRET team, but this is the first such report of an industrialuse case that was written by researchers that have not been involved FRET'sdevelopment.",Marie Farrell,2021/12/8,2022/2/2
2201.11451v1,Setting AI in context: A case study on defining the context and operational design domain for automated driving,http://arxiv.org/abs/2201.11451v1,"[Context and motivation] For automated driving systems, the operationalcontext needs to be known in order to state guarantees on performance andsafety. The operational design domain (ODD) is an abstraction of theoperational context, and its definition is an integral part of the systemdevelopment process. [Question / problem] There are still major uncertaintiesin how to clearly define and document the operational context in a diverse anddistributed development environment such as the automotive industry. This casestudy investigates the challenges with context definitions for the developmentof perception functions that use machine learning for automated driving.[Principal ideas/results] Based on qualitative analysis of data fromsemi-structured interviews, the case study shows that there is a lack ofstandardisation for context definitions across the industry, ambiguities in theprocesses that lead to deriving the ODD, missing documentation of assumptionsabout the operational context, and a lack of involvement of function developersin the context definition. [Contribution] The results outline challengesexperienced by an automotive supplier company when defining the operationalcontext for systems using machine learning. Furthermore, the study collectedideas for potential solutions from the perspective of practitioners.",Hans-Martin Heyn,2022/1/27,2022/1/27
2401.12075v1,NLP-based Relation Extraction Methods in RE,http://arxiv.org/abs/2401.12075v1,"In the context of requirements engineering, relation extraction is the taskof documenting the traceability between requirements artefacts. When dealingwith textual requirements (i.e., requirements expressed using naturallanguage), relation extraction becomes a cognitively challenging task,especially in terms of ambiguity and required effort from domain-experts.Hence, in highly-adaptive, large-scale environments, effective and efficientautomated relation extraction using natural language processing techniquesbecomes essential. In this chapter, we present a comprehensive overview ofnatural language-based relation extraction from text-based requirements. Weinitially describe the fundamentals of requirements relations based on the mostrelevant literature in the field, including the most common requirementsrelations types. The core of the chapter is composed by two main sections: (i)natural language techniques for the identification and categorization ofrequirements relations (i.e., syntactic vs. semantic techniques), and (ii)information extraction methods for the task of relation extraction (i.e.,retrieval-based vs. machine learning-based methods). We complement thisanalysis with the state-of-the-art challenges and the envisioned futureresearch directions. Overall, this chapter aims at providing a clearperspective on the theoretical and practical fundamentals in the field ofnatural language-based relation extraction.",Quim Motger,2024/1/22,2024/1/22
2303.07476v2,Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision,http://arxiv.org/abs/2303.07476v2,"Many engineering organizations are reimplementing and extending deep neuralnetworks from the research community. We describe this process as deep learningmodel reengineering. Deep learning model reengineering - reusing, reproducing,adapting, and enhancing state-of-the-art deep learning approaches - ischallenging for reasons including under-documented reference models, changingrequirements, and the cost of implementation and testing. In addition,individual engineers may lack expertise in software engineering, yet teams mustapply knowledge of software engineering and deep learning to succeed. Priorwork has examined on DL systems from a ""product"" view, examining defects fromprojects regardless of the engineers' purpose. Our study is focused onreengineering activities from a ""process"" view, and focuses on engineersspecifically engaged in the reengineering process.  Our goal is to understand the characteristics and challenges of deep learningmodel reengineering. We conducted a case study of this phenomenon, focusing onthe context of computer vision. Our results draw from two data sources: defectsreported in open-source reeengineering projects, and interviews conducted withopen-source project contributors and the leaders of a reengineering team. Ourresults describe how deep learning-based computer vision techniques arereengineered, analyze the distribution of defects in this process, and discusschallenges and practices. Integrating our quantitative and qualitative data, weproposed a novel reengineering workflow. Our findings inform several futuredirections, including: measuring additional unknown aspects of modelreengineering; standardizing engineering practices to facilitate reengineering;and developing tools to support model reengineering and model reuse.",Wenxin Jiang,2023/3/13,2023/8/25
2401.01508v1,Practical Guidelines for the Selection and Evaluation of NLP Techniques in RE,http://arxiv.org/abs/2401.01508v1,"Natural Language Processing (NLP) is now a cornerstone of requirementsautomation. One compelling factor behind the growing adoption of NLP inRequirements Engineering (RE) is the prevalent use of natural language (NL) forspecifying requirements in industry. NLP techniques are commonly used forautomatically classifying requirements, extracting important information, e.g.,domain models and glossary terms, and performing quality assurance tasks, suchas ambiguity handling and completeness checking. With so many different NLPsolution strategies available and the possibility of applying machine learningalongside, it can be challenging to choose the right strategy for a specific REtask and to evaluate the resulting solution in an empirically rigorous manner.This book chapter presents guidelines for the selection of NLP techniques aswell as for their evaluation in the context of RE. In particular, we discusshow to choose among different strategies such as traditional NLP, feature-basedmachine learning, and language-model-based methods. Our ultimate hope for thischapter is to serve as a stepping stone, assisting newcomers to NLP4RE inquickly initiating themselves into the NLP technologies most pertinent to theRE field.",Mehrdad Sabetzadeh,2024/1/3,2024/1/3
2202.01035v1,Detecting Privacy Requirements from User Stories with NLP Transfer Learning Models,http://arxiv.org/abs/2202.01035v1,"To provide privacy-aware software systems, it is crucial to consider privacyfrom the very beginning of the development. However, developers do not have theexpertise and the knowledge required to embed the legal and social requirementsfor data protection into software systems. Objective: We present an approach todecrease privacy risks during agile software development by automaticallydetecting privacy-related information in the context of user storyrequirements, a prominent notation in agile Requirement Engineering (RE).Methods: The proposed approach combines Natural Language Processing (NLP) andlinguistic resources with deep learning algorithms to identify privacy aspectsinto User Stories. NLP technologies are used to extract information regardingthe semantic and syntactic structure of the text. This information is thenprocessed by a pre-trained convolutional neural network, which paved the wayfor the implementation of a Transfer Learning technique. We evaluate theproposed approach by performing an empirical study with a dataset of 1680 userstories. Results: The experimental results show that deep learning algorithmsallow to obtain better predictions than those achieved with conventional(shallow) machine learning methods. Moreover, the application of TransferLearning allows to considerably improve the accuracy of the predictions, ca.10%. Conclusions: Our study contributes to encourage software engineeringresearchers in considering the opportunities to automate privacy detection inthe early phase of design, by also exploiting transfer learning models.",Francesco Casillo,2022/2/2,2022/2/2
2111.14142v1,Agility in Software 2.0 -- Notebook Interfaces and MLOps with Buttresses and Rebars,http://arxiv.org/abs/2111.14142v1,"Artificial intelligence through machine learning is increasingly used in thedigital society. Solutions based on machine learning bring both greatopportunities, thus coined ""Software 2.0,"" but also great challenges for theengineering community to tackle. Due to the experimental approach used by datascientists when developing machine learning models, agility is an essentialcharacteristic. In this keynote address, we discuss two contemporarydevelopment phenomena that are fundamental in machine learning development,i.e., notebook interfaces and MLOps. First, we present a solution that canremedy some of the intrinsic weaknesses of working in notebooks by supportingeasy transitions to integrated development environments. Second, we proposereinforced engineering of AI systems by introducing metaphorical buttresses andrebars in the MLOps context. Machine learning-based solutions are dynamic innature, and we argue that reinforced continuous engineering is required toquality assure the trustworthy AI systems of tomorrow.",Markus Borg,2021/11/28,2021/11/28
2108.06645v1,On Multi-Modal Learning of Editing Source Code,http://arxiv.org/abs/2108.06645v1,"In recent years, Neural Machine Translator (NMT) has shown promise inautomatically editing source code. Typical NMT based code editor only considersthe code that needs to be changed as input and suggests developers with aranked list of patched code to choose from - where the correct one may notalways be at the top of the list. While NMT based code editing systems generatea broad spectrum of plausible patches, the correct one depends on thedevelopers' requirement and often on the context where the patch is applied.Thus, if developers provide some hints, using natural language, or providingpatch context, NMT models can benefit from them. As a proof of concept, in thisresearch, we leverage three modalities of information: edit location, edit codecontext, commit messages (as a proxy of developers' hint in natural language)to automatically generate edits with NMT models. To that end, we build MODIT, amulti-modal NMT based code editing engine. With in-depth investigation andanalysis, we show that developers' hint as an input modality can narrow thesearch space for patches and outperform state-of-the-art models to generatecorrectly patched code in top-1 position.",Saikat Chakraborty,2021/8/15,2021/8/15
2210.16433v3,Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models,http://arxiv.org/abs/2210.16433v3,"Fully-parametric language models generally require a huge number of modelparameters to store the necessary knowledge for solving multiple naturallanguage tasks in zero/few-shot settings. In addition, it is hard to adapt tothe evolving world knowledge without the costly model re-training. In thispaper, we develop a novel semi-parametric language model architecture,Knowledge-in-Context (KiC), which empowers a parametric text-to-text languagemodel with a knowledge-rich external memory. Specifically, the external memorycontains six different types of knowledge: entity, dictionary, commonsense,event, script, and causality knowledge. For each input instance, the KiC modeladaptively selects a knowledge type and retrieves the most helpful pieces ofknowledge. The input instance along with its knowledge augmentation is fed intoa text-to-text model (e.g., T5) to generate the output answer, where both theinput and the output are in natural language forms after prompting.Interestingly, we find that KiC can be identified as a specialmixture-of-experts (MoE) model, where the knowledge selector plays the role ofa router that is used to determine the sequence-to-expert assignment in MoE.This key observation inspires us to develop a novel algorithm for training KiCwith an instance-adaptive knowledge selector. As a knowledge-richsemi-parametric language model, KiC only needs a much smaller parametric partto achieve superior zero-shot performance on unseen tasks. By evaluating on 40+different tasks, we show that KiC_Large with 770M parameters easily outperformslarge language models (LMs) that are 4-39x larger by a large margin. We alsodemonstrate that KiC exhibits emergent abilities at a much smaller model scalecompared to the fully-parametric models.",Xiaoman Pan,2022/10/28,2023/3/27
2304.09333v1,BIM-GPT: a Prompt-Based Virtual Assistant Framework for BIM Information Retrieval,http://arxiv.org/abs/2304.09333v1,"Efficient information retrieval (IR) from building information models (BIMs)poses significant challenges due to the necessity for deep BIM knowledge orextensive engineering efforts for automation. We introduce BIM-GPT, aprompt-based virtual assistant (VA) framework integrating BIM and generativepre-trained transformer (GPT) technologies to support NL-based IR. A promptmanager and dynamic template generate prompts for GPT models, enablinginterpretation of NL queries, summarization of retrieved information, andanswering BIM-related questions. In tests on a BIM IR dataset, our approachachieved 83.5% and 99.5% accuracy rates for classifying NL queries with no dataand 2% data incorporated in prompts, respectively. Additionally, we validatedthe functionality of BIM-GPT through a VA prototype for a hospital building.This research contributes to the development of effective and versatile VAs forBIM IR in the construction industry, significantly enhancing BIM accessibilityand reducing engineering efforts and training data requirements for processingNL queries.",Junwen Zheng,2023/4/18,2023/4/18
2401.02418v1,Learning to Prompt with Text Only Supervision for Vision-Language Models,http://arxiv.org/abs/2401.02418v1,"Foundational vision-language models such as CLIP are becoming a new paradigmin vision, due to their excellent generalization abilities. However, adaptingthese models for downstream tasks while maintaining their generalizationremains a challenge. In literature, one branch of methods adapts CLIP bylearning prompts using visual information. While effective, most of these worksrequire labeled data which is not practical, and often struggle to generalizetowards new datasets due to over-fitting on the source data. An alternativeapproach resorts to training-free methods by generating class descriptions fromlarge language models (LLMs) and perform prompt ensembling. However, thesemethods often generate class specific prompts that cannot be transferred toother classes, which incur higher costs by generating LLM descriptions for eachclass separately. In this work, we propose to combine the strengths of theseboth streams of methods by learning prompts using only text data derived fromLLMs. As supervised training of prompts is not trivial due to absence ofimages, we develop a training approach that allows prompts to extract richcontextual knowledge from LLM data. Moreover, with LLM contextual data mappedwithin the learned prompts, it enables zero-shot transfer of prompts to newclasses and datasets potentially cutting the LLM prompt engineering cost. Tothe best of our knowledge, this is the first work that learns generalizedprompts using text only data. We perform extensive evaluations on 4 benchmarkswhere our method improves over prior ensembling works while being competitiveto those utilizing labeled images. Our code and pre-trained models areavailable at https://github.com/muzairkhattak/ProText.",Muhammad Uzair Khattak,2024/1/4,2024/1/4
2401.00268v1,COMMA: Co-Articulated Multi-Modal Learning,http://arxiv.org/abs/2401.00268v1,"Pretrained large-scale vision-language models such as CLIP have demonstratedexcellent generalizability over a series of downstream tasks. However, they aresensitive to the variation of input text prompts and need a selection of prompttemplates to achieve satisfactory performance. Recently, various methods havebeen proposed to dynamically learn the prompts as the textual inputs to avoidthe requirements of laboring hand-crafted prompt engineering in the fine-tuningprocess. We notice that these methods are suboptimal in two aspects. First, theprompts of the vision and language branches in these methods are usuallyseparated or uni-directionally correlated. Thus, the prompts of both branchesare not fully correlated and may not provide enough guidance to align therepresentations of both branches. Second, it's observed that most previousmethods usually achieve better performance on seen classes but causeperformance degeneration on unseen classes compared to CLIP. This is becausethe essential generic knowledge learned in the pretraining stage is partlyforgotten in the fine-tuning process. In this paper, we propose Co-ArticulatedMulti-Modal Learning (COMMA) to handle the above limitations. Especially, ourmethod considers prompts from both branches to generate the prompts to enhancethe representation alignment of both branches. Besides, to alleviate forgettingabout the essential knowledge, we minimize the feature discrepancy between thelearned prompts and the embeddings of hand-crafted prompts in the pre-trainedCLIP in the late transformer layers. We evaluate our method across threerepresentative tasks of generalization to novel classes, new target datasetsand unseen domain shifts. Experimental results demonstrate the superiority ofour method by exhibiting a favorable performance boost upon all tasks with highefficiency.",Lianyu Hu,2023/12/30,2023/12/30
2103.14230v2,Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution,http://arxiv.org/abs/2103.14230v2,"Spatial-temporal reasoning is a challenging task in Artificial Intelligence(AI) due to its demanding but unique nature: a theoretic requirement onrepresenting and reasoning based on spatial-temporal knowledge in mind, and anapplied requirement on a high-level cognitive system capable of navigating andacting in space and time. Recent works have focused on an abstract reasoningtask of this kind -- Raven's Progressive Matrices (RPM). Despite theencouraging progress on RPM that achieves human-level performance in terms ofaccuracy, modern approaches have neither a treatment of human-like reasoning ongeneralization, nor a potential to generate answers. To fill in this gap, wepropose a neuro-symbolic Probabilistic Abduction and Execution (PrAE) learner;central to the PrAE learner is the process of probabilistic abduction andexecution on a probabilistic scene representation, akin to the mentalmanipulation of objects. Specifically, we disentangle perception and reasoningfrom a monolithic model. The neural visual perception frontend predictsobjects' attributes, later aggregated by a scene inference engine to produce aprobabilistic scene representation. In the symbolic logical reasoning backend,the PrAE learner uses the representation to abduce the hidden rules. An answeris predicted by executing the rules on the probabilistic representation. Theentire system is trained end-to-end in an analysis-by-synthesis manner withoutany visual attribute annotations. Extensive experiments demonstrate that thePrAE learner improves cross-configuration generalization and is capable ofrendering an answer, in contrast to prior works that merely make a categoricalchoice from candidates.",Chi Zhang,2021/3/26,2021/5/14
1710.00239v1,$$-PMP: Enhancing Physics-based Motion Planners with Knowledge-based Reasoning,http://arxiv.org/abs/1710.00239v1,"Physics-based motion planning is a challenging task, since it requires thecomputation of the robot motions while allowing possible interactions with(some of) the obstacles in the environment. Kinodynamic motion plannersequipped with a dynamic engine acting as state propagator are usually used forthat purpose. The difficulties arise in the setting of the adequate forces forthe interactions and because these interactions may change the pose of themanipulatable obstacles, thus either facilitating or preventing the finding ofa solution path. The use of knowledge can alleviate the stated difficulties.This paper proposes the use of an enhanced state propagator composed of adynamic engine and a low-level geometric reasoning process that is used todetermine how to interact with the objects, i.e. from where and with whichforces. The proposal, called \k{appa}-PMP can be used with any kinodynamicplanner, thus giving rise to e.g. \k{appa}-RRT. The approach also includes apreprocessing step that infers from a semantic abstract knowledge described interms of an ontology the manipulation knowledge required by the reasoningprocess. The proposed approach has been validated with several examplesinvolving an holonomic mobile robot, a robot with differential constraints anda serial manipulator, and benchmarked using several state-of-the artkinodynamic planners. The results showed a significant difference in the powerconsumption with respect to simple physics-based planning, an improvement inthe success rate and in the quality of the solution paths.",Muhayyuddin,2017/9/30,2017/9/30
2110.12591v1,Assuring Increasingly Autonomous Systems in Human-Machine Teams: An Urban Air Mobility Case Study,http://arxiv.org/abs/2110.12591v1,"As aircraft systems become increasingly autonomous, the human-machine roleallocation changes and opportunities for new failure modes arise. Thisnecessitates an approach to identify the safety requirements for theincreasingly autonomous system (IAS) as well as a framework and techniques toverify and validate that an IAS meets its safety requirements. We use CrewResource Management techniques to identify requirements and behaviors for safehuman-machine teaming behaviors. We provide a methodology to verify that an IASmeets its requirements. We apply the methodology to a case study in Urban AirMobility, which includes two contingency scenarios: unreliable sensor andaborted landing. For this case study, we implement an IAS agent in the Soarlanguage that acts as a copilot for the selected contingency scenarios andperforms takeoff and landing preparation, while the pilot maintains finaldecision authority. We develop a formal human-machine team architecture modelin the Architectural Analysis and Design Language (AADL), with operator and IASrequirements formalized in the Assume Guarantee REasoning Environment (AGREE)Annex to AADL. We formally verify safety requirements for the human-machineteam given the requirements on the IAS and operator. We develop an automatedtranslator from Soar to the nuXmv model checking language and formally verifythat the IAS agent satisfies its requirements using nuXmv. We share the designand requirements errors found in the process as well as our lessons learned.",Siddhartha Bhattacharyya,2021/10/25,2021/10/25
2101.10484v1,Compositional Cyber-Physical Systems Modeling,http://arxiv.org/abs/2101.10484v1,"Assuring the correct behavior of cyber-physical systems requires significantmodeling effort, particularly during early stages of the engineering and designprocess when a system is not yet available for testing or verification ofproper behavior. A primary motivation for `getting things right' in these earlydesign stages is that altering the design is significantly less costly and moreeffective than when hardware and software have already been developed.Engineering cyber-physical systems requires the construction of severaldifferent types of models, each representing a different view, which includestakeholder requirements, system behavior, and the system architecture.Furthermore, each of these models can be represented at different levels ofabstraction. Formal reasoning has improved the precision and expanded theavailable types of analysis in assuring correctness of requirements, behaviors,and architectures. However, each is usually modeled in distinct formalisms andcorresponding tools. Currently, this disparity means that a system designermust manually check that the different models are in agreement. Manuallyediting and checking models is error prone, time consuming, and sensitive toany changes in the design of the models themselves. Wiring diagrams and relatedtheory provide a means for formally organizing these different but relatedmodeling views, resulting in a compositional modeling language forcyber-physical systems. Such a categorical language can make concrete therelationship between different model views, thereby managing complexity,allowing hierarchical decomposition of system models, and formally provingconsistency between models.",Georgios Bakirtzis,2021/1/26,2021/1/26
2208.08389v1,One-particle engine with a porous piston,http://arxiv.org/abs/2208.08389v1,"We propose a variation of the classical Szilard engine that uses a porouspiston. Such an engine requires neither information about the position of theparticle, nor the removal and subsequent insertion of the piston when resettingthe engine to continue doing work by lifting a mass against a gravitationalfield. Though the engine operates in contact with a single thermal reservoir,the reset mechanism acts as a second reservoir, dissipating energy when a massthat has been lifted by the engine is removed to initiate a new operationcycle.",Carlos E. lvarez,2022/8/17,2022/8/17
2203.03856v1,DARER: Dual-task Temporal Relational Recurrent Reasoning Network for Joint Dialog Sentiment Classification and Act Recognition,http://arxiv.org/abs/2203.03856v1,"The task of joint dialog sentiment classification (DSC) and act recognition(DAR) aims to simultaneously predict the sentiment label and act label for eachutterance in a dialog. In this paper, we put forward a new framework whichmodels the explicit dependencies via integrating \textit{prediction-levelinteractions} other than semantics-level interactions, more consistent withhuman intuition. Besides, we propose a speaker-aware temporal graph (SATG) anda dual-task relational temporal graph (DRTG) to introduce \textit{temporalrelations} into dialog understanding and dual-task reasoning. To implement ourframework, we propose a novel model dubbed DARER, which first generates thecontext-, speaker- and temporal-sensitive utterance representations viamodeling SATG, then conducts recurrent dual-task relational reasoning on DRTG,in which process the estimated label distributions act as key clues inprediction-level interactions. Experiment results show that DARER outperformsexisting models by large margins while requiring much less computation resourceand costing less training time. Remarkably, on DSC task in Mastodon, DARERgains a relative improvement of about 25% over previous best model in terms ofF1, with less than 50% parameters and about only 60% required GPU memory.",Bowen Xing,2022/3/8,2022/3/8
2109.01121v1,A Reasoning Engine for the Gamification of Loop-Invariant Discovery,http://arxiv.org/abs/2109.01121v1,"We describe the design and implementation of a reasoning engine thatfacilitates the gamification of loop-invariant discovery. Our reasoning engineenables students, computational agents and regular software engineers with noformal methods expertise to collaboratively prove interesting theorems aboutsimple programs using browser-based, online games. Within an hour, players areable to specify and verify properties of programs that are beyond thecapabilities of fully-automated tools. The hour limit includes the time forsetting up the system, completing a short tutorial explaining game play andreasoning about simple imperative programs. Players are never required tounderstand formal proofs; they only provide insights by proposing invariants.The reasoning engine is responsible for managing and evaluating the proposedinvariants, as well as generating actionable feedback.",Andrew Walter,2021/9/2,2021/9/2
1703.09694v2,Strained graphene based highly efficient quantum heat engine operating at maximum power,http://arxiv.org/abs/1703.09694v2,"A strained graphene monolayer is shown to operate as a highly efficientquantum heat engine delivering maximum power. The efficiency and power of theproposed device exceeds that of recent proposals. The reason for theseexcellent characteristics is that strain enables complete valley separation intransmittance through the device, implying that increasing strain leads to veryhigh Seebeck coefficient as well as lower conductance. In addition, sincetime-reversal symmetry is unbroken in our system, the proposed strainedgraphene quantum heat engine can also act as a high performance refrigerator.",Arjun Mani,2017/3/28,2017/8/28
1702.05568v4,"""SHORT""er Reasoning About Larger Requirements Models",http://arxiv.org/abs/1702.05568v4,"When Requirements Engineering(RE) models are unreasonably complex, theycannot support efficient decision making. SHORT is a tool to simplify thatreasoning by exploiting the ""key"" decisions within RE models. These ""keys"" havethe property that once values are assigned to them, it is very fast to reasonover the remaining decisions. Using these ""keys"", reasoning about RE models canbe greatly SHORTened by focusing stakeholder discussion on just these keydecisions.  This paper evaluates the SHORT tool on eight complex RE models. We find thatthe number of keys are typically only 12% of all decisions. Since they are sofew in number, keys can be used to reason faster about models. For example,using keys, we can optimize over those models (to achieve the most goals atleast cost) two to three orders of magnitude faster than standard methods.Better yet, finding those keys is not difficult: SHORT runs in low orderpolynomial time and terminates in a few minutes for the largest models.",George Mathew,2017/2/18,2017/8/22
quant-ph/9602006v1,What are quantum theorists doing at a conference on consciousness?,http://arxiv.org/abs/quant-ph/9602006v1,"The reason why orthodox quantum theory necessarily invokes consciousness isexplained. Several procedures whereby the Born probability rule can beintroduced are discussed, and reasons are given for prefering one in whichconsciousness selects a unique realised world. Consciousness is somethingoutside of the laws of physics (quantum mechanics), but it has a real effectupon the experienced world. Finally, orthodox quantum theory is shown torequire that consciousness acts non-locally.",Euan Squires,1996/2/9,1996/2/9
2202.02574v1,Governance of Autonomous Agents on the Web: Challenges and Opportunities,http://arxiv.org/abs/2202.02574v1,"The study of autonomous agents has a long tradition in the Multiagent Systemsand the Semantic Web communities, with applications ranging from automatingbusiness processes to personal assistants. More recently, the Web of Things(WoT), which is an extension of the Internet of Things (IoT) with metadataexpressed in Web standards, and its community provide further motivation forpushing the autonomous agents research agenda forward. Although representingand reasoning about norms, policies and preferences is crucial to ensuring thatautonomous agents act in a manner that satisfies stakeholder requirements,normative concepts, policies and preferences have yet to be considered asfirst-class abstractions in Web-based multiagent systems. Towards this end,this paper motivates the need for alignment and joint research across theMultiagent Systems, Semantic Web, and WoT communities, introduces a conceptualframework for governance of autonomous agents on the Web, and identifiesseveral research challenges and opportunities.",Timotheus Kampik,2022/2/5,2022/2/5
1402.1985v1,Generating Logical Specifications from Requirements Models for Deduction-based Formal Verification,http://arxiv.org/abs/1402.1985v1,"The work concerns automatic generation of logical specifications fromrequirements models. Logical specifications obtained in such a way can besubjected to formal verification using deductive reasoning. Formal verificationconcerns correctness of a model behaviour. Reliability of the requirementsengineering is essential for all phases of software development processes.Deductive reasoning is an important alternative among other formal methods.However, logical specifications, considered as sets of temporal logic formulas,are difficult to specify manually by inexperienced users and this fact can beregarded as a significant obstacle to practical use of deduction-basedverification tools. A method of building requirements models using some UMLdiagrams, including their logical specifications, is presented step by step.Organizing activity diagrams into predefined workflow patterns enablesautomated extraction of logical specifications. The crucial aspect of thepresented approach is integrating the requirements engineering phase and theautomatic generation of logical specifications. A system of the deduction-basedverification is proposed. The reasoning process could be based on the semantictableaux method. A simple yet illustrative example of the requirementselicitation and verification is provided.",Radoslaw Klimek,2014/2/9,2014/2/9
2307.13604v1,Cloud Render Farm Services Discovery Using NLP And Ontology Based Knowledge Graph,http://arxiv.org/abs/2307.13604v1,"Cloud render farm services are the animation domain specific cloud servicesPlatform-as-a-Service (PaaS) type of cloud services that provides a completeplatform to render the animation files. However, identifying the render farmservices that is cost effective and also matches the functional requirementsthat changes for almost every project like the animation software, plug-insrequired etc., is a challenge. This research work proposes an ontology-basedservice discovery engine named RenderSelect for the cloud render farm services.The cloud render farm ontology semantically defines the relationship among thecloud render farm services. The knowledge-based reasoning algorithms namely,the Concept similarity reasoning, Equivalent reasoning and the Numericalsimilarity reasoning have been applied to determine the similarity among thecloud services. The service discovery engine was evaluated for finding theservices under three different scenarios namely a) with help of the ontology,b) without the help of the ontology and c) using a common search engine on theinternet. The results show that the proposed service discovery engine which isspecifically designed for the cloud render farm services using the ontologyperforms significantly better than the other two.",Ruby Annette,2023/7/10,2023/7/10
0902.0924v1,Towards a Theory of Requirements Elicitation: Acceptability Condition for the Relative Validity of Requirements,http://arxiv.org/abs/0902.0924v1,"A requirements engineering artifact is valid relative to the stakeholders ofthe system-to-be if they agree on the content of that artifact. Checkingrelative validity involves a discussion between the stakeholders and therequirements engineer. This paper proposes (i) a language for therepresentation of information exchanged in a discussion about the relativevalidity of an artifact; (ii) the acceptability condition, which, when itverifies in a discussion captured in the proposed language, signals that therelative validity holds for the discussed artifact and for the participants inthe discussion; and (iii) reasoning procedures to automatically check theacceptability condition in a discussions captured by the proposed language.",Ivan Jureta,2009/2/5,2009/2/5
1905.09519v1,"The African Wildlife Ontology tutorial ontologies: requirements, design, and content",http://arxiv.org/abs/1905.09519v1,"Background. Most tutorial ontologies focus on illustrating one aspect ofontology development, notably language features and automated reasoners, butignore ontology development factors, such as emergent modelling guidelines andontological principles. Yet, novices replicate examples from the exercises theycarry out. Not providing good examples holistically causes the propagation ofsub-optimal ontology development, which may negatively affect the quality of areal domain ontology. Results. We identified 22 requirements that a goodtutorial ontology should satisfy regarding subject domain, logics andreasoning, and engineering aspects. We developed a set of ontologies aboutAfrican Wildlife to serve as tutorial ontologies. A majority of therequirements have been met with the set of African Wildlife Ontology tutorialontologies, which are introduced in this paper. The African Wildlife Ontologyis mature and has been used yearly in an ontology engineering course ortutorial since 2010 and is included in a recent ontology engineering textbookwith relevant examples and exercises. Conclusion. The African Wildlife Ontologyprovides a wide range of options concerning examples and exercises for ontologyengineering well beyond illustrating only language features and automatedreasoning. It assists in demonstrating tasks about ontology quality, such asalignment to a foundational ontology and satisfying competency questions,versioning, and multilingual ontologies.",C Maria Keet,2019/5/23,2019/5/23
2401.01974v1,Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers,http://arxiv.org/abs/2401.01974v1,"Visual reasoning is dominated by end-to-end neural networks scaled tobillions of model parameters and training examples. However, even the largestmodels struggle with compositional reasoning, generalization, fine-grainedspatial and temporal reasoning, and counting. Visual reasoning with largelanguage models (LLMs) as controllers can, in principle, address theselimitations by decomposing the task and solving subtasks by orchestrating a setof (visual) tools. Recently, these models achieved great performance on taskssuch as compositional visual question answering, visual grounding, and videotemporal reasoning. Nevertheless, in their current form, these models heavilyrely on human engineering of in-context examples in the prompt, which are oftendataset- and task-specific and require significant labor by highly skilledprogrammers. In this work, we present a framework that mitigates these issuesby introducing spatially and temporally abstract routines and by leveraging asmall number of labeled examples to automatically generate in-context examples,thereby avoiding human-created in-context examples. On a number of visualreasoning tasks, we show that our framework leads to consistent gains inperformance, makes LLMs as controllers setup more robust, and removes the needfor human engineering of in-context examples.",Aleksandar Stani,2024/1/3,2024/1/3
2311.06318v1,Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion,http://arxiv.org/abs/2311.06318v1,"Large Language Models (LLMs) excel at tackling various natural languagetasks. However, due to the significant costs involved in re-training orfine-tuning them, they remain largely static and difficult to personalize.Nevertheless, a variety of applications could benefit from generations that aretailored to users' preferences, goals, and knowledge. Among them is web search,where knowing what a user is trying to accomplish, what they care about, andwhat they know can lead to improved search experiences. In this work, wepropose a novel and general approach that augments an LLM with relevant contextfrom users' interaction histories with a search engine in order to personalizeits outputs. Specifically, we construct an entity-centric knowledge store foreach user based on their search and browsing activities on the web, which isthen leveraged to provide contextually relevant LLM prompt augmentations. Thisknowledge store is light-weight, since it only produces user-specific aggregateprojections of interests and knowledge onto public knowledge graphs, andleverages existing search log infrastructure, thereby mitigating the privacy,compliance, and scalability concerns associated with building deep userprofiles for personalization. We then validate our approach on the task ofcontextual query suggestion, which requires understanding not only the user'scurrent search context but also what they historically know and care about.Through a number of experiments based on human evaluation, we show that ourapproach is significantly better than several other LLM-powered baselines,generating query suggestions that are contextually more relevant, personalized,and useful.",Jinheon Baek,2023/11/10,2023/11/10
2311.02192v1,Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models,http://arxiv.org/abs/2311.02192v1,"Identifying contextual integrity (CI) and governing knowledge commons (GKC)parameters in privacy policy texts can facilitate normative privacy analysis.However, GKC-CI annotation has heretofore required manual or crowdsourcedeffort. This paper demonstrates that high-accuracy GKC-CI parameter annotationof privacy policies can be performed automatically using large language models.We fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotationsfrom 16 ground truth privacy policies. Our best-performing model (fine-tunedGPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding theperformance of prior crowdsourcing approaches despite the complexity of privacypolicy texts and the nuance of the GKC-CI annotation task. We apply ourbest-performing model to privacy policies from 164 popular online services,demonstrating the effectiveness of scaling GKC-CI annotation for dataexploration. We make all annotated policies as well as the training data andscripts needed to fine-tune our best-performing model publicly available forfuture research.",Jake Chanenson,2023/11/3,2023/11/3
2309.07990v1,Leveraging Contextual Information for Effective Entity Salience Detection,http://arxiv.org/abs/2309.07990v1,"In text documents such as news articles, the content and key events usuallyrevolve around a subset of all the entities mentioned in a document. Theseentities, often deemed as salient entities, provide useful cues of theaboutness of a document to a reader. Identifying the salience of entities wasfound helpful in several downstream applications such as search, ranking, andentity-centric summarization, among others. Prior work on salient entitydetection mainly focused on machine learning models that require heavy featureengineering. We show that fine-tuning medium-sized language models with across-encoder style architecture yields substantial performance gains overfeature engineering approaches. To this end, we conduct a comprehensivebenchmarking of four publicly available datasets using models representative ofthe medium-sized pre-trained language model family. Additionally, we show thatzero-shot prompting of instruction-tuned language models yields inferiorresults, indicating the task's uniqueness and complexity.",Rajarshi Bhowmik,2023/9/14,2023/9/14
1905.06437v1,Specifying and Reasoning about Contextual Preferences in the Goal-oriented Requirements Modelling,http://arxiv.org/abs/1905.06437v1,"Goal-oriented requirements variability modelling has established theunderstanding for adaptability in the early stage of software development-theRequirements Engineering phase. Goal-oriented requirements variabilitymodelling considers both the intentions, which are captured as goals in goalmodels, and the preferences of different stakeholders as the main sources ofsystem behaviour variability. Most often, however, intentions and preferencesvary according to contexts. In this paper, we propose an approach for acontextual preference-based requirements variability analysis in thegoal-oriented Requirements Engineering. We introduce a quantitative contextualpreference specification to express the varying preferences imposed overrequirements that are represented in the goal model. Such contextualpreferences are used as criteria to evaluate alternative solutions that satisfythe requirements variability problem. We utilise a state-of-the-art reasoningimplementation from the Answer Set Programming domain to automate thederivation and evaluation of solutions that fulfill the goals and satisfy thecontextual preferences. Our approach will support systems analysts in theirdecisions upon alternative design solutions that define subsequent systemimplementations.",Khavee Agustus Botangen,2019/5/15,2019/5/15
2308.16771v1,Linking microblogging sentiments to stock price movement: An application of GPT-4,http://arxiv.org/abs/2308.16771v1,"This paper investigates the potential improvement of the GPT-4 LanguageLearning Model (LLM) in comparison to BERT for modeling same-day daily stockprice movements of Apple and Tesla in 2017, based on sentiment analysis ofmicroblogging messages. We recorded daily adjusted closing prices andtranslated them into up-down movements. Sentiment for each day was extractedfrom messages on the Stocktwits platform using both LLMs. We develop a novelmethod to engineer a comprehensive prompt for contextual sentiment analysiswhich unlocks the true capabilities of modern LLM. This enables us to carefullyretrieve sentiments, perceived advantages or disadvantages, and the relevancetowards the analyzed company. Logistic regression is used to evaluate whetherthe extracted message contents reflect stock price movements. As a result,GPT-4 exhibited substantial accuracy, outperforming BERT in five out of sixmonths and substantially exceeding a naive buy-and-hold strategy, reaching apeak accuracy of 71.47 % in May. The study also highlights the importance ofprompt engineering in obtaining desired outputs from GPT-4's contextualabilities. However, the costs of deploying GPT-4 and the need for fine-tuningprompts highlight some practical considerations for its use.",Rick Steinert,2023/8/31,2023/8/31
2209.14308v1,Prompt Emission of Gamma-Ray Bursts in the High-density Environment of Active Galactic Nuclei Accretion Disks,http://arxiv.org/abs/2209.14308v1,"Long and short gamma-ray bursts are traditionally associated with galacticenvironments, where circumburst densities are small or moderate (few tohundreds of protons per cubic cm). However, both are also expected to occur inthe disks of Active Galactic Nuclei, where the ambient medium density can bemuch larger. In this work we study, via semi-analytical methods, thepropagation of the GRB outflow, its interaction with the external material, andthe ensuing prompt radiation. In particular, we focus on the case in which theexternal shock develops early in the evolution, at a radius that is smallerthan the internal shock one. We find that bursts in such high densityenvironments are likely characterized by a single, long emission episode thatis due to the superposition of individual pulses, with a characteristic hard tosoft evolution irrespective of the light curve luminosity. While multi-pulselight curves are not impossible, they would require the central engine to godormant for a long time before re-igniting. In addition, short GRB engineswould produce bursts with prompt duration that would exceed the canonical 2 sseparation threshold and would likely be incorrectly classified as long events,even though they would not be accompanied by a simultaneous supernova. Finally,these events have a large dynamical efficiency which would produce a brightprompt emission followed by a somewhat dim afterglow.",Davide Lazzati,2022/9/28,2022/9/28
2308.07308v3,"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked",http://arxiv.org/abs/2308.07308v3,"Large language models (LLMs) are popular for high-quality text generation butcan produce harmful content, even when aligned with human values throughreinforcement learning. Adversarial prompts can bypass their safety measures.We propose LLM Self Defense, a simple approach to defend against these attacksby having an LLM screen the induced responses. Our method does not require anyfine-tuning, input preprocessing, or iterative output generation. Instead, weincorporate the generated content into a pre-defined prompt and employ anotherinstance of an LLM to analyze the text and predict whether it is harmful. Wetest LLM Self Defense on GPT 3.5 and Llama 2, two of the current most prominentLLMs against various types of attacks, such as forcefully inducing affirmativeresponses to prompts and prompt engineering attacks. Notably, LLM Self Defensesucceeds in reducing the attack success rate to virtually 0 using both GPT 3.5and Llama 2.",Mansi Phute,2023/8/14,2023/10/24
1703.07909v1,Data Driven Exploratory Attacks on Black Box Classifiers in Adversarial Domains,http://arxiv.org/abs/1703.07909v1,"While modern day web applications aim to create impact at the civilizationlevel, they have become vulnerable to adversarial activity, where the nextcyber-attack can take any shape and can originate from anywhere. The increasingscale and sophistication of attacks, has prompted the need for a data drivensolution, with machine learning forming the core of many cybersecurity systems.Machine learning was not designed with security in mind, and the essentialassumption of stationarity, requiring that the training and testing data followsimilar distributions, is violated in an adversarial domain. In this paper, anadversary's view point of a classification based system, is presented. Based ona formal adversarial model, the Seed-Explore-Exploit framework is presented,for simulating the generation of data driven and reverse engineering attacks onclassifiers. Experimental evaluation, on 10 real world datasets and using theGoogle Cloud Prediction Platform, demonstrates the innate vulnerability ofclassifiers and the ease with which evasion can be carried out, without anyexplicit information about the classifier type, the training data or theapplication domain. The proposed framework, algorithms and empiricalevaluation, serve as a white hat analysis of the vulnerabilities, and aim tofoster the development of secure machine learning frameworks.",Tegjyot Singh Sethi,2017/3/23,2017/3/23
2307.15043v2,Universal and Transferable Adversarial Attacks on Aligned Language Models,http://arxiv.org/abs/2307.15043v2,"Because ""out-of-the-box"" large language models are capable of generating agreat deal of objectionable content, recent work has focused on aligning thesemodels in an attempt to prevent undesirable generation. While there has beensome success at circumventing these measures -- so-called ""jailbreaks"" againstLLMs -- these attacks have required significant human ingenuity and are brittlein practice. In this paper, we propose a simple and effective attack methodthat causes aligned language models to generate objectionable behaviors.Specifically, our approach finds a suffix that, when attached to a wide rangeof queries for an LLM to produce objectionable content, aims to maximize theprobability that the model produces an affirmative response (rather thanrefusing to answer). However, instead of relying on manual engineering, ourapproach automatically produces these adversarial suffixes by a combination ofgreedy and gradient-based search techniques, and also improves over pastautomatic prompt generation methods.  Surprisingly, we find that the adversarial prompts generated by our approachare quite transferable, including to black-box, publicly released LLMs.Specifically, we train an adversarial attack suffix on multiple prompts (i.e.,queries asking for many different types of objectionable content), as well asmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resultingattack suffix is able to induce objectionable content in the public interfacesto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,Pythia, Falcon, and others. In total, this work significantly advances thestate-of-the-art in adversarial attacks against aligned language models,raising important questions about how such systems can be prevented fromproducing objectionable information. Code is available atgithub.com/llm-attacks/llm-attacks.",Andy Zou,2023/7/27,2023/12/20
2307.14539v2,Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models,http://arxiv.org/abs/2307.14539v2,"We introduce new jailbreak attacks on vision language models (VLMs), whichuse aligned LLMs and are resilient to text-only jailbreak attacks.Specifically, we develop cross-modality attacks on alignment where we pairadversarial images going through the vision encoder with textual prompts tobreak the alignment of the language model. Our attacks employ a novelcompositional strategy that combines an image, adversarially targeted towardstoxic embeddings, with generic prompts to accomplish the jailbreak. Thus, theLLM draws the context to answer the generic prompt from the adversarial image.The generation of benign-appearing adversarial images leverages a novelembedding-space-based methodology, operating with no access to the LLM model.Instead, the attacks require access only to the vision encoder and utilize oneof our four embedding space targeting strategies. By not requiring access tothe LLM, the attacks lower the entry barrier for attackers, particularly whenvision encoders such as CLIP are embedded in closed-source LLMs. The attacksachieve a high success rate across different VLMs, highlighting the risk ofcross-modality alignment vulnerabilities, and the need for new alignmentapproaches for multi-modal models.",Erfan Shayegani,2023/7/26,2023/10/10
2203.14940v1,Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model,http://arxiv.org/abs/2203.14940v1,"Recently, vision-language pre-training shows great potential inopen-vocabulary object detection, where detectors trained on base classes aredevised for detecting new classes. The class text embedding is firstlygenerated by feeding prompts to the text encoder of a pre-trainedvision-language model. It is then used as the region classifier to supervisethe training of a detector. The key element that leads to the success of thismodel is the proper prompt, which requires careful words tuning and ingeniousdesign. To avoid laborious prompt engineering, there are some promptrepresentation learning methods being proposed for the image classificationtask, which however can only be sub-optimal solutions when applied to thedetection task. In this paper, we introduce a novel method, detection prompt(DetPro), to learn continuous prompt representations for open-vocabulary objectdetection based on the pre-trained vision-language model. Different from theprevious classification-oriented methods, DetPro has two highlights: 1) abackground interpretation scheme to include the proposals in image backgroundinto the prompt training; 2) a context grading scheme to separate proposals inimage foreground for tailored prompt training. We assemble DetPro with ViLD, arecent state-of-the-art open-world object detector, and conduct experiments onthe LVIS as well as transfer learning on the Pascal VOC, COCO, Objects365datasets. Experimental results show that our DetPro outperforms the baselineViLD in all settings, e.g., +3.4 APbox and +3.0 APmask improvements on thenovel classes of LVIS. Code and models are available athttps://github.com/dyabel/detpro.",Yu Du,2022/3/28,2022/3/28
2109.01134v6,Learning to Prompt for Vision-Language Models,http://arxiv.org/abs/2109.01134v6,"Large pre-trained vision-language models like CLIP have shown great potentialin learning representations that are transferable across a wide range ofdownstream tasks. Different from the traditional representation learning thatis based mostly on discretized labels, vision-language pre-training alignsimages and texts in a common feature space, which allows zero-shot transfer toa downstream task via prompting, i.e., classification weights are synthesizedfrom natural language describing classes of interest. In this work, we showthat a major challenge for deploying such models in practice is promptengineering, which requires domain expertise and is extremely time-consuming --one needs to spend a significant amount of time on words tuning since a slightchange in wording could have a huge impact on performance. Inspired by recentadvances in prompt learning research in natural language processing (NLP), wepropose Context Optimization (CoOp), a simple approach specifically foradapting CLIP-like vision-language models for downstream image recognition.Concretely, CoOp models a prompt's context words with learnable vectors whilethe entire pre-trained parameters are kept fixed. To handle different imagerecognition tasks, we provide two implementations of CoOp: unified context andclass-specific context. Through extensive experiments on 11 datasets, wedemonstrate that CoOp requires as few as one or two shots to beat hand-craftedprompts with a decent margin and is able to gain significant improvements overprompt engineering with more shots, e.g., with 16 shots the average gain isaround 15% (with the highest reaching over 45%). Despite being a learning-basedapproach, CoOp achieves superb domain generalization performance compared withthe zero-shot model using hand-crafted prompts.",Kaiyang Zhou,2021/9/2,2022/10/6
2201.10777v1,Meta-learning Spiking Neural Networks with Surrogate Gradient Descent,http://arxiv.org/abs/2201.10777v1,"Adaptive ""life-long"" learning at the edge and during online task performanceis an aspirational goal of AI research. Neuromorphic hardware implementingSpiking Neural Networks (SNNs) are particularly attractive in this regard, astheir real-time, event-based, local computing paradigm makes them suitable foredge implementations and fast learning. However, the long and iterativelearning that characterizes state-of-the-art SNN training is incompatible withthe physical nature and real-time operation of neuromorphic hardware. Bi-levellearning, such as meta-learning is increasingly used in deep learning toovercome these limitations. In this work, we demonstrate gradient-basedmeta-learning in SNNs using the surrogate gradient method that approximates thespiking threshold function for gradient estimations. Because surrogategradients can be made twice differentiable, well-established, and effectivesecond-order gradient meta-learning methods such as Model Agnostic MetaLearning (MAML) can be used. We show that SNNs meta-trained using MAML match orexceed the performance of conventional ANNs meta-trained with MAML onevent-based meta-datasets. Furthermore, we demonstrate the specific advantagesthat accrue from meta-learning: fast learning without the requirement of highprecision weights or gradients. Our results emphasize how meta-learningtechniques can become instrumental for deploying neuromorphic learningtechnologies on real-world problems.",Kenneth Stewart,2022/1/26,2022/1/26
2308.10248v3,Activation Addition: Steering Language Models Without Optimization,http://arxiv.org/abs/2308.10248v3,"Reliably controlling the behavior of large language models is a pressing openproblem. Existing methods include supervised finetuning, reinforcement learningfrom human feedback, prompt engineering and guided decoding. We insteadinvestigate activation engineering: modifying activations at inference-time topredictably alter model behavior. We bias the forward pass with a 'steeringvector' implicitly specified through natural language. Past work learned thesesteering vectors; our Activation Addition (ActAdd) method instead computes themby taking the activation differences which result from pairs of prompts.  We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet, and replicatethe effect on Llama-13B and GPT-J-6B. Our approach yields inference-timecontrol over high-level properties of output & preserves performance onoff-target topics. The method requires far less compute and implementationeffort than finetuning and RLHF, allows for natural language specification byusers, and its overhead scales naturally with model size.",Alexander Matt Turner,2023/8/20,2023/11/13
2210.01822v1,Galaxy-Classification Activity for All Ages,http://arxiv.org/abs/2210.01822v1,"Classification is a general tool of science; it is used to sort andcategorize biological organisms, chemical elements, astronomical objects, andmany other things. In scientific classification, taxonomy often reflects sharedphysical properties that, in turn, may indicate shared origins and/orevolution. A ""hands-on"" galaxy-classification activity developed andimplemented by Professional Development Program (PDP) participants, for ahigh-school summer STEM enrichment program, has been adopted for various agegroups and venues, from young (K-3) to college students. We detail the basictools required, outline the general activity, and describe the modifications tothe activity based on learners' ages and learning objectives. We describe thefacilitation strategies learned through PDP training and used when implementingthe activity, including prompts to motivate the students. We also discuss howwe connected the classification process to astronomy and science more broadlyduring the concluding remarks.",Kathy L. Cooksey,2022/10/4,2022/10/4
2310.12921v1,Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning,http://arxiv.org/abs/2310.12921v1,"Reinforcement learning (RL) requires either manually specifying a rewardfunction, which is often infeasible, or learning a reward model from a largeamount of human feedback, which is often very expensive. We study a moresample-efficient alternative: using pretrained vision-language models (VLMs) aszero-shot reward models (RMs) to specify tasks via natural language. We proposea natural and general approach to using VLMs as reward models, which we callVLM-RMs. We use VLM-RMs based on CLIP to train a MuJoCo humanoid to learncomplex tasks without a manually specified reward function, such as kneeling,doing the splits, and sitting in a lotus position. For each of these tasks, weonly provide a single sentence text prompt describing the desired task withminimal prompt engineering. We provide videos of the trained agents at:https://sites.google.com/view/vlm-rm. We can improve performance by providing asecond ``baseline'' prompt and projecting out parts of the CLIP embedding spaceirrelevant to distinguish between goal and baseline. Further, we find a strongscaling effect for VLM-RMs: larger VLMs trained with more compute and data arebetter reward models. The failure modes of VLM-RMs we encountered are allrelated to known capability limitations of current VLMs, such as limitedspatial reasoning ability or visually unrealistic environments that are faroff-distribution for the VLM. We find that VLM-RMs are remarkably robust aslong as the VLM is large enough. This suggests that future VLMs will becomemore and more useful reward models for a wide range of RL applications.",Juan Rocamonde,2023/10/19,2023/10/19
1912.05111v1,Entropy production in a generalized breathing parabola model: exact path integral calculations,http://arxiv.org/abs/1912.05111v1,"Models of particle dynamics based on Brownian motion and its variants are arich source of insights into the stochastic behaviour of complex condensedphase systems. In this paper we use one such variant - a breathing parabolawith an additive time-dependent term b(t) - as a non-trivial and previouslyunexplored model system for the verification of the integral fluctuationtheorem (IFT). We demonstrate the IFT's applicability to this system within theframework of an exact path integral calculation. As a by-product of thecalculation, we also show that in the limit b(t) equals to zero, where themodel is representative of the solution dynamics of a colloid trapped in aharmonic potential with a time-dependent spring constant a(t), the mean of thetotal entropy production del S_tot can be obtained in closed form as a functionof a(t). This result is expected to be relevant to the study of colloidal heatengines and other cyclically operating molecular machines. While del_S totconforms to the IFT (and therefore assumes both positive and negative values),its mean is shown to increase monotonically with time, as required by thesecond law of thermodynamics.",Neha Tyagi,2019/12/11,2019/12/11
1712.00472v1,Models of Positive Truth,http://arxiv.org/abs/1712.00472v1,"This paper is a follow-up to ""Models of PT${}^-$ with internal induction fortotal formulae."" We give a strenghtening of the main result on the semanticalnon-conservativity of the theory of PT${}^-$ with internal induction for totalformulae (PT${}^- +$ INT(tot)). We show that if to PT${}^-$ the axiom ofinternal induction for all arithmetical formulae is added (PT${}^-$), then thistheory is semantically stronger than PT${}^- +$ INT(tot). In particular thelatter is not relatively truth definable (in the sense of Fujimoto) in theformer. Last but not least we provide an axiomatic theory of truth which meetsthe requirements put forward by Fischer and Horsten in ""The expressive power oftruth.""",Mateusz eyk,2017/12/1,2017/12/1
2307.04810v1,"Great Inequality of Jupiter and Saturn I: The Planetary Three Body Problem, Heliocentric development by Lagrange multipliers, Perturbation Theory Formulation",http://arxiv.org/abs/2307.04810v1,"In this paper, we undertake to present a self-contained and thorough analysisof the gravitational three body problem, with anticipated application to theGreat Inequality of Jupiter and Saturn. The analysis of the three bodyLagrangian is very convenient in heliocentric coordinates with Lagrangemultipliers, the coordinates being the vector-sides $\vec{r}_i,\,i=1,2,3$ ofthe triangle that the bodies form. In two dimensions to begin with, theequations of motion are formulated into a dynamical system for the polar angles$\theta_i$, angular momenta $\ell_i$ and eccentricity vectors $\vec{e}_i$. Thedynamical system is simplified considerably by change of variables to certainauxiliary vector $\vec{f}_i=\hat{r}_i+\vec{e}_i$. We then begin to formulatethe Hamiltonian perturbation theory of the problem, now in three dimensions. Wefirst give the geometric definitions for the Delaunay action-angle variables ofthe two body problem. We express the three body Hamiltonian in terms ofDelaunay variables in each sector $i=1,2,3$, revealing that it is a nearlyintegrable Hamiltonian. We then present the KAM theory perturbative approachthat will be followed in future work, including the modification that will berequired because the Hamiltonian is degenerate.",Jonathan Tot,2023/7/10,2023/7/10
1911.12059v1,Estimating relationship between the Time Over Threshold and energy loss by photons in plastic scintillators used in the J-PET scanner,http://arxiv.org/abs/1911.12059v1,"Time-Over-Threshold (TOT) technique is being used widely due to itsimplications in developing the multi channel readouts mainly when fast signalprocessing is required. Using TOT technique as a measure of energy loss insteadof charge integration methods significantly reduces the signals readout cost bycombining the time and energy information. Therefore, this approach canpotentially be used in J-PET tomograph which is build from plasticscintillators characterized by fast light signals. The drawback in adoptingthis technique is lying in the non-linear correlation between input energy lossand TOT of the signal. The main motivation behind this work is to develop therelationship between TOT and energy loss and validate it with the J-PETtomograph.  The experiment was performed using the $^{22}$Na beta emitter source placedin the center of the J-PET tomograph. One can obtain primary photons of twodifferent energies: 511 keV photon from the annihilation of positron (directannihilation or through the formation of para-Positronim atom or pick-offprocess of ortho-Positronium atoms), and 1275 keV prompt photon. This allows tostudy the correlation between TOT values and energy loss for energy range up to1000 keV. As the photon interacts dominantly via Compton scattering inside theplastic scintillator, there is no direct information of primary photon energy.However, using the J-PET geometry one can measure the scattering angle of theinteracting photon. Since, $^{22}$Na source emits photons of two differentenergies, it is required to know unambiguously the energy of incident photonsand its corresponding scattering angle for the estimation of energy deposition.In this work, the relationship between Time Over Threshold and energy loss byinteracting photons inside the plastic scintillators used in J-PET scanner isestablished for a energy deposited range 100-1000 keV",S. Sharma,2019/11/27,2019/11/27
2201.09279v2,Improving Time and Position Resolution of RPC detectors using Time Over Threshold Information,http://arxiv.org/abs/2201.09279v2,"INO-ICAL is a proposed underground particle physics experiment to study theneutrino oscillation parameters by detecting neutrinos produced in theatmospheric air showers. Iron CALorimeter (ICAL) is to have 151 layers of ironstacked vertically, with active detector elements in between the iron layers.The iron layers will be magnetized to enable the measurement of momentum andcharge of the $\mu^-$ (or $\mu^+$) produced by $\nu_\mu$ (or $\bar{\nu}_\mu$)interactions. Resistive Plate Chambers (RPCs) have been chosen as the activedetector elements due to their large area coverage, uncompromised sensitivity,consistent performance for decades, as well as cost effectiveness. The majorfactors that decide the physics potential of the ICAL experiment areefficiency, position resolution and time resolution of the large area RPCs. Aprototype detector called miniICAL (with 11 iron layers) was commissioned tounderstand the engineering challenges in building the large scale magnet andits ancillary systems, and also to study the performance of the RPC detectorsand readout electronics developed by the INO collaboration. As part of theperformance study of the RPC detectors, an attempt is made to improve theposition and time resolution of them. Even a small improvement in the positionand time resolution will help to improve the measurements of momentum anddirectionality of the neutrinos in ICAL. The Time-over-Threshold (ToT) of theRPC pulses (signals) is recorded by the readout electronics. ToT is a measureof the pulse width and consequently the amplitude. This information is used toimprove the time and position resolution of the RPCs and consequently INOphysics potential.",Jim M John,2022/1/23,2023/11/15
2106.00174v2,Characterization of the CMS Endcap Timing Layer readout chip prototype with charge injection,http://arxiv.org/abs/2106.00174v2,"We present the characterization of a readout Application-Specific IntegratedCircuit (ASIC) for the CMS Endcap Timing Layer (ETL) of the High-Luminosity LHCupgrade with charge injection. The ASIC, named ETROC and developed in a 65 nmCMOS technology, reads out a 16x16 pixel matrix of the Low-Gain AvalancheDetector (LGAD). The jitter contribution from ETROC is required to be below 40ps to achieve the 50 ps overall time resolution per hit. The analog readoutcircuits in ETROC consist of the preamplifier and the discriminator. Thepreamplifier handles the LGAD charge signal with the most probable value ofaround 15 fC. The discriminator generates the digital pulse, which provides theTime-Of-Arrival (TOA, leading edge) and Time-Over-Threshold (TOT, pulse width)information. The prototype of ETROC (ETROC0) that implements a single channelof analog readout circuits has been evaluated with charge injection. The jitterof the analog readout circuits, measured from the discriminator's leading edge,is better than 16 ps for a charge larger than 15 fC with the sensorcapacitance. The time walk resulting from different pulse heights can becorrected using the TOT measurement. The time resolution distribution has astandard deviation of 29 ps after the time-walk correction from the chargeinjection. At room temperature, the preamplifier's power consumption ismeasured to be 0.74 mW and 1.53 mW per pixel in the low- and high-power mode,respectively. The measured power consumption of the discriminator is 0.84 mWper pixel. With the ASIC alone or the LGAD sensor, The characterizationperformances fulfill the ETL's challenging requirements.",H. Sun,2021/6/1,2021/9/2
2112.10636v1,Development of a single-photon imaging detector with pixelated anode and integrated digital read-out,http://arxiv.org/abs/2112.10636v1,"We present the development of a single-photon detector and the connectedread-out electronics. This `hybrid' detector is based on a vacuum tube,transmission photocathode, microchannel plate and a pixelated CMOS read-outanode encapsulating the analog and digital-front end electronics. This assemblywill be capable of detecting up to $10^9$ photons per second with simultaneousmeasurement of position and time.  The pixelated read-out anode used is based on the Timepix4 ASIC($65~\mathrm{nm}$ CMOS technology) designed in the framework of the Medipix4collaboration. This ASIC is an array of $512\times448$ pixels distributed on a$55~\mathrm{\mu m}$ square pitch, with a sensitive area of $\sim7~\mathrm{cm}^2$. It features $50$-$70~\mathrm{e^{-}}$ equivalent noise charge,a maximum rate of $2.5~\mathrm{Ghits/s}$, and allows to time-stamp theleading-edge time and to measure the Time-over-Threshold (ToT) for each pixel.The pixel-cluster position combined with its ToT information will allow toreach $5$-$10~\mathrm{\mu m}$ position resolution. This information can also beused to correct for the leading-edge time-walk achieving a timing resolution ofthe order of $10~\mathrm{ps}$.  The detector will be highly compact thanks to the encapsulated front-endelectronics allowing local data processing and digitization. An FPGA-based dataacquisition board, placed far from the detector, will receive the detector hitsusing $16$ electro-optical links operated at $10.24~\mathrm{Gbps}$. The dataacquisition board will decode the information and store the relevant data in aserver for offline analysis.  These performance will allow significant advances in particle physics, lifesciences, quantum optics or other emerging fields where the detection of singlephotons with excellent timing and position resolutions are simultaneouslyrequired.",J. A. Alozy,2021/12/20,2021/12/20
1311.4179v3,The Adams-Novikov spectral sequence and Voevodsky's slice tower,http://arxiv.org/abs/1311.4179v3,"We show that the spectral sequence converging to the stable homotopy groupsof spheres, induced by the Betti realization of the slice tower for the motivicsphere spectrum, agrees with the Adams-Novikov spectral sequence, after asuitable re-indexing. The proof relies on an extension of Deligne's d\'ecalageconstruction to the Tot-tower of a cosimplicial spectrum.",Marc Levine,2013/11/17,2015/10/3
1805.02833v1,A neural network based algorithm for MRPC time reconstruction,http://arxiv.org/abs/1805.02833v1,"Multi-gap Resistive Plate Chamber(MRPC) is a widely used timing detector witha typical time resolution of about 60 ps. This makes MRPC an optimal choice forthe time of flight(ToF) system in many large physics experiments. The priorwork on improving the time resolution is mainly focused on altering thedetector geometry, and therefore the improvement of the data analysis algorithmhas not been fully explored. This paper proposes a new time reconstructionalgorithm based on the deep neural networks(NN) and improves the MRPC timeresolution by about 10 ps. Since the development of the high energy physicsexperiments has pushed the timing requirements for the MRPC to a higher level,this algorithm could become a potential substitution of the time overthreshold(ToT) method to achieve a time resolution below 30 ps.",Fuyue Wang,2018/5/8,2018/5/8
1812.06176v1,Bootstrapping Conversational Agents With Weak Supervision,http://arxiv.org/abs/1812.06176v1,"Many conversational agents in the market today follow a standard botdevelopment framework which requires training intent classifiers to recognizeuser input. The need to create a proper set of training examples is often thebottleneck in the development process. In many occasions agent developers haveaccess to historical chat logs that can provide a good quantity as well ascoverage of training examples. However, the cost of labeling them with tens tohundreds of intents often prohibits taking full advantage of these chat logs.In this paper, we present a framework called \textit{search, label, andpropagate} (SLP) for bootstrapping intents from existing chat logs using weaksupervision. The framework reduces hours to days of labeling effort down tominutes of work by using a search engine to find examples, then relies on adata programming approach to automatically expand the labels. We report on auser study that shows positive user feedback for this new approach to buildconversational agents, and demonstrates the effectiveness of using dataprogramming for auto-labeling. While the system is developed for trainingconversational agents, the framework has broader application in significantlyreducing labeling effort for training text classifiers.",Neil Mallinar,2018/12/14,2018/12/14
2211.03015v1,Experience Report on the Challenges and Opportunities in Securing Smartphones Against Zero-Click Attacks,http://arxiv.org/abs/2211.03015v1,"Zero-click attacks require no user interaction and typically exploit zero-day(i.e., unpatched) vulnerabilities in instant chat applications (such asWhatsApp and iMessage) to gain root access to the victim's smartphone andexfiltrate sensitive data. In this paper, we report our experiences inattempting to secure smartphones against zero-click attacks. We approached theproblem by first enumerating several properties we believed were necessary toprevent zero-click attacks against smartphones. Then, we created a securitydesign that satisfies all the identified properties, and attempted to build itusing off-the-shelf components. Our key idea was to shift the attack surfacefrom the user's smartphone to a sandboxed virtual smartphone ecosystem whereeach chat application runs in isolation. Our performance and usabilityevaluations of the system we built highlighted several shortcomings and thefundamental challenges in securing modern smartphones against zero-clickattacks. In this experience report, we discuss the lessons we learned, andshare insights on the missing components necessary to achieve foolproofsecurity against zero-click attacks for modern mobile devices.",Narmeen Shafqat,2022/11/6,2022/11/6
2307.11769v1,Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain,http://arxiv.org/abs/2307.11769v1,"Engineering knowledge-based (or expert) systems require extensive manualeffort and domain knowledge. As Large Language Models (LLMs) are trained usingan enormous amount of cross-domain knowledge, it becomes possible to automatesuch engineering processes. This paper presents an empirical automation andsemi-automation framework for domain knowledge distillation using promptengineering and the LLM ChatGPT. We assess the framework empirically in theautonomous driving domain and present our key observations. In ourimplementation, we construct the domain knowledge ontology by ""chatting"" withChatGPT. The key finding is that while fully automated domain ontologyconstruction is possible, human supervision and early intervention typicallyimprove efficiency and output quality as they lessen the effects of responserandomness and the butterfly effect. We, therefore, also develop a web-baseddistillation assistant enabling supervision and flexible intervention atruntime. We hope our findings and tools could inspire future research towardrevolutionizing the engineering of knowledge-based systems across applicationdomains.",Yun Tang,2023/7/17,2023/7/17
2401.08772v1,HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance,http://arxiv.org/abs/2401.08772v1,"In this work, we present HuixiangDou, a technical assistant powered by LargeLanguage Models (LLM). This system is designed to assist algorithm developersby providing insightful responses to questions related to open-source algorithmprojects, such as computer vision and deep learning projects from OpenMMLab. Wefurther explore the integration of this assistant into the group chats ofinstant messaging (IM) tools such as WeChat and Lark. Through several iterativeimprovements and trials, we have developed a sophisticated technical chatassistant capable of effectively answering users' technical questions withoutcausing message flooding. This paper's contributions include: 1) Designing analgorithm pipeline specifically for group chat scenarios; 2) Verifying thereliable performance of text2vec in task rejection; 3) Identifying threecritical requirements for LLMs in technical-assistant-like products, namelyscoring ability, In-Context Learning (ICL), and Long Context. We have made thesoftware and source code available at https://github.com/internlm/huixiangdouto aid in future research and application. HuixiangDou is applicable to anygroup chat within IM tools.",Huanjun Kong,2024/1/16,2024/1/16
1811.07600v2,"A Trustworthy, Responsible and Interpretable System to Handle Chit Chat in Conversational Bots",http://arxiv.org/abs/1811.07600v2,"Most often, chat-bots are built to solve the purpose of a search engine or ahuman assistant: Their primary goal is to provide information to the user orhelp them complete a task. However, these chat-bots are incapable of respondingto unscripted queries like ""Hi, what's up"", ""What's your favourite food"". Humanevaluation judgments show that 4 humans come to a consensus on the intent of agiven query which is from chat domain only 77% of the time, thus making itevident how non-trivial this task is. In our work, we show why it is difficultto break the chitchat space into clearly defined intents. We propose a systemto handle this task in chat-bots, keeping in mind scalability,interpretability, appropriateness, trustworthiness, relevance and coverage. Ourwork introduces a pipeline for query understanding in chitchat usinghierarchical intents as well as a way to use seq-seq auto-generation models inprofessional bots. We explore an interpretable model for chat domain detectionand also show how various components such as adult/offensive classification,grammars/regex patterns, curated personality based responses, generic guidedevasive responses and response generation models can be combined in a scalableway to solve this problem.",Parag Agrawal,2018/11/19,2018/11/23
0903.1511v1,MIMO Based Multimedia Communication System,http://arxiv.org/abs/0903.1511v1,"High data rate is required for multimedia communication. But thecommunication at high data rate is always challenging. In this work we havesuccessfully performed data chatting, Voice chatting and high quality videotransmission between two distant units using MIMO adapter, Direct sequencespread spectrum system and MATLAB/SIMULINK platform.",D. Kandar,2009/3/9,2009/3/9
2312.09731v1,Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs,http://arxiv.org/abs/2312.09731v1,"Understanding and identifying the causes behind developers' emotions (e.g.,Frustration caused by `delays in merging pull requests') can be crucial towardsfinding solutions to problems and fostering collaboration in open-sourcecommunities. Effectively identifying such information in the high volume ofcommunications across the different project channels, such as chats, emails,and issue comments, requires automated recognition of emotions and theircauses. To enable this automation, large-scale software engineering-specificdatasets that can be used to train accurate machine learning models arerequired. However, such datasets are expensive to create with the variety andinformal nature of software projects' communication channels.  In this paper, we explore zero-shot LLMs that are pre-trained on massivedatasets but without being fine-tuned specifically for the task of detectingemotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Ourevaluation indicates that these recently available models can identify emotioncategories when given detailed emotions, although they perform worse than thetop-rated models. For emotion cause identification, our results indicate thatzero-shot LLMs are effective at recognizing the correct emotion cause with aBLEU-2 score of 0.598. To highlight the potential use of these techniques, weconduct a case study of the causes of Frustration in the last year ofdevelopment of a popular open-source project, revealing several interestinginsights.",Mia Mohammad Imran,2023/12/15,2023/12/15
2008.10074v1,"Your instruction may be crisp, but not clear to me!",http://arxiv.org/abs/2008.10074v1,"The number of robots deployed in our daily surroundings is ever-increasing.Even in the industrial set-up, the use of coworker robots is increasingrapidly. These cohabitant robots perform various tasks as instructed byco-located human beings. Thus, a natural interaction mechanism plays a big rolein the usability and acceptability of the robot, especially by a non-expertuser. The recent development in natural language processing (NLP) has paved theway for chatbots to generate an automatic response for users' query. A robotcan be equipped with such a dialogue system. However, the goal of human-robotinteraction is not focused on generating a response to queries, but it ofteninvolves performing some tasks in the physical world. Thus, a system isrequired that can detect user intended task from the natural instruction alongwith the set of pre- and post-conditions. In this work, we develop a dialogueengine for a robot that can classify and map a task instruction to the robot'scapability. If there is some ambiguity in the instructions or some requiredinformation is missing, which is often the case in natural conversation, itasks an appropriate question(s) to resolve it. The goal is to generate minimaland pin-pointed queries for the user to resolve an ambiguity. We evaluate oursystem for a telepresence scenario where a remote user instructs the robot forvarious tasks. Our study based on 12 individuals shows that the proposeddialogue strategy can help a novice user to effectively interact with a robot,leading to satisfactory user experience.",Pradip Pramanick,2020/8/23,2020/8/23
2306.14565v3,Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning,http://arxiv.org/abs/2306.14565v3,"Despite the promising progress in multi-modal tasks, current largemulti-modal models (LMMs) are prone to hallucinating inconsistent descriptionswith respect to the associated image and human instructions. This paperaddresses this issue by introducing the first large and diverse visualinstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.Our dataset comprises 400k visual instructions generated by GPT4, covering 16vision-and-language tasks with open-ended instructions and answers. Unlikeexisting studies that primarily focus on positive instruction samples, wedesign LRV-Instruction to include both positive and negative instructions formore robust visual instruction tuning. Our negative instructions are designedat three semantic levels: (i) Nonexistent Object Manipulation, (ii) ExistentObject Manipulation and (iii) Knowledge Manipulation. To efficiently measurethe hallucination generated by LMMs, we propose GPT4-Assisted VisualInstruction Evaluation (GAVIE), a stable approach to evaluate visualinstruction tuning like human experts. GAVIE does not require human-annotatedgroundtruth answers and can adapt to diverse instruction formats. We conductcomprehensive experiments to investigate the hallucination of LMMs. Our resultsdemonstrate existing LMMs exhibit significant hallucinations when presentedwith our negative instructions, particularly Existent Object and KnowledgeManipulation instructions. Moreover, we successfully mitigate hallucination byfinetuning MiniGPT4 and mPLUG-Owl on LRV-Instruction while improvingperformance on several public datasets compared to state-of-the-art methods.Additionally, we observed that a balanced ratio of positive and negativeinstances in the training data leads to a more robust model.",Fuxiao Liu,2023/6/26,2023/9/29
2310.02003v2,L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation,http://arxiv.org/abs/2310.02003v2,"Transformer-based large language models (LLMs) are constrained by the fixedcontext window of the underlying transformer architecture, hindering theirability to produce long and logically consistent code. Memory-augmented LLMsare a promising solution, but current approaches cannot handle long codegeneration tasks since they (1) only focus on reading memory and reduce itsevolution to the concatenation of new memories or (2) use very specializedmemories that cannot adapt to other domains. This paper presents L2MAC, thefirst practical LLM-based stored-program automatic computer for long andconsistent code generation. Its memory has two components: the instructionregistry, which is populated with a prompt program to solve the user-giventask, and a file store, which will contain the final and intermediate outputs.Each instruction is executed by a separate LLM instance, whose context ismanaged by a control unit capable of precise memory reading and writing toensure effective interaction with the file store. These components enable L2MACto generate virtually unbounded code structures, bypassing the constraints ofthe finite context window while producing code that fulfills complexuser-specified requirements. We empirically show that L2MAC succeeds ingenerating large code bases for system design tasks where other coding methodsfall short in implementing user requirements and provide insight into thereasons for this performance gap.",Samuel Holt,2023/10/2,2023/12/11
2204.07167v2,Towards Porting Operating Systems with Program Synthesis,http://arxiv.org/abs/2204.07167v2,"The end of Moore's Law has ushered in a diversity of hardware not seen indecades. Operating system (and system software) portability is accordinglybecoming increasingly critical. Simultaneously, there has been tremendousprogress in program synthesis. We set out to explore the feasibility of usingmodern program synthesis to generate the machine-dependent parts of anoperating system. Our ultimate goal is to generate new ports automatically fromdescriptions of new machines. One of the issues involved is writingspecifications, both for machine-dependent operating system functionality andfor instruction set architectures. We designed two domain-specific languages:Alewife for machine-independent specifications of machine-dependent operatingsystem functionality and Cassiopea for describing instruction set architecturesemantics. Automated porting also requires an implementation. We developed atoolchain that, given an Alewife specification and a Cassiopea machinedescription, specializes the machine-independent specification to the targetinstruction set architecture and synthesizes an implementation in assemblylanguage with a customized symbolic execution engine. Using this approach, wedemonstrate successful synthesis of a total of 140 OS components from twopre-existing OSes for four real hardware platforms. We also developed severaloptimization methods for OS-related assembly synthesis to improve scalability.The effectiveness of our languages and ability to synthesize code for all 140specifications is evidence of the feasibility of program synthesis formachine-dependent OS code. However, many research challenges remain; we alsodiscuss the benefits and limitations of our synthesis-based approach toautomated OS porting.",Jingmei Hu,2022/4/15,2022/9/22
1809.06194v2,The Fast and the Flexible: training neural networks to learn to follow instructions from small data,http://arxiv.org/abs/1809.06194v2,"Learning to follow human instructions is a long-pursued goal in artificialintelligence. The task becomes particularly challenging if no prior knowledgeof the employed language is assumed while relying only on a handful of examplesto learn from. Work in the past has relied on hand-coded components or manuallyengineered features to provide strong inductive biases that make learning insuch situations possible. In contrast, here we seek to establish whether thisknowledge can be acquired automatically by a neural network system through atwo phase training procedure: A (slow) offline learning stage where the networklearns about the general structure of the task and a (fast) online adaptationphase where the network learns the language of a new given speaker. Controlledexperiments show that when the network is exposed to familiar instructions butcontaining novel words, the model adapts very efficiently to the newvocabulary. Moreover, even for human speakers whose language usage can departsignificantly from our artificial training language, our network can still makeuse of its automatically acquired inductive bias to learn to followinstructions more effectively.",Rezka Leonandya,2018/9/17,2019/4/2
2306.02739v2,Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations,http://arxiv.org/abs/2306.02739v2,"Aging societies, labor shortages and increasing wage costs call forassistance robots capable of autonomously performing a wide array of real-worldtasks. Such open-ended robotic manipulation requires not only powerfulknowledge representations and reasoning (KR&R) algorithms, but also methods forhumans to instruct robots what tasks to perform and how to perform them. Inthis paper, we present a system for automatically generating executable robotcontrol programs from human task demonstrations in virtual reality (VR). Weleverage common-sense knowledge and game engine-based physics to semanticallyinterpret human VR demonstrations, as well as an expressive and general taskrepresentation and automatic path planning and code generation, embedded into astate-of-the-art cognitive architecture. We demonstrate our approach in thecontext of force-sensitive fetch-and-place for a robotic shopping assistant.The source code is available athttps://github.com/ease-crc/vr-program-synthesis.",Benjamin Alt,2023/6/5,2023/7/3
2309.05447v1,TeGit: Generating High-Quality Instruction-Tuning Data with Text-Grounded Task Design,http://arxiv.org/abs/2309.05447v1,"High-quality instruction-tuning data is critical to improving LLMcapabilities. Existing data collection methods are limited by unrealisticmanual labeling costs or by the hallucination of relying solely on LLMgeneration. To address the problems, this paper presents a scalable method toautomatically collect high-quality instructional adaptation data by traininglanguage models to automatically design tasks based on human-written texts.Intuitively, human-written text helps to help the model attenuate illusionsduring the generation of tasks. Unlike instruction back-translation-basedmethods that directly take the given text as a response, we require the modelto generate the \textit{instruction}, \textit{input}, and \textit{output}simultaneously to filter the noise. The results of the automated and manualevaluation experiments demonstrate the quality of our dataset.",Yongrui Chen,2023/9/11,2023/9/11
2101.08458v3,UNIT: Unifying Tensorized Instruction Compilation,http://arxiv.org/abs/2101.08458v3,"Because of the increasing demand for computation in DNN, researchers developeboth hardware and software mechanisms to reduce the compute and memory burden.A widely adopted approach is to use mixed precision data types. However, it ishard to leverage mixed precision without hardware support because of theoverhead of data casting. Hardware vendors offer tensorized instructions formixed-precision tensor operations, like Intel VNNI, Tensor Core, and ARM-DOT.These instructions involve a computing idiom that reduces multiple lowprecision elements into one high precision element. The lack of compilationtechniques for this makes it hard to utilize these instructions: Usingvendor-provided libraries for computationally-intensive kernels is inflexibleand prevents further optimizations, and manually writing hardware intrinsics iserror-prone and difficult for programmers. Some prior works address thisproblem by creating compilers for each instruction. This requires excessiveeffort when it comes to many tensorized instructions. In this work, we developa compiler framework to unify the compilation for these instructions -- aunified semantics abstraction eases the integration of new instructions, andreuses the analysis and transformations. Tensorized instructions from differentplatforms can be compiled via UNIT with moderate effort for favorableperformance. Given a tensorized instruction and a tensor operation, UNITautomatically detects the applicability, transforms the loop organization ofthe operation,and rewrites the loop body to leverage the tensorizedinstruction. According to our evaluation, UNIT can target various mainstreamhardware platforms. The generated end-to-end inference model achieves 1.3xspeedup over Intel oneDNN on an x86 CPU, 1.75x speedup over Nvidia cuDNN on anNvidiaGPU, and 1.13x speedup over a carefully tuned TVM solution for ARM DOT onan ARM CPU.",Jian Weng,2021/1/21,2021/3/28
2309.10447v2,Toward Unified Controllable Text Generation via Regular Expression Instruction,http://arxiv.org/abs/2309.10447v2,"Controllable text generation is a fundamental aspect of natural languagegeneration, with numerous methods proposed for different constraint types.However, these approaches often require significant architectural or decodingmodifications, making them challenging to apply to additional constraints orresolve different constraint combinations. To address this, our paperintroduces Regular Expression Instruction (REI), which utilizes aninstruction-based mechanism to fully exploit regular expressions' advantages touniformly model diverse constraints. Specifically, our REI supports all popularfine-grained controllable generation constraints, i.e., lexical, positional,and length, as well as their complex combinations, via regular expression-styleinstructions. Our method only requires fine-tuning on medium-scale languagemodels or few-shot, in-context learning on large language models, and requiresno further adjustment when applied to various constraint combinations.Experiments demonstrate that our straightforward approach yields high successrates and adaptability to various constraints while maintaining competitivenessin automatic metrics and outperforming most previous baselines.",Xin Zheng,2023/9/19,2023/9/20
1904.12371v1,Counterexample-Driven Synthesis for Probabilistic Program Sketches,http://arxiv.org/abs/1904.12371v1,"Probabilistic programs are key to deal with uncertainty in e.g. controllersynthesis. They are typically small but intricate. Their development is complexand error prone requiring quantitative reasoning over a myriad of alternativedesigns. To mitigate this complexity, we adopt counterexample-guided inductivesynthesis (CEGIS) to automatically synthesise finite-state probabilisticprograms. Our approach leverages efficient model checking, modern SMT solving,and counterexample generation at program level. Experiments on practicallyrelevant case studies show that design spaces with millions of candidatedesigns can be fully explored using a few thousand verification queries.",Milan eka,2019/4/28,2019/4/28
2202.13040v1,Iterative Genetic Improvement: Scaling Stochastic Program Synthesis,http://arxiv.org/abs/2202.13040v1,"Program synthesis aims to {\it automatically} find programs from anunderlying programming language that satisfy a given specification. While thishas the potential to revolutionize computing, how to search over the vast spaceof programs efficiently is an unsolved challenge in program synthesis. In caseswhere large programs are required for a solution, it is generally believed that{\it stochastic} search has advantages over other classes of search techniques.Unfortunately, existing stochastic program synthesizers do not meet thisexpectation very well, suffering from the scalability issue. Here we propose anew framework for stochastic program synthesis, called iterative geneticimprovement to overcome this problem, a technique inspired by the practice ofthe software development process. The key idea of iterative genetic improvementis to apply genetic improvement to improve a current reference program, andthen iteratively replace the reference program by the best program found.Compared to traditional stochastic synthesis approaches, iterative geneticimprovement can build up the complexity of programs incrementally in a morerobust way. We evaluate the approach on two program synthesis domains: listmanipulation and string transformation. Our empirical results indicate thatthis method has considerable advantages over several representative stochasticprogram synthesizer techniques, both in terms of scalability and of solutionquality.",Yuan Yuan,2022/2/26,2022/2/26
2401.09042v1,LLMs for Relational Reasoning: How Far are We?,http://arxiv.org/abs/2401.09042v1,"Large language models (LLMs) have revolutionized many areas (e.g. naturallanguage processing, software engineering, etc.) by achieving state-of-the-artperformance on extensive downstream tasks. Aiming to achieve robust and generalartificial intelligence, there has been a surge of interest in investigatingthe reasoning ability of the LLMs. Whereas the textual and numerical reasoningbenchmarks adopted by previous works are rather shallow and simple, it is hardto conclude that the LLMs possess strong reasoning ability by merely achievingpositive results on these benchmarks. Recent efforts have demonstrated that theLLMs are poor at solving sequential decision-making problems that requirecommon-sense planning by evaluating their performance on the reinforcementlearning benchmarks. In this work, we conduct an in-depth assessment of severalstate-of-the-art LLMs' reasoning ability based on the inductive logicprogramming (ILP) benchmark, which is broadly recognized as a representativeand challenging measurement for evaluating logic program induction/synthesissystems as it requires inducing strict cause-effect logic to achieve robustdeduction on independent and identically distributed (IID) andout-of-distribution (OOD) test samples. Our evaluations illustrate thatcompared with the neural program induction systems which are much smaller inmodel size, the state-of-the-art LLMs are much poorer in terms of reasoningability by achieving much lower performance and generalization using eithernatural language prompting or truth-value matrix prompting.",Zhiming Li,2024/1/17,2024/1/17
2307.09036v2,PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation,http://arxiv.org/abs/2307.09036v2,"Generative text-to-image models have gained great popularity among the publicfor their powerful capability to generate high-quality images based on naturallanguage prompts. However, developing effective prompts for desired images canbe challenging due to the complexity and ambiguity of natural language. Thisresearch proposes PromptMagician, a visual analysis system that helps usersexplore the image results and refine the input prompts. The backbone of oursystem is a prompt recommendation model that takes user prompts as input,retrieves similar prompt-image pairs from DiffusionDB, and identifies special(important and relevant) prompt keywords. To facilitate interactive promptrefinement, PromptMagician introduces a multi-level visualization for thecross-modal embedding of the retrieved images and recommended keywords, andsupports users in specifying multiple criteria for personalized exploration.Two usage scenarios, a user study, and expert interviews demonstrate theeffectiveness and usability of our system, suggesting it facilitates promptengineering and improves the creativity support of the generative text-to-imagemodel.",Yingchaojie Feng,2023/7/18,2023/8/15
2308.07610v1,LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis,http://arxiv.org/abs/2308.07610v1,"Automated log analysis is crucial in modern software-intensive systems forensuring reliability and resilience throughout software maintenance andengineering life cycles. Existing methods perform tasks such as log parsing andlog anomaly detection by providing a single prediction value withoutinterpretation. However, given the increasing volume of system events, thelimited interpretability of analysis results hinders analysts' trust and theirability to take appropriate actions. Moreover, these methods requiresubstantial in-domain training data, and their performance declines sharply (byup to 62.5%) in online scenarios involving unseen logs from new domains, acommon occurrence due to rapid software updates. In this paper, we proposeLogPrompt, a novel zero-shot and interpretable log analysis approach. LogPromptemploys large language models (LLMs) to perform zero-shot log analysis tasksvia a suite of advanced prompt strategies tailored for log tasks, whichenhances LLMs' performance by up to 107.5% compared with simple prompts.Experiments on nine publicly available evaluation datasets across two tasksdemonstrate that LogPrompt, despite using no training data, outperformsexisting approaches trained on thousands of logs by up to around 50%. We alsoconduct a human evaluation of LogPrompt's interpretability, with sixpractitioners possessing over 10 years of experience, who highly rated thegenerated content in terms of usefulness and readability (averagely 4.42/5).LogPrompt also exhibits remarkable compatibility with open-source andsmaller-scale LLMs, making it flexible for practical deployment.",Yilun Liu,2023/8/15,2023/8/15
2305.14493v3,Do prompt positions really matter?,http://arxiv.org/abs/2305.14493v3,"Prompt-based models have gathered a lot of attention from researchers due totheir remarkable advancements in the fields of zero-shot and few-shot learning.Developing an effective prompt template plays a critical role. However, priorstudies have mainly focused on prompt vocabulary selection or embeddinginitialization within a predefined template with the prompt position fixed. Inthis empirical study, we conduct the most comprehensive analysis to date ofprompt position for diverse natural language process tasks. Our findingsquantify the substantial impact prompt position has on model performance. Weobserve that the prompt position used in prior studies is often sub-optimal.These findings suggest prompt position optimisation as a valuable researchdirection to fill the gap in existing prompt engineering methodologies.",Junyu Mao,2023/5/23,2023/11/15
2305.09648v1,Prompt-Tuning Decision Transformer with Preference Ranking,http://arxiv.org/abs/2305.09648v1,"Prompt-tuning has emerged as a promising method for adapting pre-trainedmodels to downstream tasks or aligning with human preferences. Prompt learningis widely used in NLP but has limited applicability to RL due to the complexphysical meaning and environment-specific information contained within RLprompts. These factors require supervised learning to imitate thedemonstrations and may result in a loss of meaning after learning.Additionally, directly extending prompt-tuning approaches to RL is challengingbecause RL prompts guide agent behavior based on environmental modeling andanalysis, rather than filling in missing information, making it unlikely thatadjustments to the prompt format for downstream tasks, as in NLP, can yieldsignificant improvements. In this work, we propose the Prompt-Tuning DTalgorithm to address these challenges by using trajectory segments as promptsto guide RL agents in acquiring environmental information and optimizingprompts via black-box tuning to enhance their ability to contain more relevantinformation, thereby enabling agents to make better decisions. Our approachinvolves randomly sampling a Gaussian distribution to fine-tune the elements ofthe prompt trajectory and using preference ranking function to find theoptimization direction, thereby providing more informative prompts and guidingthe agent towards specific preferences in the target environment. Extensiveexperiments show that with only 0.03% of the parameters learned, Prompt-TuningDT achieves comparable or even better performance than full-model fine-tuningin low-data scenarios. Our work contributes to the advancement of prompt-tuningapproaches in RL, providing a promising direction for optimizing large RLagents for specific preference tasks.",Shengchao Hu,2023/5/16,2023/5/16
2305.14877v1,Improving Probability-based Prompt Selection Through Unified Evaluation and Analysis,http://arxiv.org/abs/2305.14877v1,"Large Language Models (LLMs) have demonstrated great capabilities in solvinga wide range of tasks in a resource-efficient manner through prompting, whichdoes not require task-specific training, but suffers from performancefluctuation when there are multiple prompt candidates. Previous works haveintroduced gradient-free probability-based prompt selection methods that aim tochoose the optimal prompt among the candidates for a given task but fail toprovide a comprehensive and fair comparison between each other. In this paper,we propose a unified framework to interpret and evaluate the existingprobability-based prompt selection methods by performing extensive experimentson 13 common NLP tasks. We find that all existing methods can be unified intosome variant of the method that maximizes the mutual information between theinput and the corresponding model output (denoted as MI). Using the finding, wedevelop several variants of MI and increases the effectiveness of the bestprompt selection method from 87.79% to 94.98%, measured as the ratio of theperformance of the selected prompt to that of the optimal oracle prompt.Furthermore, we propose a novel calibration method called Calibration byMarginalization (CBM) that is orthogonal to existing methods and helps increasethe prompt selection effectiveness of the best method by 99.44%. The code anddatasets used in our work will be released athttps://github.com/soheeyang/unified-prompt-selection.",Sohee Yang,2023/5/24,2023/5/24
2306.01312v2,Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis,http://arxiv.org/abs/2306.01312v2,"Multimodal Sentiment Analysis (MSA) has been a popular topic in naturallanguage processing nowadays, at both sentence and aspect level. However, theexisting approaches almost require large-size labeled datasets, which bringabout large consumption of time and resources. Therefore, it is practical toexplore the method for few-shot sentiment analysis in cross-modalities.Previous works generally execute on textual modality, using the prompt-basedmethods, mainly two types: hand-crafted prompts and learnable prompts. Theexisting approach in few-shot multi-modality sentiment analysis task hasutilized both methods, separately. We further design a hybrid pattern that cancombine one or more fixed hand-crafted prompts and learnable prompts andutilize the attention mechanisms to optimize the prompt encoder. Theexperiments on both sentence-level and aspect-level datasets prove that we geta significant outperformance.",Zikai Zhou,2023/6/2,2023/7/31
2109.07830v3,Reframing Instructional Prompts to GPTk's Language,http://arxiv.org/abs/2109.07830v3,"What kinds of instructional prompts are easier to follow for Language Models(LMs)? We study this question by conducting extensive empirical analysis thatshed light on important features of successful instructional prompts.Specifically, we study several classes of reframing techniques for manualreformulation of prompts into more effective ones. Some examples includedecomposing a complex task instruction into multiple simpler tasks or itemizinginstructions into sequential steps. Our experiments compare the zero-shot andfew-shot performance of LMs prompted with reframed instructions on 12 NLP tasksacross 6 categories. Compared with original instructions, our reframedinstructions lead to significant improvements across LMs with different sizes.For example, the same reframed prompts boost few-shot performance ofGPT3-series and GPT2-series by 12.5% and 6.7% respectively averaged over alltasks. Furthermore, reframed instructions reduce the number of examplesrequired to prompt LMs in the few-shot setting. We hope theseempirically-driven techniques will pave the way towards more effective futureprompting algorithms.",Swaroop Mishra,2021/9/16,2022/3/15
2203.15754v1,Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting,http://arxiv.org/abs/2203.15754v1,"Large language models have shown that impressive zero-shot performance can beachieved through natural language prompts (Radford et al., 2019; Brown et al.,2020; Sanh et al., 2021). Creating an effective prompt, however, requiressignificant trial and error. That \textit{prompts} the question: how do thequalities of a prompt effects its performance? To this end, we collect andstandardize prompts from a diverse range of tasks for use with tasks they werenot designed for. We then evaluate these prompts across fixed multiple choicedatasets for a quantitative analysis of how certain attributes of a promptaffect performance. We find that including the choices and using prompts notused during pre-training provide significant improvements. All experiments andcode can be found https://github.com/gabeorlanski/zero-shot-cross-task.",Gabriel Orlanski,2022/3/29,2022/3/29
2305.13954v2,Robust Prompt Optimization for Large Language Models Against Distribution Shifts,http://arxiv.org/abs/2305.13954v2,"Large Language Model (LLM) has demonstrated significant ability in variousNatural Language Processing tasks. However, their effectiveness is highlydependent on the phrasing of the task prompt, leading to research on automaticprompt optimization using labeled task data. We reveal that these promptoptimization techniques are vulnerable to distribution shifts such assubpopulation shifts, which are common for LLMs in real-world scenarios such ascustomer reviews analysis. In this light, we propose a new problem of robustprompt optimization for LLMs against distribution shifts, which requires theprompt optimized over the labeled source group can simultaneously generalize toan unlabeled target group. To solve this problem, we propose Generalized PromptOptimization framework, which incorporates the unlabeled data from the targetgroup into prompt optimization. Extensive experimental results demonstrate theeffectiveness of the proposed framework with significant performanceimprovement on the target group and comparable performance on the source group.",Moxin Li,2023/5/23,2023/10/16
2307.11031v1,Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification,http://arxiv.org/abs/2307.11031v1,"Recent work has shown that language models' (LMs) prompt-based learningcapabilities make them well suited for automating data labeling in domainswhere manual annotation is expensive. The challenge is that while writing aninitial prompt is cheap, improving a prompt is costly -- practitioners oftenrequire significant labeled data in order to evaluate the impact of promptmodifications. Our work asks whether it is possible to improve prompt-basedlearning without additional labeled data. We approach this problem byattempting to modify the predictions of a prompt, rather than the promptitself. Our intuition is that accurate predictions should also be consistent:samples which are similar under some feature representation should receive thesame prompt prediction. We propose Embroid, a method which computes multiplerepresentations of a dataset under different embedding functions, and uses theconsistency between the LM predictions for neighboring samples to identifymispredictions. Embroid then uses these neighborhoods to create additionalpredictions for each sample, and combines these predictions with a simplelatent variable graphical model in order to generate a final correctedprediction. In addition to providing a theoretical analysis of Embroid, weconduct a rigorous empirical evaluation across six different LMs and up to 95different tasks. We find that (1) Embroid substantially improves performanceover original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) alsorealizes improvements for more sophisticated prompting strategies (e.g.,chain-of-thought), and (3) can be specialized to domains like law through theembedding functions.",Neel Guha,2023/7/20,2023/7/20
2311.08268v1,A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,http://arxiv.org/abs/2311.08268v1,"Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed toprovide useful and safe responses. However, adversarial prompts known as'jailbreaks' can circumvent safeguards, leading LLMs to generate harmfulcontent. Exploring jailbreak prompts can help to better reveal the weaknessesof LLMs and further steer us to secure them. Unfortunately, existing jailbreakmethods either suffer from intricate manual design or require optimization onanother white-box model, compromising generalization or jailbreak efficiency.In this paper, we generalize jailbreak prompt attacks into two aspects: (1)Prompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM,an automatic framework that leverages LLMs themselves to generate effectivejailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantlyimproves the attack success rate while greatly reducing the time cost comparedto existing baselines. Our study also reveals the inadequacy of current defensemethods in safeguarding LLMs. Finally, we offer detailed analysis anddiscussion from the perspective of prompt execution priority on the failure ofLLMs' defense. We hope that our research can catalyze both the academiccommunity and LLMs vendors towards the provision of safer and more regulatedLarge Language Models.",Peng Ding,2023/11/14,2023/11/14
2305.18787v2,Universality and Limitations of Prompt Tuning,http://arxiv.org/abs/2305.18787v2,"Despite the demonstrated empirical efficacy of prompt tuning to adapt apretrained language model for a new task, the theoretical underpinnings of thedifference between ""tuning parameters before the input"" against ""the tuning ofmodel weights"" are limited. We thus take one of the first steps to understandthe role of soft-prompt tuning for transformer-based architectures. Byconsidering a general purpose architecture, we analyze prompt tuning from thelens of both: universal approximation and limitations with finite-depthfixed-weight pretrained transformers for continuous-valued functions. Ouruniversality result guarantees the existence of a strong transformer with aprompt to approximate any sequence-to-sequence function in the set of Lipschitzfunctions. The limitations of prompt tuning for limited-depth transformers arefirst proved by constructing a set of datasets, that cannot be memorized by aprompt of any length for a given single encoder layer. We also provide a lowerbound on the required number of tunable prompt parameters and compare theresult with the number of parameters required for a low-rank update (based onLoRA) for a single-layer setting. We finally extend our analysis to multi-layersettings by providing sufficient conditions under which the transformer can atbest learn datasets from invertible functions only. Our theoretical claims arealso corroborated by empirical results.",Yihan Wang,2023/5/30,2023/11/16
2305.14569v1,Few-shot Unified Question Answering: Tuning Models or Prompts?,http://arxiv.org/abs/2305.14569v1,"Question-answering (QA) tasks often investigate specific question types,knowledge domains, or reasoning skills, leading to specialized models cateringto specific categories of QA tasks. While recent research has explored the ideaof unified QA models, such models are usually explored for high-resourcescenarios and require re-training to extend their capabilities. To overcomethese drawbacks, the paper explores the potential of two paradigms of tuning,model, and prompts, for unified QA under a low-resource setting. The paperprovides an exhaustive analysis of their applicability using 16 QA datasets,revealing that prompt tuning can perform as well as model tuning in a few-shotsetting with a good initialization. The study also shows that parameter-sharingresults in superior few-shot performance, simple knowledge transfer techniquesfor prompt initialization can be effective, and prompt tuning achieves asignificant performance boost from pre-training in a low-resource regime. Theresearch offers insights into the advantages and limitations of prompt tuningfor unified QA in a few-shot setting, contributing to the development ofeffective and efficient systems in low-resource scenarios.",Srijan Bansal,2023/5/23,2023/5/23
2204.08167v1,A Study on Prompt-based Few-Shot Learning Methods for Belief State Tracking in Task-oriented Dialog Systems,http://arxiv.org/abs/2204.08167v1,"We tackle the Dialogue Belief State Tracking(DST) problem of task-orientedconversational systems. Recent approaches to this problem leveragingTransformer-based models have yielded great results. However, training thesemodels is expensive, both in terms of computational resources and time.Additionally, collecting high quality annotated dialogue datasets remains achallenge for researchers because of the extensive annotation required fortraining these models. Driven by the recent success of pre-trained languagemodels and prompt-based learning, we explore prompt-based few-shot learning forDialogue Belief State Tracking. We formulate the DST problem as a 2-stageprompt-based language modelling task and train language models for both tasksand present a comprehensive empirical analysis of their separate and jointperformance. We demonstrate the potential of prompt-based methods in few-shotlearning for DST and provide directions for future improvement.",Debjoy Saha,2022/4/18,2022/4/18
2311.12131v1,Human Learning by Model Feedback: The Dynamics of Iterative Prompting with Midjourney,http://arxiv.org/abs/2311.12131v1,"Generating images with a Text-to-Image model often requires multiple trials,where human users iteratively update their prompt based on feedback, namely theoutput image. Taking inspiration from cognitive work on reference games anddialogue alignment, this paper analyzes the dynamics of the user prompts alongsuch iterations. We compile a dataset of iterative interactions of human userswith Midjourney. Our analysis then reveals that prompts predictably convergetoward specific traits along these iterations. We further study whether thisconvergence is due to human users, realizing they missed important details, ordue to adaptation to the model's ``preferences'', producing better images for aspecific language style. We show initial evidence that both possibilities areat play. The possibility that users adapt to the model's preference raisesconcerns about reusing user data for further training. The prompts may bebiased towards the preferences of a specific model, rather than align withhuman intentions and natural manner of expression.",Shachar Don-Yehiya,2023/11/20,2023/11/20
2309.02045v2,Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies,http://arxiv.org/abs/2309.02045v2,"Large Language Models (LLMs) have made significant strides in both scientificresearch and practical applications. Existing studies have demonstrated thestate-of-the-art (SOTA) performance of LLMs in various natural languageprocessing tasks. However, the question of how to further enhance LLMs'performance in specific task using prompting strategies remains a pivotalconcern. This paper explores the enhancement of LLMs' performance in sentimentanalysis through the application of prompting strategies. We formulate theprocess of prompting for sentiment analysis tasks and introduce two novelstrategies tailored for sentiment analysis: RolePlaying (RP) prompting andChain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoTprompting strategy which is a combination of RP prompting and CoT prompting. Weconduct comparative experiments on three distinct domain datasets to evaluatethe effectiveness of the proposed sentiment analysis strategies. The resultsdemonstrate that the adoption of the proposed prompting strategies leads to aincreasing enhancement in sentiment analysis accuracy. Further, the CoTprompting strategy exhibits a notable impact on implicit sentiment analysis,with the RP-CoT prompting strategy delivering the most superior performanceamong all strategies.",Yajing Wang,2023/9/5,2024/1/7
2211.13515v1,TSGP: Two-Stage Generative Prompting for Unsupervised Commonsense Question Answering,http://arxiv.org/abs/2211.13515v1,"Unsupervised commonsense question answering requires mining effectivecommonsense knowledge without the rely on the labeled task data. Previousmethods typically retrieved from traditional knowledge bases or usedpre-trained language models (PrLMs) to generate fixed types of knowledge, whichhave poor generalization ability. In this paper, we aim to address the abovelimitation by leveraging the implicit knowledge stored in PrLMs and propose atwo-stage prompt-based unsupervised commonsense question answering framework(TSGP). Specifically, we first use knowledge generation prompts to generate theknowledge required for questions with unlimited types and possible candidateanswers independent of specified choices. Then, we further utilize answergeneration prompts to generate possible candidate answers independent ofspecified choices. Experimental results and analysis on three differentcommonsense reasoning tasks, CommonsenseQA, OpenBookQA, and SocialIQA,demonstrate that TSGP significantly improves the reasoning ability of languagemodels in unsupervised settings. Our code is available at:https://github.com/Yueqing-Sun/TSGP.",Yueqing Sun,2022/11/24,2022/11/24
2311.14722v1,Zero-Shot Question Answering over Financial Documents using Large Language Models,http://arxiv.org/abs/2311.14722v1,"We introduce a large language model (LLM) based approach to answer complexquestions requiring multi-hop numerical reasoning over financial reports. WhileLLMs have exhibited remarkable performance on various natural language andreasoning tasks, complex reasoning problems often rely on few-shot prompts thatrequire carefully crafted examples. In contrast, our approach uses novelzero-shot prompts that guide the LLM to encode the required reasoning into aPython program or a domain specific language. The generated program is thenexecuted by a program interpreter, thus mitigating the limitations of LLM inperforming accurate arithmetic calculations.  We evaluate the proposed approach on three financial datasets using some ofthe recently developed generative pretrained transformer (GPT) models andperform comparisons with various zero-shot baselines. The experimental resultsdemonstrate that our approach significantly improves the accuracy for all theLLMs over their respective baselines. We provide a detailed analysis of theresults, generating insights to support our findings. The success of ourapproach demonstrates the enormous potential to extract complex domain specificnumerical reasoning by designing zero-shot prompts to effectively exploit theknowledge embedded in LLMs.",Karmvir Singh Phogat,2023/11/19,2023/11/19
2311.06530v1,How ChatGPT is Solving Vulnerability Management Problem,http://arxiv.org/abs/2311.06530v1,"Recently, ChatGPT has attracted great attention from the code analysisdomain. Prior works show that ChatGPT has the capabilities of processingfoundational code analysis tasks, such as abstract syntax tree generation,which indicates the potential of using ChatGPT to comprehend code syntax andstatic behaviors. However, it is unclear whether ChatGPT can complete morecomplicated real-world vulnerability management tasks, such as the predictionof security relevance and patch correctness, which require an all-encompassingunderstanding of various aspects, including code syntax, program semantics, andrelated manual comments.  In this paper, we explore ChatGPT's capabilities on 6 tasks involving thecomplete vulnerability management process with a large-scale dataset containing78,445 samples. For each task, we compare ChatGPT against SOTA approaches,investigate the impact of different prompts, and explore the difficulties. Theresults suggest promising potential in leveraging ChatGPT to assistvulnerability management. One notable example is ChatGPT's proficiency in taskslike generating titles for software bug reports. Furthermore, our findingsreveal the difficulties encountered by ChatGPT and shed light on promisingfuture directions. For instance, directly providing random demonstrationexamples in the prompt cannot consistently guarantee good performance invulnerability management. By contrast, leveraging ChatGPT in a self-heuristicway -- extracting expertise from demonstration examples itself and integratingthe extracted expertise in the prompt is a promising research direction.Besides, ChatGPT may misunderstand and misuse the information in the prompt.Consequently, effectively guiding ChatGPT to focus on helpful informationrather than the irrelevant content is still an open problem.",Peiyu Liu,2023/11/11,2023/11/11
1410.4453v1,"A Review of CUDA, MapReduce, and Pthreads Parallel Computing Models",http://arxiv.org/abs/1410.4453v1,"The advent of high performance computing (HPC) and graphics processing units(GPU), present an enormous computation resource for Large data transactions(big data) that require parallel processing for robust and prompt dataanalysis. While a number of HPC frameworks have been proposed, parallelprogramming models present a number of challenges, for instance, how to fullyutilize features in the different programming models to implement and manageparallelism via multi-threading in both CPUs and GPUs. In this paper, we takean overview of three parallel programming models, CUDA, MapReduce, andPthreads. The goal is to explore literature on the subject and provide a highlevel view of the features presented in the programming models to assist highperformance users with a concise understanding of parallel programming conceptsand thus faster implementation of big data projects using high performancecomputing.",Kato Mivule,2014/10/16,2014/10/16
2309.00940v1,Content Prompting: Modeling Content Provider Dynamics to Improve User Welfare in Recommender Ecosystems,http://arxiv.org/abs/2309.00940v1,"Users derive value from a recommender system (RS) only to the extent that itis able to surface content (or items) that meet their needs/preferences. WhileRSs often have a comprehensive view of user preferences across the entire userbase, content providers, by contrast, generally have only a local view of thepreferences of users that have interacted with their content. This limits aprovider's ability to offer new content to best serve the broader population.In this work, we tackle this information asymmetry with content promptingpolicies. A content prompt is a hint or suggestion to a provider to makeavailable novel content for which the RS predicts unmet user demand. Aprompting policy is a sequence of such prompts that is responsive to thedynamics of a provider's beliefs, skills and incentives. We aim to determine ajoint prompting policy that induces a set of providers to make contentavailable that optimizes user social welfare in equilibrium, while respectingthe incentives of the providers themselves. Our contributions include: (i) anabstract model of the RS ecosystem, including content provider behaviors, thatsupports such prompting; (ii) the design and theoretical analysis of sequentialprompting policies for individual providers; (iii) a mixed integer programmingformulation for optimal joint prompting using path planning in content space;and (iv) simple, proof-of-concept experiments illustrating how such policiesimprove ecosystem health and user welfare.",Siddharth Prasad,2023/9/2,2023/9/2
2306.00618v1,Effective Structured Prompting by Meta-Learning and Representative Verbalizer,http://arxiv.org/abs/2306.00618v1,"Prompt tuning for pre-trained masked language models (MLM) has shownpromising performance in natural language processing tasks with few labeledexamples. It tunes a prompt for the downstream task, and a verbalizer is usedto bridge the predicted token and label prediction. Due to the limited trainingdata, prompt initialization is crucial for prompt tuning. Recently,MetaPrompting (Hou et al., 2022) uses meta-learning to learn a sharedinitialization for all task-specific prompts. However, a single initializationis insufficient to obtain good prompts for all tasks and samples when the tasksare complex. Moreover, MetaPrompting requires tuning the whole MLM, causing aheavy burden on computation and memory as the MLM is usually large. To addressthese issues, we use a prompt pool to extract more task knowledge and constructinstance-dependent prompts via attention. We further propose a novel softverbalizer (RepVerb) which constructs label embedding from feature embeddingsdirectly. Combining meta-learning the prompt pool and RepVerb, we proposeMetaPrompter for effective structured prompting. MetaPrompter isparameter-efficient as only the pool is required to be tuned. Experimentalresults demonstrate that MetaPrompter performs better than the recentstate-of-the-arts and RepVerb outperforms existing soft verbalizers.",Weisen Jiang,2023/6/1,2023/6/1
2209.11486v4,MetaPrompting: Learning to Learn Better Prompts,http://arxiv.org/abs/2209.11486v4,"Prompting method is regarded as one of the crucial progress for few-shotnature language processing. Recent research on prompting moves from discretetokens based ``hard prompts'' to continuous ``soft prompts'', which employlearnable vectors as pseudo prompt tokens and achieve better performance.Though showing promising prospects, these soft-prompting methods are observedto rely heavily on good initialization to take effect. Unfortunately, obtaininga perfect initialization for soft prompts requires understanding of innerlanguage models working and elaborate design, which is no easy task and has torestart from scratch for each new task. To remedy this, we propose ageneralized soft prompting method called MetaPrompting, which adopts thewell-recognized model-agnostic meta-learning algorithm to automatically findbetter prompt initialization that facilitates fast adaptation to new promptingtasks.Extensive experiments show MetaPrompting tackles soft promptinitialization problem and brings significant improvement on four differentdatasets (over 6 points improvement in accuracy for 1-shot setting), achievingnew state-of-the-art performance.",Yutai Hou,2022/9/23,2023/2/3
2202.00828v1,Co-training Improves Prompt-based Learning for Large Language Models,http://arxiv.org/abs/2202.00828v1,"We demonstrate that co-training (Blum & Mitchell, 1998) can improve theperformance of prompt-based learning by using unlabeled data. While promptinghas emerged as a promising paradigm for few-shot and zero-shot learning, it isoften brittle and requires much larger models compared to the standardsupervised setup. We find that co-training makes it possible to improve theoriginal prompt model and at the same time learn a smaller, downstreamtask-specific model. In the case where we only have partial access to a promptmodel (e.g., output probabilities from GPT-3 (Brown et al., 2020)) we learn acalibration model over the prompt outputs. When we have full access to theprompt model's gradients but full finetuning remains prohibitively expensive(e.g., T0 (Sanh et al., 2021)), we learn a set of soft prompt continuousvectors to iteratively update the prompt model. We find that models trained inthis manner can significantly improve performance on challenging datasets wherethere is currently a large gap between prompt-based learning andfully-supervised models.",Hunter Lang,2022/2/2,2022/2/2
2304.07991v1,One-shot and Partially-Supervised Cell Image Segmentation Using Small Visual Prompt,http://arxiv.org/abs/2304.07991v1,"Semantic segmentation of microscopic cell images using deep learning is animportant technique, however, it requires a large number of images and groundtruth labels for training. To address the above problem, we consider anefficient learning framework with as little data as possible, and we proposetwo types of learning strategies: One-shot segmentation which can learn withonly one training sample, and Partially-supervised segmentation which assignsannotations to only a part of images. Furthermore, we introduce novelsegmentation methods using the small prompt images inspired by prompt learningin recent studies. Our proposed methods use a pre-trained model based on onlycell images and teach the information of the prompt pairs to the target imageto be segmented by the attention mechanism, which allows for efficient learningwhile reducing the burden of annotation costs. Through experiments conducted onthree types of microscopic cell image datasets, we confirmed that the proposedmethod improved the Dice score coefficient (DSC) in comparison with theconventional methods.",Sota Kato,2023/4/17,2023/4/17
1808.00803v2,Mobile big data analysis with machine learning,http://arxiv.org/abs/1808.00803v2,"This paper investigates to identify the requirement and the development ofmachine learning-based mobile big data analysis through discussing the insightsof challenges in the mobile big data (MBD). Furthermore, it reviews thestate-of-the-art applications of data analysis in the area of MBD. Firstly, weintroduce the development of MBD. Secondly, the frequently adopted methods ofdata analysis are reviewed. Three typical applications of MBD analysis, namelywireless channel modeling, human online and offline behavior analysis, andspeech recognition in the internet of vehicles, are introduced respectively.Finally, we summarize the main challenges and future development directions ofmobile big data analysis.",Jiyang Xie,2018/8/2,2020/2/2
2301.09362v1,A Comprehensive Survey on Heart Sound Analysis in the Deep Learning Era,http://arxiv.org/abs/2301.09362v1,"Heart sound auscultation has been demonstrated to be beneficial in clinicalusage for early screening of cardiovascular diseases. Due to the highrequirement of well-trained professionals for auscultation, automaticauscultation benefiting from signal processing and machine learning can helpauxiliary diagnosis and reduce the burdens of training professional clinicians.Nevertheless, classic machine learning is limited to performance improvement inthe era of big data. Deep learning has achieved better performance than classicmachine learning in many research fields, as it employs more complex modelarchitectures with stronger capability of extracting effective representations.Deep learning has been successfully applied to heart sound analysis in the pastyears. As most review works about heart sound analysis were given before 2017,the present survey is the first to work on a comprehensive overview tosummarise papers on heart sound analysis with deep learning in the past sixyears 2017--2022. We introduce both classic machine learning and deep learningfor comparison, and further offer insights about the advances and futureresearch directions in deep learning for heart sound analysis.",Zhao Ren,2023/1/23,2023/1/23
1805.06088v1,What's in a Domain? Learning Domain-Robust Text Representations using Adversarial Training,http://arxiv.org/abs/1805.06088v1,"Most real world language problems require learning from heterogenous corpora,raising the problem of learning robust models which generalise well to bothsimilar (in domain) and dissimilar (out of domain) instances to those seen intraining. This requires learning an underlying task, while not learningirrelevant signals and biases specific to individual domains. We propose anovel method to optimise both in- and out-of-domain accuracy based on jointlearning of a structured neural model with domain-specific and domain-generalcomponents, coupled with adversarial training for domain. Evaluating onmulti-domain language identification and multi-domain sentiment analysis, weshow substantial improvements over standard domain adaptation techniques, anddomain-adversarial training.",Yitong Li,2018/5/16,2018/5/16
2210.05331v1,Generalization Analysis on Learning with a Concurrent Verifier,http://arxiv.org/abs/2210.05331v1,"Machine learning technologies have been used in a wide range of practicalsystems. In practical situations, it is natural to expect the input-outputpairs of a machine learning model to satisfy some requirements. However, it isdifficult to obtain a model that satisfies requirements by just learning fromexamples. A simple solution is to add a module that checks whether theinput-output pairs meet the requirements and then modifies the model's outputs.Such a module, which we call a {\em concurrent verifier} (CV), can give acertification, although how the generalizability of the machine learning modelchanges using a CV is unclear. This paper gives a generalization analysis oflearning with a CV. We analyze how the learnability of a machine learning modelchanges with a CV and show a condition where we can obtain a guaranteedhypothesis using a verifier only in the inference time. We also show thattypical error bounds based on Rademacher complexity will be no larger than thatof the original model when using a CV in multi-class classification andstructured prediction settings.",Masaaki Nishino,2022/10/11,2022/10/11
2002.03432v3,On the distance between two neural networks and the stability of learning,http://arxiv.org/abs/2002.03432v3,"This paper relates parameter distance to gradient breakdown for a broad classof nonlinear compositional functions. The analysis leads to a new distancefunction called deep relative trust and a descent lemma for neural networks.Since the resulting learning rule seems to require little to no learning ratetuning, it may unlock a simpler workflow for training deeper and more complexneural networks. The Python code used in this paper is here:https://github.com/jxbz/fromage.",Jeremy Bernstein,2020/2/9,2021/1/8
1906.01404v1,Posterior Variance Analysis of Gaussian Processes with Application to Average Learning Curves,http://arxiv.org/abs/1906.01404v1,"The posterior variance of Gaussian processes is a valuable measure of thelearning error which is exploited in various applications such as safereinforcement learning and control design. However, suitable analysis of theposterior variance which captures its behavior for finite and infinite numberof training data is missing. This paper derives a novel bound for the posteriorvariance function which requires only local information because it depends onlyon the number of training samples in the proximity of a considered test point.Furthermore, we prove sufficient conditions which ensure the convergence of theposterior variance to zero. Finally, we demonstrate that the extension of ourbound to an average learning bound outperforms existing approaches.",Armin Lederer,2019/6/4,2019/6/4
1604.02883v1,Analysing health professionals' learning interactions in online social networks: A social network analysis approach,http://arxiv.org/abs/1604.02883v1,"Online Social Networking may be a way to support health professionals' needfor continuous learning through interaction with peers and experts.Understanding and evaluating such learning is important but difficult, andSocial Network Analysis (SNA) offers a solution. This paper demonstrates howSNA can be used to study levels of participation as well as the patterns ofinteractions that take place among health professionals in a large onlineprofessional learning network. Our analysis has shown that their learningnetwork is highly centralised and loosely connected. The level of participationis low in general, and most interactions are structured around a small set ofusers consisting of moderators and core members. The structural patterns ofinteraction indicates there is a chance of small group learning occurring andrequires further investigation to identify those potential learning groups.This first stage of analysis, to be followed by longitudinal study of thedynamics of interaction and complemented by content analysis of theirdiscussion, may contribute to greater sophistication in the analysis andutilisation of new environments for health professional learning.",Xin Li,2016/4/11,2016/4/11
1805.02686v2,Holarchic Structures for Decentralized Deep Learning - A Performance Analysis,http://arxiv.org/abs/1805.02686v2,"Structure plays a key role in learning performance. In centralizedcomputational systems, hyperparameter optimization and regularizationtechniques such as dropout are computational means to enhance learningperformance by adjusting the deep hierarchical structure. However, indecentralized deep learning by the Internet of Things, the structure is anactual network of autonomous interconnected devices such as smart phones thatinteract via complex network protocols. Self-adaptation of the learningstructure is a challenge. Uncertainties such as network latency, node and linkfailures or even bottlenecks by limited processing capacity and energyavailability can signif- icantly downgrade learning performance. Networkself-organization and self-management is complex, while it requires additionalcomputational and network resources that hinder the feasibility ofdecentralized deep learning. In contrast, this paper introduces a self-adaptivelearning approach based on holarchic learning structures for exploring,mitigating and boosting learning performance in distributed environments withuncertainties. A large-scale performance analysis with 864000 experiments fedwith synthetic and real-world data from smart grid and smart city pilotprojects confirm the cost-effectiveness of holarchic structures fordecentralized deep learning.",Evangelos Pournaras,2018/5/7,2018/9/17
2110.12773v1,Scientific Machine Learning Benchmarks,http://arxiv.org/abs/2110.12773v1,"The breakthrough in Deep Learning neural networks has transformed the use ofAI and machine learning technologies for the analysis of very largeexperimental datasets. These datasets are typically generated by large-scaleexperimental facilities at national laboratories. In the context of science,scientific machine learning focuses on training machines to identify patterns,trends, and anomalies to extract meaningful scientific insights from suchdatasets. With a new generation of experimental facilities, the rate of datageneration and the scale of data volumes will increasingly require the use ofmore automated data analysis. At present, identifying the most appropriatemachine learning algorithm for the analysis of any given scientific dataset isstill a challenge for scientists. This is due to many different machinelearning frameworks, computer architectures, and machine learning models.Historically, for modelling and simulation on HPC systems such problems havebeen addressed through benchmarking computer applications, algorithms, andarchitectures. Extending such a benchmarking approach and identifying metricsfor the application of machine learning methods to scientific datasets is a newchallenge for both scientists and computer scientists. In this paper, wedescribe our approach to the development of scientific machine learningbenchmarks and review other approaches to benchmarking scientific machinelearning.",Jeyan Thiyagalingam,2021/10/25,2021/10/25
1705.06573v1,Online learnability of Statistical Relational Learning in anomaly detection,http://arxiv.org/abs/1705.06573v1,"Statistical Relational Learning (SRL) methods for anomaly detection areintroduced via a security-related application. Operational requirements foronline learning stability are outlined and compared to mathematical definitionsas applied to the learning process of a representative SRL method - BayesianLogic Programs (BLP). Since a formal proof of online stability appears to beimpossible, tentative common sense requirements are formulated and tested bytheoretical and experimental analysis of a simple and analytically tractableBLP model. It is found that learning algorithms in initial stages of onlinelearning can lock on unstable false predictors that nevertheless comply withour tentative stability requirements and thus masquerade as bona fidesolutions. The very expressiveness of SRL seems to cause significant stabilityissues in settings with many variables and scarce data. We conclude thatreliable anomaly detection with SRL-methods requires monitoring by anoverarching framework that may involve a comprehensive context knowledge baseor human supervision.",Magnus Jndel,2017/5/18,2017/5/18
1502.02860v2,Gaussian Processes for Data-Efficient Learning in Robotics and Control,http://arxiv.org/abs/1502.02860v2,"Autonomous learning has been a promising direction in control and roboticsfor more than a decade since data-driven learning allows to reduce the amountof engineering knowledge, which is otherwise required. However, autonomousreinforcement learning (RL) approaches typically require many interactions withthe system to learn controllers, which is a practical limitation in realsystems, such as robots, where many interactions can be impractical and timeconsuming. To address this problem, current learning approaches typicallyrequire task-specific knowledge in form of expert demonstrations, realisticsimulators, pre-shaped policies, or specific knowledge about the underlyingdynamics. In this article, we follow a different approach and speed up learningby extracting more information from data. In particular, we learn aprobabilistic, non-parametric Gaussian process transition model of the system.By explicitly incorporating model uncertainty into long-term planning andcontroller learning our approach reduces the effects of model errors, a keyproblem in model-based learning. Compared to state-of-the art RL ourmodel-based policy search method achieves an unprecedented speed of learning.We demonstrate its applicability to autonomous learning in real robot andcontrol tasks.",Marc Peter Deisenroth,2015/2/10,2017/10/10
2006.15442v2,A General Machine Learning Framework for Survival Analysis,http://arxiv.org/abs/2006.15442v2,"The modeling of time-to-event data, also known as survival analysis, requiresspecialized methods that can deal with censoring and truncation, time-varyingfeatures and effects, and that extend to settings with multiple competingevents. However, many machine learning methods for survival analysis onlyconsider the standard setting with right-censored data and proportional hazardsassumption. The methods that do provide extensions usually address at most asubset of these challenges and often require specialized software that can notbe integrated into standard machine learning workflows directly. In this work,we present a very general machine learning framework for time-to-event analysisthat uses a data augmentation strategy to reduce complex survival tasks tostandard Poisson regression tasks. This reformulation is based on welldeveloped statistical theory. With the proposed approach, any algorithm thatcan optimize a Poisson (log-)likelihood, such as gradient boosted trees, deepneural networks, model-based boosting and many more can be used in the contextof time-to-event analysis. The proposed technique does not require anyassumptions with respect to the distribution of event times or the functionalshapes of feature and interaction effects. Based on the proposed framework wedevelop new methods that are competitive with specialized state of the artapproaches in terms of accuracy, and versatility, but with comparatively smallinvestments of programming effort or requirements for specializedmethodological know-how.",Andreas Bender,2020/6/27,2021/4/17
2209.12691v1,Predicting students' learning styles using regression techniques,http://arxiv.org/abs/2209.12691v1,"Traditional learning systems have responded quickly to the COVID pandemic andmoved to online or distance learning. Online learning requires apersonalization method because the interaction between learners and instructorsis minimal, and learners have a specific learning method that works best forthem. One of the personalization methods is detecting the learners' learningstyle. To detect learning styles, several works have been proposed usingclassification techniques. However, the current detection models becomeineffective when learners have no dominant style or a mix of learning styles.Thus, the objective of this study is twofold. Firstly, constructing aprediction model based on regression analysis provides a probabilistic approachfor inferring the preferred learning style. Secondly, comparing regressionmodels and classification models for detecting learning style. To ground ourconceptual model, a set of machine learning algorithms have been implementedbased on a dataset collected from a sample of 72 students using visual,auditory, reading/writing, and kinesthetic (VARK's) inventory questionnaire.Results show that regression techniques are more accurate and representativefor real-world scenarios than classification algorithms, where students mighthave multiple learning styles but with different probabilities. We believe thatthis research will help educational institutes to engage learning styles in theteaching process.",Ahmad Mousa Altamimi,2022/9/12,2022/9/12
1608.00619v2,Recursion-Free Online Multiple Incremental/Decremental Analysis Based on Ridge Support Vector Learning,http://arxiv.org/abs/1608.00619v2,"This study presents a rapid multiple incremental and decremental mechanismbased on Weight-Error Curves (WECs) for support-vector analysis. Recursion-freecomputation is proposed for predicting the Lagrangian multipliers of newsamples. This study examines Ridge Support Vector Models, subsequently devisinga recursion-free function derived from WECs. With the proposed function, allthe new Lagrangian multipliers can be computed at once without using anygradual step sizes. Moreover, such a function relaxes a constraint, where theincrement of new multiple Lagrangian multipliers should be the same in theprevious work, thereby easily satisfying the requirement of KKT conditions. Theproposed mechanism no longer requires typical bookkeeping strategies, whichcompute the step size by checking all the training samples in each incrementalround.",Bo-Wei Chen,2016/8/1,2016/10/11
2306.10034v1,Unlocking Insights into Business Trajectories with Transformer-based Spatio-temporal Data Analysis,http://arxiv.org/abs/2306.10034v1,The world of business is constantly evolving and staying ahead of the curverequires a deep understanding of market trends and performance. This articleaddresses this requirement by modeling business trajectories using newsarticles data.,Muhammad Arslan,2023/6/7,2023/6/7
cmp-lg/9711005v1,Some apparently disjoint aims and requirements for grammar development environments: the case of natural language generation,http://arxiv.org/abs/cmp-lg/9711005v1,"Grammar development environments (GDE's) for analysis and for generation havenot yet come together. Despite the fact that analysis-oriented GDE's (such asALEP) may include some possibility of sentence generation, the developmenttechniques and kinds of resources suggested are apparently not those requiredfor practical, large-scale natural language generation work. Indeed, there isno use of `standard' (i.e., analysis-oriented) GDE's in currentprojects/applications targetting the generation of fluent, coherent texts. Thisunsatisfactory situation requires some analysis and explanation, which thispaper attempts using as an example an extensive GDE for generation. The supportprovided for distributed large-scale grammar development, multilinguality, andresource maintenance are discussed and contrasted with analysis-orientedapproaches.",John A. Bateman,1997/11/19,1997/11/19
2311.13871v1,Legal Requirements Analysis,http://arxiv.org/abs/2311.13871v1,"Modern software has been an integral part of everyday activities in manydisciplines and application contexts. Introducing intelligent automation byleveraging artificial intelligence (AI) led to break-throughs in many fields.The effectiveness of AI can be attributed to several factors, among which isthe increasing availability of data. Regulations such as the general dataprotection regulation (GDPR) in the European Union (EU) are introduced toensure the protection of personal data. Software systems that collect, process,or share personal data are subject to compliance with such regulations.Developing compliant software depends heavily on addressing legal requirementsstipulated in applicable regulations, a central activity in the requirementsengineering (RE) phase of the software development process. RE is concernedwith specifying and maintaining requirements of a system-to-be, including legalrequirements. Legal agreements which describe the policies organizationsimplement for processing personal data can provide an additional source toregulations for eliciting legal requirements. In this chapter, we explore avariety of methods for analyzing legal requirements and exemplify them on GDPR.Specifically, we describe possible alternatives for creating machine-analyzablerepresentations from regulations, survey the existing automated means forenabling compliance verification against regulations, and further reflect onthe current challenges of legal requirements analysis.",Sallam Abualhaija,2023/11/23,2023/11/23
1704.02824v1,Towards Industry 4.0: Gap Analysis between Current Automotive MES and Industry Standards using Model-Based Requirement Engineering,http://arxiv.org/abs/1704.02824v1,"The dawn of the fourth industrial revolution, Industry 4.0 has created greatenthusiasm among companies and researchers by giving them an opportunity topave the path towards the vision of a connected smart factory ecosystem.However, in context of automotive industry there is an evident gap between therequirements supported by the current automotive manufacturing executionsystems (MES) and the requirements proposed by industrial standards from theInternational Society of Automation (ISA) such as, ISA-95, ISA-88 over whichthe Industry 4.0 is being built on. In this paper, we bridge this gap byfollowing a model-based requirements engineering approach along with a gapanalysis process. Our work is mainly divided into three phases, (i) automotiveMES tool selection phase, (ii) requirements modeling phase, (iii) and gapanalysis phase based on the modeled requirements. During the MES tool selectionphase, we used known reliable sources such as, MES product survey reports,white papers that provide in-depth and comprehensive information about variouscomparison criteria and tool vendors list for the current MES landscape. Duringthe requirement modeling phase, we specified requirements derived from theneeds of ISA-95 and ISA-88 industrial standards using the general purposeSystems Modeling Language (SysML). During the gap analysis phase, we find themisalignment between standard requirements and the compliance of the existingsoftware tools to those standards.",Manoj Kannan Soundarapandian,2017/4/10,2017/4/10
1712.02890v1,Network Analysis for Explanation,http://arxiv.org/abs/1712.02890v1,"Safety critical systems strongly require the quality aspects of artificialintelligence including explainability. In this paper, we analyzed a trainednetwork to extract features which mainly contribute the inference. Based on theanalysis, we developed a simple solution to generate explanations of theinference processes.",Hiroshi Kuwajima,2017/12/7,2017/12/7
1708.01796v1,Automatic generation of analysis class diagrams from use case specifications,http://arxiv.org/abs/1708.01796v1,"In object oriented software development, the analysis modeling is concernedwith the task of identifying problem level objects along with the relationshipsbetween them from software requirements. The software requirements are usuallywritten in some natural language, and the analysis modeling is normallyperformed by experienced human analysts. The huge gap between the softwarerequirements which are unstructured texts and analysis models which are usuallystructured UML diagrams, along with human slip-ups inevitably makes thetransformation process error prone. The automation of this process can help inreducing the errors in the transformation. In this paper we propose a toolsupported approach for automated transformation of use case specificationsdocumented in English language into analysis class diagrams. The approach worksin four steps. It first takes the textual specification of a use case as input,and then using a natural language parser generates type dependencies and partsof speech tags for each sentence in the specification. Then, it identifies thesentence structure of each sentence using a set of comprehensive sentencestructure rules. Next, it applies a set of transformation rules on the typedependencies and parts of speech tags of the sentences to discover the problemlevel objects and the relationships between them. Finally, it generates andvisualizes the analysis class diagram. We conducted a controlled experiment tocompare the correctness, completeness and redundancy of the analysis classdiagrams generated by our approach with those generated by the existingautomated approaches. The results showed that the analysis class diagramsgenerated by our approach were more correct, more complete, and less redundantthan those generated by the other approaches.",Jitendra Singh Thakur,2017/8/5,2017/8/5
1111.1022v1,Towards the integration of formal specification in the ncora methodology,http://arxiv.org/abs/1111.1022v1,"There are some non-formal methodologies such as RUP, OpenUP, agilemethodologies such as SCRUP, XP and techniques like those proposed by UML,which allow the development of software. The software industry has struggled togenerate quality software, as importance has not been given to the engineeringrequirements, resulting in a poor specification of requirements and software ofpoor quality. In order to generate a contribution to the specification ofrequirements, this article describes a methodological proposal, implementingformal methods to the results of the process of requirements analysis of themethodology \'Ancora.",Carlos Alberto Fernandez-y-Fernandez,2011/11/4,2011/11/4
1502.06515v2,An improved a priori error analysis of Nitsche's method for Robin boundary conditions,http://arxiv.org/abs/1502.06515v2,"In a previous paper [6] we have extended Nitsche's method [8] for the Poissonequation with general Robin boundary conditions. The analysis required that thesolution is in H^s, with s > 3/2. Here we give an improved error analysis usinga technique proposed by Gudi [5].",Nora Lthen,2015/2/23,2015/2/24
1704.01308v1,Flexibility Analysis for Smart Grid Demand Response,http://arxiv.org/abs/1704.01308v1,"Flexibility is a key enabler for the smart grid, required to facilitateDemand Side Management (DSM) programs, managing electrical consumption toreduce peaks, balance renewable generation and provide ancillary services tothe grid. Flexibility analysis is required to identify and quantify theavailable electrical load of a site or building which can be shed or increasedin response to a DSM signal. A methodology for assessing flexibility isdeveloped, based on flexibility formulations and optimization requirements. Themethodology characterizes the loads, storage and on-site generation,incorporates site assessment using the ISO 50002:2014 energy audit standard andbenchmarks performance against documented studies. An example application ofthe methodology is detailed using a pilot site demonstrator.",Sarah O'Connell,2017/4/5,2017/4/5
1506.08789v1,Requirement Tracing using Term Extraction,http://arxiv.org/abs/1506.08789v1,"Requirements traceability is an essential step in ensuring the quality ofsoftware during the early stages of its development life cycle. Requirementstracing usually consists of document parsing, candidate link generation andevaluation and traceability analysis. This paper demonstrates the applicabilityof Statistical Term Extraction metrics to generate candidate links. It isapplied and validated using two data sets and four types of filters two foreach data set, 0.2 and 0.25 for MODIS, 0 and 0.05 for CM1. This methodgenerates requirements traceability matrices between textual requirementsartifacts (such as high-level requirements traced to low-level requirements).The proposed method includes ten word frequency metrics divided into three maingroups for calculating the frequency of terms. The results show that theproposed method gives better result when compared with the traditional TF-IDFmethod.",Najla Al-Saati,2015/6/29,2015/6/29
2310.13976v2,Advancing Requirements Engineering through Generative AI: Assessing the Role of LLMs,http://arxiv.org/abs/2310.13976v2,"Requirements Engineering (RE) is a critical phase in software developmentincluding the elicitation, analysis, specification, and validation of softwarerequirements. Despite the importance of RE, it remains a challenging processdue to the complexities of communication, uncertainty in the early stages andinadequate automation support. In recent years, large-language models (LLMs)have shown significant promise in diverse domains, including natural languageprocessing, code generation, and program understanding. This chapter exploresthe potential of LLMs in driving RE processes, aiming to improve the efficiencyand accuracy of requirements-related tasks. We propose key directions and SWOTanalysis for research and development in using LLMs for RE, focusing on thepotential for requirements elicitation, analysis, specification, andvalidation. We further present the results from a preliminary evaluation, inthis context.",Chetan Arora,2023/10/21,2023/11/1
2211.16716v1,Automated Generating Natural Language Requirements based on Domain Ontology,http://arxiv.org/abs/2211.16716v1,"Software requirements specification is undoubtedly critical for the wholesoftware life-cycle. Nowadays, writing software requirements specificationsprimarily depends on human work. Although massive studies have been proposed tofasten the process via proposing advanced elicitation and analysis techniques,it is still a time-consuming and error-prone task that needs to take domainknowledge and business information into consideration. In this paper, wepropose an approach, named ReqGen, which can provide recommendations byautomatically generating natural language requirements specifications based oncertain given keywords. Specifically, ReqGen consists of three critical steps.First, keywords-oriented knowledge is selected from domain ontology and isinjected to the basic Unified pre-trained Language Model (UniLM) for domainfine-tuning. Second, a copy mechanism is integrated to ensure the occurrence ofkeywords in the generated statements. Finally, a requirement syntax constraineddecoding is designed to close the semantic and syntax distance between thecandidate and reference specifications. Experiments on two public datasets fromdifferent groups and domains show that ReqGen outperforms six popular naturallanguage generation approaches with respect to the hard constraint ofkeywords(phrases) inclusion, BLEU, ROUGE and syntax compliance. We believe thatReqGen can promote the efficiency and intelligence of specifying softwarerequirements.",Ziyan Zhao,2022/11/30,2022/11/30
1707.03070v1,Choosing Requirements for Experimentation with User Interfaces of Requirements Modeling Tools,http://arxiv.org/abs/1707.03070v1,"When designing a new presentation front-end called FlexiView for requirementsmodeling tools, we encountered a general problem: designing such an interfacerequires a lot of experimentation which is costly when the code of the toolneeds to be adapted for every experiment. On the other hand, when usingsimplified user interface (UI) tools, the results are difficult to generalize.To improve this situation, we are developing a UI experimentation tool which isbased on so-called ImitGraphs. ImitGraphs can act as a simple, but an accuratesubstitute for a modeling tool. In this paper, we define requirements for sucha UI experimentation tool based on an analysis of the features of existingrequirements modeling tools.",Parisa Ghazi,2017/7/10,2017/7/10
1611.03213v1,Length Matters: Clustering System Log Messages using Length of Words,http://arxiv.org/abs/1611.03213v1,"The analysis techniques of system log messages (syslog messages) have a longhistory from when the syslog mechanism was invented. Typically, the analysisconsists of two parts, one is a message template generation, and the other isfinding something interesting using the messages classified by the inferredtemplates. It is important to generate better templates to achieve better,precise, or convincible analysis results. In this paper, we propose aclassification methodology using the length of words of each message. Ourmethod is suitable for online template generation because it does not requiretwo-pass analysis to generate template messages, that is an important factorconsidering increasing amount of log messages produced by a large number ofsystem components such as cloud infrastructure.",Keiichi Shima,2016/11/10,2016/11/10
1709.09755v1,Quasi-random Monte Carlo application in CGE systematic sensitivity analysis,http://arxiv.org/abs/1709.09755v1,"The uncertainty and robustness of Computable General Equilibrium models canbe assessed by conducting a Systematic Sensitivity Analysis. Different methodshave been used in the literature for SSA of CGE models such as GaussianQuadrature and Monte Carlo methods. This paper explores the use of Quasi-randomMonte Carlo methods based on the Halton and Sobol' sequences as means toimprove the efficiency over regular Monte Carlo SSA, thus reducing thecomputational requirements of the SSA. The findings suggest that by usinglow-discrepancy sequences, the number of simulations required by the regular MCSSA methods can be notably reduced, hence lowering the computational timerequired for SSA of CGE models.",Theodoros Chatzivasileiadis,2017/9/27,2017/9/27
2211.01973v1,On the invariant region for compressible Euler equations with a general equation of state,http://arxiv.org/abs/2211.01973v1,"The state space for solutions of the compressible Euler equations with ageneral equation of state is examined. An arbitrary equation of state isallowed, subject only to the physical requirements of thermodynamics. Aninvariant region of the resulting Euler system is identified and the convexityproperty of this region is justified by using only very minimal thermodynamicalassumptions. Finally, we show how an invariant-region-preserving (IRP) limitercan be constructed for use in high order finite-volume type schemes to solvethe compressible Euler equations with a general constitutive relation.",Hailiang Liu,2022/11/3,2022/11/3
2202.03153v1,Approaches to Artificial General Intelligence: An Analysis,http://arxiv.org/abs/2202.03153v1,"This paper is an analysis of the different methods proposed to achieve AGI,including Human Brain Emulation, AIXI and Integrated Cognitive Architecture.First, the definition of AGI as used in this paper has been defined, and itsrequirements have been stated. For each proposed method mentioned, the methodin question was summarized and its key processes were detailed, showcasing howit functioned. Then, each method listed was analyzed, taking various factorsinto consideration, such as technological requirements, computational ability,and adequacy to the requirements. It was concluded that while there are variousmethods to achieve AGI that could work, such as Human Brain Emulation andIntegrated Cognitive Architectures, the most promising method to achieve AGI isIntegrated Cognitive Architectures. This is because Human Brain Emulation wasfound to require scanning technologies that will most likely not be availableuntil the 2030s, making it unlikely to be created before then. Moreover,Integrated Cognitive Architectures has reduced computational requirements and asuitable functionality for General Intelligence, making it the most likely wayto achieve AGI.",Soumil Rathi,2022/1/29,2022/1/29
1001.2607v1,Linear differential operators for generic algebraic curves,http://arxiv.org/abs/1001.2607v1,We give a computationally efficient method for constructing the lineardifferential operator with polynomial coefficients whose space of holomorphicsolutions is spanned by all the branches of a function defined by a genericalgebraic curve. The proposed method does not require solving the algebraicequation and can be applied in the case when its Galois group is not solvable.,V. A. Krasikov,2010/1/15,2010/1/15
2306.01264v2,Convex and Non-convex Optimization Under Generalized Smoothness,http://arxiv.org/abs/2306.01264v2,"Classical analysis of convex and non-convex optimization methods oftenrequires the Lipshitzness of the gradient, which limits the analysis tofunctions bounded by quadratics. Recent work relaxed this requirement to anon-uniform smoothness condition with the Hessian norm bounded by an affinefunction of the gradient norm, and proved convergence in the non-convex settingvia gradient clipping, assuming bounded noise. In this paper, we furthergeneralize this non-uniform smoothness condition and develop a simple, yetpowerful analysis technique that bounds the gradients along the trajectory,thereby leading to stronger results for both convex and non-convex optimizationproblems. In particular, we obtain the classical convergence rates for(stochastic) gradient descent and Nesterov's accelerated gradient method in theconvex and/or non-convex setting under this general smoothness condition. Thenew analysis approach does not require gradient clipping and allowsheavy-tailed noise with bounded variance in the stochastic setting.",Haochuan Li,2023/6/2,2023/11/3
1409.8211v2,Efficient multivariate sequence classification,http://arxiv.org/abs/1409.8211v2,"Kernel-based approaches for sequence classification have been successfullyapplied to a variety of domains, including the text categorization, imageclassification, speech analysis, biological sequence analysis, time series andmusic classification, where they show some of the most accurate results.  Typical kernel functions for sequences in these domains (e.g., bag-of-words,mismatch, or subsequence kernels) are restricted to {\em discrete univariate}(i.e. one-dimensional) string data, such as sequences of words in the textanalysis, codeword sequences in the image analysis, or nucleotide or amino acidsequences in the DNA and protein sequence analysis. However, original sequencedata are often of real-valued multivariate nature, i.e. are not univariate anddiscrete as required by typical $k$-mer based sequence kernel functions.  In this work, we consider the problem of the {\em multivariate} sequenceclassification such as classification of multivariate music sequences, ormultidimensional protein sequence representations. To this end, we extend {\emunivariate} kernel functions typically used in sequence analysis and proposeefficient {\em multivariate} similarity kernel method (MVDFQ-SK) based on (1) adirect feature quantization (DFQ) of each sequence dimension in the original{\em real-valued} multivariate sequences and (2) applying novel multivariatediscrete kernel measures on these multivariate discrete DFQ sequencerepresentations to more accurately capture similarity relationships amongsequences and improve classification performance.  Experiments using the proposed MVDFQ-SK kernel method show excellentclassification performance on three challenging music classification tasks aswell as protein sequence classification with significant 25-40% improvementsover univariate kernel methods and existing state-of-the-art sequenceclassification methods.",Pavel P. Kuksa,2014/9/29,2014/9/30
2104.11642v1,Turkish Text Classification: From Lexicon Analysis to Bidirectional Transformer,http://arxiv.org/abs/2104.11642v1,"Text classification has seen an increased use in both academic and industrysettings. Though rule based methods have been fairly successful, supervisedmachine learning has been shown to be most successful for most languages, wheremost research was done on English. In this article, the success of lexiconanalysis, support vector machines, and extreme gradient boosting for the taskof text classification and sentiment analysis are evaluated in Turkish and apretrained transformer based classifier is proposed, outperforming previousmethods for Turkish text classification. In the context of text classification,all machine learning models proposed in the article are domain-independent anddo not require any task-specific modifications.",Deniz Kavi,2020/8/21,2020/8/21
1209.5038v1,Fast Randomized Model Generation for Shapelet-Based Time Series Classification,http://arxiv.org/abs/1209.5038v1,Time series classification is a field which has drawn much attention over thepast decade. A new approach for classification of time series usesclassification trees based on shapelets. A shapelet is a subsequence extractedfrom one of the time series in the dataset. A disadvantage of this approach isthe time required for building the shapelet-based classification tree. Thesearch for the best shapelet requires examining all subsequences of all lengthsfrom all time series in the training set.  A key goal of this work was to find an evaluation order of the shapeletsspace which enables fast convergence to an accurate model. The comparativeanalysis we conducted clearly indicates that a random evaluation order yieldsthe best results. Our empirical analysis of the distribution of high-qualityshapelets within the shapelets space provides insights into why randomizedshapelets sampling is superior to alternative evaluation orders.  We present an algorithm for randomized model generation for shapelet-basedclassification that converges extremely quickly to a model with surprisinglyhigh accuracy after evaluating only an exceedingly small fraction of theshapelets space.,Daniel Gordon,2012/9/23,2012/9/23
2306.14606v1,Multivariate Time Series Early Classification Across Channel and Time Dimensions,http://arxiv.org/abs/2306.14606v1,"Nowadays, the deployment of deep learning models on edge devices foraddressing real-world classification problems is becoming more prevalent.Moreover, there is a growing popularity in the approach of earlyclassification, a technique that involves classifying the input data afterobserving only an early portion of it, aiming to achieve reduced communicationand computation requirements, which are crucial parameters in edge intelligenceenvironments. While early classification in the field of time series analysishas been broadly researched, existing solutions for multivariate time seriesproblems primarily focus on early classification along the temporal dimension,treating the multiple input channels in a collective manner. In this study, wepropose a more flexible early classification pipeline that offers a moregranular consideration of input channels and extends the early classificationparadigm to the channel dimension. To implement this method, we utilizereinforcement learning techniques and introduce constraints to ensure thefeasibility and practicality of our objective. To validate its effectiveness,we conduct experiments using synthetic data and we also evaluate itsperformance on real datasets. The comprehensive results from our experimentsdemonstrate that, for multiple datasets, our method can enhance the earlyclassification paradigm by achieving improved accuracy for equal inpututilization.",Leonardos Pantiskas,2023/6/26,2023/6/26
1002.0676v1,Soft clustering analysis of galaxy morphologies: A worked example with SDSS,http://arxiv.org/abs/1002.0676v1,"Context: The huge and still rapidly growing amount of galaxies in modern skysurveys raises the need of an automated and objective classification method.Unsupervised learning algorithms are of particular interest, since theydiscover classes automatically. Aims: We briefly discuss the pitfalls ofoversimplified classification methods and outline an alternative approachcalled ""clustering analysis"". Methods: We categorise different classificationmethods according to their capabilities. Based on this categorisation, wepresent a probabilistic classification algorithm that automatically detects theoptimal classes preferred by the data. We explore the reliability of thisalgorithm in systematic tests. Using a small sample of bright galaxies from theSDSS, we demonstrate the performance of this algorithm in practice. We are ableto disentangle the problems of classification and parametrisation of galaxymorphologies in this case. Results: We give physical arguments that aprobabilistic classification scheme is necessary. The algorithm we presentproduces reasonable morphological classes and object-to-class assignmentswithout any prior assumptions. Conclusions: There are sophisticated automatedclassification algorithms that meet all necessary requirements, but a lot ofwork is still needed on the interpretation of the results.",Rene Andrae,2010/2/3,2010/2/3
1505.01802v1,Optimal Decision-Theoretic Classification Using Non-Decomposable Performance Metrics,http://arxiv.org/abs/1505.01802v1,"We provide a general theoretical analysis of expected out-of-sample utility,also referred to as decision-theoretic classification, for non-decomposablebinary classification metrics such as F-measure and Jaccard coefficient. Ourkey result is that the expected out-of-sample utility for many performancemetrics is provably optimized by a classifier which is equivalent to a signedthresholding of the conditional probability of the positive class. Our analysisbridges a gap in the literature on binary classification, revealed in light ofrecent results for non-decomposable metrics in population utility maximizationstyle classification. Our results identify checkable properties of aperformance metric which are sufficient to guarantee a probability rankingprinciple. We propose consistent estimators for optimal expected out-of-sampleclassification. As a consequence of the probability ranking principle,computational requirements can be reduced from exponential to cubic complexityin the general case, and further reduced to quadratic complexity in specialcases. We provide empirical results on simulated and benchmark datasetsevaluating the performance of the proposed algorithms for decision-theoreticclassification and comparing them to baseline and state-of-the-art methods inpopulation utility maximization for non-decomposable metrics.",Nagarajan Natarajan,2015/5/7,2015/5/7
2012.06782v1,Light-Weight 1-D Convolutional Neural Network Architecture for Mental Task Identification and Classification Based on Single-Channel EEG,http://arxiv.org/abs/2012.06782v1,"Mental task identification and classification using single/limited channel(s)electroencephalogram (EEG) signals in real-time play an important role in thedesign of portable brain-computer interface (BCI) and neurofeedback (NFB)systems. However, the real-time recorded EEG signals are often contaminatedwith noises such as ocular artifacts (OAs) and muscle artifacts (MAs), whichdeteriorate the hand-crafted features extracted from EEG signal, resultinginadequate identification and classification of mental tasks. Therefore, weinvestigate the use of recent deep learning techniques which do not require anymanual feature extraction or artifact suppression step. In this paper, wepropose a light-weight one-dimensional convolutional neural network (1D-CNN)architecture for mental task identification and classification. The robustnessof the proposed architecture is evaluated using artifact-free andartifact-contaminated EEG signals taken from two publicly available databases(i.e, Keirn and Aunon ($K$) database and EEGMAT ($E$) database) and in-house($R$) database recorded using single-channel neurosky mindwave mobile 2 (MWM2)EEG headset in performing not only mental/non-mental binary task classificationbut also different mental/mental multi-tasks classification. Evaluation resultsdemonstrate that the proposed architecture achieves the highestsubject-independent classification accuracy of $99.7\%$ and $100\%$ formulti-class classification and pair-wise mental tasks classificationrespectively in database $K$. Further, the proposed architecture achievessubject-independent classification accuracy of $99\%$ and $98\%$ in database$E$ and the recorded database $R$ respectively. Comparative performanceanalysis demonstrates that the proposed architecture outperforms existingapproaches not only in terms of classification accuracy but also in robustnessagainst artifacts.",Manali Saini,2020/12/12,2020/12/12
2304.09730v1,Hyperspectral Image Analysis with Subspace Learning-based One-Class Classification,http://arxiv.org/abs/2304.09730v1,"Hyperspectral image (HSI) classification is an important task in manyapplications, such as environmental monitoring, medical imaging, and landuse/land cover (LULC) classification. Due to the significant amount of spectralinformation from recent HSI sensors, analyzing the acquired images ischallenging using traditional Machine Learning (ML) methods. As the number offrequency bands increases, the required number of training samples increasesexponentially to achieve a reasonable classification accuracy, also known asthe curse of dimensionality. Therefore, separate band selection ordimensionality reduction techniques are often applied before performing anyclassification task over HSI data. In this study, we investigate recentlyproposed subspace learning methods for one-class classification (OCC). Thesemethods map high-dimensional data to a lower-dimensional feature space that isoptimized for one-class classification. In this way, there is no separatedimensionality reduction or feature selection procedure needed in the proposedclassification framework. Moreover, one-class classifiers have the ability tolearn a data description from the category of a single class only. Consideringthe imbalanced labels of the LULC classification problem and rich spectralinformation (high number of dimensions), the proposed classification approachis well-suited for HSI data. Overall, this is a pioneer study focusing onsubspace learning-based one-class classification for HSI data. We analyze theperformance of the proposed subspace learning one-class classifiers in theproposed pipeline. Our experiments validate that the proposed approach helpstackle the curse of dimensionality along with the imbalanced nature of HSIdata.",Sertac Kilickaya,2023/4/19,2023/4/19
2005.14623v2,Acoustic scene classification in DCASE 2020 Challenge: generalization across devices and low complexity solutions,http://arxiv.org/abs/2005.14623v2,"This paper presents the details of Task 1: Acoustic Scene Classification inthe DCASE 2020 Challenge. The task consists of two subtasks: classification ofdata from multiple devices, requiring good generalization properties, andclassification using low-complexity solutions. Here we describe the datasetsand baseline systems. After the challenge submission deadline, challengeresults and analysis of the submissions will be added.",Toni Heittola,2020/5/29,2020/11/2
1907.08962v1,Logical Classification of Partially Ordered Data,http://arxiv.org/abs/1907.08962v1,Issues concerning intelligent data analysis occurring in machine learning areinvestigated. A scheme for synthesizing correct supervised classificationprocedures is proposed. These procedures are focused on specifying partialorder relations on sets of feature values; they are based on a generalizationof the classical concepts of logical classification. It is shown that learningthe correct logical classifier requires an intractable discrete problem to besolved. This is the dualization problem over products of partially orderedsets. The matrix formulation of this problem is given. The effectiveness of theproposed approach to the supervised classification problem is illustrated onmodel and real-life data.,Elena V. Djukova,2019/7/21,2019/7/21
1912.01974v2,Image-free real-time classification of fast moving objects using 'learned' spatial light modulation and a single-pixel detector,http://arxiv.org/abs/1912.01974v2,"Objects classification generally relies on image acquisition and analysis.Real-time classification of high-speed moving objects is challenging, as bothhigh temporal resolution in image acquisition and low computational complexityin objects classification algorithms are required. Here we propose andexperimentally demonstrate an approach for real-time moving objectsclassification without image acquisition. As objects classification algorithmsrely on the feature information of objects, we propose to use spatial lightmodulation to acquire the feature information directly rather than performingimage acquisition followed by features extraction. A convolutional neuralnetwork is designed and trained to learn the spatial features of the targetobjects. The trained network can generate structured patterns for spatial lightmodulation. Using the resulting structured patterns for spatial lightmodulation, the feature information of target objects can be compressivelyencoded into a short light intensity sequence. The resulting one-dimensionalsignal is collected by a single-pixel detector and fed to the convolutionalneural network for objects classification. As experimentally demonstrated, theproposed approach can achieve accurate and real-time classification of fastmoving objects. The proposed method has potential applications in the fieldswhere fast moving objects classification in real time and for long duration isrequired.",Zibang Zhang,2019/12/3,2019/12/5
2209.13233v1,Genetic Programming-Based Evolutionary Deep Learning for Data-Efficient Image Classification,http://arxiv.org/abs/2209.13233v1,"Data-efficient image classification is a challenging task that aims to solveimage classification using small training data. Neural network-based deeplearning methods are effective for image classification, but they typicallyrequire large-scale training data and have major limitations such as requiringexpertise to design network architectures and having poor interpretability.Evolutionary deep learning is a recent hot topic that combines evolutionarycomputation with deep learning. However, most evolutionary deep learningmethods focus on evolving architectures of neural networks, which still sufferfrom limitations such as poor interpretability. To address this, this paperproposes a new genetic programming-based evolutionary deep learning approach todata-efficient image classification. The new approach can automatically evolvevariable-length models using many important operators from both image andclassification domains. It can learn different types of image features fromcolour or gray-scale images, and construct effective and diverse ensembles forimage classification. A flexible multi-layer representation enables the newapproach to automatically construct shallow or deep models/trees for differenttasks and perform effective transformations on the input data via multipleinternal nodes. The new approach is applied to solve five image classificationtasks with different training set sizes. The results show that it achievesbetter performance in most cases than deep learning methods for data-efficientimage classification. A deep analysis shows that the new approach has goodconvergence and evolves models with high interpretability, differentlengths/sizes/shapes, and good transferability.",Ying Bi,2022/9/27,2022/9/27
1809.07011v4,Positive-Unlabeled Classification under Class Prior Shift and Asymmetric Error,http://arxiv.org/abs/1809.07011v4,"Bottlenecks of binary classification from positive and unlabeled data (PUclassification) are the requirements that given unlabeled patterns are drawnfrom the test marginal distribution, and the penalty of the false positiveerror is identical to the false negative error. However, such requirements areoften not fulfilled in practice. In this paper, we generalize PU classificationto the class prior shift and asymmetric error scenarios. Based on the analysisof the Bayes optimal classifier, we show that given a test class prior, PUclassification under class prior shift is equivalent to PU classification withasymmetric error. Then, we propose two different frameworks to handle theseproblems, namely, a risk minimization framework and density ratio estimationframework. Finally, we demonstrate the effectiveness of the proposed frameworksand compare both frameworks through experiments using benchmark datasets.",Nontawat Charoenphakdee,2018/9/19,2020/11/9
2012.10120v1,Technical Progress Analysis Using a Dynamic Topic Model for Technical Terms to Revise Patent Classification Codes,http://arxiv.org/abs/2012.10120v1,"Japanese patents are assigned a patent classification code, FI (File Index),that is unique to Japan. FI is a subdivision of the IPC, an internationalpatent classification code, that is related to Japanese technology. FIs arerevised to keep up with technological developments. These revisions havealready established more than 30,000 new FIs since 2006. However, theserevisions require a lot of time and workload. Moreover, these revisions are notautomated and are thus inefficient. Therefore, using machine learning to assistin the revision of patent classification codes (FI) will lead to improvedaccuracy and efficiency. This study analyzes patent documents from this newperspective of assisting in the revision of patent classification codes withmachine learning. To analyze time-series changes in patents, we used thedynamic topic model (DTM), which is an extension of the latent Dirichletallocation (LDA). Also, unlike English, the Japanese language requiresmorphological analysis. Patents contain many technical words that are not usedin everyday life, so morphological analysis using a common dictionary is notsufficient. Therefore, we used a technique for extracting technical terms fromtext. After extracting technical terms, we applied them to DTM. In this study,we determined the technological progress of the lighting class F21 for 14 yearsand compared it with the actual revision of patent classification codes. Inother words, we extracted technical terms from Japanese patents and applied DTMto determine the progress of Japanese technology. Then, we analyzed the resultsfrom the new perspective of revising patent classification codes with machinelearning. As a result, it was found that those whose topics were on the risewere judged to be new technologies.",Mana Iwata,2020/12/18,2020/12/18
1203.0532v1,A new methodology for constructing a publication-level classification system of science,http://arxiv.org/abs/1203.0532v1,"Classifying journals or publications into research areas is an essentialelement of many bibliometric analyses. Classification usually takes place atthe level of journals, where the Web of Science subject categories are the mostpopular classification system. However, journal-level classification systemshave two important limitations: They offer only a limited amount of detail, andthey have difficulties with multidisciplinary journals. To avoid theselimitations, we introduce a new methodology for constructing classificationsystems at the level of individual publications. In the proposed methodology,publications are clustered into research areas based on citation relations. Themethodology is able to deal with very large numbers of publications. We presentan application in which a classification system is produced that includesalmost ten million publications. Based on an extensive analysis of thisclassification system, we discuss the strengths and the limitations of theproposed methodology. Important strengths are the transparency and relativesimplicity of the methodology and its fairly modest computing and memoryrequirements. The main limitation of the methodology is its exclusive relianceon direct citation relations between publications. The accuracy of themethodology can probably be increased by also taking into account other typesof relations, for instance based on bibliographic coupling.",Ludo Waltman,2012/3/2,2012/3/2
2304.13344v1,High stakes classification with multiple unknown classes based on imperfect data,http://arxiv.org/abs/2304.13344v1,"High stakes classification refers to classification problems whereerroneously predicting the wrong class is very bad, but assigning ""unknown"" isacceptable. We make the argument that these problems require us to givemultiple unknown classes, to get the most information out of our analysis. Withimperfect data we refer to covariates with a large number of missing values,large noise variance, and some errors in the data. The combination of highstakes classification and imperfect data is very common in practice, but it isvery difficult to work on using current methods.  We present a one-class classifier (OCC) to solve this problem, and we call itNBP. The classifier is based on Naive Bayes, simple to implement, andinterpretable. We show that NBP gives both good predictive performance, andworks for high stakes classification based on imperfect data.  The model we present is quite simple; it is just an OCC based on densityestimation. However, we have always felt a big gap between the appliedclassification problems we have worked on and the theory and models we use forclassification, and this model closes that gap. Our main contribution is themotivation for why this model is a good approach, and we hope that this paperwill inspire further development down this path.",Haakon Bakka,2023/4/26,2023/4/26
1710.09589v1,ALL-IN-1: Short Text Classification with One Model for All Languages,http://arxiv.org/abs/1710.09589v1,"We present ALL-IN-1, a simple model for multilingual text classification thatdoes not require any parallel data. It is based on a traditional Support VectorMachine classifier exploiting multilingual word embeddings and charactern-grams. Our model is simple, easily extendable yet very effective, overallranking 1st (out of 12 teams) in the IJCNLP 2017 shared task on customerfeedback analysis in four languages: English, French, Japanese and Spanish.",Barbara Plank,2017/10/26,2017/10/26
2211.11548v1,Survey of Query-based Text Summarization,http://arxiv.org/abs/2211.11548v1,Query-based text summarization is an important real world problem thatrequires to condense the prolix text data into a summary under the guidance ofthe query information provided by users. The topic has been studied for a longtime and there are many existing interesting research related to query-basedtext summarization. Yet much of the work is not systematically surveyed. Thissurvey aims at summarizing some interesting work in query-based textsummarization methods as well as related generic text summarization methods.Not all taxonomies in this paper exist the related work to the best of ourknowledge and some analysis will be presented.,Hang Yu,2022/9/17,2022/9/17
2108.01064v1,Automated News Summarization Using Transformers,http://arxiv.org/abs/2108.01064v1,"The amount of text data available online is increasing at a very fast pacehence text summarization has become essential. Most of the modern recommenderand text classification systems require going through a huge amount of data.Manually generating precise and fluent summaries of lengthy articles is a verytiresome and time-consuming task. Hence generating automated summaries for thedata and using it to train machine learning models will make these models spaceand time-efficient. Extractive summarization and abstractive summarization aretwo separate methods of generating summaries. The extractive techniqueidentifies the relevant sentences from the original document and extracts onlythose from the text. Whereas in abstractive summarization techniques, thesummary is generated after interpreting the original text, hence making it morecomplicated. In this paper, we will be presenting a comprehensive comparison ofa few transformer architecture based pre-trained models for text summarization.For analysis and comparison, we have used the BBC news dataset that containstext data that can be used for summarization and human generated summaries forevaluating and comparing the summaries generated by machine learning models.",Anushka Gupta,2021/4/23,2021/4/23
1707.07062v1,A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization,http://arxiv.org/abs/1707.07062v1,"We study the problem of domain adaptation for neural abstractivesummarization. We make initial efforts in investigating what information can betransferred to a new domain. Experimental results on news stories and opinionarticles indicate that neural summarization model benefits from pre-trainingbased on extractive summaries. We also find that the combination of in-domainand out-of-domain setup yields better summaries when in-domain data isinsufficient. Further analysis shows that, the model is capable to selectsalient content even trained on out-of-domain data, but requires in-domain datato capture the style for a target domain.",Xinyu Hua,2017/7/21,2017/7/21
2110.12680v1,TODSum: Task-Oriented Dialogue Summarization with State Tracking,http://arxiv.org/abs/2110.12680v1,"Previous dialogue summarization datasets mainly focus on open-domain chitchatdialogues, while summarization datasets for the broadly used task-orienteddialogue haven't been explored yet. Automatically summarizing suchtask-oriented dialogues can help a business collect and review needs to improvethe service. Besides, previous datasets pay more attention to generate goodsummaries with higher ROUGE scores, but they hardly understand the structuredinformation of dialogues and ignore the factuality of summaries. In this paper,we introduce a large-scale public Task-Oriented Dialogue Summarization dataset,TODSum, which aims to summarize the key points of the agent completing certaintasks with the user. Compared to existing work, TODSum suffers from severescattered information issues and requires strict factual consistency, whichmakes it hard to directly apply recent dialogue summarization models.Therefore, we introduce additional dialogue state knowledge for TODSum toenhance the faithfulness of generated summaries. We hope a better understandingof conversational content helps summarization models generate concise andcoherent summaries. Meanwhile, we establish a comprehensive benchmark forTODSum and propose a state-aware structured dialogue summarization model tointegrate dialogue state information and dialogue history. Exhaustiveexperiments and qualitative analysis prove the effectiveness of dialoguestructure guidance. Finally, we discuss the current issues of TODSum andpotential development directions for future work.",Lulu Zhao,2021/10/25,2021/10/25
2207.00939v1,"An Empirical Survey on Long Document Summarization: Datasets, Models and Metrics",http://arxiv.org/abs/2207.00939v1,"Long documents such as academic articles and business reports have been thestandard format to detail out important issues and complicated subjects thatrequire extra attention. An automatic summarization system that can effectivelycondense long documents into short and concise texts to encapsulate the mostimportant information would thus be significant in aiding the reader'scomprehension. Recently, with the advent of neural architectures, significantresearch efforts have been made to advance automatic text summarizationsystems, and numerous studies on the challenges of extending these systems tothe long document domain have emerged. In this survey, we provide acomprehensive overview of the research on long document summarization and asystematic evaluation across the three principal components of its researchsetting: benchmark datasets, summarization models, and evaluation metrics. Foreach component, we organize the literature within the context of long documentsummarization and conduct an empirical analysis to broaden the perspective oncurrent research progress. The empirical analysis includes a study on theintrinsic characteristics of benchmark datasets, a multi-dimensional analysisof summarization models, and a review of the summarization evaluation metrics.Based on the overall findings, we conclude by proposing possible directions forfuture exploration in this rapidly growing field.",Huan Yee Koh,2022/7/3,2022/7/3
1811.06567v1,Automatic Text Document Summarization using Semantic-based Analysis,http://arxiv.org/abs/1811.06567v1,"Since the advent of the web, the amount of data on wen has been increasedseveral million folds. In recent years web data generated is more than datastored for years. One important data format is text. To answer user queriesover the internet, and to overcome the problem of information overload onepossible solution is text document summarization. This not only reduces queryaccess time, but also optimize the document results according to specific usersrequirements. Summarization of text document can be categorized as abstractiveand extractive. Most of the work has been done in the direction of Extractivesummarization. Extractive summarized result is a subset of original documentswith the objective of more content coverage and lea redundancy. Our work isbased on Extractive approaches. In the first approach, we are using somestatistical features and semantic-based features. To include sentiment as afeature is an idea cached from a view that emotion plays an important role. Iteffectively conveys a message. So, it may play a vital role in text documentsummarization.",Chandra Shekhar Yadav,2018/11/15,2018/11/15
2105.06762v4,DialogSum: A Real-Life Scenario Dialogue Summarization Dataset,http://arxiv.org/abs/2105.06762v4,"Proposal of large-scale datasets has facilitated research on deep neuralmodels for news summarization. Deep learning can also be potentially useful forspoken dialogue summarization, which can benefit a range of real-life scenariosincluding customer service management and medication tracking. To this end, wepropose DialogSum, a large-scale labeled dialogue summarization dataset. Weconduct empirical analysis on DialogSum using state-of-the-art neuralsummarizers. Experimental results show unique challenges in dialoguesummarization, such as spoken terms, special discourse structures, coreferencesand ellipsis, pragmatics and social common sense, which require specificrepresentation learning technologies to better deal with.",Yulong Chen,2021/5/14,2021/6/16
2010.04379v1,Q-learning with Language Model for Edit-based Unsupervised Summarization,http://arxiv.org/abs/2010.04379v1,"Unsupervised methods are promising for abstractive text summarization in thatthe parallel corpora is not required. However, their performance is still farfrom being satisfied, therefore research on promising solutions is on-going. Inthis paper, we propose a new approach based on Q-learning with an edit-basedsummarization. The method combines two key modules to form an Editorial Agentand Language Model converter (EALM). The agent predicts edit actions (e.t.,delete, keep, and replace), and then the LM converter deterministicallygenerates a summary on the basis of the action signals. Q-learning is leveragedto train the agent to produce proper edit actions. Experimental results showthat EALM delivered competitive performance compared with the previousencoder-decoder-based methods, even with truly zero paired data (i.e., novalidation set). Defining the task as Q-learning enables us not only to developa competitive method but also to make the latest techniques in reinforcementlearning available for unsupervised summarization. We also conduct qualitativeanalysis, providing insights into future study on unsupervised summarizers.",Ryosuke Kohita,2020/10/9,2020/10/9
1810.08838v1,Abstractive Summarization Using Attentive Neural Techniques,http://arxiv.org/abs/1810.08838v1,"In a world of proliferating data, the ability to rapidly summarize text isgrowing in importance. Automatic summarization of text can be thought of as asequence to sequence problem. Another area of natural language processing thatsolves a sequence to sequence problem is machine translation, which is rapidlyevolving due to the development of attention-based encoder-decoder networks.This work applies these modern techniques to abstractive summarization. Weperform analysis on various attention mechanisms for summarization with thegoal of developing an approach and architecture aimed at improving the state ofthe art. In particular, we modify and optimize a translation model withself-attention for generating abstractive sentence summaries. The effectivenessof this base model along with attention variants is compared and analyzed inthe context of standardized evaluation sets and test metrics. However, we showthat these metrics are limited in their ability to effectively scoreabstractive summaries, and propose a new approach based on the intuition thatan abstractive model requires an abstractive evaluation.",Jacob Krantz,2018/10/20,2018/10/20
1911.06197v1,Towards automatic extractive text summarization of A-133 Single Audit reports with machine learning,http://arxiv.org/abs/1911.06197v1,"The rapid growth of text data has motivated the development ofmachine-learning based automatic text summarization strategies that conciselycapture the essential ideas in a larger text. This study aimed to devise anextractive summarization method for A-133 Single Audits, which assess ifrecipients of federal grants are compliant with program requirements for use offederal funding. Currently, these voluminous audits must be manually analyzedby officials for oversight, risk management, and prioritization purposes.Automated summarization has the potential to streamline these processes.Analysis focused on the ""Findings"" section of ~20,000 Single Audits spanning2016-2018. Following text preprocessing and GloVe embedding, sentence-levelk-means clustering was performed to partition sentences by topic and toestablish the importance of each sentence. For each audit, key summarysentences were extracted by proximity to cluster centroids. Summaries werejudged by non-expert human evaluation and compared to human-generated summariesusing the ROUGE metric. Though the goal was to fully automate summarization ofA-133 audits, human input was required at various stages due to largevariability in audit writing style, content, and context. Examples of humaninputs include the number of clusters, the choice to keep or discard certainclusters based on their content relevance, and the definition of a topsentence. Overall, this approach made progress towards automated extractivesummaries of A-133 audits, with future work to focus on full automation andimproving summary consistency. This work highlights the inherent difficulty andsubjective nature of automated summarization in a real-world application.",Vivian T. Chou,2019/11/8,2019/11/8
2304.02228v2,Galerkin-Koornwinder approximations of delay differential equations for physicists,http://arxiv.org/abs/2304.02228v2,"Formulas for Galerkin-Koornwinder (GK) approximations of delay differentialequations are summarized. The functional analysis ingredients (semigroups,operators, etc.) are intentionally omitted to focus instead on the formulasrequired to perform GK approximations in practice.",Mickal D. Chekroun,2023/4/5,2023/4/19
1905.00983v1,SUMMARIZED: Efficient Framework for Analyzing Multidimensional Process Traces under Edit-distance Constraint,http://arxiv.org/abs/1905.00983v1,"Domains such as scientific workflows and business processes exhibit datamodels with complex relationships between objects. This relationship istypically represented as sequences, where each data item is annotated withmulti-dimensional attributes. There is a need to analyze this data foroperational insights. For example, in business processes, users are interestedin clustering process traces into smaller subsets to discover less complexprocess models. This requires expensive computation of similarity metricsbetween sequence-based data. Related work on dimension reduction and embeddingmethods do not take into account the multi-dimensional attributes of data, anddo not address the interpretability of data in the embedding space (i.e., byfavoring vector-based representation). In this work, we introduce Summarized, aframework for efficient analysis on sequence-based multi-dimensional data usingintuitive and user-controlled summarizations. We introduce summarizationschemes that provide tunable trade-offs between the quality and efficiency ofanalysis tasks and derive an error model for summary-based similarity under anedit-distance constraint. Evaluations using real-world datasets show theeffectives of our framework.",Phuong Nguyen,2019/5/2,2019/5/2
1812.00108v4,Multi-Stream Dynamic Video Summarization,http://arxiv.org/abs/1812.00108v4,"With vast amounts of video content being uploaded to the Internet everyminute, video summarization becomes critical for efficient browsing, searching,and indexing of visual content. Nonetheless, the spread of social andegocentric cameras creates an abundance of sparse scenarios captured by severaldevices, and ultimately required to be jointly summarized. In this paper, wediscuss the problem of summarizing videos recorded independently by severaldynamic cameras that intermittently share the field of view. We present arobust framework that (a) identifies a diverse set of important events amongmoving cameras that often are not capturing the same scene, and (b) selects themost representative view(s) at each event to be included in a universalsummary. Due to the lack of an applicable alternative, we collected a newmulti-view egocentric dataset, Multi-Ego. Our dataset is recordedsimultaneously by three cameras, covering a wide variety of real-lifescenarios. The footage is annotated by multiple individuals under varioussummarization configurations, with a consensus analysis ensuring a reliableground truth. We conduct extensive experiments on the compiled dataset inaddition to three other standard benchmarks that show the robustness and theadvantage of our approach in both supervised and unsupervised settings.Additionally, we show that our approach learns collectively from data of variednumber-of-views and orthogonal to other summarization methods, deeming itscalable and generic.",Mohamed Elfeki,2018/12/1,2021/10/14
2206.10883v3,Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities,http://arxiv.org/abs/2206.10883v3,"With the advent of large language models, methods for abstractivesummarization have made great strides, creating potential for use inapplications to aid knowledge workers processing unwieldy document collections.One such setting is the Civil Rights Litigation Clearinghouse (CRLC)(https://clearinghouse.net),which posts information about large-scale civilrights lawsuits, serving lawyers, scholars, and the general public. Today,summarization in the CRLC requires extensive training of lawyers and lawstudents who spend hours per case understanding multiple relevant documents inorder to produce high-quality summaries of key events and outcomes. Motivatedby this ongoing real-world summarization effort, we introduce Multi-LexSum, acollection of 9,280 expert-authored summaries drawn from ongoing CRLC writing.Multi-LexSum presents a challenging multi-document summarization task given thelength of the source documents, often exceeding two hundred pages per case.Furthermore, Multi-LexSum is distinct from other datasets in its multipletarget summaries, each at a different granularity (ranging from one-sentence""extreme"" summaries to multi-paragraph narrations of over five hundred words).We present extensive analysis demonstrating that despite the high-qualitysummaries in the training data (adhering to strict content and styleguidelines), state-of-the-art summarization models perform poorly on this task.We release Multi-LexSum for further research in summarization methods as wellas to facilitate development of applications to assist in the CRLC's mission athttps://multilexsum.github.io.",Zejiang Shen,2022/6/22,2022/7/22
2312.02393v1,Lecture Notes on Computerized Tomography,http://arxiv.org/abs/2312.02393v1,"These lecture notes give an introduction to the mathematics of computer(ized)tomography (CT). Treated are the imaging principle of X-ray tomography, theRadon transform as mathematical model for the measurement process and itsproperties, the ill-posedness of the underlying mathematical reconstructionproblem and classical reconstruction techniques. The required background fromFourier analysis is also briefly summarized.",Matthias Beckmann,2023/12/4,2023/12/4
2312.12915v1,Survey on Multi-Document Summarization: Systematic Literature Review,http://arxiv.org/abs/2312.12915v1,"In this era of information technology, abundant information is available onthe internet in the form of web pages and documents on any given topic. Findingthe most relevant and informative content out of these huge number ofdocuments, without spending several hours of reading has become a verychallenging task. Various methods of multi-document summarization have beendeveloped to overcome this problem. The multi-document summarization methodstry to produce high-quality summaries of documents with low redundancy. Thisstudy conducts a systematic literature review of existing methods formulti-document summarization methods and provides an in-depth analysis ofperformance achieved by these methods. The findings of the study show that moreeffective methods are still required for getting higher accuracy of thesemethods. The study also identifies some open challenges that can gain theattention of future researchers of this domain.",Uswa Ihsan,2023/12/20,2023/12/20
1501.06715v1,Time Aware Knowledge Extraction for Microblog Summarization on Twitter,http://arxiv.org/abs/1501.06715v1,"Microblogging services like Twitter and Facebook collect millions of usergenerated content every moment about trending news, occurring events, and soon. Nevertheless, it is really a nightmare to find information of interestthrough the huge amount of available posts that are often noise and redundant.In general, social media analytics services have caught increasing attentionfrom both side research and industry. Specifically, the dynamic context ofmicroblogging requires to manage not only meaning of information but also theevolution of knowledge over the timeline. This work defines Time AwareKnowledge Extraction (briefly TAKE) methodology that relies on temporalextension of Fuzzy Formal Concept Analysis. In particular, a microblogsummarization algorithm has been defined filtering the concepts organized byTAKE in a time-dependent hierarchy. The algorithm addresses topic-basedsummarization on Twitter. Besides considering the timing of the concepts,another distinguish feature of the proposed microblog summarization frameworkis the possibility to have more or less detailed summary, according to theuser's needs, with good levels of quality and completeness as highlighted inthe experimental results.",Carmen De Maio,2015/1/27,2015/1/27
2005.01840v3,Exploring Content Selection in Summarization of Novel Chapters,http://arxiv.org/abs/2005.01840v3,"We present a new summarization task, generating summaries of novel chaptersusing summary/chapter pairs from online study guides. This is a harder taskthan the news summarization task, given the chapter length as well as theextreme paraphrasing and generalization found in the summaries. We focus onextractive summarization, which requires the creation of a gold-standard set ofextractive summaries. We present a new metric for aligning reference summarysentences with chapter sentences to create gold extracts and also experimentwith different alignment methods. Our experiments demonstrate significantimprovement over prior alignment approaches for our task as shown throughautomatic metrics and a crowd-sourced pyramid analysis. We make our datacollection scripts available athttps://github.com/manestay/novel-chapter-dataset .",Faisal Ladhak,2020/5/4,2021/3/30
2105.12532v1,Unsupervised Video Summarization via Multi-source Features,http://arxiv.org/abs/2105.12532v1,"Video summarization aims at generating a compact yet representative visualsummary that conveys the essence of the original video. The advantage ofunsupervised approaches is that they do not require human annotations to learnthe summarization capability and generalize to a wider range of domains.Previous work relies on the same type of deep features, typically based on amodel pre-trained on ImageNet data. Therefore, we propose the incorporation ofmultiple feature sources with chunk and stride fusion to provide moreinformation about the visual content. For a comprehensive evaluation on the twobenchmarks TVSum and SumMe, we compare our method with four state-of-the-artapproaches. Two of these approaches were implemented by ourselves to reproducethe reported results. Our evaluation shows that we obtain state-of-the-artresults on both datasets, while also highlighting the shortcomings of previouswork with regard to the evaluation methodology. Finally, we perform erroranalysis on videos for the two benchmark datasets to summarize and spot thefactors that lead to misclassifications.",Hussain Kanafani,2021/5/26,2021/5/26
nucl-th/9907048v1,Space-time analysis: HBT at SPS and RHIC,http://arxiv.org/abs/nucl-th/9907048v1,"In this review talk, I first summarize the conclusions which can be drawnfrom a particle interferometric analysis of CERN SPS data and then I addressrelated questions which are relevant for the upcoming experiments at RHIC.",Urs Achim Wiedemann,1999/7/12,1999/7/12
2111.07699v1,Measuring Uncertainty in Translation Quality Evaluation (TQE),http://arxiv.org/abs/2111.07699v1,"From both human translators (HT) and machine translation (MT) researchers'point of view, translation quality evaluation (TQE) is an essential task.Translation service providers (TSPs) have to deliver large volumes oftranslations which meet customer specifications with harsh constraints ofrequired quality level in tight time-frames and costs. MT researchers strive tomake their models better, which also requires reliable quality evaluation.While automatic machine translation evaluation (MTE) metrics and qualityestimation (QE) tools are widely available and easy to access, existingautomated tools are not good enough, and human assessment from professionaltranslators (HAP) are often chosen as the golden standard\cite{han-etal-2021-TQA}. Human evaluations, however, are often accused ofhaving low reliability and agreement. Is this caused by subjectivity orstatistics is at play? How to avoid the entire text to be checked and be moreefficient with TQE from cost and efficiency perspectives, and what is theoptimal sample size of the translated text, so as to reliably estimate thetranslation quality of the entire material? This work carries out suchmotivated research to correctly estimate the confidence intervals\cite{Brown_etal2001Interval} depending on the sample size of the translatedtext, e.g. the amount of words or sentences, that needs to be processed on TQEworkflow step for confident and reliable evaluation of overall translationquality. The methodology we applied for this work is from Bernoulli StatisticalDistribution Modelling (BSDM) and Monte Carlo Sampling Analysis (MCSA).",Serge Gladkoff,2021/11/15,2021/11/15
2102.10613v1,Multi-species consensus network of DNA strand displacement for concentration-to-strand translation,http://arxiv.org/abs/2102.10613v1,"We propose novel chemical reaction networks to translate levels ofconcentration into unique DNA strand species, which we call concentrationtranslators. Our design of the concentration translators is based oncombination of two chemical reaction networks, consensus network and conversionnetwork with any number of chemical species. We give geometric analysis of theproposed CRNs from the viewpoint of nonlinear dynamical systems and show thatthe CRNs can actually operate as translator. Our concentration translatorsexploit DNA strand displacement (DSD) reaction, which is known for a universalreaction that can implement arbitrary chemical reaction networks. Wedemonstrate two specific types of concentration translators (translator A andB) with different switching behavior and biochemical cost and compared theircharacteristics computationally. The proposed concentration translators have anadvantage of being able to readout the concentration of targeted nucleic acidstrand without any fluorescence-based techniques. These characteristics can betailored according to requirements from applications, including dynamic range,sensitivity and implementation cost.",Toshiyuki Yamane,2021/2/21,2021/2/21
hep-th/9601159v1,The Analysis of Time-Space Translations in Quantum Fields,http://arxiv.org/abs/hep-th/9601159v1,"I discuss the indefinite metrical structure of the time-space translations asrealized in the indefinite inner products for relativistic quantum fields,familiar in the example of quantum gauge fields. The arising indefinite unitarynondiagonalizable representations of the translations suggest as the positiveunitarity condition for the probability interpretable positive definiteasymptotic particle state space the requirement of a vanishing nilpotent partin the time-space translations realization. A trivial Becchi-Rouet-Stora charge(classical gauge invariance) for the asymptotics in quantum gauge theories canbe interpreted as one special case of this general principle - the asymptoticprojection to the eigenstates of the time-space translations.",Heinrich Saller,1996/1/30,1996/1/30
1805.10553v1,Translators asymptotic to cylinders,http://arxiv.org/abs/1805.10553v1,"We show that the Bowl soliton in $\mathbb{R}^3$ is the unique translatingsolutions of the mean curvature flow which has the family of shrinkingcylinders as an asymptotic shrinker at $-\infty$. As an application, we showthat for a generic mean curvature flow, all (non-static) translating limitflows are the bowl soliton. The crucial point is that we do not make any globalconvexity assumption, while as the same time, the asymptotic requirement isvery weak.",Or Hershkovits,2018/5/26,2018/5/26
2008.11257v1,The Impact of Indirect Machine Translation on Sentiment Classification,http://arxiv.org/abs/2008.11257v1,"Sentiment classification has been crucial for many natural languageprocessing (NLP) applications, such as the analysis of movie reviews, tweets,or customer feedback. A sufficiently large amount of data is required to builda robust sentiment classification system. However, such resources are notalways available for all domains or for all languages.  In this work, we propose employing a machine translation (MT) system totranslate customer feedback into another language to investigate in which casestranslated sentences can have a positive or negative impact on an automaticsentiment classifier. Furthermore, as performing a direct translation is notalways possible, we explore the performance of automatic classifiers onsentences that have been translated using a pivot MT system.  We conduct several experiments using the above approaches to analyse theperformance of our proposed sentiment classification system and discuss theadvantages and drawbacks of classifying translated sentences.",Alberto Poncelas,2020/8/25,2020/8/25
2308.13715v1,A Computational Evaluation Framework for Singable Lyric Translation,http://arxiv.org/abs/2308.13715v1,"Lyric translation plays a pivotal role in amplifying the global resonance ofmusic, bridging cultural divides, and fostering universal connections.Translating lyrics, unlike conventional translation tasks, requires a delicatebalance between singability and semantics. In this paper, we present acomputational framework for the quantitative evaluation of singable lyrictranslation, which seamlessly integrates musical, linguistic, and culturaldimensions of lyrics. Our comprehensive framework consists of four metrics thatmeasure syllable count distance, phoneme repetition similarity, musicalstructure distance, and semantic similarity. To substantiate the efficacy ofour framework, we collected a singable lyrics dataset, which precisely alignsEnglish, Japanese, and Korean lyrics on a line-by-line and section-by-sectionbasis, and conducted a comparative analysis between singable and non-singablelyrics. Our multidisciplinary approach provides insights into the keycomponents that underlie the art of lyric translation and establishes a solidgroundwork for the future of computational lyric translation assessment.",Haven Kim,2023/8/26,2023/8/26
2202.03086v4,Machine Translation from Signed to Spoken Languages: State of the Art and Challenges,http://arxiv.org/abs/2202.03086v4,"Automatic translation from signed to spoken languages is an interdisciplinaryresearch domain, lying on the intersection of computer vision, machinetranslation and linguistics. Nevertheless, research in this domain is performedmostly by computer scientists in isolation. As the domain is becomingincreasingly popular - the majority of scientific papers on the topic of signlanguage translation have been published in the past three years - we providean overview of the state of the art as well as some required background in thedifferent related disciplines. We give a high-level introduction to signlanguage linguistics and machine translation to illustrate the requirements ofautomatic sign language translation. We present a systematic literature reviewto illustrate the state of the art in the domain and then, harking back to therequirements, lay out several challenges for future research. We find thatsignificant advances have been made on the shoulders of spoken language machinetranslation research. However, current approaches are often not linguisticallymotivated or are not adapted to the different input modality of sign languages.We explore challenges related to the representation of sign language data, thecollection of datasets, the need for interdisciplinary research andrequirements for moving beyond research, towards applications. Based on ourfindings, we advocate for interdisciplinary research and to base futureresearch on linguistic analysis of sign languages. Furthermore, the inclusionof deaf and hearing end users of sign language translation applications in usecase identification, data collection and evaluation is of the utmost importancein the creation of useful sign language translation models. We recommenditerative, human-in-the-loop, design and development of sign languagetranslation models.",Mathieu De Coster,2022/2/7,2023/4/5
1806.06397v2,MedGAN: Medical Image Translation using GANs,http://arxiv.org/abs/1806.06397v2,"Image-to-image translation is considered a new frontier in the field ofmedical image analysis, with numerous potential applications. However, a largeportion of recent approaches offers individualized solutions based onspecialized task-specific architectures or require refinement throughnon-end-to-end training. In this paper, we propose a new framework, namedMedGAN, for medical image-to-image translation which operates on the imagelevel in an end-to-end manner. MedGAN builds upon recent advances in the fieldof generative adversarial networks (GANs) by merging the adversarial frameworkwith a new combination of non-adversarial losses. We utilize a discriminatornetwork as a trainable feature extractor which penalizes the discrepancybetween the translated medical images and the desired modalities. Moreover,style-transfer losses are utilized to match the textures and fine-structures ofthe desired target images to the translated images. Additionally, we present anew generator architecture, titled CasNet, which enhances the sharpness of thetranslated medical outputs through progressive refinement via encoder-decoderpairs. Without any application-specific modifications, we apply MedGAN on threedifferent tasks: PET-CT translation, correction of MR motion artefacts and PETimage denoising. Perceptual analysis by radiologists and quantitativeevaluations illustrate that the MedGAN outperforms other existing translationapproaches.",Karim Armanious,2018/6/17,2019/4/4
2305.17867v1,Automatic Synthesis of Low-Complexity Translation Operators for the Fast Multipole Method,http://arxiv.org/abs/2305.17867v1,"We demonstrate a new, hybrid symbolic-numerical method for the automaticsynthesis of all families of translation operators required for the executionof the Fast Multipole Method (FMM). Our method is applicable in anydimensionality and to any translation-invariant kernel. The Fast MultipoleMethod, of course, is the leading approach for attaining linear complexity inthe evaluation of long-range (e.g. Coulomb) many-body interactions. Lowcomplexity in translation operators for the Fast Multipole Method (FMM) isusually achieved by algorithms specialized for a potential obeying a specificpartial differential equation (PDE). Absent a PDE or specialized algorithms,Taylor series based FMMs or kernel-independent FMM have been used, atasymptotically higher expense.  When symbolically provided with a constant-coefficient elliptic PDE obeyed bythe potential, our algorithm can automatically synthesize translation operatorsrequiring $\mathrm{O}(p^d)$ operations, where $p$ is the expansion order and$d$ is dimension, compared with $\mathrm{O}(p^{2d})$ operations in a naiveapproach carried out on (Cartesian) Taylor expansions. This is achieved byusing a compression scheme that asymptotically reduces the number of terms inthe Taylor expansion and then operating directly on this ``compressed''representation. Judicious exploitation of shared subexpressions permitsformation, translation, and evaluation of local and multipole expansions to beperformed in $\mathrm{O}(p^{d})$ operations, while an FFT-based scheme permitsmultipole-to-local translations in $\mathrm{O}(p^{d-1}\log(p))$ operations. Wedemonstrate computational scaling of code generation and evaluation as well asnumerical accuracy through numerical experiments on a number of potentials fromclassical physics.",Isuru Fernando,2023/5/29,2023/5/29
2210.16609v1,$\mathcal{H}^2$-matrices for translation-invariant kernel functions,http://arxiv.org/abs/2210.16609v1,"Boundary element methods for elliptic partial differential equationstypically lead to boundary integral operators with translation-invariant kernelfunctions. Taking advantage of this property is fairly simple for particlemethods, e.g., Nystrom-type discretizations, but more challenging if thesupports of basis functions have to be taken into account.  In this article, we present a modified construction for$\mathcal{H}^2$-matrices that uses translation-invariance to significantlyreduce the storage requirements. Due to the uniformity of the boxes used forthe construction, we need only a few uncomplicated assumptions to proveestimates for the resulting storage complexity.",Steffen Brm,2022/10/29,2022/10/29
2102.09493v1,Inferring Graph Signal Translations as Invariant Transformations for Classification Tasks,http://arxiv.org/abs/2102.09493v1,"The field of Graph Signal Processing (GSP) has proposed tools to generalizeharmonic analysis to complex domains represented through graphs. Among thesetools are translations, which are required to define many others. Most workspropose to define translations using solely the graph structure (i.e. edges).Such a problem is ill-posed in general as a graph conveys information aboutneighborhood but not about directions. In this paper, we propose to infertranslations as edge-constrained operations that make a supervisedclassification problem invariant using a deep learning framework. As such, ourmethodology uses both the graph structure and labeled signals to infertranslations. We perform experiments with regular 2D images and abstracthyperlink networks to show the effectiveness of the proposed methodology ininferring meaningful translations for signals supported on graphs.",Raphael Baena,2021/2/18,2021/2/18
1703.03666v1,Comparison of SMT and RBMT; The Requirement of Hybridization for Marathi-Hindi MT,http://arxiv.org/abs/1703.03666v1,"We present in this paper our work on comparison between Statistical MachineTranslation (SMT) and Rule-based machine translation for translation fromMarathi to Hindi. Rule Based systems although robust take lots of time tobuild. On the other hand statistical machine translation systems are easier tocreate, maintain and improve upon. We describe the development of a basicMarathi-Hindi SMT system and evaluate its performance. Through a detailed erroranalysis, we, point out the relative strengths and weaknesses of both systems.Effectively, we shall see that even with a small amount of training corpus astatistical machine translation system has many advantages for high qualitydomain specific machine translation over that of a rule-based counterpart.",Sreelekha. S,2017/3/10,2017/3/10
2009.09654v2,Generative Imagination Elevates Machine Translation,http://arxiv.org/abs/2009.09654v2,"There are common semantics shared across text and images. Given a sentence ina source language, whether depicting the visual scene helps translation into atarget language? Existing multimodal neural machine translation methods (MNMT)require triplets of bilingual sentence - image for training and tuples ofsource sentence - image for inference. In this paper, we propose ImagiT, anovel machine translation method via visual imagination. ImagiT first learns togenerate visual representation from the source sentence, and then utilizes bothsource sentence and the ""imagined representation"" to produce a targettranslation. Unlike previous methods, it only needs the source sentence at theinference time. Experiments demonstrate that ImagiT benefits from visualimagination and significantly outperforms the text-only neural machinetranslation baselines. Further analysis reveals that the imagination process inImagiT helps fill in missing information when performing the degradationstrategy.",Quanyu Long,2020/9/21,2021/4/13
2105.06977v3,Do Context-Aware Translation Models Pay the Right Attention?,http://arxiv.org/abs/2105.06977v3,"Context-aware machine translation models are designed to leverage contextualinformation, but often fail to do so. As a result, they inaccuratelydisambiguate pronouns and polysemous words that require context for resolution.In this paper, we ask several questions: What contexts do human translators useto resolve ambiguous words? Are models paying large amounts of attention to thesame context? What if we explicitly train them to do so? To answer thesequestions, we introduce SCAT (Supporting Context for Ambiguous Translations), anew English-French dataset comprising supporting context words for 14Ktranslations that professional translators found useful for pronoundisambiguation. Using SCAT, we perform an in-depth analysis of the context usedto disambiguate, examining positional and lexical characteristics of thesupporting words. Furthermore, we measure the degree of alignment between themodel's attention scores and the supporting context from SCAT, and apply aguided attention strategy to encourage agreement between the two.",Kayo Yin,2021/5/14,2021/8/7
2210.15851v1,Improving Zero-Shot Multilingual Translation with Universal Representations and Cross-Mappings,http://arxiv.org/abs/2210.15851v1,"The many-to-many multilingual neural machine translation can translatebetween language pairs unseen during training, i.e., zero-shot translation.Improving zero-shot translation requires the model to learn universalrepresentations and cross-mapping relationships to transfer the knowledgelearned on the supervised directions to the zero-shot directions. In this work,we propose the state mover's distance based on the optimal theory to model thedifference of the representations output by the encoder. Then, we bridge thegap between the semantic-equivalent representations of different languages atthe token level by minimizing the proposed distance to learn universalrepresentations. Besides, we propose an agreement-based training scheme, whichcan help the model make consistent predictions based on the semantic-equivalentsentences to learn universal cross-mapping relationships for all translationdirections. The experimental results on diverse multilingual datasets show thatour method can improve consistently compared with the baseline system and othercontrast methods. The analysis proves that our method can better align thesemantic space and improve the prediction consistency.",Shuhao Gu,2022/10/28,2022/10/28
1211.2517v2,A SVD accelerated kernel-independent fast multipole method and its application to BEM,http://arxiv.org/abs/1211.2517v2,"The kernel-independent fast multipole method (KIFMM) proposed in [1] is ofalmost linear complexity. In the original KIFMM the time-consuming M2Ltranslations are accelerated by FFT. However, when more equivalent points areused to achieve higher accuracy, the efficiency of the FFT approach tends to belower because more auxiliary volume grid points have to be added. In thispaper, all the translations of the KIFMM are accelerated by using the singularvalue decomposition (SVD) based on the low-rank property of the translatingmatrices. The acceleration of M2L is realized by first transforming theassociated translating matrices into more compact form, and then using low-rankapproximations. By using the transform matrices for M2L, the orders of thetranslating matrices in upward and downward passes are also reduced. Theimproved KIFMM is then applied to accelerate BEM. The performance of theproposed algorithms are demonstrated by three examples. Numerical results showthat, compared with the original KIFMM, the present method can reduce about 40%of the iterating time and 25% of the memory requirement.",Yanchuang Cao,2012/11/12,2013/3/12
1510.06124v3,Hierarchy of knowledge translation: from health problems to ad-hoc drug design,http://arxiv.org/abs/1510.06124v3,"An innovative approach to analyze the complexity of translating novelmolecular entities and nanomaterials into pharmaceutical alternatives (i.e.,knowledge translation, KT) is discussed. First, some key concepts on theorganization and translation of the biomedical knowledge (paradigms, homophily,power law distributions, hierarchy, modularity, and research fronts) arereviewed. Then, we propose a model for the knowledge translation (KT) in DrugDiscovery that considers the complexity of interdisciplinary communication.Specifically, we address two highly relevant aspects: 1) A successful KTrequires the emergence of organized bodies of inter-and transdisciplinaryresearch, and 2) The hierarchical and modular topological organization of thesebodies of knowledge. We focused on a set of previously-published studies on KTwhich rely on a combination of network analysis and computer-assisted analysisof the contents of scientific literature and patents. The selected studiesprovide a duo of complementary perspectives: the demand of knowledge (cervicalcancer and Ebola hemorrhagic fever) and the supply of knowledge (liposomes andnanoparticles to treat cancer and the paradigmatic Doxil, the first nanodrug tobe approved).",David Fajardo,2015/10/21,2015/10/26
2202.04306v1,Can Open Domain Question Answering Systems Answer Visual Knowledge Questions?,http://arxiv.org/abs/2202.04306v1,"The task of Outside Knowledge Visual Question Answering (OKVQA) requires anautomatic system to answer natural language questions about pictures and imagesusing external knowledge. We observe that many visual questions, which containdeictic referential phrases referring to entities in the image, can berewritten as ""non-grounded"" questions and can be answered by existingtext-based question answering systems. This allows for the reuse of existingtext-based Open Domain Question Answering (QA) Systems for visual questionanswering. In this work, we propose a potentially data-efficient approach thatreuses existing systems for (a) image analysis, (b) question rewriting, and (c)text-based question answering to answer such visual questions. Given an imageand a question pertaining to that image (a visual question), we first extractthe entities present in the image using pre-trained object and sceneclassifiers. Using these detected entities, the visual questions can berewritten so as to be answerable by open domain QA systems. We explore tworewriting strategies: (1) an unsupervised method using BERT for masking andrewriting, and (2) a weakly supervised approach that combines adaptiverewriting and reinforcement learning techniques to use the implicit feedbackfrom the QA system. We test our strategies on the publicly available OKVQAdataset and obtain a competitive performance with state-of-the-art models whileusing only 10% of the training data.",Jiawen Zhang,2022/2/9,2022/2/9
1606.05433v4,FVQA: Fact-based Visual Question Answering,http://arxiv.org/abs/1606.05433v4,"Visual Question Answering (VQA) has attracted a lot of attention in bothComputer Vision and Natural Language Processing communities, not least becauseit offers insight into the relationships between two important sources ofinformation. Current datasets, and the models built upon them, have focused onquestions which are answerable by direct analysis of the question and imagealone. The set of such questions that require no external information to answeris interesting, but very limited. It excludes questions which require commonsense, or basic factual knowledge to answer, for example. Here we introduceFVQA, a VQA dataset which requires, and supports, much deeper reasoning. FVQAonly contains questions which require external information to answer.  We thus extend a conventional visual question answering dataset, whichcontains image-question-answerg triplets, through additionalimage-question-answer-supporting fact tuples. The supporting fact isrepresented as a structural triplet, such as <Cat,CapableOf,ClimbingTrees>.  We evaluate several baseline models on the FVQA dataset, and describe a novelmodel which is capable of reasoning about an image on the basis of supportingfacts.",Peng Wang,2016/6/17,2017/8/8
2211.07455v1,Towards Robust Numerical Question Answering: Diagnosing Numerical Capabilities of NLP Systems,http://arxiv.org/abs/2211.07455v1,"Numerical Question Answering is the task of answering questions that requirenumerical capabilities. Previous works introduce general adversarial attacks toNumerical Question Answering, while not systematically exploring numericalcapabilities specific to the topic. In this paper, we propose to conductnumerical capability diagnosis on a series of Numerical Question Answeringsystems and datasets. A series of numerical capabilities are highlighted, andcorresponding dataset perturbations are designed. Empirical results indicatethat existing systems are severely challenged by these perturbations. E.g.,Graph2Tree experienced a 53.83% absolute accuracy drop against the ``Extra''perturbation on ASDiv-a, and BART experienced 13.80% accuracy drop against the``Language'' perturbation on the numerical subset of DROP. As a counteractingapproach, we also investigate the effectiveness of applying perturbations asdata augmentation to relieve systems' lack of robust numerical capabilities.With experiment analysis and empirical studies, it is demonstrated thatNumerical Question Answering with robust numerical capabilities is still to alarge extent an open question. We discuss future directions of NumericalQuestion Answering and summarize guidelines on future dataset collection andsystem design.",Jialiang Xu,2022/11/14,2022/11/14
1904.08607v1,Progressive Attention Memory Network for Movie Story Question Answering,http://arxiv.org/abs/1904.08607v1,"This paper proposes the progressive attention memory network (PAMN) for moviestory question answering (QA). Movie story QA is challenging compared to VQA intwo aspects: (1) pinpointing the temporal parts relevant to answer the questionis difficult as the movies are typically longer than an hour, (2) it has bothvideo and subtitle where different questions require different modality toinfer the answer. To overcome these challenges, PAMN involves three mainfeatures: (1) progressive attention mechanism that utilizes cues from bothquestion and answer to progressively prune out irrelevant temporal parts inmemory, (2) dynamic modality fusion that adaptively determines the contributionof each modality for answering the current question, and (3) belief correctionanswering scheme that successively corrects the prediction score on eachcandidate answer. Experiments on publicly available benchmark datasets, MovieQAand TVQA, demonstrate that each feature contributes to our movie story QAarchitecture, PAMN, and improves performance to achieve the state-of-the-artresult. Qualitative analysis by visualizing the inference mechanism of PAMN isalso provided.",Junyeong Kim,2019/4/18,2019/4/18
1712.00733v1,Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks,http://arxiv.org/abs/1712.00733v1,"Visual Question Answering (VQA) has attracted much attention since it offersinsight into the relationships between the multi-modal analysis of images andnatural language. Most of the current algorithms are incapable of answeringopen-domain questions that require to perform reasoning beyond the imagecontents. To address this issue, we propose a novel framework which endows themodel capabilities in answering more complex questions by leveraging massiveexternal knowledge with dynamic memory networks. Specifically, the questionsalong with the corresponding images trigger a process to retrieve the relevantinformation in external knowledge bases, which are embedded into a continuousvector space by preserving the entity-relation structures. Afterwards, weemploy dynamic memory networks to attend to the large body of facts in theknowledge graph and images, and then perform reasoning over these facts togenerate corresponding answers. Extensive experiments demonstrate that ourmodel not only achieves the state-of-the-art performance in the visual questionanswering task, but can also answer open-domain questions effectively byleveraging the external knowledge.",Guohao Li,2017/12/3,2017/12/3
2205.03966v2,Chart Question Answering: State of the Art and Future Directions,http://arxiv.org/abs/2205.03966v2,"Information visualizations such as bar charts and line charts are very commonfor analyzing data and discovering critical insights. Often people analyzecharts to answer questions that they have in mind. Answering such questions canbe challenging as they often require a significant amount of perceptual andcognitive effort. Chart Question Answering (CQA) systems typically take a chartand a natural language question as input and automatically generate the answerto facilitate visual data analysis. Over the last few years, there has been agrowing body of literature on the task of CQA. In this survey, wesystematically review the current state-of-the-art research focusing on theproblem of chart question answering. We provide a taxonomy by identifyingseveral important dimensions of the problem domain including possible inputsand outputs of the task and discuss the advantages and limitations of proposedsolutions. We then summarize various evaluation techniques used in the surveyedpapers. Finally, we outline the open challenges and future researchopportunities related to chart question answering.",Enamul Hoque,2022/5/8,2022/5/21
1705.06824v2,Learning Convolutional Text Representations for Visual Question Answering,http://arxiv.org/abs/1705.06824v2,"Visual question answering is a recently proposed artificial intelligence taskthat requires a deep understanding of both images and texts. In deep learning,images are typically modeled through convolutional neural networks, and textsare typically modeled through recurrent neural networks. While the requirementfor modeling images is similar to traditional computer vision tasks, such asobject recognition and image classification, visual question answering raises adifferent need for textual representation as compared to other natural languageprocessing tasks. In this work, we perform a detailed analysis on naturallanguage questions in visual question answering. Based on the analysis, wepropose to rely on convolutional neural networks for learning textualrepresentations. By exploring the various properties of convolutional neuralnetworks specialized for text data, such as width and depth, we present our""CNN Inception + Gate"" model. We show that our model improves questionrepresentations and thus the overall accuracy of visual question answeringmodels. We also show that the text representation requirement in visualquestion answering is more complicated and comprehensive than that inconventional natural language processing tasks, making it a better task toevaluate textual representation methods. Shallow models like fastText, whichcan obtain comparable results with deep learning models in tasks like textclassification, are not suitable in visual question answering.",Zhengyang Wang,2017/5/18,2018/4/18
2101.02235v1,Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies,http://arxiv.org/abs/2101.02235v1,"A key limitation in current datasets for multi-hop reasoning is that therequired steps for answering the question are mentioned in it explicitly. Inthis work, we introduce StrategyQA, a question answering (QA) benchmark wherethe required reasoning steps are implicit in the question, and should beinferred using a strategy. A fundamental challenge in this setup is how toelicit such creative questions from crowdsourcing workers, while covering abroad range of potential strategies. We propose a data collection procedurethat combines term-based priming to inspire annotators, careful control overthe annotator population, and adversarial filtering for eliminating reasoningshortcuts. Moreover, we annotate each question with (1) a decomposition intoreasoning steps for answering it, and (2) Wikipedia paragraphs that contain theanswers to each step. Overall, StrategyQA includes 2,780 examples, eachconsisting of a strategy question, its decomposition, and evidence paragraphs.Analysis shows that questions in StrategyQA are short, topic-diverse, and covera wide range of strategies. Empirically, we show that humans perform well (87%)on this task, while our best baseline reaches an accuracy of $\sim$66%.",Mor Geva,2021/1/6,2021/1/6
2107.14420v3,Talk2Data: A Natural Language Interface for Exploratory Visual Analysis via Question Decomposition,http://arxiv.org/abs/2107.14420v3,"Through a natural language interface (NLI) for exploratory visual analysis,users can directly ""ask"" analytical questions about the given tabular data.This process greatly improves user experience and lowers the technical barriersof data analysis. Existing techniques focus on generating a visualization froma concrete question. However, complex questions, requiring multiple dataqueries and visualizations to answer, are frequently asked in data explorationand analysis, which cannot be easily solved with the existing techniques. Toaddress this issue, in this paper, we introduce Talk2Data, a natural languageinterface for exploratory visual analysis that supports answering complexquestions. It leverages an advanced deep-learning model to resolve complexquestions into a series of simple questions that could gradually elaborate onthe users' requirements. To present answers, we design a set of annotated andcaptioned visualizations to represent the answers in a form that supportsinterpretation and narration. We conducted an ablation study and a controlleduser study to evaluate Talk2Data's effectiveness and usefulness.",Yi Guo,2021/7/30,2023/5/16
2208.03030v1,ChiQA: A Large Scale Image-based Real-World Question Answering Dataset for Multi-Modal Understanding,http://arxiv.org/abs/2208.03030v1,"Visual question answering is an important task in both natural language andvision understanding. However, in most of the public visual question answeringdatasets such as VQA, CLEVR, the questions are human generated that specific tothe given image, such as `What color are her eyes?'. The human generatedcrowdsourcing questions are relatively simple and sometimes have the biastoward certain entities or attributes. In this paper, we introduce a newquestion answering dataset based on image-ChiQA. It contains the real-worldqueries issued by internet users, combined with several related open-domainimages. The system should determine whether the image could answer the questionor not. Different from previous VQA datasets, the questions are real-worldimage-independent queries that are more various and unbiased. Compared withprevious image-retrieval or image-caption datasets, the ChiQA not only measuresthe relatedness but also measures the answerability, which demands morefine-grained vision and language reasoning. ChiQA contains more than 40Kquestions and more than 200K question-images pairs. A three-level 2/1/0 labelis assigned to each pair indicating perfect answer, partially answer andirrelevant. Data analysis shows ChiQA requires a deep understanding of bothlanguage and vision, including grounding, comparisons, and reading. We evaluateseveral state-of-the-art visual-language models such as ALBEF, demonstratingthat there is still a large room for improvements on ChiQA.",Bingning Wang,2022/8/5,2022/8/5
2210.06628v1,OpenCQA: Open-ended Question Answering with Charts,http://arxiv.org/abs/2210.06628v1,"Charts are very popular to analyze data and convey important insights. Peopleoften analyze visualizations to answer open-ended questions that requireexplanatory answers. Answering such questions are often difficult andtime-consuming as it requires a lot of cognitive and perceptual efforts. Toaddress this challenge, we introduce a new task called OpenCQA, where the goalis to answer an open-ended question about a chart with descriptive texts. Wepresent the annotation process and an in-depth analysis of our dataset. Weimplement and evaluate a set of baselines under three practical settings. Inthe first setting, a chart and the accompanying article is provided as input tothe model. The second setting provides only the relevant paragraph(s) to thechart instead of the entire article, whereas the third setting requires themodel to generate an answer solely based on the chart. Our analysis of theresults show that the top performing models generally produce fluent andcoherent text while they struggle to perform complex logical and arithmeticreasoning.",Shankar Kantharaj,2022/10/12,2022/10/12
1906.00067v2,OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge,http://arxiv.org/abs/1906.00067v2,"Visual Question Answering (VQA) in its ideal form lets us study reasoning inthe joint space of vision and language and serves as a proxy for the AI task ofscene understanding. However, most VQA benchmarks to date are focused onquestions such as simple counting, visual attributes, and object detection thatdo not require reasoning or knowledge beyond what is in the image. In thispaper, we address the task of knowledge-based visual question answering andprovide a benchmark, called OK-VQA, where the image content is not sufficientto answer the questions, encouraging methods that rely on external knowledgeresources. Our new dataset includes more than 14,000 questions that requireexternal knowledge to answer. We show that the performance of thestate-of-the-art VQA models degrades drastically in this new setting. Ouranalysis shows that our knowledge-based VQA task is diverse, difficult, andlarge compared to previous knowledge-based VQA datasets. We hope that thisdataset enables researchers to open up new avenues for research in this domain.See http://okvqa.allenai.org to download and browse the dataset.",Kenneth Marino,2019/5/31,2019/9/4
2009.12770v1,Hierarchical Deep Multi-modal Network for Medical Visual Question Answering,http://arxiv.org/abs/2009.12770v1,"Visual Question Answering in Medical domain (VQA-Med) plays an important rolein providing medical assistance to the end-users. These users are expected toraise either a straightforward question with a Yes/No answer or a challengingquestion that requires a detailed and descriptive answer. The existingtechniques in VQA-Med fail to distinguish between the different question typessometimes complicates the simpler problems, or over-simplifies the complicatedones. It is certainly true that for different question types, several distinctsystems can lead to confusion and discomfort for the end-users. To address thisissue, we propose a hierarchical deep multi-modal network that analyzes andclassifies end-user questions/queries and then incorporates a query-specificapproach for answer prediction. We refer our proposed approach as HierarchicalQuestion Segregation based Visual Question Answering, in short HQS-VQA. Ourcontributions are three-fold, viz. firstly, we propose a question segregation(QS) technique for VQAMed; secondly, we integrate the QS model to thehierarchical deep multi-modal neural network to generate proper answers to thequeries related to medical images; and thirdly, we study the impact of QS inMedical-VQA by comparing the performance of the proposed model with QS and amodel without QS. We evaluate the performance of our proposed model on twobenchmark datasets, viz. RAD and CLEF18. Experimental results show that ourproposed HQS-VQA technique outperforms the baseline models with significantmargins. We also conduct a detailed quantitative and qualitative analysis ofthe obtained results and discover potential causes of errors and theirsolutions.",Deepak Gupta,2020/9/27,2020/9/27
1908.06917v1,Message Passing for Complex Question Answering over Knowledge Graphs,http://arxiv.org/abs/1908.06917v1,"Question answering over knowledge graphs (KGQA) has evolved from simplesingle-fact questions to complex questions that require graph traversal andaggregation. We propose a novel approach for complex KGQA that usesunsupervised message passing, which propagates confidence scores obtained byparsing an input question and matching terms in the knowledge graph to a set ofpossible answers. First, we identify entity, relationship, and class namesmentioned in a natural language question, and map these to their counterpartsin the graph. Then, the confidence scores of these mappings propagate throughthe graph structure to locate the answer entities. Finally, these areaggregated depending on the identified question type. This approach can beefficiently implemented as a series of sparse matrix multiplications mimickingjoins over small local subgraphs. Our evaluation results show that the proposedapproach outperforms the state-of-the-art on the LC-QuAD benchmark. Moreover,we show that the performance of the approach depends only on the quality of thequestion interpretation results, i.e., given a correct relevance scoredistribution, our approach always produces a correct answer ranking. Our erroranalysis reveals correct answers missing from the benchmark dataset andinconsistencies in the DBpedia knowledge graph. Finally, we provide acomprehensive evaluation of the proposed approach accompanied with an ablationstudy and an error analysis, which showcase the pitfalls for each of thequestion answering components in more detail.",Svitlana Vakulenko,2019/8/19,2019/8/19
1603.01417v1,Dynamic Memory Networks for Visual and Textual Question Answering,http://arxiv.org/abs/1603.01417v1,"Neural network architectures with memory and attention mechanisms exhibitcertain reasoning capabilities required for question answering. One sucharchitecture, the dynamic memory network (DMN), obtained high accuracy on avariety of language tasks. However, it was not shown whether the architectureachieves strong results for question answering when supporting facts are notmarked during training or whether it could be applied to other modalities suchas images. Based on an analysis of the DMN, we propose several improvements toits memory and input modules. Together with these changes we introduce a novelinput module for images in order to be able to answer visual questions. Our newDMN+ model improves the state of the art on both the Visual Question Answeringdataset and the \babi-10k text question-answering dataset without supportingfact supervision.",Caiming Xiong,2016/3/4,2016/3/4
2206.01718v1,A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge,http://arxiv.org/abs/2206.01718v1,"The Visual Question Answering (VQA) task aspires to provide a meaningfultestbed for the development of AI models that can jointly reason over visualand natural language inputs. Despite a proliferation of VQA datasets, this goalis hindered by a set of common limitations. These include a reliance onrelatively simplistic questions that are repetitive in both concepts andlinguistic structure, little world knowledge needed outside of the pairedimage, and limited reasoning required to arrive at the correct answer. Weintroduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about25K questions requiring a broad base of commonsense and world knowledge toanswer. In contrast to the existing knowledge-based VQA datasets, the questionsgenerally cannot be answered by simply querying a knowledge base, and insteadrequire some form of commonsense reasoning about the scene depicted in theimage. We demonstrate the potential of this new dataset through a detailedanalysis of its contents and baseline performance measurements over a varietyof state-of-the-art vision-language models. Project page:http://a-okvqa.allenai.org/",Dustin Schwenk,2022/6/3,2022/6/3
1903.07113v2,Question Answering via Web Extracted Tables and Pipelined Models,http://arxiv.org/abs/1903.07113v2,"In this paper, we describe a dataset and baseline result for a questionanswering that utilizes web tables. It contains commonly asked questions on theweb and their corresponding answers found in tables on websites. Our dataset isnovel in that every question is paired with a table of a different signature.In particular, the dataset contains two classes of tables: entity-instancetables and the key-value tables. Each QA instance comprises a table of eitherkind, a natural language question, and a corresponding structured SQL query. Webuild our model by dividing question answering into several tasks, includingtable retrieval and question element classification, and conduct experiments tomeasure the performance of each task. We extract various features specific toeach task and compose a full pipeline which constructs the SQL query from itsparts. Our work provides qualitative results and error analysis for each task,and identifies in detail the reasoning required to generate SQL expressionsfrom natural language questions. This analysis of reasoning informs futuremodels based on neural machine learning.",Bhavya Karki,2019/3/17,2019/4/16
2307.14712v1,Evaluating Generative Models for Graph-to-Text Generation,http://arxiv.org/abs/2307.14712v1,"Large language models (LLMs) have been widely employed for graph-to-textgeneration tasks. However, the process of finetuning LLMs requires significanttraining resources and annotation work. In this paper, we explore thecapability of generative models to generate descriptive text from graph data ina zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on twograph-to-text datasets and compare their performance with that of finetuned LLMmodels such as T5 and BART. Our results demonstrate that generative models arecapable of generating fluent and coherent text, achieving BLEU scores of 10.57and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our erroranalysis reveals that generative models still struggle with understanding thesemantic relations between entities, and they also tend to generate text withhallucinations or irrelevant information. As a part of error analysis, weutilize BERT to detect machine-generated text and achieve high macro-F1 scores.We have made the text generated by generative models publicly available.",Shuzhou Yuan,2023/7/27,2023/7/27
2302.07979v2,PRedItOR: Text Guided Image Editing with Diffusion Prior,http://arxiv.org/abs/2302.07979v2,"Diffusion models have shown remarkable capabilities in generating highquality and creative images conditioned on text. An interesting application ofsuch models is structure preserving text guided image editing. Existingapproaches rely on text conditioned diffusion models such as Stable Diffusionor Imagen and require compute intensive optimization of text embeddings orfine-tuning the model weights for text guided image editing. We explore textguided image editing with a Hybrid Diffusion Model (HDM) architecture similarto DALLE-2. Our architecture consists of a diffusion prior model that generatesCLIP image embedding conditioned on a text prompt and a custom Latent DiffusionModel trained to generate images conditioned on CLIP image embedding. Wediscover that the diffusion prior model can be used to perform text guidedconceptual edits on the CLIP image embedding space without any finetuning oroptimization. We combine this with structure preserving edits on the imagedecoder using existing approaches such as reverse DDIM to perform text guidedimage editing. Our approach, PRedItOR does not require additional inputs,fine-tuning, optimization or objectives and shows on par or better results thanbaselines qualitatively and quantitatively. We provide further analysis andunderstanding of the diffusion prior model and believe this opens up newpossibilities in diffusion models research.",Hareesh Ravi,2023/2/15,2023/3/20
2310.05009v1,WikiIns: A High-Quality Dataset for Controlled Text Editing by Natural Language Instruction,http://arxiv.org/abs/2310.05009v1,"Text editing, i.e., the process of modifying or manipulating text, is acrucial step in human writing process. In this paper, we study the problem ofcontrolled text editing by natural language instruction. According to a giveninstruction that conveys the edit intention and necessary information, anoriginal draft text is required to be revised into a target text. Existingautomatically constructed datasets for this task are limited because they donot have informative natural language instruction. The informativeness requiresthe information contained in the instruction to be enough to produce therevised text. To address this limitation, we build and release WikiIns, ahigh-quality controlled text editing dataset with improved informativeness. Wefirst preprocess the Wikipedia edit history database to extract the raw data(WikiIns-Raw). Then we crowdsource high-quality validation and test sets, aswell as a small-scale training set (WikiIns-Gold). With the high-qualityannotated dataset, we further propose automatic approaches to generate alarge-scale ``silver'' training set (WikiIns-Silver). Finally, we provide someinsightful analysis on our WikiIns dataset, including the evaluation resultsand the edit intention analysis. Our analysis and the experiment results onWikiIns may assist the ongoing research on text editing. The dataset, sourcecode and annotation guideline are available athttps://github.com/CasparSwift/WikiIns.",Xiang Chen,2023/10/8,2023/10/8
2004.03212v4,Text-Guided Neural Image Inpainting,http://arxiv.org/abs/2004.03212v4,"Image inpainting task requires filling the corrupted image with contentscoherent with the context. This research field has achieved promising progressby using neural image inpainting methods. Nevertheless, there is still acritical challenge in guessing the missed content with only the context pixels.The goal of this paper is to fill the semantic information in corrupted imagesaccording to the provided descriptive text. Unique from existing text-guidedimage generation works, the inpainting models are required to compare thesemantic content of the given text and the remaining part of the image, thenfind out the semantic content that should be filled for missing part. Tofulfill such a task, we propose a novel inpainting model named Text-Guided DualAttention Inpainting Network (TDANet). Firstly, a dual multimodal attentionmechanism is designed to extract the explicit semantic information about thecorrupted regions, which is done by comparing the descriptive text andcomplementary image areas through reciprocal attention. Secondly, an image-textmatching loss is applied to maximize the semantic similarity of the generatedimage and the text. Experiments are conducted on two open datasets. Resultsshow that the proposed TDANet model reaches new state-of-the-art on bothquantitative and qualitative measures. Result analysis suggests that thegenerated images are consistent with the guidance text, enabling the generationof various results by providing different descriptions. Codes are available athttps://github.com/idealwhite/TDANet",Lisai Zhang,2020/4/7,2021/3/22
2303.15181v3,DreamStone: Image as Stepping Stone for Text-Guided 3D Shape Generation,http://arxiv.org/abs/2303.15181v3,"In this paper, we present a new text-guided 3D shape generation approachDreamStone that uses images as a stepping stone to bridge the gap between textand shape modalities for generating 3D shapes without requiring paired text and3D data. The core of our approach is a two-stage feature-space alignmentstrategy that leverages a pre-trained single-view reconstruction (SVR) model tomap CLIP features to shapes: to begin with, map the CLIP image feature to thedetail-rich 3D shape space of the SVR model, then map the CLIP text feature tothe 3D shape space through encouraging the CLIP-consistency between renderedimages and the input text. Besides, to extend beyond the generative capabilityof the SVR model, we design a text-guided 3D shape stylization module that canenhance the output shapes with novel structures and textures. Further, weexploit pre-trained text-to-image diffusion models to enhance the generativediversity, fidelity, and stylization capability. Our approach is generic,flexible, and scalable, and it can be easily integrated with various SVR modelsto expand the generative space and improve the generative fidelity. Extensiveexperimental results demonstrate that our approach outperforms thestate-of-the-art methods in terms of generative quality and consistency withthe input text. Codes and models are released athttps://github.com/liuzhengzhe/DreamStone-ISS.",Zhengzhe Liu,2023/3/24,2023/9/23
2109.10197v1,"One Source, Two Targets: Challenges and Rewards of Dual Decoding",http://arxiv.org/abs/2109.10197v1,"Machine translation is generally understood as generating one target textfrom an input source document. In this paper, we consider a strongerrequirement: to jointly generate two texts so that each output side effectivelydepends on the other. As we discuss, such a device serves several practicalpurposes, from multi-target machine translation to the generation of controlledvariations of the target text. We present an analysis of possibleimplementations of dual decoding, and experiment with four applications.Viewing the problem from multiple angles allows us to better highlight thechallenges of dual decoding and to also thoroughly analyze the benefits ofgenerating matched, rather than independent, translations.",Jitao Xu,2021/9/21,2021/9/21
2305.15605v1,Revisiting Sentence Union Generation as a Testbed for Text Consolidation,http://arxiv.org/abs/2305.15605v1,"Tasks involving text generation based on multiple input texts, such asmulti-document summarization, long-form question answering and contemporarydialogue applications, challenge models for their ability to properlyconsolidate partly-overlapping multi-text information. However, these tasksentangle the consolidation phase with the often subjective and ill-definedcontent selection requirement, impeding proper assessment of models'consolidation capabilities. In this paper, we suggest revisiting the sentenceunion generation task as an effective well-defined testbed for assessing textconsolidation capabilities, decoupling the consolidation challenge fromsubjective content selection. To support research on this task, we presentrefined annotation methodology and tools for crowdsourcing sentence union,create the largest union dataset to date and provide an analysis of its richcoverage of various consolidation aspects. We then propose a comprehensiveevaluation protocol for union generation, including both human and automaticevaluation. Finally, as baselines, we evaluate state-of-the-art language modelson the task, along with a detailed analysis of their capacity to addressmulti-text consolidation challenges and their limitations.",Eran Hirsch,2023/5/24,2023/5/24
2311.11441v1,Spot the Bot: Distinguishing Human-Written and Bot-Generated Texts Using Clustering and Information Theory Techniques,http://arxiv.org/abs/2311.11441v1,"With the development of generative models like GPT-3, it is increasingly morechallenging to differentiate generated texts from human-written ones. There isa large number of studies that have demonstrated good results in botidentification. However, the majority of such works depend on supervisedlearning methods that require labelled data and/or prior knowledge about thebot-model architecture. In this work, we propose a bot identification algorithmthat is based on unsupervised learning techniques and does not depend on alarge amount of labelled data. By combining findings in semantic analysis byclustering (crisp and fuzzy) and information techniques, we construct a robustmodel that detects a generated text for different types of bot. We find thatthe generated texts tend to be more chaotic while literary works are morecomplex. We also demonstrate that the clustering of human texts results infuzzier clusters in comparison to the more compact and well-separated clustersof bot-generated texts.",Vasilii Gromov,2023/11/19,2023/11/19
2208.15001v1,MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model,http://arxiv.org/abs/2208.15001v1,"Human motion modeling is important for many modern graphics applications,which typically require professional skills. In order to remove the skillbarriers for laymen, recent motion generation methods can directly generatehuman motions conditioned on natural languages. However, it remains challengingto achieve diverse and fine-grained motion generation with various text inputs.To address this problem, we propose MotionDiffuse, the first diffusionmodel-based text-driven motion generation framework, which demonstrates severaldesired properties over existing methods. 1) Probabilistic Mapping. Instead ofa deterministic language-motion mapping, MotionDiffuse generates motionsthrough a series of denoising steps in which variations are injected. 2)Realistic Synthesis. MotionDiffuse excels at modeling complicated datadistribution and generating vivid motion sequences. 3) Multi-LevelManipulation. MotionDiffuse responds to fine-grained instructions on bodyparts, and arbitrary-length motion synthesis with time-varied text prompts. Ourexperiments show MotionDiffuse outperforms existing SoTA methods by convincingmargins on text-driven motion generation and action-conditioned motiongeneration. A qualitative analysis further demonstrates MotionDiffuse'scontrollability for comprehensive motion generation. Homepage:https://mingyuan-zhang.github.io/projects/MotionDiffuse.html",Mingyuan Zhang,2022/8/31,2022/8/31
2211.12950v1,"Look, Read and Ask: Learning to Ask Questions by Reading Text in Images",http://arxiv.org/abs/2211.12950v1,"We present a novel problem of text-based visual question generation orTextVQG in short. Given the recent growing interest of the document imageanalysis community in combining text understanding with conversationalartificial intelligence, e.g., text-based visual question answering, TextVQGbecomes an important task. TextVQG aims to generate a natural language questionfor a given input image and an automatically extracted text also known as OCRtoken from it such that the OCR token is an answer to the generated question.TextVQG is an essential ability for a conversational agent. However, it ischallenging as it requires an in-depth understanding of the scene and theability to semantically bridge the visual content with the text present in theimage. To address TextVQG, we present an OCR consistent visual questiongeneration model that Looks into the visual content, Reads the scene text, andAsks a relevant and meaningful natural language question. We refer to ourproposed model as OLRA. We perform an extensive evaluation of OLRA on twopublic benchmarks and compare them against baselines. Our model OLRAautomatically generates questions similar to the public text-based visualquestion answering datasets that were curated manually. Moreover, wesignificantly outperform baseline approaches on the performance measurespopularly used in text generation literature.",Soumya Jahagirdar,2022/11/23,2022/11/23
2011.14037v1,Text Mining for Processing Interview Data in Computational Social Science,http://arxiv.org/abs/2011.14037v1,"We use commercially available text analysis technology to process interviewtext data from a computational social science study. We find that topicalclustering and terminological enrichment provide for convenient exploration andquantification of the responses. This makes it possible to generate and testhypotheses and to compare textual and non-textual variables, and saves analysteffort. We encourage studies in social science to use text analysis, especiallyfor exploratory open-ended studies. We discuss how replicability requirementsare met by text analysis technology. We note that the most recent learningmodels are not designed with transparency in mind, and that research requires amodel to be editable and its decisions to be explainable. The tools availabletoday, such as the one used in the present study, are not built for processinginterview texts. While many of the variables under consideration arequantifiable using lexical statistics, we find that some interesting andpotentially valuable features are difficult or impossible to automatisereliably at present. We note that there are some potentially interestingapplications for traditional natural language processing mechanisms such asnamed entity recognition and anaphora resolution in this application area. Weconclude with a suggestion for language technologists to investigate thechallenge of processing interview data comprehensively, especially theinterplay between question and response, and we encourage social scienceresearchers not to hesitate to use text analysis tools, especially for theexploratory phase of processing interview data.?",Jussi Karlgren,2020/11/28,2020/11/28
1805.11404v1,iLCM - A Virtual Research Infrastructure for Large-Scale Qualitative Data,http://arxiv.org/abs/1805.11404v1,"The iLCM project pursues the development of an integrated researchenvironment for the analysis of structured and unstructured data in a ""Softwareas a Service"" architecture (SaaS). The research environment addressesrequirements for the quantitative evaluation of large amounts of qualitativedata with text mining methods as well as requirements for the reproducibilityof data-driven research designs in the social sciences. For this, the iLCMresearch environment comprises two central components. First, the LeipzigCorpus Miner (LCM), a decentralized SaaS application for the analysis of largeamounts of news texts developed in a previous Digital Humanities project.Second, the text mining tools implemented in the LCM are extended by an ""OpenResearch Computing"" (ORC) environment for executable script documents,so-called ""notebooks"". This novel integration allows to combine generic,high-performance methods to process large amounts of unstructured text data andwith individual program scripts to address specific research requirements incomputational social science and digital humanities.",Andreas Niekler,2018/5/11,2018/5/11
2301.07389v2,Towards Models that Can See and Read,http://arxiv.org/abs/2301.07389v2,"Visual Question Answering (VQA) and Image Captioning (CAP), which are amongthe most popular vision-language tasks, have analogous scene-text versions thatrequire reasoning from the text in the image. Despite their obviousresemblance, the two are treated independently and, as we show, yieldtask-specific methods that can either see or read, but not both. In this work,we conduct an in-depth analysis of this phenomenon and propose UniTNT, aUnified Text-Non-Text approach, which grants existing multimodal architecturesscene-text understanding capabilities. Specifically, we treat scene-textinformation as an additional modality, fusing it with any pretrainedencoder-decoder-based architecture via designated modules. Thorough experimentsreveal that UniTNT leads to the first single model that successfully handlesboth task types. Moreover, we show that scene-text understanding capabilitiescan boost vision-language models' performance on general VQA and CAP by up to2.69% and 0.6 CIDEr, respectively.",Roy Ganz,2023/1/18,2023/3/21
2301.07464v2,CLIPTER: Looking at the Bigger Picture in Scene Text Recognition,http://arxiv.org/abs/2301.07464v2,"Reading text in real-world scenarios often requires understanding the contextsurrounding it, especially when dealing with poor-quality text. However,current scene text recognizers are unaware of the bigger picture as theyoperate on cropped text images. In this study, we harness the representativecapabilities of modern vision-language models, such as CLIP, to providescene-level information to the crop-based recognizer. We achieve this by fusinga rich representation of the entire image, obtained from the vision-languagemodel, with the recognizer word-level features via a gated cross-attentionmechanism. This component gradually shifts to the context-enhancedrepresentation, allowing for stable fine-tuning of a pretrained recognizer. Wedemonstrate the effectiveness of our model-agnostic framework, CLIPTER (CLIPTExt Recognition), on leading text recognition architectures and achievestate-of-the-art results across multiple benchmarks. Furthermore, our analysishighlights improved robustness to out-of-vocabulary words and enhancedgeneralization in low-data regimes.",Aviad Aberdam,2023/1/18,2023/7/23
2210.00968v1,Membership Inference Attacks Against Text-to-image Generation Models,http://arxiv.org/abs/2210.00968v1,"Text-to-image generation models have recently attracted unprecedentedattention as they unlatch imaginative applications in all areas of life.However, developing such models requires huge amounts of data that mightcontain privacy-sensitive information, e.g., face identity. While privacy riskshave been extensively demonstrated in the image classification and GANgeneration domains, privacy risks in the text-to-image generation domain arelargely unexplored. In this paper, we perform the first privacy analysis oftext-to-image generation models through the lens of membership inference.Specifically, we propose three key intuitions about membership information anddesign four attack methodologies accordingly. We conduct comprehensiveevaluations on two mainstream text-to-image generation models includingsequence-to-sequence modeling and diffusion-based modeling. The empiricalresults show that all of the proposed attacks can achieve significantperformance, in some cases even close to an accuracy of 1, and thus thecorresponding risk is much more severe than that shown by existing membershipinference attacks. We further conduct an extensive ablation study to analyzethe factors that may affect the attack performance, which can guide developersand researchers to be alert to vulnerabilities in text-to-image generationmodels. All these findings indicate that our proposed attacks pose a realisticprivacy threat to the text-to-image generation models.",Yixin Wu,2022/10/3,2022/10/3
2311.15561v1,ET3D: Efficient Text-to-3D Generation via Multi-View Distillation,http://arxiv.org/abs/2311.15561v1,"Recent breakthroughs in text-to-image generation has shown encouragingresults via large generative models. Due to the scarcity of 3D assets, it ishardly to transfer the success of text-to-image generation to that oftext-to-3D generation. Existing text-to-3D generation methods usually adopt theparadigm of DreamFusion, which conducts per-asset optimization by distilling apretrained text-to-image diffusion model. The generation speed usually rangesfrom several minutes to tens of minutes per 3D asset, which degrades the userexperience and also imposes a burden to the service providers due to the highcomputational budget.  In this work, we present an efficient text-to-3D generation method, whichrequires only around 8 $ms$ to generate a 3D asset given the text prompt on aconsumer graphic card. The main insight is that we exploit the images generatedby a large pre-trained text-to-image diffusion model, to supervise the trainingof a text conditioned 3D generative adversarial network. Once the network istrained, we are able to efficiently generate a 3D asset via a single forwardpass. Our method requires no 3D training data and provides an alternativeapproach for efficient text-to-3D generation by distilling pre-trained imagediffusion models.",Yiming Chen,2023/11/27,2023/11/27
1712.04344v1,Real-time Text Analytics Pipeline Using Open-source Big Data Tools,http://arxiv.org/abs/1712.04344v1,"Real-time text processing systems are required in many domains to quicklyidentify patterns, trends, sentiments, and insights. Nowadays, social networks,e-commerce stores, blogs, scientific experiments, and server logs are mainsources generating huge text data. However, to process huge text data in realtime requires building a data processing pipeline. The main challenge inbuilding such pipeline is to minimize latency to process high-throughput data.In this paper, we explain and evaluate our proposed real-time text processingpipeline using open-source big data tools which minimize the latency to processdata streams. Our proposed data processing pipeline is based on Apache Kafkafor data ingestion, Apache Spark for in-memory data processing, ApacheCassandra for storing processed results, and D3 JavaScript library forvisualization. We evaluate the effectiveness of the proposed pipeline undervarying deployment scenarios to perform sentiment analysis using Twitterdataset. Our experimental evaluations show less than a minute latency toprocess $466,700$ Tweets in $10.7$ minutes when three virtual machinesallocated to the proposed pipeline.",Hassan Nazeer,2017/12/12,2017/12/12
1909.09901v2,Learning a Fixed-Length Fingerprint Representation,http://arxiv.org/abs/1909.09901v2,"We present DeepPrint, a deep network, which learns to extract fixed-lengthfingerprint representations of only 200 bytes. DeepPrint incorporatesfingerprint domain knowledge, including alignment and minutiae detection, intothe deep network architecture to maximize the discriminative power of itsrepresentation. The compact, DeepPrint representation has several advantagesover the prevailing variable length minutiae representation which (i) requirescomputationally expensive graph matching techniques, (ii) is difficult tosecure using strong encryption schemes (e.g. homomorphic encryption), and (iii)has low discriminative power in poor quality fingerprints where minutiaeextraction is unreliable. We benchmark DeepPrint against two top performingCOTS SDKs (Verifinger and Innovatrics) from the NIST and FVC evaluations.Coupled with a re-ranking scheme, the DeepPrint rank-1 search accuracy on theNIST SD4 dataset against a gallery of 1.1 million fingerprints is comparable tothe top COTS matcher, but it is significantly faster (DeepPrint: 98.80% in 0.3seconds vs. COTS A: 98.85% in 27 seconds). To the best of our knowledge, theDeepPrint representation is the most compact and discriminative fixed-lengthfingerprint representation reported in the academic literature.",Joshua J. Engelsma,2019/9/21,2019/12/18
2210.09261v1,Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them,http://arxiv.org/abs/2210.09261v1,"BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite thatfocuses on tasks believed to be beyond the capabilities of current languagemodels. Language models have already made good progress on this benchmark, withthe best model in the BIG-Bench paper outperforming average reportedhuman-rater results on 65% of the BIG-Bench tasks via few-shot prompting. Buton what tasks do language models fall short of average human-rater performance,and are those tasks actually unsolvable by current language models?  In this work, we focus on a suite of 23 challenging BIG-Bench tasks which wecall BIG-Bench Hard (BBH). These are the task for which prior language modelevaluations did not outperform the average human-rater. We find that applyingchain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass theaverage human-rater performance on 10 of the 23 tasks, and Codex(code-davinci-002) to surpass the average human-rater performance on 17 of the23 tasks. Since many tasks in BBH require multi-step reasoning, few-shotprompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al.,2022), substantially underestimates the best performance and capabilities oflanguage models, which is better captured via CoT prompting. As furtheranalysis, we explore the interaction between CoT and model scale on BBH,finding that CoT enables emergent task performance on several BBH tasks withotherwise flat scaling curves.",Mirac Suzgun,2022/10/17,2022/10/17
2305.08391v1,Uncovering the Potential of ChatGPT for Discourse Analysis in Dialogue: An Empirical Study,http://arxiv.org/abs/2305.08391v1,"Large Language Models (LLMs) like ChatGPT have proven a great shallowunderstanding of many traditional NLP tasks, such as translation,summarization, etc. However, its performance on high-level understanding, suchas dialogue discourse analysis task that requires a higher level ofunderstanding and reasoning, remains less explored. This study investigatesChatGPT's capabilities in three dialogue discourse tasks: topic segmentation,discourse relation recognition, and discourse parsing, of varying difficultylevels. To adapt ChatGPT to these tasks, we propose discriminative andgenerative paradigms and introduce the Chain of Thought (COT) approach toimprove ChatGPT's performance in more difficult tasks. The results show thatour generative paradigm allows ChatGPT to achieve comparative performance inthe topic segmentation task comparable to state-of-the-art methods but revealsroom for improvement in the more complex tasks of discourse relationrecognition and discourse parsing. Notably, the COT can significantly enhanceChatGPT's performance with the help of understanding complex structures in morechallenging tasks. Through a series of case studies, our in-depth analysissuggests that ChatGPT can be a good annotator in topic segmentation but hasdifficulties understanding complex rhetorical structures. We hope thesefindings provide a foundation for future research to refine dialogue discourseanalysis approaches in the era of LLMs.",Yaxin Fan,2023/5/15,2023/5/15
2108.00730v1,YASMIN: a Real-time Middleware for COTS Heterogeneous Platforms,http://arxiv.org/abs/2108.00730v1,"Commercial-Off-The-Shelf heterogeneous platforms provide immensecomputational power, but are difficult to program and to correctly use whenreal-time requirements come into play: A sound configuration of the operatingsystem scheduler is needed, and a suitable mapping of tasks to computing unitsmust be determined. Flawed designs may lead a sub-optimal system configurationsand thus to wasted resources, or even to deadline misses and failures. Wepropose YASMIN, a middleware to schedule end-user applications with real-timerequirements in user space and on behalf of the operating system. YASMINprovides an easy-to-use programming interface and portability. It treatsheterogeneity on COTS heterogeneous embedded platforms as a first-classcitizen: It supports multiple functionally equivalent task implementations withdistinct extra-functional behaviour. This enables the system designer toquickly explore different scheduling policies and task-to-core mappings, andthus, to improve overall system performance. In this paper, we present thedesign and implementation of YASMIN and provide an analysis of the schedulingoverhead on an Odroid-XU4 platform. Last but not least, we demonstrate themerits of YASMIN on an industrial use-case involving a Search & Rescue drone.",Rouxel Benjamin,2021/8/2,2021/8/2
2310.04959v1,Towards Better Chain-of-Thought Prompting Strategies: A Survey,http://arxiv.org/abs/2310.04959v1,"Chain-of-Thought (CoT), a step-wise and coherent reasoning chain, shows itsimpressive strength when used as a prompting strategy for large language models(LLM). Recent years, the prominent effect of CoT prompting has attractedemerging research. However, there still lacks of a systematic summary about keyfactors of CoT prompting and comprehensive guide for prompts utilizing. For adeeper understanding about CoT prompting, we survey on a wide range of currentresearch, presenting a systematic and comprehensive analysis on several factorsthat may influence the effect of CoT prompting, and introduce how to betterapply it in different applications under these discussions. We further analyzethe challenges and propose some future directions about CoT prompting. Thissurvey could provide an overall reference on related research.",Zihan Yu,2023/10/8,2023/10/8
2305.11255v4,Reasoning Implicit Sentiment with Chain-of-Thought Prompting,http://arxiv.org/abs/2305.11255v4,"While sentiment analysis systems try to determine the sentiment polarities ofgiven targets based on the key opinion expressions in input texts, in implicitsentiment analysis (ISA) the opinion cues come in an implicit and obscuremanner. Thus detecting implicit sentiment requires the common-sense andmulti-hop reasoning ability to infer the latent intent of opinion. Inspired bythe recent chain-of-thought (CoT) idea, in this work we introduce a Three-hopReasoning (THOR) CoT framework to mimic the human-like reasoning process forISA. We design a three-step prompting principle for THOR to step-by-step inducethe implicit aspect, opinion, and finally the sentiment polarity. OurTHOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 onsupervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50%F1 on zero-shot setting. Our code is open athttps://github.com/scofield7419/THOR-ISA.",Hao Fei,2023/5/18,2023/6/9
2305.14740v2,ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning,http://arxiv.org/abs/2305.14740v2,"We introduce ECHo (Event Causality Inference via Human-Centric Reasoning), adiagnostic dataset of event causality inference grounded in visio-linguisticsocial scenarios. ECHo employs real-world human-centric deductive informationbuilding on a television crime drama. ECHo requires the Theory-of-Mind (ToM)ability to understand and reason about social interactions based on multimodalinformation. Using ECHo, we propose a unified Chain-of-Thought (CoT) frameworkto assess the reasoning capability of current AI systems. Our ToM-enhanced CoTpipeline accommodates various large foundation models in both zero-shot andfew-shot visio-linguistic reasoning. We use this framework to scrutinize recentlarge foundation models such as InstructGPT and MiniGPT-4 on three diagnostichuman-centric tasks. Further analysis demonstrates ECHo as a challengingdataset to expose imperfections and inconsistencies in reasoning. Our data andcode are publicly available at https://github.com/YuxiXie/ECHo.",Yuxi Xie,2023/5/24,2023/10/23
2304.03262v2,When do you need Chain-of-Thought Prompting for ChatGPT?,http://arxiv.org/abs/2304.03262v2,"Chain-of-Thought (CoT) prompting can effectively elicit complex multi-stepreasoning from Large Language Models~(LLMs). For example, by simply adding CoTinstruction ``Let's think step-by-step'' to each input query of MultiArithdataset, GPT-3's accuracy can be improved from 17.7\% to 78.7\%. However, it isnot clear whether CoT is still effective on more recent instruction finetuned(IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longereffective for certain tasks such as arithmetic reasoning while still keepingeffective on other reasoning tasks. Moreover, on the former tasks, ChatGPTusually achieves the best performance and can generate CoT even without beinginstructed to do so. Hence, it is plausible that ChatGPT has already beentrained on these tasks with CoT and thus memorized the instruction so itimplicitly follows such an instruction when applied to the same queries, evenwithout CoT. Our analysis reflects a potential risk of overfitting/bias towardinstructions introduced in IFT, which becomes more common in training LLMs. Inaddition, it indicates possible leakage of the pretraining recipe, e.g., onecan verify whether a dataset and instruction were used in training ChatGPT. Ourexperiments report new baseline results of ChatGPT on a variety of reasoningtasks and shed novel insights into LLM's profiling, instruction memorization,and pretraining dataset leakage.",Jiuhai Chen,2023/4/6,2023/4/18
2210.01240v4,Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought,http://arxiv.org/abs/2210.01240v4,"Large language models (LLMs) have shown remarkable reasoning capabilitiesgiven chain-of-thought prompts (examples with intermediate reasoning steps).Existing benchmarks measure reasoning ability indirectly, by evaluatingaccuracy on downstream tasks such as mathematical reasoning. However, it isunclear how these models obtain the answers and whether they rely on simpleheuristics rather than the generated chain-of-thought. To enable systematicexploration of the reasoning ability of LLMs, we present a new syntheticquestion-answering dataset called PrOntoQA, where each example is generatedfrom a synthetic world model represented in first-order logic. This allows usto parse the generated chain-of-thought into symbolic proofs for formalanalysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quitecapable of making correct individual deduction steps, and so are generallycapable of reasoning, even in fictional contexts. However, they have difficultywith proof planning: When multiple valid deduction steps are available, theyare not able to systematically explore the different options.",Abulhair Saparov,2022/10/3,2023/3/2
2304.13007v3,Answering Questions by Meta-Reasoning over Multiple Chains of Thought,http://arxiv.org/abs/2304.13007v3,"Modern systems for multi-hop question answering (QA) typically breakquestions into a sequence of reasoning steps, termed chain-of-thought (CoT),before arriving at a final answer. Often, multiple chains are sampled andaggregated through a voting mechanism over the final answers, but theintermediate steps themselves are discarded. While such approaches improveperformance, they do not consider the relations between intermediate stepsacross chains and do not provide a unified explanation for the predictedanswer. We introduce Multi-Chain Reasoning (MCR), an approach which promptslarge language models to meta-reason over multiple chains of thought, ratherthan aggregating their answers. MCR examines different reasoning chains, mixesinformation between them and selects the most relevant facts in generating anexplanation and predicting the answer. MCR outperforms strong baselines on 7multi-hop QA datasets. Moreover, our analysis reveals that MCR explanationsexhibit high quality, enabling humans to verify its answers.",Ori Yoran,2023/4/25,2023/10/17
2304.02015v1,How well do Large Language Models perform in Arithmetic tasks?,http://arxiv.org/abs/2304.02015v1,"Large language models have emerged abilities including chain-of-thought toanswer math word problems step by step. Solving math word problems not onlyrequires abilities to disassemble problems via chain-of-thought but also needsto calculate arithmetic expressions correctly for each step. To the best of ourknowledge, there is no work to focus on evaluating the arithmetic ability oflarge language models. In this work, we propose an arithmetic dataset MATH 401to test the latest large language models including GPT-4, ChatGPT, InstrctGPT,Galactica, and LLaMA with various arithmetic expressions and provide a detailedanalysis of the ability of large language models. MATH 401 and evaluation codesare released at \url{https://github.com/GanjinZero/math401-llm}.",Zheng Yuan,2023/3/16,2023/3/16
2310.16069v2,CPSeg: Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting,http://arxiv.org/abs/2310.16069v2,"Natural scene analysis and remote sensing imagery offer immense potential foradvancements in large-scale language-guided context-aware data utilization.This potential is particularly significant for enhancing performance indownstream tasks such as object detection and segmentation with designedlanguage prompting. In light of this, we introduce the CPSeg, Chain-of-ThoughtLanguage Prompting for Finer-grained Semantic Segmentation), an innovativeframework designed to augment image segmentation performance by integrating anovel ""Chain-of-Thought"" process that harnesses textual information associatedwith images. This groundbreaking approach has been applied to a flood disasterscenario. CPSeg encodes prompt texts derived from various sentences toformulate a coherent chain-of-thought. We propose a new vision-languagedataset, FloodPrompt, which includes images, semantic masks, and correspondingtext information. This not only strengthens the semantic understanding of thescenario but also aids in the key task of semantic segmentation through aninterplay of pixel and text matching maps. Our qualitative and quantitativeanalyses validate the effectiveness of CPSeg.",Lei Li,2023/10/24,2023/10/26
2310.12049v1,Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models,http://arxiv.org/abs/2310.12049v1,"Existing text scaling methods often require a large corpus, struggle withshort texts, or require labeled data. We develop a text scaling method thatleverages the pattern recognition capabilities of generative large languagemodels (LLMs). Specifically, we propose concept-guided chain-of-thought(CGCoT), which uses prompts designed to summarize ideas and identify targetparties in texts to generate concept-specific breakdowns, in many ways similarto guidance for human coder content analysis. CGCoT effectively shifts pairwisetext comparisons from a reasoning problem to a pattern recognition problem. Wethen pairwise compare concept-specific breakdowns using an LLM. We use theresults of these pairwise comparisons to estimate a scale using theBradley-Terry model. We use this approach to scale affective speech on Twitter.Our measures correlate more strongly with human judgments than alternativeapproaches like Wordfish. Besides a small set of pilot data to develop theCGCoT prompts, our measures require no additional labeled data and producebinary predictions comparable to a RoBERTa-Large model fine-tuned on thousandsof human-labeled tweets. We demonstrate how combining substantive knowledgewith LLMs can create state-of-the-art measures of abstract concepts.",Patrick Y. Wu,2023/10/18,2023/10/18
2305.13826v1,"""Is the Pope Catholic?"" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures",http://arxiv.org/abs/2305.13826v1,"Conversational implicatures are pragmatic inferences that require listenersto deduce the intended meaning conveyed by a speaker from their explicitutterances. Although such inferential reasoning is fundamental to humancommunication, recent research indicates that large language models struggle tocomprehend these implicatures as effectively as the average human. This paperdemonstrates that by incorporating Grice's Four Maxims into the model throughchain-of-thought prompting, we can significantly enhance its performance,surpassing even the average human performance on this task.",Zae Myung Kim,2023/5/23,2023/5/23
2312.11524v1,Assessing GPT4-V on Structured Reasoning Tasks,http://arxiv.org/abs/2312.11524v1,"Multi-modality promises to unlock further uses for large language models.Recently, the state-of-the-art language model GPT-4 was enhanced with visioncapabilities. We carry out a prompting evaluation of GPT-4V and five otherbaselines on structured reasoning tasks, such as mathematical reasoning, visualdata analysis, and code generation. We show that visual Chain-of-Thought, anextension of Chain-of-Thought to multi-modal LLMs, yields significantimprovements over the vanilla model. We also present a categorized analysis ofscenarios where these models perform well and where they struggle, highlightingchallenges associated with coherent multimodal reasoning.",Mukul Singh,2023/12/13,2023/12/13
2311.10227v1,Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities,http://arxiv.org/abs/2311.10227v1,"Human interactions are deeply rooted in the interplay of thoughts, beliefs,and desires made possible by Theory of Mind (ToM): our cognitive ability tounderstand the mental states of ourselves and others. Although ToM may comenaturally to us, emulating it presents a challenge to even the most advancedLarge Language Models (LLMs). Recent improvements to LLMs' reasoningcapabilities from simple yet effective prompting techniques such asChain-of-Thought have seen limited applicability to ToM. In this paper, we turnto the prominent cognitive science theory ""Simulation Theory"" to bridge thisgap. We introduce SimToM, a novel two-stage prompting framework inspired bySimulation Theory's notion of perspective-taking. To implement this idea oncurrent ToM benchmarks, SimToM first filters context based on what thecharacter in question knows before answering a question about their mentalstate. Our approach, which requires no additional training and minimalprompt-tuning, shows substantial improvement over existing methods, and ouranalysis reveals the importance of perspective-taking to Theory-of-Mindcapabilities. Our findings suggest perspective-taking as a promising directionfor future research into improving LLMs' ToM capabilities.",Alex Wilf,2023/11/16,2023/11/16
2312.08762v1,Multi-modal Latent Space Learning for Chain-of-Thought Reasoning in Language Models,http://arxiv.org/abs/2312.08762v1,"Chain-of-thought (CoT) reasoning has exhibited impressive performance inlanguage models for solving complex tasks and answering questions. However,many real-world questions require multi-modal information, such as text andimages. Previous research on multi-modal CoT has primarily focused onextracting fixed image features from off-the-shelf vision models and thenfusing them with text using attention mechanisms. This approach has limitationsbecause these vision models were not designed for complex reasoning tasks anddo not align well with language thoughts. To overcome this limitation, weintroduce a novel approach for multi-modal CoT reasoning that utilizes latentspace learning via diffusion processes to generate effective image featuresthat align with language thoughts. Our method fuses image features and textrepresentations at a deep level and improves the complex reasoning ability ofmulti-modal CoT. We demonstrate the efficacy of our proposed method onmulti-modal ScienceQA and machine translation benchmarks, achievingstate-of-the-art performance on ScienceQA. Overall, our approach offers a morerobust and effective solution for multi-modal reasoning in language models,enhancing their ability to tackle complex real-world problems.",Liqi He,2023/12/14,2023/12/14
2308.09115v1,MaScQA: A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models,http://arxiv.org/abs/2308.09115v1,"Information extraction and textual comprehension from materials literatureare vital for developing an exhaustive knowledge base that enables acceleratedmaterials discovery. Language models have demonstrated their capability toanswer domain-specific questions and retrieve information from knowledge bases.However, there are no benchmark datasets in the materials domain that canevaluate the understanding of the key concepts by these language models. Inthis work, we curate a dataset of 650 challenging questions from the materialsdomain that require the knowledge and skills of a materials student who hascleared their undergraduate degree. We classify these questions based on theirstructure and the materials science domain-based subcategories. Further, weevaluate the performance of GPT-3.5 and GPT-4 models on solving these questionsvia zero-shot and chain of thought prompting. It is observed that GPT-4 givesthe best performance (~62% accuracy) as compared to GPT-3.5. Interestingly, incontrast to the general observation, no significant improvement in accuracy isobserved with the chain of thought prompting. To evaluate the limitations, weperformed an error analysis, which revealed conceptual errors (~64%) as themajor contributor compared to computational errors (~36%) towards the reducedperformance of LLMs. We hope that the dataset and analysis performed in thiswork will promote further research in developing better materials sciencedomain-specific LLMs and strategies for information extraction.",Mohd Zaki,2023/8/17,2023/8/17
1608.02757v1,A Rule-Based Change Impact Analysis Approach in Software Architecture for Requirements Changes,http://arxiv.org/abs/1608.02757v1,"Software systems usually operate in a dynamic context where theirrequirements change continuously and new requirements emerge frequently. Asingle requirement hardly exists in isolation: it is related to otherrequirements and to the software development artifacts that implement it. Whena requirements change is introduced, the requirements engineer may have tomanually analyze all requirements and architectural elements for a singlechange. This may result in neglecting the actual impact of a change. We aim atimproving change impact analysis in software architecture for requirementschanges by using formal semantics of requirements relations, requirementschanges and traces between Requirements & Architecture. In our previous work wepresented a technique for change impact analysis in requirements. The techniqueuses the formal semantics of requirements relations and changes. Its output isa set of candidate requirements for the impact with proposed changes and apropagation path in the requirements model. In this paper we present acomplementary technique which propagates requirements changes to softwarearchitecture and finds out which architectural elements are impacted by thesechanges. The formalization of requirements relations, changes and tracesbetween R&A is used to determine candidate architectural elements for theimpact of requirements changes in the architecture. The tool support is anextension of our Tool for Requirements Inferencing and Consistency Checking(TRIC). Our approach helps in the elimination of some false positive impacts inchange propagation. We illustrate our approach in an industrial example whichshows that the formal semantics of requirements relations, changes and tracesenables the identification of candidate architectural elements with thereduction of some false positive impacts.",Arda Goknil,2016/8/9,2016/8/9
2104.06033v4,Not All Requirements Prioritization Criteria Are Equal at All Times: A Quantitative Analysis,http://arxiv.org/abs/2104.06033v4,"Requirement prioritization is recognized as an important decision-makingactivity in requirements engineering and software development. Requirementprioritization is applied to determine which requirements should be implementedand released. In order to prioritize requirements, there are severalapproaches/techniques/tools that use different requirements prioritizationcriteria, which are often identified by gut feeling instead of an in-depthanalysis of which criteria are most important to use. Therefore, in this studywe investigate which requirements prioritization criteria are most important touse in industry when determining which requirements are implemented andreleased, and if the importance of the criteria change depending on how far arequirement has reached in the development process. We conducted a quantitativestudy of one completed project from one software developing company byextracting 32,139 requirements prioritization decisions based on eightrequirements prioritization criteria for 11,110 requirements. The results showthat not all requirements prioritization criteria are equally important, andthis change depending on how far a requirement has reached in the developmentprocess.",Richard Berntsson Svensson,2021/4/13,2023/12/20
1002.3008v1,Cognitive Process of Comprehension in Requirement Analysis in IT Applications,http://arxiv.org/abs/1002.3008v1,"Requirement Analysis is an important phase in software development whichdeals with understanding the customers requirements. It includes the collectionof information from the customer, which is regarding the customers requirementsand what he expects from the software which is to be developed. By doing so,you can have a better understanding of what the customer actually needs andhence can deliver the output as per the customers requirements. Studies arebeing carried out to bring about improvements in the process of requirementanalysis so that errors in software development could be minimized and henceimproved and reliable products could be delivered.",Abhishek Kotnala,2010/2/16,2010/2/16
2104.14110v1,"Requirements Contracts: Definition, Design, and Analysis",http://arxiv.org/abs/2104.14110v1,"What are the necessary and sufficient conditions for a proposition to becalled a requirement? In Requirements Engineering research, a proposition is arequirement if and only if specific grammatical and/or communication conditionshold. I offer an alternative, that a proposition is a requirement if and onlyif specific contractual, economic, and engineering relationships hold. Iintroduce and define the concept of ""Requirements Contract"" which defines theseconditions. I argue that seeing requirements as propositions governed byspecific types of contracts leads to new and interesting questions for thefield, and relates requirements engineering to such topics as economicincentives, interest alignment, principal agent problem, and decision-makingwith incomplete information.",Ivan J. Jureta,2021/4/29,2021/4/29
1109.2285v1,Case study and analysis of WAN Optimization pre-requirements,http://arxiv.org/abs/1109.2285v1,"This paper deals with HOW to analyze the requirements for setting up the WANOptimizer. The criteria's that needs to be taken into account, the stepsinvolved in the analysis of WAN optimization requirement. These entire analyseswill give a complete framework for setting up a WAN optimizer within anorganization and the organization will have a clear record on the analysis madebefore setting up this WAN Optimizer.",Bhargav. Balakrishnan,2011/9/11,2011/9/11
1702.02977v1,Scalability Analysis of the RADAR Decision Support Tool,http://arxiv.org/abs/1702.02977v1,This report presents a theoretical complexity analysis and empiricalscalability analysis of the Requirements and Architecture Decision Analyser(RADAR).,Saheed A. Busari,2017/2/9,2017/2/9
2103.02255v1,Automatically detecting the conflicts between software requirements based on finer semantic analysis,http://arxiv.org/abs/2103.02255v1,"Context: Conflicts between software requirements bring uncertainties toproduct development. Some great approaches have been proposed to identify theseconflicts. However, they usually require the software requirements representedwith specific templates and/or depend on other external source which is oftenuneasy to build for lots of projects in practice. Objective: We aim to proposean approach Finer Semantic Analysis-based Requirements Conflict Detector(FSARC) to automatically detecting the conflicts between the given naturallanguage functional requirements by analyzing their finer semanticcompositions. Method: We build a harmonized semantic meta-model of functionalrequirements with the form of eight-tuple. Then we propose algorithms toautomatically analyze the linguistic features of requirements and to annotatethe semantic elements for their semantic model construction. And we defineseven types of conflicts as long as their heuristic detecting rules on theground of their text pattern and semantical dependency. Finally, we design andimplement the algorithm for conflicts detection. Results: The experiment withfour requirement datasets illustrates that the recall of FSARC is nearly 100%and the average precision is 83.88% on conflicts detection. Conclusion: Weprovide a useful tool for detecting the conflicts between natural languagefunctional requirements to improve the quality of the final requirements set.Besides, our approach is capable of transforming the natural languagefunctional requirements into eight semantic tuples, which is useful not onlythe detection of the conflicts between requirements but also some other taskssuch as constructing the association between requirements and so on.",Weize Guo,2021/3/3,2021/3/3
2208.00825v1,How Do Requirements Evolve During Elicitation? An Empirical Study Combining Interviews and App Store Analysis,http://arxiv.org/abs/2208.00825v1,"Requirements are elicited from the customer and other stakeholders through aniterative process of interviews, prototyping, and other interactive sessions.Then, requirements can be further extended, based on the analysis of thefeatures of competing products available on the market. Understanding how thisprocess takes place can help to identify the contribution of the differentelicitation phases, thereby allowing requirements analysts to better distributetheir resources. In this work, we empirically study in which way requirementsget transformed from initial ideas into documented needs, and then evolve basedon the inspiration coming from similar products. To this end, we select 30subjects that act as requirements analysts, and we perform interview-basedelicitation sessions with a fictional customer. After the sessions, theanalysts produce a first set of requirements for the system. Then, they arerequired to search similar products in the app stores, and extend therequirements, inspired by the identified apps. The requirements documented ateach step are evaluated, to assess to which extent and in which way the initialidea evolved throughout the process. Our results show that only between 30\%and 38\% of the requirements produced after the interviews include content thatcan be fully traced to initial customer's ideas. Furthermore, up to 42\% of therequirements inspired by the app stores cover additional features compared tothe ones identified after the interviews. The results empirically show thatrequirements are not elicited in strict sense, but actually co-created throughinterviews, with analysts playing a crucial role in the process. In addition,we show evidence that app store-inspired elicitation can be particularlybeneficial to complete the requirements.",Alessio Ferrari,2022/8/1,2022/8/1
1610.06307v1,Breakdown of a Benchmark Score Without Internal Analysis of Benchmarking Program,http://arxiv.org/abs/1610.06307v1,"A breakdown of a benchmark score is how much each aspect of the systemperformance affects the score. Existing methods require internal analysis onthe benchmarking program and then involve the following problems: (1) require acertain amount of labor for code analysis, profiling, simulation, and so on and(2) require the benchmarking program itself. In this paper, we present a methodfor breaking down a benchmark score without internal analysis of thebenchmarking program. The method utilizes regression analysis of benchmarkscores on a number of systems. Experimental results with 3 benchmarks on 15Android smartphones showed that our method could break down those benchmarkscores even though there is room for improvement in accuracy.",Naoki Matagawa,2016/10/20,2016/10/20
1912.07817v1,"Prema: A Tool for Precise Requirements Editing, Modeling and Analysis",http://arxiv.org/abs/1912.07817v1,"We present Prema, a tool for Precise Requirement Editing, Modeling andAnalysis. It can be used in various fields for describing precise requirementsusing formal notations and performing rigorous analysis. By parsing therequirements written in formal modeling language, Prema is able to get a modelwhich aptly depicts the requirements. It also provides different rigorousverification and validation techniques to check whether the requirements meetusers' expectation and find potential errors. We show that our tool can providea unified environment for writing and verifying requirements without usingtools that are not well inter-related. For experimental demonstration, we usethe requirements of the automatic train protection (ATP) system of CASCO signalco. LTD., the largest railway signal control system manufacturer of China. Thecode of the tool cannot be released here because the project is commerciallyconfidential. However, a demonstration video of the tool is available athttps://youtu.be/BX0yv8pRMWs.",Yihao Huang,2019/12/17,2019/12/17
2103.00781v1,validation method to improve behavioral flows on uml requirements analysis model by cross-checking with state transition model,http://arxiv.org/abs/2103.00781v1,"We propose a method to evaluate and improve the validity of requiredspecifications by comparing models from different viewpoints. Inconsistenciesare automatically extracted from the model in which the analyst defines theservice procedure based on the initial requirement; thereafter, the analystautomatically compares it with a state transition model from the same initialrequirement that has been created by an evaluator who is different from theanalyst. The identified inconsistencies are reported to the analyst to enablethe improvement of the required specifications. We develop a tool forextraction and comparison and then discuss its effectiveness by applying themethod to a requirements specification example.",Hikaru Morita,2021/3/1,2021/3/1
1803.05367v1,Integrating UML with Service Refinement for Requirements Modeling and Analysis,http://arxiv.org/abs/1803.05367v1,"Unified Modeling Language (UML) is the de facto standard for requirementsmodeling and system design. UML as a visual language can tremendously helpcustomers, project managers, and developers to specify the requirements of atarget system. However, UML lacks the ability to specify the requirementsprecisely such as the contracts of the system operation, and verify theconsistency and refinement of the requirements. These disadvantages result inthat the potential faults of software are hard to be discovered in the earlystage of software development process, and then requiring more efforts insoftware testing to find the bugs. Service refinement is a formal method, whichcould be a supplement to enhance the UML. In this paper, we show how tointegrate UML with service refinement to specify requirements, and verify theconsistency and refinements of the requirements through a case study of onlineshopping system. Particularly, requirements are modeled through UML diagrams,which includes a) use case diagram, b) system sequence diagrams and c)conceptual class diagram. Service refinement enhances the requirements model byintroducing the contracts. Furthermore, the consistency and refinements ofrequirement model can be verified through service refinement. Our approachdemonstrates integrating UML with service refinement can require fewer effortsto achieve the consistency requirements than only using UML for requirementmodeling.",Yilong Yang,2018/3/14,2018/3/14
2212.10375v2,Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering,http://arxiv.org/abs/2212.10375v2,"Despite the surprising few-shot performance of in-context learning (ICL), itis still a common practice to randomly sample examples to serve as context.This paper advocates a new principle for ICL: self-adaptive in-contextlearning. The self-adaption mechanism is introduced to help each sample find anin-context example permutation (i.e., selection and ordering) that can derivethe correct prediction, thus maximizing performance. To validate theeffectiveness of self-adaptive ICL, we propose a general select-then-rankframework and instantiate it with new selection and ranking algorithms. Uponextensive evaluation on eight different NLP datasets, our self-adaptive ICLmethod achieves a 40% relative improvement over the common practice setting.Further analysis reveals the enormous potential of self-adaptive ICL that itmight be able to close the gap between ICL and finetuning given more advancedalgorithms. Our code is released to facilitate future research in this area:https://github.com/Shark-NLP/self-adaptive-ICL",Zhiyong Wu,2022/12/20,2023/5/3
2301.00234v3,A Survey on In-context Learning,http://arxiv.org/abs/2301.00234v3,"With the increasing ability of large language models (LLMs), in-contextlearning (ICL) has become a new paradigm for natural language processing (NLP),where LLMs make predictions only based on contexts augmented with a fewexamples. It has been a new trend to explore ICL to evaluate and extrapolatethe ability of LLMs. In this paper, we aim to survey and summarize the progressand challenges of ICL. We first present a formal definition of ICL and clarifyits correlation to related studies. Then, we organize and discuss advancedtechniques, including training strategies, demonstration designing strategies,as well as related analysis. Finally, we discuss the challenges of ICL andprovide potential directions for further research. We hope that our work canencourage more research on uncovering how ICL works and improving ICL.",Qingxiu Dong,2022/12/31,2023/6/1
1811.03253v2,Theoretical Predictions of Colors and Metallicity of the Intra-Cluster Light,http://arxiv.org/abs/1811.03253v2,"We study colors and metallicities of the Brightest Cluster Galaxies (BCGs)and Intra-Cluster Light (ICL) in galaxy groups and clusters, as predicted by asemi-analytic model of galaxy formation, coupled with a set of high-resolutionN-body simulations. The model assumes stellar stripping and violent relaxationprocesses during galaxy mergers to be the main channels for the formation ofthe ICL. We find that BCGs are more metal-rich and redder than the ICL, at allredshifts since the ICL starts to form ($z\sim 1$). In good agreement withseveral observed data, our model predicts negative radial metallicity and colorgradients in the BCG+ICL system. By comparing the typical colors of the ICLwith those of satellite galaxies, we find that mass and metals in the ICL comefrom galaxies of different mass, depending on the redshift. Stripping of lowmass galaxies, $9<\log M_* <10$, is the most important contributor in the earlystage of the ICL formation, but the bulk of the mass/metals contents are givenby intermediate/massive galaxies, $10<\log M_* <11$, at lower redshift. Ouranalysis supports the idea that stellar stripping is more important than galaxymergers in building-up the ICL, and highlights the importance ofcolors/metallicity measurements for understanding the formation and evolutionof the ICL.",E. Contini,2018/11/8,2018/11/26
1710.03240v1,Intracluster Light at the Frontier II: The Frontier Fields Clusters,http://arxiv.org/abs/1710.03240v1,"Multiwavelength deep observations are a key tool to understand the origin ofthe diffuse light in clusters of galaxies: the intra-cluster light (ICL). Forthis reason, we take advantage of the Hubble Frontier Fields survey toinvestigate the properties of the stellar populations of the ICL of its 6massive intermediate redshift (0.3<z<0.6) clusters. We carry on this analysisdown to a radial distance of ~120 kpc from the brightest cluster galaxy. Wefound that the average metallicity of the ICL is [Fe/H] ~-0.5, compatible withthe value of the outskirts of the Milky Way. The mean stellar ages of the ICLare between 2 to 6 Gyr younger than the most massive galaxies of the clusters.Those results suggest that the ICL of these massive (> 10^15 Msol) clusters isformed by the stripping of MW-like objects that have been accreted at z<1, inagreement with current simulations. We do not find any significant increase inthe fraction of light of the ICL with cosmic time, although the redshift rangeexplored is narrow to derive any strong conclusion. When exploring the slope ofthe stellar mass density profile, we found that the ICL of the HFF clustersfollows the shape of their underlying dark matter haloes, in agreement with theidea that the ICL is the result of the stripping of galaxies at recent times.",Mireia Montes,2017/10/9,2017/10/9
2302.11042v2,In-context Example Selection with Influences,http://arxiv.org/abs/2302.11042v2,"In-context learning (ICL) is a powerful paradigm emerged from large languagemodels (LLMs). Despite its promises, ICL performance is known to be highlysensitive to input examples. In this work, we use $\textit{in-contextinfluences}$ to analyze few-shot ICL performance directly from the in-contextexamples. Our proposed influence-based example selection method can identifyboth positive and negative examples, outperforming several baselines whenevaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\%$performance gap between using the most negative in-context examples compared tothe most positive. In a case study, we apply our influence-based framework toquantify the phenomena of recency bias in example ordering for few-shot ICL.",Tai Nguyen,2023/2/21,2023/6/5
2311.07811v1,"In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax",http://arxiv.org/abs/2311.07811v1,"In-context learning (ICL) is now a common method for supervising largelanguage models (LLMs): given labeled examples in the input context, the LLMlearns to perform the task without weight updates. Despite ICL's prevalence andutility, we understand little about whether models supervised in this mannerrepresent the underlying structure of their tasks, rather than superficialheuristics that only generalize to identically distributed examples. In thisstudy, we investigate the robustness of LLMs supervised via ICL using the testcase of sensitivity to syntax, which is a prerequisite for robust languageunderstanding. Our experiments are based on two simple and well-controlledsyntactic transformations tasks, where correct out-of-distributiongeneralization requires an accurate syntactic analysis of the input. We furtherinvestigate whether out-of-distribution generalization can be improved viachain-of-thought prompting, where the model is provided with a sequence ofintermediate computation steps that illustrate how the task ought to beperformed. In experiments with models from the GPT, PaLM, and Llama 2 families,we find large variance across LMs on this fundamental linguistic phenomenon,and that the variance is explained more by the composition of the pre-trainingcorpus and supervision methods than by model size. In particular, we findevidence that models pre-trained on code generalize better, and benefit to agreater extent from chain-of-thought prompting.",Aaron Mueller,2023/11/13,2023/11/13
2303.08119v3,How Many Demonstrations Do You Need for In-context Learning?,http://arxiv.org/abs/2303.08119v3,"Large language models (LLMs) are capable to perform complex reasoning byin-context learning (ICL) when provided with a few input-output demonstrations(demos) and more powerful when intermediate reasoning steps (""chain of thoughts(CoT)"") of the demos are given. Is it necessary to use multi-demo in ICL? Inthis paper, we study ICL using fewer demos for each test query on the tasksin~\cite{wei2022chain}. Surprisingly, we do not observe significant degradationwhen using only one randomly chosen demo. To study this phenomenon, for eachtest query, we categorize demos into ""correct demos"" leading to the correctanswer, and ""wrong demos"" resulting in wrong answers. Our analysis reveals aninherent bias in those widely studied datasets: most demos are correct for amajority of test queries, which explains the good performance of using onerandom demo. Moreover, ICL (with and w/o CoT) using only one correct demosignificantly outperforms all-demo ICL adopted by most previous works,indicating the weakness of LLMs in finding correct demo(s) for input queries,which is difficult to evaluate on the biased datasets. Furthermore, we observea counterintuitive behavior of ICL using multi-demo, i.e., its accuracydegrades(improves) when given more correct(wrong) demos. This implies that ICLcan be easily misguided by interference among demos and their spuriouscorrelations. Our analyses highlight several fundamental challenges that needto be addressed in LLMs training, ICL, and benchmark design.",Jiuhai Chen,2023/3/14,2023/4/24
2310.20135v2,The Connection between the Intracluster Light and its Host Halo: Formation Time and Contribution from Different Channels,http://arxiv.org/abs/2310.20135v2,"We extend the analysis presented in \cite{contini2023a} to higher redshifts,up to $z=2$, by focusing on the relation between the intracluster light (ICL)fraction and the halo mass, its dependence with redshift, role played by thehalo concentration and formation time, in a large sample of simulated galaxygroups/clusters with $13\lesssim \log M_{halo} \lesssim 15$. Moreover, a keyfocus is to isolate the relative contributions provided by the main channelsfor the ICL formation to the total amount. The ICL fraction at higher redshiftis weakly dependent on halo mass, and comparable with that at the present time,in agreement with recent observations. Stellar stripping, mergers andpre-processing are the major responsible channels of the ICL formation, withstellar stripping that accounts for $\sim 90\%$ of the total ICL, regardless ofhalo mass and redshift. Pre-processing is an important process for clusters toaccrete already formed ICL. The diffuse component forms very early, $z\sim0.6$, and its formation depends on both concentration and formation time of thehalo, with more concentrated and earlier formed haloes that assemble their ICLearlier than later formed ones. The efficiency of this process is independentof halo mass, but increases with decreasing redshift, which implies thatstellar stripping becomes more important with time as the concentrationincreases. This highlights the link between the ICL and the dynamical state ofa halo: groups/clusters that have a higher fraction of diffuse light are moreconcentrated, relaxed and in an advanced stage of growth.",Emanuele Contini,2023/10/31,2023/11/15
2311.18021v1,Understanding and Improving In-Context Learning on Vision-language Models,http://arxiv.org/abs/2311.18021v1,"Recently, in-context learning (ICL) on large language models (LLMs) hasreceived great attention, and this technique can also be applied tovision-language models (VLMs) built upon LLMs. These VLMs can respond toqueries by conditioning responses on a series of multimodal demonstrations,which comprise images, queries, and answers. Though ICL has been extensivelystudied on LLMs, its research on VLMs remains limited. The inclusion ofadditional visual information in the demonstrations motivates the followingresearch questions: which of the two modalities in the demonstration is moresignificant? How can we select effective multimodal demonstrations to enhanceICL performance? This study investigates the significance of both visual andlanguage information. Our findings indicate that ICL in VLMs is predominantlydriven by the textual information in the demonstrations whereas the visualinformation in the demonstrations barely affects the ICL performance.Subsequently, we provide an understanding of the findings by analyzing themodel information flow and comparing model inner states given different ICLsettings. Motivated by our analysis, we propose a simple yet effectiveapproach, termed Mixed Modality In-Context Example Selection (MMICES), whichconsiders both visual and language modalities when selecting demonstrations andshows better ICL performance. Extensive experiments are conducted to supportour findings, understanding, and improvement of the ICL performance of VLMs.",Shuo Chen,2023/11/29,2023/11/29
2212.10670v1,In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models,http://arxiv.org/abs/2212.10670v1,"Given the success with in-context learning of large pre-trained languagemodels, we introduce in-context learning distillation to transfer in-contextfew-shot learning ability from large models to smaller models. We propose tocombine in-context learning objectives with language modeling objectives todistill both the ability to read in-context examples and task knowledge to thesmaller models. We perform in-context learning distillation under two differentfew-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and MultitaskIn-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitaskfew-shot learning but also requires more computation than Meta-ICT. Our methodshows consistent improvements for both Meta-ICT and Multitask-ICT on twobenchmarks: LAMA and CrossFit. Our extensive experiments and analysis revealthat in-context learning objectives and language modeling objectives arecomplementary under the Multitask-ICT paradigm. In-context learning objectivesachieve the best performance when combined with language modeling objectives.",Yukun Huang,2022/12/20,2022/12/20
2310.12300v2,Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly,http://arxiv.org/abs/2310.12300v2,"In-context learning (ICL) is a new learning paradigm that has gainedpopularity along with the development of large language models. In this work,we adapt a recently proposed hardness metric, pointwise $\mathcal{V}$-usableinformation (PVI), to an in-context version (in-context PVI). Compared to theoriginal PVI, in-context PVI is more efficient in that it requires only a fewexemplars and does not require fine-tuning. We conducted a comprehensiveempirical analysis to evaluate the reliability of in-context PVI. Our findingsindicate that in-context PVI estimates exhibit similar characteristics to theoriginal PVI. Specific to the in-context setting, we show that in-context PVIestimates remain consistent across different exemplar selections and numbers ofshots. The variance of in-context PVI estimates across different exemplarselections is insignificant, which suggests that in-context PVI are stable.Furthermore, we demonstrate how in-context PVI can be employed to identifychallenging instances. Our work highlights the potential of in-context PVI andprovides new insights into the capabilities of ICL.",Sheng Lu,2023/10/18,2023/12/8
2111.01104v1,NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and Parameters,http://arxiv.org/abs/2111.01104v1,"Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs)identify context-dependent relationships between variables, but thenon-convexity induced by the acyclicity requirement makes it difficult to shareinformation between context-specific estimators (e.g. with graph generatorfunctions). For this reason, existing methods for inferring context-specificBayesian networks have favored breaking datasets into subsamples, limitingstatistical power and resolution, and preventing the use of multidimensionaland latent contexts. To overcome this challenge, we propose NOTEARS-optimizedMixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesiannetworks as the output of a function which learns to mix archetypal networksaccording to sample context. The archetypal networks are estimated jointly withthe context-specific networks and do not require any prior knowledge. We encodethe acyclicity constraint as a smooth regularization loss which isback-propagated to the mixing function; in this way, NOTMAD shares informationbetween context-specific acyclic graphs, enabling the estimation of Bayesiannetwork structures and parameters at even single-sample resolution. Wedemonstrate the utility of NOTMAD and sample-specific network inference throughanalysis and experiments, including patient-specific gene expression networkswhich correspond to morphological variation in cancer.",Ben Lengerich,2021/11/1,2021/11/1
2308.07922v1,RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models,http://arxiv.org/abs/2308.07922v1,"In this paper, we investigate the in-context learning ability ofretrieval-augmented encoder-decoder language models. We first conduct acomprehensive analysis of the state-of-the-art ATLAS model and identify itslimitations in in-context learning, primarily due to a mismatch betweenpretraining and testing, as well as a restricted context length. To addressthese issues, we propose RAVEN, a model that combines retrieval-augmentedmasked language modeling and prefix language modeling. We further introduceFusion-in-Context Learning to enhance the few-shot performance by enabling themodel to leverage more in-context examples without requiring additionaltraining or model modifications. Through extensive experiments, we demonstratethat RAVEN significantly outperforms ATLAS and achieves results comparable tothe most advanced language models in certain scenarios, despite havingsubstantially fewer parameters. Our work underscores the potential ofretrieval-augmented encoder-decoder language models for in-context learning andencourages further research in this direction.",Jie Huang,2023/8/15,2023/8/15
2308.05061v3,Fine-Tune Language Models as Multi-Modal Differential Equation Solvers,http://arxiv.org/abs/2308.05061v3,"In the growing domain of scientific machine learning, in-context operatorlearning has shown notable potential in learning operators and solvingdifferential equations using prompted data, during the inference stage withoutweight updates. However, the current model's overdependence on function data,may inadvertently overlook the invaluable human insight into the operator. Toaddress this, we present a transformation of in-context operator learning intoa multi-modal paradigm. In particular, we take inspiration from the recentsuccess of large language models, and propose using ""captions"" to integratehuman knowledge about the operator, expressed through natural languagedescriptions and equations. Also, we introduce a novel approach to train alanguage-model-like architecture, or directly fine-tune existing languagemodels, for in-context operator learning. We beat the baseline on single-modallearning tasks, and also demonstrated the effectiveness of multi-modal learningin enhancing performance and reducing function data requirements. The proposedmethod not only significantly improves in-context operator learning, but alsocreates a new path for the application of language models.",Liu Yang,2023/8/9,2023/11/9
2104.00924v1,Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning,http://arxiv.org/abs/2104.00924v1,"Our work addresses long-term motion context issues for predicting futureframes. To predict the future precisely, it is required to capture whichlong-term motion context (e.g., walking or running) the input motion (e.g., legmovement) belongs to. The bottlenecks arising when dealing with the long-termmotion context are: (i) how to predict the long-term motion context naturallymatching input sequences with limited dynamics, (ii) how to predict thelong-term motion context with high-dimensionality (e.g., complex motion). Toaddress the issues, we propose novel motion context-aware video prediction. Tosolve the bottleneck (i), we introduce a long-term motion context memory(LMC-Memory) with memory alignment learning. The proposed memory alignmentlearning enables to store long-term motion contexts into the memory and tomatch them with sequences including limited dynamics. As a result, thelong-term context can be recalled from the limited input sequence. In addition,to resolve the bottleneck (ii), we propose memory query decomposition to storelocal motion context (i.e., low-dimensional dynamics) and recall the suitablelocal context for each local part of the input individually. It enables toboost the alignment effects of the memory. Experimental results show that theproposed method outperforms other sophisticated RNN-based methods, especiallyin long-term condition. Further, we validate the effectiveness of the proposednetwork designs by conducting ablation studies and memory feature analysis. Thesource code of this work is available.",Sangmin Lee,2021/4/2,2021/4/2
2211.11259v3,From Traditional Adaptive Data Caching to Adaptive Context Caching: A Survey,http://arxiv.org/abs/2211.11259v3,"Context information is in demand more than ever with the rapid increase inthe number of context-aware Internet of Things applications developedworldwide. Research in context and context-awareness is being conducted tobroaden its applicability in light of many practical and technical challenges.One of the challenges is improving performance when responding to a largenumber of context queries. Context Management Platforms that infer and delivercontext to applications measure this problem using Quality of Service (QoS)parameters. Although caching is a proven way to improve QoS, transiency ofcontext and features such as variability and heterogeneity of context queriespose an additional real-time cost management problem. This paper presents acritical survey of the state-of-the-art in adaptive data caching with theobjective of developing a body of knowledge in cost- and performance-efficientadaptive caching strategies. We comprehensively survey a large number ofresearch publications and evaluate, compare, and contrast different techniques,policies, approaches, and schemes in adaptive caching. Our critical analysis ismotivated by the focus on adaptively caching context as a core researchproblem. A formal definition for adaptive context caching is then proposed,followed by identified features and requirements of a well-designed, objectiveoptimal adaptive context caching strategy.",Shakthi Weerasinghe,2022/11/21,2023/2/9
2009.03417v2,Learning Interpretable Feature Context Effects in Discrete Choice,http://arxiv.org/abs/2009.03417v2,"The outcomes of elections, product sales, and the structure of socialconnections are all determined by the choices individuals make when presentedwith a set of options, so understanding the factors that contribute to choiceis crucial. Of particular interest are context effects, which occur when theset of available options influences a chooser's relative preferences, as theyviolate traditional rationality assumptions yet are widespread in practice.However, identifying these effects from observed choices is challenging, oftenrequiring foreknowledge of the effect to be measured. In contrast, we provide amethod for the automatic discovery of a broad class of context effects fromobserved choice data. Our models are easier to train and more flexible thanexisting models and also yield intuitive, interpretable, and statisticallytestable context effects. Using our models, we identify new context effects inwidely used choice datasets and provide the first analysis of choice setcontext effects in social network growth.",Kiran Tomlinson,2020/9/7,2020/11/5
2207.11049v2,Context-aware controller inference for stabilizing dynamical systems from scarce data,http://arxiv.org/abs/2207.11049v2,"This work introduces a data-driven control approach for stabilizinghigh-dimensional dynamical systems from scarce data. The proposed context-awarecontroller inference approach is based on the observation that controllers needto act locally only on the unstable dynamics to stabilize systems. This meansit is sufficient to learn the unstable dynamics alone, which are typicallyconfined to much lower dimensional spaces than the high-dimensional statespaces of all system dynamics and thus few data samples are sufficient toidentify them. Numerical experiments demonstrate that context-aware controllerinference learns stabilizing controllers from orders of magnitude fewer datasamples than traditional data-driven control techniques and variants ofreinforcement learning. The experiments further show that the low datarequirements of context-aware controller inference are especially beneficial indata-scarce engineering problems with complex physics, for which learningcomplete system dynamics is often intractable in terms of data and trainingcosts.",Steffen W. R. Werner,2022/7/22,2023/1/18
2305.04835v3,How Do In-Context Examples Affect Compositional Generalization?,http://arxiv.org/abs/2305.04835v3,"Compositional generalization--understanding unseen combinations of seenprimitives--is an essential reasoning capability in human intelligence. The AIcommunity mainly studies this capability by fine-tuning neural networks on lotsof training samples, while it is still unclear whether and how in-contextlearning--the prevailing few-shot paradigm based on large languagemodels--exhibits compositional generalization. In this paper, we present CoFe,a test suite to investigate in-context compositional generalization. We findthat the compositional generalization performance can be easily affected by theselection of in-context examples, thus raising the research question what thekey factors are to make good in-context examples for compositionalgeneralization. We study three potential factors: similarity, diversity andcomplexity. Our systematic experiments indicate that in-context examples shouldbe structurally similar to the test case, diverse from each other, andindividually simple. Furthermore, two strong limitations are observed:in-context compositional generalization on fictional words is much weaker thanthat on commonly used ones; it is still critical that the in-context examplesshould cover required linguistic structures, even though the backbone model hasbeen pre-trained on large corpus. We hope our analysis would facilitate theunderstanding and utilization of in-context learning paradigm.",Shengnan An,2023/5/8,2023/6/9
2006.04515v1,Deep Learning for Posture Control Nonlinear Model System and Noise Identification,http://arxiv.org/abs/2006.04515v1,"In this work we present a system identification procedure based onConvolutional Neural Networks (CNN) for human posture control models. A usualapproach to the study of human posture control consists in the identificationof parameters for a control system. In this context, linear models areparticularly popular due to the relative simplicity in identifying the requiredparameters and to analyze the results. Nonlinear models, conversely, arerequired to predict the real behavior exhibited by human subjects and hence itis desirable to use them in posture control analysis. The use of CNN aims toovercome the heavy computational requirement for the identification ofnonlinear models, in order to make the analysis of experimental data less timeconsuming and, in perspective, to make such analysis feasible in the context ofclinical tests. Some potential implications of the method for humanoid roboticsare also discussed.",Vittorio Lippi,2020/6/4,2020/6/4
2303.10093v2,Investigating the Role of Attribute Context in Vision-Language Models for Object Recognition and Detection,http://arxiv.org/abs/2303.10093v2,"Vision-language alignment learned from image-caption pairs has been shown tobenefit tasks like object recognition and detection. Methods are mostlyevaluated in terms of how well object class names are learned, but captionsalso contain rich attribute context that should be considered when learningobject alignment. It is unclear how methods use this context in learning, aswell as whether models succeed when tasks require attribute and objectunderstanding. To address this gap, we conduct extensive analysis of the roleof attributes in vision-language models. We specifically measure modelsensitivity to the presence and meaning of attribute context, gauging influenceon object embeddings through unsupervised phrase grounding and classificationvia description methods. We further evaluate the utility of attribute contextin training for open-vocabulary object detection, fine-grained text-regionretrieval, and attribution tasks. Our results show that attribute context canbe wasted when learning alignment for detection, attribute meaning is notadequately considered in embeddings, and describing classes by only theirattributes is ineffective. A viable strategy that we find to increase benefitsfrom attributes is contrastive training with adjective-based negative captions.",Kyle Buettner,2023/3/17,2023/11/6
2303.12395v1,Open Learning Analytics: A Systematic Literature Review and Future Perspectives,http://arxiv.org/abs/2303.12395v1,"Open Learning Analytics (OLA) is an emerging research area that aims atimproving learning efficiency and effectiveness in lifelong learningenvironments. OLA employs multiple methods to draw value from a wide range ofeducational data coming from various learning environments and contexts inorder to gain insight into the learning processes of different stakeholders. Asthe research field is still relatively young, only a few technical platformsare available and a common understanding of requirements is lacking. This paperprovides a systematic literature review of tools available in the learninganalytics literature from 2011-2019 with an eye on their support for openness.137 tools from nine academic databases are collected to form the base for thisreview. The analysis of selected tools is performed based on four dimensions,namely 'Data, Environments, Context (What?)', 'Stakeholders (Who?)','Objectives (Why?)', and 'Methods (How?)'. Moreover, five well-known OLAframeworks available in the community are systematically compared. The reviewconcludes by eliciting the main requirements for an effective OLA platform andby identifying key challenges and future lines of work in this emerging field.",Arham Muslim,2023/3/22,2023/3/22
1907.03609v1,Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions,http://arxiv.org/abs/1907.03609v1,"We focus on grounding (i.e., localizing or linking) referring expressions inimages, e.g., ``largest elephant standing behind baby elephant''. This is ageneral yet challenging vision-language task since it does not only require thelocalization of objects, but also the multimodal comprehension of context --visual attributes (e.g., ``largest'', ``baby'') and relationships (e.g.,``behind'') that help to distinguish the referent from other objects,especially those of the same category. Due to the exponential complexityinvolved in modeling the context associated with multiple image regions,existing work oversimplifies this task to pairwise region modeling by multipleinstance learning. In this paper, we propose a variational Bayesian method,called Variational Context, to solve the problem of complex context modeling inreferring expression grounding. Specifically, our framework exploits thereciprocal relation between the referent and context, i.e., either of theminfluences estimation of the posterior distribution of the other, and therebythe search space of context can be greatly reduced. In addition to reciprocity,our framework considers the semantic information of context, i.e., thereferring expression can be reproduced based on the estimated context. We alsoextend the model to unsupervised setting where no annotation for the referentis available. Extensive experiments on various benchmarks show consistentimprovement over state-of-the-art methods in both supervised and unsupervisedsettings.",Yulei Niu,2019/7/8,2019/7/8
2208.12525v1,Visual processing in context of reinforcement learning,http://arxiv.org/abs/2208.12525v1,"Although deep reinforcement learning (RL) has recently enjoyed manysuccesses, its methods are still data inefficient, which makes solving numerousproblems prohibitively expensive in terms of data. We aim to remedy this bytaking advantage of the rich supervisory signal in unlabeled data for learningstate representations. This thesis introduces three different representationlearning algorithms that have access to different subsets of the data sourcesthat traditional RL algorithms use:  (i) GRICA is inspired by independent component analysis (ICA) and trains adeep neural network to output statistically independent features of the input.GrICA does so by minimizing the mutual information between each feature and theother features. Additionally, GrICA only requires an unsorted collection ofenvironment states.  (ii) Latent Representation Prediction (LARP) requires more context: inaddition to requiring a state as an input, it also needs the previous state andan action that connects them. This method learns state representations bypredicting the representation of the environment's next state given a currentstate and action. The predictor is used with a graph search algorithm.  (iii) RewPred learns a state representation by training a deep neural networkto learn a smoothed version of the reward function. The representation is usedfor preprocessing inputs to deep RL, while the reward predictor is used forreward shaping. This method needs only state-reward pairs from the environmentfor learning the representation.  We discover that every method has their strengths and weaknesses, andconclude from our experiments that including unsupervised representationlearning in RL problem-solving pipelines can speed up learning.",Hlynur Dav Hlynsson,2022/8/26,2022/8/26
2010.15980v2,AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts,http://arxiv.org/abs/2010.15980v2,"The remarkable success of pretrained language models has motivated the studyof what kinds of knowledge these models learn during pretraining. Reformulatingtasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approachfor gauging such knowledge, however, its usage is limited by the manual effortand guesswork required to write suitable prompts. To address this, we developAutoPrompt, an automated method to create prompts for a diverse set of tasks,based on a gradient-guided search. Using AutoPrompt, we show that maskedlanguage models (MLMs) have an inherent capability to perform sentimentanalysis and natural language inference without additional parameters orfinetuning, sometimes achieving performance on par with recent state-of-the-artsupervised models. We also show that our prompts elicit more accurate factualknowledge from MLMs than the manually created prompts on the LAMA benchmark,and that MLMs can be used as relation extractors more effectively thansupervised relation extraction models. These results demonstrate thatautomatically generated prompts are a viable parameter-free alternative toexisting probing methods, and as pretrained LMs become more sophisticated andcapable, potentially a replacement for finetuning.",Taylor Shin,2020/10/29,2020/11/7
2307.01709v1,Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge Graph Completion via Conditional Soft Prompting,http://arxiv.org/abs/2307.01709v1,"Knowledge Graph Completion (KGC) often requires both KG structural andtextual information to be effective. Pre-trained Language Models (PLMs) havebeen used to learn the textual information, usually under the fine-tuneparadigm for the KGC task. However, the fine-tuned PLMs often overwhelminglyfocus on the textual information and overlook structural knowledge. To tacklethis issue, this paper proposes CSProm-KG (Conditional Soft Prompts for KGC)which maintains a balance between structural information and textual knowledge.CSProm-KG only tunes the parameters of Conditional Soft Prompts that aregenerated by the entities and relations representations. We verify theeffectiveness of CSProm-KG on three popular static KGC benchmarks WN18RR,FB15K-237 and Wikidata5M, and two temporal KGC benchmarks ICEWS14 andICEWS05-15. CSProm-KG outperforms competitive baseline models and sets newstate-of-the-art on these benchmarks. We conduct further analysis to show (i)the effectiveness of our proposed components, (ii) the efficiency of CSProm-KG,and (iii) the flexibility of CSProm-KG.",Chen Chen,2023/7/4,2023/7/4
2308.02862v1,Improving Generalization of Image Captioning with Unsupervised Prompt Learning,http://arxiv.org/abs/2308.02862v1,"Pretrained visual-language models have demonstrated impressive zero-shotabilities in image captioning, when accompanied by hand-crafted prompts.Meanwhile, hand-crafted prompts utilize human prior knowledge to guide themodel. However, due to the diversity between different domains, suchhand-crafted prompt that provide invariant prior knowledge may result in modecollapse for some domains. Some researches attempted to incorporate expertknowledge and instruction datasets, but the results were costly and led tohallucinations. In this paper, we propose an unsupervised prompt learningmethod to improve Generalization of Image Captioning (GeneIC), which learns adomain-specific prompt vector for the target domain without requiring annotateddata. GeneIC aligns visual and language modalities with a pre-trainedContrastive Language-Image Pre-Training (CLIP) model, thus optimizing thedomain-specific prompt vector from two aspects: attribute and semanticconsistency. Specifically, GeneIC first generates attribute-transferred imageswith differing attributes, while retaining semantic similarity with originalimages. Then, GeneIC uses CLIP to measure the similarity between the images andthe generated sentences. By exploring the variable and invariant features inthe original images and attribute-transferred images, attribute consistencyconstrains the attribute change direction of both images and sentences to learndomain-specific knowledge. The semantic consistency directly measures thesimilarity between the generated sentences and images to ensure the accuracyand comprehensiveness of the generated sentences. Consequently, GeneIC onlyoptimizes the prompt vectors, which effectively retains the knowledge in thelarge model and introduces domain-specific knowledge.",Hongchen Wei,2023/8/5,2023/8/5
2208.14602v2,Continuous QA Learning with Structured Prompts,http://arxiv.org/abs/2208.14602v2,"QA models with lifelong learning (LL) abilities are important for practicalQA applications, and architecture-based LL methods are reported to be aneffective implementation for these models. However, it is non-trivial to extendprevious approaches to QA tasks since they either require access to taskidentities in the testing phase or do not explicitly model samples from unseentasks. In this paper, we propose Diana: a dynamic architecture-based lifelongQA model that tries to learn a sequence of QA tasks with a prompt enhancedlanguage model. Four types of hierarchically organized prompts are used inDiana to capture QA knowledge from different granularities. Specifically, wededicate task-level prompts to capture task-specific knowledge to retain highLL performances and maintain instance-level prompts to learn knowledge sharedacross different input samples to improve the model's generalizationperformance. Moreover, we dedicate separate prompts to explicitly model unseentasks and introduce a set of prompt key vectors to facilitate knowledge sharingbetween tasks. Extensive experiments demonstrate that Diana outperformsstate-of-the-art lifelong QA models, especially in handling unseen tasks.",Yinhe Zheng,2022/8/31,2022/10/24
2203.08745v1,Multi-Stage Prompting for Knowledgeable Dialogue Generation,http://arxiv.org/abs/2203.08745v1,"Existing knowledge-grounded dialogue systems typically use finetuned versionsof a pretrained language model (LM) and large-scale knowledge bases. Thesemodels typically fail to generalize on topics outside of the knowledge base,and require maintaining separate potentially large checkpoints each timefinetuning is needed. In this paper, we aim to address these limitations byleveraging the inherent knowledge stored in the pretrained LM as well as itspowerful generation ability. We propose a multi-stage prompting approach togenerate knowledgeable responses from a single pretrained LM. We first promptthe LM to generate knowledge based on the dialogue context. Then, we furtherprompt it to generate responses based on the dialogue context and thepreviously generated knowledge. Results show that our knowledge generatoroutperforms the state-of-the-art retrieval-based model by 5.8% when combiningknowledge relevance and correctness. In addition, our multi-stage promptingoutperforms the finetuning-based dialogue model in terms of responseknowledgeability and engagement by up to 10% and 5%, respectively. Furthermore,we scale our model up to 530 billion parameters and show that larger LMsimprove the generation correctness score by up to 10%, and response relevance,knowledgeability and engagement by up to 10%. Our code is available at:https://github.com/NVIDIA/Megatron-LM.",Zihan Liu,2022/3/16,2022/3/16
2208.03229v1,Improving Task Generalization via Unified Schema Prompt,http://arxiv.org/abs/2208.03229v1,"Task generalization has been a long standing challenge in Natural LanguageProcessing (NLP). Recent research attempts to improve the task generalizationability of pre-trained language models by mapping NLP tasks into human-readableprompted forms. However, these approaches require laborious and inflexiblemanual collection of prompts, and different prompts on the same downstream taskmay receive unstable performance. We propose Unified Schema Prompt, a flexibleand extensible prompting method, which automatically customizes the learnableprompts for each task according to the task input schema. It models the sharedknowledge between tasks, while keeping the characteristics of different taskschema, and thus enhances task generalization ability. The schema prompt takesthe explicit data structure of each task to formulate prompts so that littlehuman effort is involved. To test the task generalization ability of schemaprompt at scale, we conduct schema prompt-based multitask pre-training on awide variety of general NLP tasks. The framework achieves strong zero-shot andfew-shot generalization performance on 16 unseen downstream tasks from 8 tasktypes (e.g., QA, NLI, etc). Furthermore, comprehensive analyses demonstrate theeffectiveness of each component in the schema prompt, its flexibility in taskcompositionality, and its ability to improve performance under a full-datafine-tuning setting.",Wanjun Zhong,2022/8/5,2022/8/5
2205.11100v1,Supporting Vision-Language Model Inference with Causality-pruning Knowledge Prompt,http://arxiv.org/abs/2205.11100v1,"Vision-language models are pre-trained by aligning image-text pairs in acommon space so that the models can deal with open-set visual concepts bylearning semantic information from textual labels. To boost the transferabilityof these models on downstream tasks in a zero-shot manner, recent works exploregenerating fixed or learnable prompts, i.e., classification weights aresynthesized from natural language describing task-relevant categories, toreduce the gap between tasks in the training and test phases. However, how andwhat prompts can improve inference performance remains unclear. In this paper,we explicitly provide exploration and clarify the importance of includingsemantic information in prompts, while existing prompt methods generate promptswithout exploring the semantic information of textual labels. A challengingissue is that manually constructing prompts, with rich semantic information,requires domain expertise and is extremely time-consuming. To this end, wepropose Causality-pruning Knowledge Prompt (CapKP) for adapting pre-trainedvision-language models to downstream image recognition. CapKP retrieves anontological knowledge graph by treating the textual label as a query to exploretask-relevant semantic information. To further refine the derived semanticinformation, CapKP introduces causality-pruning by following the firstprinciple of Granger causality. Empirically, we conduct extensive evaluationsto demonstrate the effectiveness of CapKP, e.g., with 8 shots, CapKPoutperforms the manual-prompt method by 12.51% and the learnable-prompt methodby 1.39% on average, respectively. Experimental analyses prove the superiorityof CapKP in domain generalization compared to benchmark approaches.",Jiangmeng Li,2022/5/23,2022/5/23
2304.10805v1,RPLKG: Robust Prompt Learning with Knowledge Graph,http://arxiv.org/abs/2304.10805v1,"Large-scale pre-trained models have been known that they are transferable,and they generalize well on the unseen dataset. Recently, multimodalpre-trained models such as CLIP show significant performance improvement indiverse experiments. However, when the labeled dataset is limited, thegeneralization of a new dataset or domain is still challenging. To improve thegeneralization performance on few-shot learning, there have been diverseefforts, such as prompt learning and adapter. However, the current few-shotadaptation methods are not interpretable, and they require a high computationcost for adaptation. In this study, we propose a new method, robust promptlearning with knowledge graph (RPLKG). Based on the knowledge graph, weautomatically design diverse interpretable and meaningful prompt sets. Ourmodel obtains cached embeddings of prompt sets after one forwarding from alarge pre-trained model. After that, model optimizes the prompt selectionprocesses with GumbelSoftmax. In this way, our model is trained usingrelatively little memory and learning time. Also, RPLKG selects the optimalinterpretable prompt automatically, depending on the dataset. In summary, RPLKGis i) interpretable, ii) requires small computation resources, and iii) easy toincorporate prior human knowledge. To validate the RPLKG, we providecomprehensive experimental results on few-shot learning, domain generalizationand new class generalization setting. RPLKG shows a significant performanceimprovement compared to zero-shot learning and competitive performance againstseveral prompt learning methods using much lower resources.",Yewon Kim,2023/4/21,2023/4/21
2302.09236v1,Scalable Prompt Generation for Semi-supervised Learning with Language Models,http://arxiv.org/abs/2302.09236v1,"Prompt-based learning methods in semi-supervised learning (SSL) settings havebeen shown to be effective on multiple natural language understanding (NLU)datasets and tasks in the literature. However, manually designing multipleprompts and verbalizers requires domain knowledge and human effort, making itdifficult and expensive to scale across different datasets. In this paper, wepropose two methods to automatically design multiple prompts and integrateautomatic verbalizer in SSL settings without sacrificing performance. The firstmethod uses various demonstration examples with learnable continuous prompttokens to create diverse prompt models. The second method uses a varying numberof soft prompt tokens to encourage language models to learn different prompts.For the verbalizer, we use the prototypical verbalizer to replace the manualone. In summary, we obtained the best average accuracy of 73.2% (a relativeimprovement of 2.52% over even the previous state-of-the-art SSL method withmanual prompts and verbalizers) in different few-shot learning settings.",Yuhang Zhou,2023/2/18,2023/2/18
2312.08839v1,Exploration of visual prompt in Grounded pre-trained open-set detection,http://arxiv.org/abs/2312.08839v1,"Text prompts are crucial for generalizing pre-trained open-set objectdetection models to new categories. However, current methods for text promptsare limited as they require manual feedback when generalizing to newcategories, which restricts their ability to model complex scenes, oftenleading to incorrect detection results. To address this limitation, we proposea novel visual prompt method that learns new category knowledge from a fewlabeled images, which generalizes the pre-trained detection model to the newcategory. To allow visual prompts to represent new categories adequately, wepropose a statistical-based prompt construction module that is not limited bypredefined vocabulary lengths, thus allowing more vectors to be used whenrepresenting categories. We further utilize the category dictionaries in thepre-training dataset to design task-specific similarity dictionaries, whichmake visual prompts more discriminative. We evaluate the method on the ODinWdataset and show that it outperforms existing prompt learning methods andperforms more consistently in combinatorial inference.",Qibo Chen,2023/12/14,2023/12/14
2308.02047v1,Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough,http://arxiv.org/abs/2308.02047v1,"This paper critically evaluates the European Commission's proposed AI Act'sapproach to risk management and risk acceptability for high-risk AI systemsthat pose risks to fundamental rights and safety. The Act aims to promote""trustworthy"" AI with a proportionate regulatory burden. Its provisions on riskacceptability require residual risks from high-risk systems to be reduced oreliminated ""as far as possible"", having regard to the ""state of the art"". Thiscriterion, especially if interpreted narrowly, is unworkable and promotesneither proportionate regulatory burden, nor trustworthiness. By contrast theParliament's most recent draft amendments to the risk management provisionsintroduce ""reasonableness"", cost-benefit analysis, and are more transparentabout the value-laden and contextual nature of risk acceptability judgements.This paper argues that the Parliament's approach is more workable, and betterbalances the goals of proportionality and trustworthiness. It explains whatreasonableness in risk acceptability judgments would entail, drawing onprinciples from negligence law and European medical devices regulation. And itcontends that the approach to risk acceptability judgments need a firmfoundation of civic legitimacy: including detailed guidance or involvement fromregulators, and meaningful input from affected stakeholders.",Henry Fraser,2023/7/26,2023/7/26
2110.13341v1,How Should AI Interpret Rules? A Defense of Minimally Defeasible Interpretive Argumentation,http://arxiv.org/abs/2110.13341v1,"Can artificially intelligent systems follow rules? The answer might seem anobvious `yes', in the sense that all (current) AI strictly acts in accordancewith programming code constructed from highly formalized and well-definedrulesets. But here I refer to the kinds of rules expressed in human languagethat are the basis of laws, regulations, codes of conduct, ethical guidelines,and so on. The ability to follow such rules, and to reason about them, is notnearly as clear-cut as it seems on first analysis. Real-world rules areunavoidably rife with open-textured terms, which imbue rules with a possiblyinfinite set of possible interpretations. Narrowing down this set requires acomplex reasoning process that is not yet within the scope of contemporary AI.This poses a serious problem for autonomous AI: If one cannot reason aboutopen-textured terms, then one cannot reason about (or in accordance with)real-world rules. And if one cannot reason about real-world rules, then onecannot: follow human laws, comply with regulations, act in accordance withwritten agreements, or even obey mission-specific commands that are anythingmore than trivial. But before tackling these problems, we must first answer amore fundamental question: Given an open-textured rule, what is its correctinterpretation? Or more precisely: How should our artificially intelligentsystems determine which interpretation to consider correct? In this essay, Idefend the following answer: Rule-following AI should act in accordance withthe interpretation best supported by minimally defeasible interpretivearguments (MDIA).",John Licato,2021/10/26,2021/10/26
1906.01983v1,The Computational Structure of Unintentional Meaning,http://arxiv.org/abs/1906.01983v1,"Speech-acts can have literal meaning as well as pragmatic meaning, but theseboth involve consequences typically intended by a speaker. Speech-acts can alsohave unintentional meaning, in which what is conveyed goes above and beyondwhat was intended. Here, we present a Bayesian analysis of how, to a listener,the meaning of an utterance can significantly differ from a speaker's intendedmeaning. Our model emphasizes how comprehending the intentional andunintentional meaning of speech-acts requires listeners to engage insophisticated model-based perspective-taking and reasoning about the history ofthe state of the world, each other's actions, and each other's observations. Totest our model, we have human participants make judgments about vignettes wherespeakers make utterances that could be interpreted as intentional insults orunintentional faux pas. In elucidating the mechanics of speech-acts withunintentional meanings, our account provides insight into how communicationboth functions and malfunctions.",Mark K. Ho,2019/6/3,2019/6/3
2309.17382v2,"Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency",http://arxiv.org/abs/2309.17382v2,"Large language models (LLMs) demonstrate impressive reasoning abilities, buttranslating reasoning into actions in the real world remains challenging. Inparticular, it remains unclear how to complete a given task provably within aminimum number of interactions with the external environment, e.g., through aninternal mechanism of reasoning. To this end, we propose a principled frameworkwith provable regret guarantees to orchestrate reasoning and acting, which wecall ""reason for future, act for now"" (\texttt{RAFA}). Specifically, we designa prompt template for reasoning that learns from the memory buffer and plans afuture trajectory over a long horizon (""reason for future""). At each step, theLLM agent takes the initial action of the planned trajectory (""act for now""),stores the collected feedback in the memory buffer, and reinvokes the reasoningroutine to replan the future trajectory from the new state.  The key idea is to cast reasoning in LLMs as learning and planning inBayesian adaptive Markov decision processes (MDPs). Correspondingly, we promptLLMs to form an updated posterior of the unknown environment from the memorybuffer (learning) and generate an optimal trajectory for multiple future stepsthat maximizes a value function (planning). The learning and planningsubroutines are performed in an ""in-context"" manner to emulate the actor-criticupdate for MDPs. Our theoretical analysis proves that the novel combination oflong-term reasoning and short-term acting achieves a $\sqrt{T}$ regret. Inparticular, the regret bound highlights an intriguing interplay between theprior knowledge obtained through pretraining and the uncertainty reductionachieved by reasoning and acting. Our empirical validation shows that itoutperforms various existing frameworks and achieves nearly perfect scores on afew benchmarks.",Zhihan Liu,2023/9/29,2023/10/11
2210.03520v1,Exploring the Relationships between Privacy by Design Schemes and Privacy Laws: A Comparative Analysis,http://arxiv.org/abs/2210.03520v1,"Internet of Things (IoT) applications have the potential to derive sensitiveinformation about individuals. Therefore, developers must exercise duediligence to make sure that data are managed according to the privacyregulations and data protection laws. However, doing so can be a difficult andchallenging task. Recent research has revealed that developers typically facedifficulties when complying with regulations. One key reason is that, at times,regulations are vague, and could be challenging to extract and enact such legalrequirements. In our research paper, we have conducted a systematic analysis ofthe data protection laws that are used across different continents, namely: (i)General Data Protection Regulations (GDPR), (ii) the Personal InformationProtection and Electronic Documents Act (PIPEDA), (iii) the California ConsumerPrivacy Act (CCPA), (iv) Australian Privacy Principles (APPs), and (v) NewZealand's Privacy Act 1993. In this technical report, we presented the detailedresults of the conducted framework analysis method to attain a comprehensiveview of different data protection laws and highlighted the disparities, inorder to assist developers in adhering to the regulations across differentregions, along with creating a Combined Privacy Law Framework (CPLF). Afterthat, we gave an overview of various Privacy by Design (PbD) schemes developedpreviously by different researchers. Then, the key principles and individuals'rights of the CPLF were mapped with the privacy principles, strategies,guidelines, and patterns of the Privacy by Design (PbD) schemes in order toinvestigate the gaps in existing schemes.",Atheer Aljeraisy,2022/10/6,2022/10/6
2311.09603v1,SCORE: A framework for Self-Contradictory Reasoning Evaluation,http://arxiv.org/abs/2311.09603v1,"Large language models (LLMs) have demonstrated impressive reasoning abilityin various language-based tasks. Despite many proposed reasoning methods aimedat enhancing performance in downstream tasks, two fundamental questionspersist: Does reasoning genuinely support predictions, and how reliable is thequality of reasoning? In this paper, we propose a framework \textsc{SCORE} toanalyze how well LLMs can reason. Specifically, we focus on self-contradictoryreasoning, where reasoning does not support the prediction. We find that LLMsoften contradict themselves when performing reasoning tasks that involvecontextual information and commonsense. The model may miss evidence or useshortcuts, thereby exhibiting self-contradictory behaviors. We also employ thePoint-of-View (POV) method, which probes models to generate reasoning frommultiple perspectives, as a diagnostic tool for further analysis. We find thatthough LLMs may appear to perform well in one-perspective settings, they failto stabilize such behavior in multi-perspectives settings. Even for correctpredictions, the reasoning may be messy and incomplete, and LLMs can easily beled astray from good reasoning. \textsc{SCORE}'s results underscore the lack ofrobustness required for trustworthy reasoning and the urgency for furtherresearch to establish best practices for a comprehensive evaluation ofreasoning beyond accuracy-based metrics.",Ziyi Liu,2023/11/16,2023/11/16
2212.08286v2,ALERT: Adapting Language Models to Reasoning Tasks,http://arxiv.org/abs/2212.08286v2,"Current large language models can perform reasonably well on complex tasksthat require step-by-step reasoning with few-shot learning. Are these modelsapplying reasoning skills they have learnt during pre-training and reasonoutside of their training context, or are they simply memorizing their trainingcorpus at finer granularity and have learnt to better understand their context?To tease apart these possibilities, we introduce ALERT, a benchmark and suiteof analyses for assessing language models' reasoning ability comparingpre-trained and finetuned models on complex tasks that require reasoning skillsto solve. ALERT provides a test bed to asses any language model on fine-grainedreasoning skills, which spans over 20 datasets and covers 10 differentreasoning skills. We leverage ALERT to further investigate the role offinetuning. With extensive empirical analysis we find that language modelslearn more reasoning skills such as textual entailment, abductive reasoning,and analogical reasoning during finetuning stage compared to pretraining state.We also find that when language models are finetuned they tend to overfit tothe prompt template, which hurts the robustness of models causinggeneralization problems.",Ping Yu,2022/12/16,2023/7/7
2210.11265v2,Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers,http://arxiv.org/abs/2210.11265v2,"This paper presents ReasonFormer, a unified reasoning framework for mirroringthe modular and compositional reasoning process of humans in complexdecision-making. Inspired by dual-process theory in cognitive science, therepresentation module (automatic thinking) and reasoning modules (controlledthinking) are decoupled to capture different levels of cognition. Upon the topof the representation module, the pre-trained reasoning modules are modular andprofessional in specific and fundamental reasoning skills (e.g., logic, simpleQA, etc). To mimic the controlled compositional thinking process, differentreasoning modules are dynamically activated and composed in both parallel andcascaded manners to control what reasoning skills are activated and how deepthe reasoning process will be reached to solve the current problems. Theunified reasoning framework solves multiple tasks with a single model, and istrained and inferred in an end-to-end manner. Evaluated on 11 datasetsrequiring different reasoning skills and complexity, ReasonFormer demonstratessubstantial performance boosts, revealing the compositional reasoning ability.Few-shot experiments exhibit better generalization ability by learning tocompose pre-trained skills for new tasks with limited data, and decoupling therepresentation module and the reasoning modules. Further analysis shows themodularity of reasoning modules as different tasks activate distinct reasoningskills at different reasoning depths.",Wanjun Zhong,2022/10/20,2022/12/7
2310.03249v1,Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning,http://arxiv.org/abs/2310.03249v1,"Large language models (LLMs) have achieved remarkable success across a widespectrum of tasks; however, they still face limitations in scenarios thatdemand long-term planning and spatial reasoning. To facilitate this line ofresearch, in this work, we propose a new benchmark, termed $\textbf{P}$ath$\textbf{P}$lanning from $\textbf{N}$atural $\textbf{L}$anguage($\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning byformulating ''path planning'' tasks that require an LLM to navigate to targetlocations while avoiding obstacles and adhering to constraints. Leveraging thisbenchmark, we systematically investigate LLMs including GPT-4 via differentfew-shot prompting methodologies and BART and T5 of various sizes viafine-tuning. Our experimental results show the promise of few-shot GPT-4 inspatial reasoning, when it is prompted to reason and act interleavedly,although it still fails to make long-term temporal reasoning. In contrast,while fine-tuned LLMs achieved impressive results on in-distribution reasoningtasks, they struggled to generalize to larger environments or environments withmore obstacles.",Mohamed Aghzal,2023/10/5,2023/10/5
0805.3518v1,Logic programming with social features,http://arxiv.org/abs/0805.3518v1,"In everyday life it happens that a person has to reason about what otherpeople think and how they behave, in order to achieve his goals. In otherwords, an individual may be required to adapt his behaviour by reasoning aboutthe others' mental state. In this paper we focus on a knowledge representationlanguage derived from logic programming which both supports the representationof mental states of individual communities and provides each with thecapability of reasoning about others' mental states and acting accordingly. Theproposed semantics is shown to be translatable into stable model semantics oflogic programs with aggregates.",Francesco Buccafurri,2008/5/22,2008/5/22
2310.00074v1,SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation,http://arxiv.org/abs/2310.00074v1,"To comprehensively assess the capacity of current models for complexreasoning, it is crucial to assess their step-by-step reasoning in a scalablemanner. Established reference-based evaluation metrics rely on human-annotatedreasoning chains to assess the model-derived chains. However, such``gold-standard'' human-written reasoning chains may not be unique and theiracquisition is often labor-intensive. Existing reference-free reasoning metricseliminate the need for human-crafted reasoning chains as references, but theytypically require fine-tuning on datasets with human-derived reasoning chains,which complicates the process and raises concerns regarding generalizabilityacross diverse datasets. To address these challenges, we harness GPT-4 toautomatically evaluate reasoning chain quality, obviating the need forhuman-crafted references. Leveraging the Socratic method, we devise tailoredprompts to enhance reference-free reasoning evaluation, which we term SocREval(Socratic method for Reasoning Evaluation). Empirical results from four humanannotated datasets reveal that SocREval significantly improves GPT-4'sperformance, surpassing existing reference-free and reference-based reasoningevaluation metrics. Beyond its demonstrated efficacy, our proposed framework,large language models (LLMs) with the Socratic method, proves to be bothcost-efficient and robust to prompt writing and example selection, assubstantiated by our in-depth analysis.",Hangfeng He,2023/9/29,2023/9/29
2103.00973v1,Virtual Adversarial Humans finding Hazards in Robot Workplaces,http://arxiv.org/abs/2103.00973v1,"During the planning phase of industrial robot workplaces, hazard analyses arerequired so that potential hazards for human workers can be identified andappropriate safety measures can be implemented. Existing hazard analysismethods use human reasoning, checklists and/or abstract system models, whichlimit the level of detail. We propose a new approach that frames hazardanalysis as a search problem in a dynamic simulation environment. Our goal isto identify workplace hazards by searching for simulation sequences that resultin hazardous situations. We solve this search problem by placing virtual humansinto workplace simulation models. These virtual humans act in an adversarialmanner: They learn to provoke unsafe situations, and thereby uncover workplacehazards. Although this approach cannot replace a thorough hazard analysis, itcan help uncover hazards that otherwise may have been overlooked, especially inearly development stages. Thus, it helps to prevent costly re-designs at laterdevelopment stages. For validation, we performed hazard analyses in sixdifferent example scenarios that reflect typical industrial robot workplaces.",Tom P. Huck,2021/3/1,2021/3/1
2009.14795v2,Explaining AI as an Exploratory Process: The Peircean Abduction Model,http://arxiv.org/abs/2009.14795v2,"Current discussions of ""Explainable AI"" (XAI) do not much consider the roleof abduction in explanatory reasoning (see Mueller, et al., 2018). It might beworthwhile to pursue this, to develop intelligent systems that allow for theobservation and analysis of abductive reasoning and the assessment of abductivereasoning as a learnable skill. Abductive inference has been defined in manyways. For example, it has been defined as the achievement of insight. Mostoften abduction is taken as a single, punctuated act of syllogistic reasoning,like making a deductive or inductive inference from given premises. Incontrast, the originator of the concept of abduction---the Americanscientist/philosopher Charles Sanders Peirce---regarded abduction as anexploratory activity. In this regard, Peirce's insights about reasoning alignwith conclusions from modern psychological research. Since abduction is oftendefined as ""inferring the best explanation,"" the challenge of implementingabductive reasoning and the challenge of automating the explanation process areclosely linked. We explore these linkages in this report. This analysisprovides a theoretical framework for understanding what the XAI researchers arealready doing, it explains why some XAI projects are succeeding (or mightsucceed), and it leads to design advice.",Robert R. Hoffman,2020/9/30,2020/10/1
2310.10467v1,Stance Detection with Collaborative Role-Infused LLM-Based Agents,http://arxiv.org/abs/2310.10467v1,"Stance detection automatically detects the stance in a text towards a target,vital for content analysis in web and social media research. Despite theirpromising capabilities, LLMs encounter challenges when directly applied tostance detection. First, stance detection demands multi-aspect knowledge, fromdeciphering event-related terminologies to understanding the expression stylesin social media platforms. Second, stance detection requires advanced reasoningto infer authors' implicit viewpoints, as stance are often subtly embeddedrather than overtly stated in the text. To address these challenges, we designa three-stage framework COLA (short for Collaborative rOle-infused LLM-basedAgents) in which LLMs are designated distinct roles, creating a collaborativesystem where each role contributes uniquely. Initially, in the multidimensionaltext analysis stage, we configure the LLMs to act as a linguistic expert, adomain specialist, and a social media veteran to get a multifaceted analysis oftexts, thus overcoming the first challenge. Next, in the reasoning-enhanceddebating stage, for each potential stance, we designate a specific LLM-basedagent to advocate for it, guiding the LLM to detect logical connections betweentext features and stance, tackling the second challenge. Finally, in the stanceconclusion stage, a final decision maker agent consolidates prior insights todetermine the stance. Our approach avoids extra annotated data and modeltraining and is highly usable. We achieve state-of-the-art performance acrossmultiple datasets. Ablation studies validate the effectiveness of each designrole in handling stance detection. Further experiments have demonstrated theexplainability and the versatility of our approach. Our approach excels inusability, accuracy, effectiveness, explainability and versatility,highlighting its value.",Xiaochong Lan,2023/10/16,2023/10/16
2010.05587v1,Social Commonsense Reasoning with Multi-Head Knowledge Attention,http://arxiv.org/abs/2010.05587v1,"Social Commonsense Reasoning requires understanding of text, knowledge aboutsocial events and their pragmatic implications, as well as commonsensereasoning skills. In this work we propose a novel multi-head knowledgeattention model that encodes semi-structured commonsense inference rules andlearns to incorporate them in a transformer-based reasoning cell. We assess themodel's performance on two tasks that require different reasoning skills:Abductive Natural Language Inference and Counterfactual Invariance Predictionas a new task. We show that our proposed model improves performance over strongstate-of-the-art models (i.e., RoBERTa) across both reasoning tasks. Notably weare, to the best of our knowledge, the first to demonstrate that a model thatlearns to perform counterfactual reasoning helps predicting the bestexplanation in an abductive reasoning task. We validate the robustness of themodel's reasoning capabilities by perturbing the knowledge and providequalitative analysis on the model's knowledge incorporation capabilities.",Debjit Paul,2020/10/12,2020/10/12
2108.07994v2,EviDR: Evidence-Emphasized Discrete Reasoning for Reasoning Machine Reading Comprehension,http://arxiv.org/abs/2108.07994v2,"Reasoning machine reading comprehension (R-MRC) aims to answer complexquestions that require discrete reasoning based on text. To support discretereasoning, evidence, typically the concise textual fragments that describequestion-related facts, including topic entities and attribute values, arecrucial clues from question to answer. However, previous end-to-end methodsthat achieve state-of-the-art performance rarely solve the problem by payingenough emphasis on the modeling of evidence, missing the opportunity to furtherimprove the model's reasoning ability for R-MRC. To alleviate the above issue,in this paper, we propose an evidence-emphasized discrete reasoning approach(EviDR), in which sentence and clause level evidence is first detected based ondistant supervision, and then used to drive a reasoning module implemented witha relational heterogeneous graph convolutional network to derive answers.Extensive experiments are conducted on DROP (discrete reasoning overparagraphs) dataset, and the results demonstrate the effectiveness of ourproposed approach. In addition, qualitative analysis verifies the capability ofthe proposed evidence-emphasized discrete reasoning for R-MRC.",Yongwei Zhou,2021/8/18,2021/10/26
1912.02703v1,Self-Supervised Contextual Language Representation of Radiology Reports to Improve the Identification of Communication Urgency,http://arxiv.org/abs/1912.02703v1,"Machine learning methods have recently achieved high-performance inbiomedical text analysis. However, a major bottleneck in the widespreadapplication of these methods is obtaining the required large amounts ofannotated training data, which is resource intensive and time consuming. Recentprogress in self-supervised learning has shown promise in leveraging large textcorpora without explicit annotations. In this work, we built a self-supervisedcontextual language representation model using BERT, a deep bidirectionaltransformer architecture, to identify radiology reports requiring promptcommunication to the referring physicians. We pre-trained the BERT model on alarge unlabeled corpus of radiology reports and used the resulting contextualrepresentations in a final text classifier for communication urgency. Our modelachieved a precision of 97.0%, recall of 93.3%, and F-measure of 95.1% on anindependent test set in identifying radiology reports for prompt communication,and significantly outperformed the previous state-of-the-art model based onword2vec representations.",Xing Meng,2019/12/5,2019/12/5
2308.07624v1,Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation,http://arxiv.org/abs/2308.07624v1,"Recent advancements in large foundation models have shown promising potentialin the medical industry due to their flexible prompting capability. One suchmodel, the Segment Anything Model (SAM), a prompt-driven segmentation model,has shown remarkable performance improvements, surpassing state-of-the-artapproaches in medical image segmentation. However, existing methods primarilyrely on tuning strategies that require extensive data or prior prompts tailoredto the specific task, making it particularly challenging when only a limitednumber of data samples are available. In this paper, we propose a novelperspective on self-prompting in medical vision applications. Specifically, weharness the embedding space of SAM to prompt itself through a simple yeteffective linear pixel-wise classifier. By preserving the encoding capabilitiesof the large model, the contextual information from its decoder, and leveragingits interactive promptability, we achieve competitive results on multipledatasets (i.e. improvement of more than 15% compared to fine-tuning the maskdecoder using a few images).",Qi Wu,2023/8/15,2023/8/15
2303.11315v2,Context-faithful Prompting for Large Language Models,http://arxiv.org/abs/2303.11315v2,"Large language models (LLMs) encode parametric knowledge about world factsand have shown remarkable performance in knowledge-driven NLP tasks. However,their reliance on parametric knowledge may cause them to overlook contextualcues, leading to incorrect predictions in context-sensitive NLP tasks (e.g.,knowledge acquisition tasks). In this paper, we seek to assess and enhanceLLMs' contextual faithfulness in two aspects: knowledge conflict and predictionwith abstention. We demonstrate that LLMs' faithfulness can be significantlyimproved using carefully designed prompting strategies. In particular, weidentify opinion-based prompts and counterfactual demonstrations as the mosteffective methods. Opinion-based prompts reframe the context as a narrator'sstatement and inquire about the narrator's opinions, while counterfactualdemonstrations use instances containing false facts to improve faithfulness inknowledge conflict situations. Neither technique requires additional training.We conduct experiments on three datasets of two standard NLP tasks, machinereading comprehension and relation extraction, and the results demonstratesignificant improvement in faithfulness to contexts. Code and data are releasedat https://github.com/wzhouad/context-faithful-llm.",Wenxuan Zhou,2023/3/20,2023/10/23
2312.07846v1,Universal Incomplete-View CT Reconstruction with Prompted Contextual Transformer,http://arxiv.org/abs/2312.07846v1,"Despite the reduced radiation dose, suitability for objects with physicalconstraints, and accelerated scanning procedure, incomplete-view computedtomography (CT) images suffer from severe artifacts, hampering their value forclinical diagnosis. The incomplete-view CT can be divided into two scenariosdepending on the sampling of projection, sparse-view CT and limited-angle CT,each encompassing various settings for different clinical requirements.Existing methods tackle with these settings separately and individually due totheir significantly different artifact patterns; this, however, gives rise tohigh computational and storage costs, hindering its flexible adaptation to newsettings. To address this challenge, we present the first-of-its-kindall-in-one incomplete-view CT reconstruction model with PROmpted ContextualTransformer, termed ProCT. More specifically, we first devise the projectionview-aware prompting to provide setting-discriminative information, enabling asingle model to handle diverse incomplete-view CT settings. Then, we proposeartifact-aware contextual learning to provide the contextual guidance of imagepairs from either CT phantom or publicly available datasets, making ProCTcapable of accurately removing the complex artifacts from the incomplete-viewCT images. Extensive experiments demonstrate that ProCT can achieve superiorperformance on a wide range of incomplete-view CT settings using a singlemodel. Remarkably, our model with only image-domain information surpasses thestate-of-the-art dual-domain methods that require the access to raw data. Thecode is available at: https://github.com/Masaaki-75/proct",Chenglong Ma,2023/12/13,2023/12/13
2305.10321v2,Controllable Speaking Styles Using a Large Language Model,http://arxiv.org/abs/2305.10321v2,"Reference-based Text-to-Speech (TTS) models can generate multiple,prosodically-different renditions of the same target text. Such models jointlylearn a latent acoustic space during training, which can be sampled from duringinference. Controlling these models during inference typically requires findingan appropriate reference utterance, which is non-trivial.  Large generative language models (LLMs) have shown excellent performance invarious language-related tasks. Given only a natural language query text (theprompt), such models can be used to solve specific, context-dependent tasks.Recent work in TTS has attempted similar prompt-based control of novel speakingstyle generation. Those methods do not require a reference utterance and can,under ideal conditions, be controlled with only a prompt. But existing methodstypically require a prompt-labelled speech corpus for jointly training aprompt-conditioned encoder.  In contrast, we instead employ an LLM to directly suggest prosodicmodifications for a controllable TTS model, using contextual informationprovided in the prompt. The prompt can be designed for a multitude of tasks.Here, we give two demonstrations: control of speaking style; prosodyappropriate for a given dialogue context. The proposed method is rated mostappropriate in 50% of cases vs. 31% for a baseline model.",Atli Thor Sigurgeirsson,2023/5/17,2023/9/19
2312.14211v1,Experimenting with Large Language Models and vector embeddings in NASA SciX,http://arxiv.org/abs/2312.14211v1,"Open-source Large Language Models enable projects such as NASA SciX (i.e.,NASA ADS) to think out of the box and try alternative approaches forinformation retrieval and data augmentation, while respecting data copyrightand users' privacy. However, when large language models are directly promptedwith questions without any context, they are prone to hallucination. At NASASciX we have developed an experiment where we created semantic vectors for ourlarge collection of abstracts and full-text content, and we designed a promptsystem to ask questions using contextual chunks from our system. Based on anon-systematic human evaluation, the experiment shows a lower degree ofhallucination and better responses when using Retrieval Augmented Generation.Further exploration is required to design new features and data augmentationprocesses at NASA SciX that leverages this technology while respecting the highlevel of trust and quality that the project holds.",Sergi Blanco-Cuaresma,2023/12/21,2023/12/21
2311.10121v2,Slide-SAM: Medical SAM Meets Sliding Window,http://arxiv.org/abs/2311.10121v2,"The Segment Anything Model (SAM) has achieved a notable success intwo-dimensional image segmentation in natural images. However, the substantialgap between medical and natural images hinders its direct application tomedical image segmentation tasks. Particularly in 3D medical images, SAMstruggles to learn contextual relationships between slices, limiting itspractical applicability. Moreover, applying 2D SAM to 3D images requiresprompting the entire volume, which is time- and label-consuming. To addressthese problems, we propose Slide-SAM, which treats a stack of three adjacentslices as a prediction window. It firstly takes three slices from a 3D volumeand point- or bounding box prompts on the central slice as inputs to predictsegmentation masks for all three slices. Subsequently, the masks of the top andbottom slices are then used to generate new prompts for adjacent slices.Finally, step-wise prediction can be achieved by sliding the prediction windowforward or backward through the entire volume. Our model is trained on multiplepublic and private medical datasets and demonstrates its effectiveness throughextensive 3D segmetnation experiments, with the help of minimal prompts. Codeis available at \url{https://github.com/Curli-quan/Slide-SAM}.",Quan Quan,2023/11/16,2023/12/5
1611.04184v3,Advanced Analysis of Quantum Contextuality in a Psychophysical Double-Detection Experiment,http://arxiv.org/abs/1611.04184v3,"The results of behavioral experiments typically exhibit inconsistentconnectedness, i.e., they violate the condition known as ""no-signaling,""""no-disturbance,"" or ""marginal selectivity."" This prevents one from evaluatingthese experiments in terms of quantum contextuality if the latter understoodtraditionally (as, e.g., in the Kochen-Specker theorem or Bell-typeinequalities). The Contextuality-by-Default (CbD) theory separatescontextuality from inconsistent connectedness. When applied to quantum physicalexperiments that exhibit inconsistent connectedness (due to context-dependenterrors and/or signaling), the CbD computations reveal quantum contextuality inspite of this. When applied to a large body of published behavioralexperiments, the CbD computations reveal no quantum contextuality: allcontext-dependence in these experiments is described by inconsistentconnectedness alone. Until recently, however, experimental analysis ofcontextuality was confined to so-called cyclic systems of binary randomvariables. Here, we present the results of a psychophysical double-detectionexperiment that do not form a cyclic system: their analysis requires that weuse a recent modification of CbD, one that makes the class of noncontextualsystems more restricted. Nevertheless our results once again indicate that wheninconsistent connectedness is taken into account, the system exhibits nocontextuality. KEYWORDS: contextuality, cyclic systems, double-detection,inconsistent connectedness, psychophysics.",Vctor H. Cervantes,2016/11/13,2017/3/31
1902.00244v1,Randomness expansion secured by quantum contextuality,http://arxiv.org/abs/1902.00244v1,"The output randomness from a random number generator can be certified byobserving the violation of quantum contextuality inequalities based on theKochen-Specker theorem. Contextuality can be tested in a single quantum system,which significantly simplifies the experimental requirements to observe theviolation comparing to the ones based on nonlocality tests. However, it is notyet resolved how to ensure compatibilities for sequential measurements that isrequired in contextuality tests. Here, we employ a modifiedKlyachko-Can-Binicio\u{g}lu-Shumovsky contextuality inequality, which can easethe strict compatibility requirement on measurements. On a trapped single \Baion system, we experimentally demonstrate violation of the contextualityinequality and realize self-testing quantum random number expansion by closingdetection loopholes. We perform $1.29 \times 10^8$ trials of experiments andextract the randomness of $8.06 \times 10^5$ bits with a speed of 270 bitss$^{-1}$. Our demonstration paves the way for the practical high-speedspot-checking quantum random number expansion and other secure informationprocessing applications.",Mark Um,2019/2/1,2019/2/1
2305.17104v1,PromptNER: Prompt Locating and Typing for Named Entity Recognition,http://arxiv.org/abs/2305.17104v1,"Prompt learning is a new paradigm for utilizing pre-trained language modelsand has achieved great success in many tasks. To adopt prompt learning in theNER task, two kinds of methods have been explored from a pair of symmetricperspectives, populating the template by enumerating spans to predict theirentity types or constructing type-specific prompts to locate entities. However,these methods not only require a multi-round prompting manner with a high timeoverhead and computational cost, but also require elaborate prompt templates,that are difficult to apply in practical scenarios. In this paper, we unifyentity locating and entity typing into prompt learning, and design a dual-slotmulti-prompt template with the position slot and type slot to prompt locatingand typing respectively. Multiple prompts can be input to the modelsimultaneously, and then the model extracts all entities by parallelpredictions on the slots. To assign labels for the slots during training, wedesign a dynamic template filling mechanism that uses the extended bipartitegraph matching between prompts and the ground-truth entities. We conductexperiments in various settings, including resource-rich flat and nested NERdatasets and low-resource in-domain and cross-domain datasets. Experimentalresults show that the proposed model achieves a significant performanceimprovement, especially in the cross-domain few-shot setting, which outperformsthe state-of-the-art model by +7.7% on average.",Yongliang Shen,2023/5/26,2023/5/26
2311.15776v2,Stable Segment Anything Model,http://arxiv.org/abs/2311.15776v2,"The Segment Anything Model (SAM) achieves remarkable promptable segmentationgiven high-quality prompts which, however, often require good skills tospecify. To make SAM robust to casual prompts, this paper presents the firstcomprehensive analysis on SAM's segmentation stability across a diversespectrum of prompt qualities, notably imprecise bounding boxes and insufficientpoints. Our key finding reveals that given such low-quality prompts, SAM's maskdecoder tends to activate image features that are biased towards the backgroundor confined to specific object parts. To mitigate this issue, our key ideaconsists of calibrating solely SAM's mask attention by adjusting the samplinglocations and amplitudes of image features, while the original SAM modelarchitecture and weights remain unchanged. Consequently, our deformablesampling plugin (DSP) enables SAM to adaptively shift attention to the promptedtarget regions in a data-driven manner, facilitated by our effective robusttraining strategy (RTS). During inference, dynamic routing plugin (DRP) isproposed that toggles SAM between the deformable and regular grid samplingmodes, conditioned on the input prompt quality. Thus, our solution, termedStable-SAM, offers several advantages: 1) improved SAM's segmentation stabilityacross a wide range of prompt qualities, while 2) retaining SAM's powerfulpromptable segmentation efficiency and generality, with 3) minimal learnableparameters (0.08 M) and fast adaptation (by 1 training epoch). Extensiveexperiments across multiple datasets validate the effectiveness and advantagesof our approach, underscoring Stable-SAM as a more robust solution forsegmenting anything. Codes will be released upon acceptance.https://github.com/fanq15/Stable-SAM",Qi Fan,2023/11/27,2023/12/5
2210.03117v3,MaPLe: Multi-modal Prompt Learning,http://arxiv.org/abs/2210.03117v3,"Pre-trained vision-language (V-L) models such as CLIP have shown excellentgeneralization ability to downstream tasks. However, they are sensitive to thechoice of input text prompts and require careful selection of prompt templatesto perform well. Inspired by the Natural Language Processing (NLP) literature,recent CLIP adaptation approaches learn prompts as the textual inputs tofine-tune CLIP for downstream tasks. We note that using prompting to adaptrepresentations in a single branch of CLIP (language or vision) is sub-optimalsince it does not allow the flexibility to dynamically adjust bothrepresentation spaces on a downstream task. In this work, we proposeMulti-modal Prompt Learning (MaPLe) for both vision and language branches toimprove alignment between the vision and language representations. Our designpromotes strong coupling between the vision-language prompts to ensure mutualsynergy and discourages learning independent uni-modal solutions. Further, welearn separate prompts across different early stages to progressively model thestage-wise feature relationships to allow rich context learning. We evaluatethe effectiveness of our approach on three representative tasks ofgeneralization to novel classes, new target datasets and unseen domain shifts.Compared with the state-of-the-art method Co-CoOp, MaPLe exhibits favorableperformance and achieves an absolute gain of 3.45% on novel classes and 2.72%on overall harmonic-mean, averaged over 11 diverse image recognition datasets.Our code and pre-trained models are available athttps://github.com/muzairkhattak/multimodal-prompt-learning.",Muhammad Uzair Khattak,2022/10/6,2023/4/1
2310.19181v1,"From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude",http://arxiv.org/abs/2310.19181v1,"The advanced capabilities of Large Language Models (LLMs) have made theminvaluable across various applications, from conversational agents and contentcreation to data analysis, research, and innovation. However, theireffectiveness and accessibility also render them susceptible to abuse forgenerating malicious content, including phishing attacks. This study exploresthe potential of using four popular commercially available LLMs - ChatGPT (GPT3.5 Turbo), GPT 4, Claude and Bard to generate functional phishing attacksusing a series of malicious prompts. We discover that these LLMs can generateboth phishing emails and websites that can convincingly imitate well-knownbrands, and also deploy a range of evasive tactics for the latter to eludedetection mechanisms employed by anti-phishing systems. Notably, these attackscan be generated using unmodified, or ""vanilla,"" versions of these LLMs,without requiring any prior adversarial exploits such as jailbreaking. As acountermeasure, we build a BERT based automated detection tool that can be usedfor the early detection of malicious prompts to prevent LLMs from generatingphishing content attaining an accuracy of 97\% for phishing website prompts,and 94\% for phishing email prompts.",Sayak Saha Roy,2023/10/29,2023/10/29
2309.11575v1,Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge,http://arxiv.org/abs/2309.11575v1,"Text-conditioned image generation models have recently achieved astonishingimage quality and alignment results. Consequently, they are employed in afast-growing number of applications. Since they are highly data-driven, relyingon billion-sized datasets randomly scraped from the web, they also produceunsafe content. As a contribution to the Adversarial Nibbler challenge, wedistill a large set of over 1,000 potential adversarial inputs from existingsafety benchmarks. Our analysis of the gathered prompts and correspondingimages demonstrates the fragility of input filters and provides furtherinsights into systematic safety issues in current generative image models.",Manuel Brack,2023/9/20,2023/9/20
2309.14348v2,Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,http://arxiv.org/abs/2309.14348v2,"Recently, Large Language Models (LLMs) have made significant advancements andare now widely used across various domains. Unfortunately, there has been arising concern that LLMs can be misused to generate harmful or maliciouscontent. Though a line of research has focused on aligning LLMs with humanvalues and preventing them from producing inappropriate content, suchalignments are usually vulnerable and can be bypassed by alignment-breakingattacks via adversarially optimized or handcrafted jailbreaking prompts. Inthis work, we introduce a Robustly Aligned LLM (RA-LLM) to defend againstpotential alignment-breaking attacks. RA-LLM can be directly constructed uponan existing aligned LLM with a robust alignment checking function, withoutrequiring any expensive retraining or fine-tuning process of the original LLM.Furthermore, we also provide a theoretical analysis for RA-LLM to verify itseffectiveness in defending against alignment-breaking attacks. Throughreal-world experiments on open-source large language models, we demonstratethat RA-LLM can successfully defend against both state-of-the-art adversarialprompts and popular handcrafted jailbreaking prompts by reducing their attacksuccess rates from nearly 100% to around 10% or less.",Bochuan Cao,2023/9/18,2023/12/7
2310.15140v2,AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models,http://arxiv.org/abs/2310.15140v2,"Safety alignment of Large Language Models (LLMs) can be compromised withmanual jailbreak attacks and (automatic) adversarial attacks. Recent studiessuggest that defending against these attacks is possible: adversarial attacksgenerate unlimited but unreadable gibberish prompts, detectable byperplexity-based filters; manual jailbreak attacks craft readable prompts, buttheir limited number due to the necessity of human creativity allows for easyblocking. In this paper, we show that these solutions may be too optimistic. Weintroduce AutoDAN, an interpretable, gradient-based adversarial attack thatmerges the strengths of both attack types. Guided by the dual goals ofjailbreak and readability, AutoDAN optimizes and generates tokens one by onefrom left to right, resulting in readable prompts that bypass perplexityfilters while maintaining high attack success rates. Notably, these prompts,generated from scratch using gradients, are interpretable and diverse, withemerging strategies commonly seen in manual jailbreak attacks. They alsogeneralize to unforeseen harmful behaviors and transfer to black-box LLMsbetter than their unreadable counterparts when using limited training data or asingle proxy model. Furthermore, we show the versatility of AutoDAN byautomatically leaking system prompts using a customized objective. Our workoffers a new way to red-team LLMs and understand jailbreak mechanisms viainterpretability.",Sicheng Zhu,2023/10/23,2023/12/14
2305.16371v1,INTapt: Information-Theoretic Adversarial Prompt Tuning for Enhanced Non-Native Speech Recognition,http://arxiv.org/abs/2305.16371v1,"Automatic Speech Recognition (ASR) systems have attained unprecedentedperformance with large speech models pre-trained based on self-supervisedspeech representation learning. However, these pre-trained speech models sufferfrom representational bias as they tend to better represent those prominentaccents (i.e., native (L1) English accent) in the pre-training speech corpusthan less represented accents, resulting in a deteriorated performance fornon-native (L2) English accents. Although there have been some approaches tomitigate this issue, all of these methods require updating the pre-trainedmodel weights. In this paper, we propose Information Theoretic AdversarialPrompt Tuning (INTapt), which introduces prompts concatenated to the originalinput that can re-modulate the attention of the pre-trained model such that thecorresponding input resembles a native (L1) English speech without updating thebackbone weights. INTapt is trained simultaneously in the following twomanners: (1) adversarial training to reduce accent feature dependence betweenthe original input and the prompt-concatenated input and (2) training tominimize CTC loss for improving ASR performance to a prompt-concatenated input.Experimental results show that INTapt improves the performance of L2 Englishand increases feature similarity between L2 and L1 accents.",Eunseop Yoon,2023/5/25,2023/5/25
2305.16220v1,On the Robustness of Segment Anything,http://arxiv.org/abs/2305.16220v1,"Segment anything model (SAM) has presented impressive objectnessidentification capability with the idea of prompt learning and a new collectedlarge-scale dataset. Given a prompt (e.g., points, bounding boxes, or masks)and an input image, SAM is able to generate valid segment masks for all objectsindicated by the prompts, presenting high generalization across diversescenarios and being a general method for zero-shot transfer to downstreamvision tasks. Nevertheless, it remains unclear whether SAM may introduce errorsin certain threatening scenarios. Clarifying this is of significant importancefor applications that require robustness, such as autonomous vehicles. In thispaper, we aim to study the testing-time robustness of SAM under adversarialscenarios and common corruptions. To this end, we first build a testing-timerobustness evaluation benchmark for SAM by integrating existing publicdatasets. Second, we extend representative adversarial attacks against SAM andstudy the influence of different prompts on robustness. Third, we study therobustness of SAM under diverse corruption types by evaluating SAM on corrupteddatasets with different prompts. With experiments conducted on SA-1B and KITTIdatasets, we find that SAM exhibits remarkable robustness against variouscorruptions, except for blur-related corruption. Furthermore, SAM remainssusceptible to adversarial attacks, particularly when subjected to PGD and BIMattacks. We think such a comprehensive study could highlight the importance ofthe robustness issues of SAM and trigger a series of new tasks for SAM as wellas downstream vision tasks.",Yihao Huang,2023/5/25,2023/5/25
2312.14440v1,Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks,http://arxiv.org/abs/2312.14440v1,"The widespread use of Text-to-Image (T2I) models in content generationrequires careful examination of their safety, including their robustness toadversarial attacks. Despite extensive research into this, the reasons fortheir effectiveness are underexplored. This paper presents an empirical studyon adversarial attacks against T2I models, focusing on analyzing factorsassociated with attack success rates (ASRs). We introduce a new attackobjective - entity swapping using adversarial suffixes and two gradient-basedattack algorithms. Human and automatic evaluations reveal the asymmetric natureof ASRs on entity swap: for example, it is easier to replace ""human"" with""robot"" in the prompt ""a human dancing in the rain."" with an adversarial suffixbut is significantly harder in reverse. We further propose probing metrics toestablish indicative signals from the model's beliefs to the adversarial ASR.We identify conditions resulting in a 60% success probability for adversarialattacks and others where this likelihood drops below 5%.",Haz Sameen Shahgir,2023/12/22,2023/12/22
2305.11186v2,"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt",http://arxiv.org/abs/2305.11186v2,"While the numerous parameters in Large Language Models (LLMs) contribute totheir superior performance, this massive scale makes them inefficient andmemory-hungry. Thus, they are hard to deploy on commodity hardware, such as onesingle GPU. Given the memory and power constraints of such devices, modelcompression methods are widely employed to reduce both the model size andinference latency, which essentially trades off model quality in return forimproved efficiency. Thus, optimizing this accuracy-efficiency trade-off iscrucial for the LLM deployment on commodity hardware. In this paper, weintroduce a new perspective to optimize this trade-off by prompting compressedmodels. Specifically, we first observe that for certain questions, thegeneration quality of a compressed LLM can be significantly improved by addingcarefully designed hard prompts, though this isn't the case for all questions.Based on this observation, we propose a soft prompt learning method where weexpose the compressed model to the prompt learning process, aiming to enhancethe performance of prompts. Our experimental analysis suggests our soft promptstrategy greatly improves the performance of the 8x compressed LLaMA-7B model(with a joint 4-bit quantization and 50% weight pruning compression), allowingthem to match their uncompressed counterparts on popular benchmarks. Also, wedemonstrate that these learned prompts can be transferred across variousdatasets, tasks, and compression levels. Hence with this transferability, wecan stitch the soft prompt to a newly compressed model to improve the test-timeaccuracy in an ``in-situ'' way.",Zhaozhuo Xu,2023/5/17,2023/10/10
2210.02952v2,Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation,http://arxiv.org/abs/2210.02952v2,"Prompt tuning, or the conditioning of a frozen pretrained language model(PLM) with soft prompts learned from data, has demonstrated impressiveperformance on a wide range of NLP tasks. However, prompt tuning requires alarge training dataset to be effective and is outperformed by finetuning theentire PLM in data-scarce regimes. Previous work (Gu et al., 2022, Vu et al.,2022) proposed to transfer soft prompts pretrained on the source domain to thetarget domain. In this paper, we explore domain adaptation for prompt tuning, aproblem setting where unlabeled data from the target domain are availableduring pretraining. We propose bOosting Prompt TunIng with doMain Adaptation(OPTIMA), which regularizes the decision boundary to be smooth around regionswhere source and target data distributions are similar. Extensive experimentsdemonstrate that OPTIMA significantly enhances the transferability andsample-efficiency of prompt tuning compared to strong baselines. Moreover, infew-shot settings, OPTIMA exceeds full-model tuning by a large margin.",Xu Guo,2022/10/6,2022/10/21
2305.12077v1,Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer,http://arxiv.org/abs/2305.12077v1,"In real-world scenarios, labeled samples for dialogue summarization areusually limited (i.e., few-shot) due to high annotation costs for high-qualitydialogue summaries. To efficiently learn from few-shot samples, previous workshave utilized massive annotated data from other downstream tasks and thenperformed prompt transfer in prompt tuning so as to enable cross-task knowledgetransfer. However, existing general-purpose prompt transfer techniques lackconsideration for dialogue-specific information. In this paper, we focus onimproving the prompt transfer from dialogue state tracking to dialoguesummarization and propose Skeleton-Assisted Prompt Transfer (SAPT), whichleverages skeleton generation as extra supervision that functions as a mediumconnecting the distinct source and target task and resulting in the model'sbetter consumption of dialogue state information. To automatically extractdialogue skeletons as supervised training data for skeleton generation, wedesign a novel approach with perturbation-based probes requiring neitherannotation effort nor domain knowledge. Training the model on such skeletonscan also help preserve model capability during prompt transfer. Our methodsignificantly outperforms existing baselines. In-depth analyses demonstrate theeffectiveness of our method in facilitating cross-task knowledge transfer infew-shot dialogue summarization.",Kaige Xie,2023/5/20,2023/5/20
2301.02903v1,Transferring Pre-trained Multimodal Representations with Cross-modal Similarity Matching,http://arxiv.org/abs/2301.02903v1,"Despite surprising performance on zero-shot transfer, pre-training alarge-scale multimodal model is often prohibitive as it requires a huge amountof data and computing resources. In this paper, we propose a method (BeamCLIP)that can effectively transfer the representations of a large pre-trainedmultimodal model (CLIP-ViT) into a small target model (e.g., ResNet-18). Forunsupervised transfer, we introduce cross-modal similarity matching (CSM) thatenables a student model to learn the representations of a teacher model bymatching the relative similarity distribution across text prompt embeddings. Tobetter encode the text prompts, we design context-based prompt augmentation(CPA) that can alleviate the lexical ambiguity of input text prompts. Ourexperiments show that unsupervised representation transfer of a pre-trainedvision-language model enables a small ResNet-18 to achieve a better ImageNet-1Ktop-1 linear probe accuracy (66.2%) than vision-only self-supervised learning(SSL) methods (e.g., SimCLR: 51.8%, SwAV: 63.7%), while closing the gap withsupervised learning (69.8%).",Byoungjip Kim,2023/1/7,2023/1/7
2309.15494v1,VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning,http://arxiv.org/abs/2309.15494v1,"Multimodal transfer learning aims to transform pretrained representations ofdiverse modalities into a common domain space for effective multimodal fusion.However, conventional systems are typically built on the assumption that allmodalities exist, and the lack of modalities always leads to poor inferenceperformance. Furthermore, extracting pretrained embeddings for all modalitiesis computationally inefficient for inference. In this work, to achieve highefficiency-performance multimodal transfer learning, we propose VideoAdviser, avideo knowledge distillation method to transfer multimodal knowledge ofvideo-enhanced prompts from a multimodal fundamental model (teacher) to aspecific modal fundamental model (student). With an intuition that the bestlearning performance comes with professional advisers and smart students, weuse a CLIP-based teacher model to provide expressive multimodal knowledgesupervision signals to a RoBERTa-based student model via optimizing astep-distillation objective loss -- first step: the teacher distills multimodalknowledge of video-enhanced prompts from classification logits to a regressionlogit -- second step: the multimodal knowledge is distilled from the regressionlogit of the teacher to the student. We evaluate our method in two challengingmultimodal tasks: video-level sentiment analysis (MOSI and MOSEI datasets) andaudio-visual retrieval (VEGAS dataset). The student (requiring only the textmodality as input) achieves an MAE score improvement of up to 12.3% for MOSIand MOSEI. Our method further enhances the state-of-the-art method by 3.4% mAPscore for VEGAS without additional computations for inference. These resultssuggest the strengths of our method for achieving high efficiency-performancemultimodal transfer learning.",Yanan Wang,2023/9/27,2023/9/27
2304.10354v1,Prompt-Learning for Cross-Lingual Relation Extraction,http://arxiv.org/abs/2304.10354v1,"Relation Extraction (RE) is a crucial task in Information Extraction, whichentails predicting relationships between entities within a given sentence.However, extending pre-trained RE models to other languages is challenging,particularly in real-world scenarios where Cross-Lingual Relation Extraction(XRE) is required. Despite recent advancements in Prompt-Learning, whichinvolves transferring knowledge from Multilingual Pre-trained Language Models(PLMs) to diverse downstream tasks, there is limited research on the effectiveuse of multilingual PLMs with prompts to improve XRE. In this paper, we presenta novel XRE algorithm based on Prompt-Tuning, referred to as Prompt-XRE. Toevaluate its effectiveness, we design and implement several prompt templates,including hard, soft, and hybrid prompts, and empirically test theirperformance on competitive multilingual PLMs, specifically mBART. Our extensiveexperiments, conducted on the low-resource ACE05 benchmark across multiplelanguages, demonstrate that our Prompt-XRE algorithm significantly outperformsboth vanilla multilingual PLMs and other existing models, achievingstate-of-the-art performance in XRE. To further show the generalization of ourPrompt-XRE on larger data scales, we construct and release a new XRE dataset-WMT17-EnZh XRE, containing 0.9M English-Chinese pairs extracted from WMT 2017parallel corpus. Experiments on WMT17-EnZh XRE also show the effectiveness ofour Prompt-XRE against other competitive baselines. The code and newlyconstructed dataset are freely available at\url{https://github.com/HSU-CHIA-MING/Prompt-XRE}.",Chiaming Hsu,2023/4/20,2023/4/20
2305.10300v3,One-Prompt to Segment All Medical Images,http://arxiv.org/abs/2305.10300v3,"Large foundation models, known for their strong zero-shot generalization,have excelled in visual and language applications. However, applying them tomedical image segmentation, a domain with diverse imaging types and targetlabels, remains an open challenge. Current approaches, such as adaptinginteractive segmentation models like Segment Anything Model (SAM), require userprompts for each sample during inference. Alternatively, transfer learningmethods like few/one-shot models demand labeled samples, leading to high costs.This paper introduces a new paradigm toward the universal medical imagesegmentation, termed 'One-Prompt Segmentation.' One-Prompt Segmentationcombines the strengths of one-shot and interactive methods. In the inferencestage, with just \textbf{one prompted sample}, it can adeptly handle the unseentask in a single forward pass. We train One-Prompt Model on 64 open-sourcemedical datasets, accompanied by the collection of over 3,000 clinician-labeledprompts. Tested on 14 previously unseen tasks, the One-Prompt Model showcasessuperior zero-shot segmentation capabilities, outperforming a wide range ofrelated methods. The code and annotated data will be publicly released.",Junde Wu,2023/5/17,2023/12/20
2401.09181v1,Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer,http://arxiv.org/abs/2401.09181v1,"Multimodal Continual Instruction Tuning (MCIT) enables Multimodal LargeLanguage Models (MLLMs) to meet continuously emerging requirements withoutexpensive retraining. MCIT faces two major obstacles: catastrophic forgetting(where old knowledge is forgotten) and negative forward transfer (where theperformance of future tasks is degraded). Although existing methods havegreatly alleviated catastrophic forgetting, they still suffer from negativeforward transfer. By performing singular value decomposition (SVD) on inputembeddings, we discover a large discrepancy in different input embeddings. Thediscrepancy results in the model learning irrelevant information for old andpre-trained tasks, which leads to catastrophic forgetting and negative forwardtransfer. To address these issues, we propose Fwd-Prompt, a prompt-based methodprojecting prompt gradient to the residual space to minimize the interferencebetween tasks and to the pre-trained subspace for reusing pre-trainedknowledge. Our experiments demonstrate that Fwd-Prompt achievesstate-of-the-art performance while updating fewer parameters and requiring noold samples. Our research sheds light on the potential of continuously adaptingMLLMs to new tasks under the instruction tuning paradigm and encourages futurestudies to explore MCIT. The code will soon be publicly available.",Junhao Zheng,2024/1/17,2024/1/17
2001.01227v1,From Learning to Meta-Learning: Reduced Training Overhead and Complexity for Communication Systems,http://arxiv.org/abs/2001.01227v1,"Machine learning methods adapt the parameters of a model, constrained to liein a given model class, by using a fixed learning procedure based on data oractive observations. Adaptation is done on a per-task basis, and retraining isneeded when the system configuration changes. The resulting inefficiency interms of data and training time requirements can be mitigated, if domainknowledge is available, by selecting a suitable model class and learningprocedure, collectively known as inductive bias. However, it is generallydifficult to encode prior knowledge into an inductive bias, particularly withblack-box model classes such as neural networks. Meta-learning provides a wayto automatize the selection of an inductive bias. Meta-learning leverages dataor active observations from tasks that are expected to be related to future,and a priori unknown, tasks of interest. With a meta-trained inductive bias,training of a machine learning model can be potentially carried out withreduced training data and/or time complexity. This paper provides a high-levelintroduction to meta-learning with applications to communication systems.",Osvaldo Simeone,2020/1/5,2020/1/5
2103.07575v1,A Review on Semi-Supervised Relation Extraction,http://arxiv.org/abs/2103.07575v1,"Relation extraction (RE) plays an important role in extracting knowledge fromunstructured text but requires a large amount of labeled corpus. To reduce theexpensive annotation efforts, semisupervised learning aims to leverage bothlabeled and unlabeled data. In this paper, we review and compare three typicalmethods in semi-supervised RE with deep learning or meta-learning:self-ensembling, which forces consistent under perturbations but may confrontinsufficient supervision; self-training, which iteratively generates pseudolabels and retrain itself with the enlarged labeled set; dual learning, whichleverages a primal task and a dual task to give mutual feedback. Mean-teacher(Tarvainen and Valpola, 2017), LST (Li et al., 2019), and DualRE (Lin et al.,2019) are elaborated as the representatives to alleviate the weakness of thesethree methods, respectively.",Yusen Lin,2021/3/12,2021/3/12
2311.02879v1,Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling,http://arxiv.org/abs/2311.02879v1,"Most meta-learning methods assume that the (very small) context set used toestablish a new task at test time is passively provided. In some settings,however, it is feasible to actively select which points to label; the potentialgain from a careful choice is substantial, but the setting requires majordifferences from typical active learning setups. We clarify the ways in whichactive meta-learning can be used to label a context set, depending on whichparts of the meta-learning process use active learning. Within this framework,we propose a natural algorithm based on fitting Gaussian mixtures for selectingwhich points to label; though simple, the algorithm also has theoreticalmotivation. The proposed algorithm outperforms state-of-the-art active learningmethods when used with various meta-learning algorithms across severalbenchmark datasets.",Wonho Bae,2023/11/6,2023/11/6
2401.10253v1,Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable and Transferable Bandwidth Allocation,http://arxiv.org/abs/2401.10253v1,"In this paper, we develop a deep learning-based bandwidth allocation policythat is: 1) scalable with the number of users and 2) transferable to differentcommunication scenarios, such as non-stationary wireless channels, differentquality-of-service (QoS) requirements, and dynamically available resources. Tosupport scalability, the bandwidth allocation policy is represented by a graphneural network (GNN), with which the number of training parameters does notchange with the number of users. To enable the generalization of the GNN, wedevelop a hybrid-task meta-learning (HML) algorithm that trains the initialparameters of the GNN with different communication scenarios duringmeta-training. Next, during meta-testing, a few samples are used to fine-tunethe GNN with unseen communication scenarios. Simulation results demonstratethat our HML approach can improve the initial performance by $8.79\%$, andsampling efficiency by $73\%$, compared with existing benchmarks. Afterfine-tuning, our near-optimal GNN-based policy can achieve close to the samereward with much lower inference complexity compared to the optimal policyobtained using iterative optimization.",Xin Hao,2023/12/23,2023/12/23
2208.13909v1,"""Prompt-Gamma Neutron Activation Analysis (PGNAA)"" Metal Spectral Classification using Deep Learning Method",http://arxiv.org/abs/2208.13909v1,"There is a pressing market demand to minimize the test time of Prompt GammaNeutron Activation Analysis (PGNAA) spectra measurement machine, so that itcould function as an instant material analyzer, e.g. to classify waste samplesinstantaneously and determine the best recycling method based on the detectedcompositions of the testing sample.  This article introduces a new development of the deep learning classificationand contrive to reduce the test time for PGNAA machine. We propose both RandomSampling Methods and Class Activation Map (CAM) to generate ""downsized"" samplesand train the CNN model continuously. Random Sampling Methods (RSM) aims toreduce the measuring time within a sample, and Class Activation Map (CAM) isfor filtering out the less important energy range of the downsized samples.  We shorten the overall PGNAA measuring time down to 2.5 seconds whileensuring the accuracy is around 96.88 % for our dataset with 12 differentspecies of substances. Compared with classifying different species ofmaterials, it requires more test time (sample count rate) for substances havingthe same elements to archive good accuracy. For example, the classification ofcopper alloys requires nearly 24 seconds test time to reach 98 % accuracy.",Ka Yung Cheng,2022/8/29,2022/8/29
2302.12246v3,Active Prompting with Chain-of-Thought for Large Language Models,http://arxiv.org/abs/2302.12246v3,"The increasing scale of large language models (LLMs) brings emergentabilities to various complex tasks requiring reasoning, such as arithmetic andcommonsense reasoning. It is known that the effective design of task-specificprompts is critical for LLMs' ability to produce high-quality answers. Inparticular, an effective approach for complex question-and-answer tasks isexample-based prompting with chain-of-thought (CoT) reasoning, whichsignificantly improves the performance of LLMs. However, current CoT methodsrely on a fixed set of human-annotated exemplars, which are not necessarily themost effective examples for different tasks. This paper proposes a new method,Active-Prompt, to adapt LLMs to different tasks with task-specific exampleprompts (annotated with human-designed CoT reasoning). For this purpose, wepropose a solution to the key problem of determining which questions are themost important and helpful ones to annotate from a pool of task-specificqueries. By borrowing ideas from the related problem of uncertainty-basedactive learning, we introduce several metrics to characterize the uncertaintyso as to select the most uncertain questions for annotation. Experimentalresults demonstrate the superiority of our proposed method, achievingstate-of-the-art on eight complex reasoning tasks. Further analyses ofdifferent uncertainty metrics, pool sizes, zero-shot learning, andaccuracy-uncertainty relationship demonstrate the effectiveness of our method.Our code will be available at https://github.com/shizhediao/active-prompt.",Shizhe Diao,2023/2/23,2023/5/23
2310.11589v1,Eliciting Human Preferences with Language Models,http://arxiv.org/abs/2310.11589v1,"Language models (LMs) can be directed to perform target tasks by usinglabeled examples or natural language prompts. But selecting examples or writingprompts for can be challenging--especially in tasks that involve unusual edgecases, demand precise articulation of nebulous preferences, or require anaccurate mental model of LM behavior. We propose to use *LMs themselves* toguide the task specification process. In this paper, we introduce **GenerativeActive Task Elicitation (GATE)**: a learning framework in which models elicitand infer intended behavior through free-form, language-based interaction withusers. We study GATE in three domains: email validation, contentrecommendation, and moral reasoning. In preregistered experiments, we show thatLMs prompted to perform GATE (e.g., by generating open-ended questions orsynthesizing informative edge cases) elicit responses that are often moreinformative than user-written prompts or labels. Users report that interactivetask elicitation requires less effort than prompting or example labeling andsurfaces novel considerations not initially anticipated by users. Our findingssuggest that LM-driven elicitation can be a powerful tool for aligning modelsto complex human preferences and values.",Belinda Z. Li,2023/10/17,2023/10/17
1708.01354v2,CASSL: Curriculum Accelerated Self-Supervised Learning,http://arxiv.org/abs/1708.01354v2,"Recent self-supervised learning approaches focus on using a few thousand datapoints to learn policies for high-level, low-dimensional action spaces.However, scaling this framework for high-dimensional control require eitherscaling up the data collection efforts or using a clever sampling strategy fortraining. We present a novel approach - Curriculum Accelerated Self-SupervisedLearning (CASSL) - to train policies that map visual information to high-level,higher- dimensional action spaces. CASSL orders the sampling of training databased on control dimensions: the learning and sampling are focused on fewcontrol parameters before other parameters. The right curriculum for learningis suggested by variance-based global sensitivity analysis of the controlspace. We apply our CASSL framework to learning how to grasp using an adaptive,underactuated multi-fingered gripper, a challenging system to control. Ourexperimental results indicate that CASSL provides significant improvement andgeneralization compared to baseline methods such as staged curriculum learning(8% increase) and complete end-to-end learning with random exploration (14%improvement) tested on a set of novel objects.",Adithyavairavan Murali,2017/8/4,2018/2/12
1901.06783v2,Dynamic Curriculum Learning for Imbalanced Data Classification,http://arxiv.org/abs/1901.06783v2,"Human attribute analysis is a challenging task in the field of computervision, since the data is largely imbalance-distributed. Common techniques suchas re-sampling and cost-sensitive learning require prior-knowledge to train thesystem. To address this problem, we propose a unified framework called DynamicCurriculum Learning (DCL) to online adaptively adjust the sampling strategy andloss learning in single batch, which resulting in better generalization anddiscrimination. Inspired by the curriculum learning, DCL consists of two levelcurriculum schedulers: (1) sampling scheduler not only manages the datadistribution from imbalanced to balanced but also from easy to hard; (2) lossscheduler controls the learning importance between classification and metriclearning loss. Learning from these two schedulers, we demonstrate our DCLframework with the new state-of-the-art performance on the widely used faceattribute dataset CelebA and pedestrian attribute dataset RAP.",Yiru Wang,2019/1/21,2019/8/15
2311.08886v1,CLIMB: Curriculum Learning for Infant-inspired Model Building,http://arxiv.org/abs/2311.08886v1,"We describe our team's contribution to the STRICT-SMALL track of the BabyLMChallenge. The challenge requires training a language model from scratch usingonly a relatively small training dataset of ten million words. We experimentwith three variants of cognitively-motivated curriculum learning and analyzetheir effect on the performance of the model on linguistic evaluation tasks. Inthe vocabulary curriculum, we analyze methods for constraining the vocabularyin the early stages of training to simulate cognitively more plausible learningcurves. In the data curriculum experiments, we vary the order of the traininginstances based on i) infant-inspired expectations and ii) the learningbehavior of the model. In the objective curriculum, we explore differentvariations of combining the conventional masked language modeling task with amore coarse-grained word class prediction task to reinforce linguisticgeneralization capabilities. Our results did not yield consistent improvementsover our own non-curriculum learning baseline across a range of linguisticbenchmarks; however, we do find marginal gains on select tasks. Our analysishighlights key takeaways for specific combinations of tasks and settings whichbenefit from our proposed curricula. We moreover determine that carefulselection of model architecture, and training hyper-parameters yieldsubstantial improvements over the default baselines provided by the BabyLMchallenge.",Richard Diehl Martinez,2023/11/15,2023/11/15
2302.01243v2,Human not in the loop: objective sample difficulty measures for Curriculum Learning,http://arxiv.org/abs/2302.01243v2,"Curriculum learning is a learning method that trains models in a meaningfulorder from easier to harder samples. A key here is to devise automatic andobjective difficulty measures of samples. In the medical domain, previous workapplied domain knowledge from human experts to qualitatively assessclassification difficulty of medical images to guide curriculum learning, whichrequires extra annotation efforts, relies on subjective human experience, andmay introduce bias. In this work, we propose a new automated curriculumlearning technique using the variance of gradients (VoG) to compute anobjective difficulty measure of samples and evaluated its effects on elbowfracture classification from X-ray images. Specifically, we used VoG as ametric to rank each sample in terms of the classification difficulty, wherehigh VoG scores indicate more difficult cases for classification, to guide thecurriculum training process We compared the proposed technique to a baseline(without curriculum learning), a previous method that used human annotations onclassification difficulty, and anti-curriculum learning. Our experiment resultsshowed comparable and higher performance for the binary and multi-class bonefracture classification tasks.",Zhengbo Zhou,2023/2/2,2023/2/25
2106.14876v1,"Multi-task curriculum learning in a complex, visual, hard-exploration domain: Minecraft",http://arxiv.org/abs/2106.14876v1,"An important challenge in reinforcement learning is training agents that cansolve a wide variety of tasks. If tasks depend on each other (e.g. needing tolearn to walk before learning to run), curriculum learning can speed uplearning by focusing on the next best task to learn. We explore curriculumlearning in a complex, visual domain with many hard exploration challenges:Minecraft. We find that learning progress (defined as a change in successprobability of a task) is a reliable measure of learnability for automaticallyconstructing an effective curriculum. We introduce a learning-progress basedcurriculum and test it on a complex reinforcement learning problem (called""Simon Says"") where an agent is instructed to obtain a desired goal item. Manyof the required skills depend on each other. Experiments demonstrate that: (1)a within-episode exploration bonus for obtaining new items improvesperformance, (2) dynamically adjusting this bonus across training such that itonly applies to items the agent cannot reliably obtain yet further increasesperformance, (3) the learning-progress based curriculum elegantly follows thelearning curve of the agent, and (4) when the learning-progress basedcurriculum is combined with the dynamic exploration bonus it learns much moreefficiently and obtains far higher performance than uniform baselines. Theseresults suggest that combining intra-episode and across-training explorationbonuses with learning progress creates a promising method for automatedcurriculum generation, which may substantially increase our ability to trainmore capable, generally intelligent agents.",Ingmar Kanitscheider,2021/6/28,2021/6/28
2112.12086v1,Improved skin lesion recognition by a Self-Supervised Curricular Deep Learning approach,http://arxiv.org/abs/2112.12086v1,"State-of-the-art deep learning approaches for skin lesion recognition oftenrequire pretraining on larger and more varied datasets, to overcome thegeneralization limitations derived from the reduced size of the skin lesionimaging datasets. ImageNet is often used as the pretraining dataset, but itstransferring potential is hindered by the domain gap between the source datasetand the target dermatoscopic scenario. In this work, we introduce a novelpretraining approach that sequentially trains a series of Self-SupervisedLearning pretext tasks and only requires the unlabeled skin lesion imagingdata. We present a simple methodology to establish an ordering that defines apretext task curriculum. For the multi-class skin lesion classificationproblem, and ISIC-2019 dataset, we provide experimental evidence showing that:i) a model pretrained by a curriculum of pretext tasks outperforms modelspretrained by individual pretext tasks, and ii) a model pretrained by theoptimal pretext task curriculum outperforms a model pretrained on ImageNet. Wedemonstrate that this performance gain is related to the fact that thecurriculum of pretext tasks better focuses the attention of the final model onthe skin lesion. Beyond performance improvement, this strategy allows for alarge reduction in the training time with respect to ImageNet pretraining,which is especially advantageous for network architectures tailored for aspecific problem.",Kirill Sirotkin,2021/12/22,2021/12/22
2007.01261v1,Curriculum Manager for Source Selection in Multi-Source Domain Adaptation,http://arxiv.org/abs/2007.01261v1,"The performance of Multi-Source Unsupervised Domain Adaptation dependssignificantly on the effectiveness of transfer from labeled source domainsamples. In this paper, we proposed an adversarial agent that learns a dynamiccurriculum for source samples, called Curriculum Manager for Source Selection(CMSS). The Curriculum Manager, an independent network module, constantlyupdates the curriculum during training, and iteratively learns which domains orsamples are best suited for aligning to the target. The intuition behind thisis to force the Curriculum Manager to constantly re-measure the transferabilityof latent domains over time to adversarially raise the error rate of the domaindiscriminator. CMSS does not require any knowledge of the domain labels, yet itoutperforms other methods on four well-known benchmarks by significant margins.We also provide interpretable results that shed light on the proposed method.",Luyu Yang,2020/7/2,2020/7/2
2009.10625v1,Curriculum Learning with Diversity for Supervised Computer Vision Tasks,http://arxiv.org/abs/2009.10625v1,"Curriculum learning techniques are a viable solution for improving theaccuracy of automatic models, by replacing the traditional random training withan easy-to-hard strategy. However, the standard curriculum methodology does notautomatically provide improved results, but it is constrained by multipleelements like the data distribution or the proposed model. In this paper, weintroduce a novel curriculum sampling strategy which takes into considerationthe diversity of the training data together with the difficulty of the inputs.We determine the difficulty using a state-of-the-art estimator based on thehuman time required for solving a visual search task. We consider this kind ofdifficulty metric to be better suited for solving general problems, as it isnot based on certain task-dependent elements, but more on the context of eachimage. We ensure the diversity during training, giving higher priority toelements from less visited classes. We conduct object detection and instancesegmentation experiments on Pascal VOC 2007 and Cityscapes data sets,surpassing both the randomly-trained baseline and the standard curriculumapproach. We prove that our strategy is very efficient for unbalanced datasets, leading to faster convergence and more accurate results, when othercurriculum-based strategies fail.",Petru Soviany,2020/9/22,2020/9/22
2106.03688v1,"A Computational Model of Representation Learning in the Brain Cortex, Integrating Unsupervised and Reinforcement Learning",http://arxiv.org/abs/2106.03688v1,"A common view on the brain learning processes proposes that the three classiclearning paradigms -- unsupervised, reinforcement, and supervised -- take placein respectively the cortex, the basal-ganglia, and the cerebellum. However,dopamine outbursts, usually assumed to encode reward, are not limited to thebasal ganglia but also reach prefrontal, motor, and higher sensory cortices. Wepropose that in the cortex the same reward-based trial-and-error processesmight support not only the acquisition of motor representations but also ofsensory representations. In particular, reward signals might guidetrial-and-error processes that mix with associative learning processes tosupport the acquisition of representations better serving downstream actionselection. We tested the soundness of this hypothesis with a computationalmodel that integrates unsupervised learning (Contrastive Divergence) andreinforcement learning (REINFORCE). The model was tested with a task requiringdifferent responses to different visual images grouped in categories involvingeither colour, shape, or size. Results show that a balanced mix of unsupervisedand reinforcement learning processes leads to the best performance. Indeed,excessive unsupervised learning tends to under-represent task-relevant featureswhile excessive reinforcement learning tends to initially learn slowly and thento incur in local minima. These results stimulate future empirical studies oncategory learning directed to investigate similar effects in the extrastriatevisual cortices. Moreover, they prompt further computational investigationsdirected to study the possible advantages of integrating unsupervised andreinforcement learning processes.",Giovanni Granato,2021/6/7,2021/6/7
2312.16204v1,Iterative Prompt Relabeling for diffusion model with RLDF,http://arxiv.org/abs/2312.16204v1,"Diffusion models have shown impressive performance in many domains, includingimage generation, time series prediction, and reinforcement learning. Thealgorithm demonstrates superior performance over the traditional GAN andtransformer based methods. However, the model's capability to follow naturallanguage instructions (e.g., spatial relationships between objects, generatingcomplex scenes) is still unsatisfactory. This has been an important researcharea to enhance such capability. Prior works adopt reinforcement learning toadjust the behavior of the diffusion models. However, RL methods not onlyrequire careful reward design and complex hyperparameter tuning, but also failsto incorporate rich natural language feedback. In this work, we proposeiterative prompt relabeling (IP-RLDF), a novel algorithm that aligns images totext through iterative image sampling and prompt relabeling. IP-RLDF firstsamples a batch of images conditioned on the text, then relabels the textprompts of unmatched text-image pairs with classifier feedback. We conductthorough experiments on three different models, including SDv2, GLIGEN, andSDXL, testing their capability to generate images following instructions. WithIP-RLDF, we improved up to 15.22% (absolute improvement) on the challengingspatial relation VISOR benchmark, demonstrating superior performance comparedto previous RL methods.",Jiaxin Ge,2023/12/23,2023/12/23
2306.06199v1,Reliability Check: An Analysis of GPT-3's Response to Sensitive Topics and Prompt Wording,http://arxiv.org/abs/2306.06199v1,"Large language models (LLMs) have become mainstream technology with theirversatile use cases and impressive performance. Despite the countlessout-of-the-box applications, LLMs are still not reliable. A lot of work isbeing done to improve the factual accuracy, consistency, and ethical standardsof these models through fine-tuning, prompting, and Reinforcement Learning withHuman Feedback (RLHF), but no systematic analysis of the responses of thesemodels to different categories of statements, or on their potentialvulnerabilities to simple prompting changes is available. In this work, weanalyze what confuses GPT-3: how the model responds to certain sensitive topicsand what effects the prompt wording has on the model response. We find thatGPT-3 correctly disagrees with obvious Conspiracies and Stereotypes but makesmistakes with common Misconceptions and Controversies. The model responses areinconsistent across prompts and settings, highlighting GPT-3's unreliability.Dataset and code of our analysis is available inhttps://github.com/tanny411/GPT3-Reliability-Check.",Aisha Khatun,2023/6/9,2023/6/9
2310.08566v1,Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining,http://arxiv.org/abs/2310.08566v1,"Large transformer models pretrained on offline reinforcement learningdatasets have demonstrated remarkable in-context reinforcement learning (ICRL)capabilities, where they can make good decisions when prompted with interactiontrajectories from unseen environments. However, when and how transformers canbe trained to perform ICRL have not been theoretically well-understood. Inparticular, it is unclear which reinforcement-learning algorithms transformerscan perform in context, and how distribution mismatch in offline training dataaffects the learned algorithms. This paper provides a theoretical frameworkthat analyzes supervised pretraining for ICRL. This includes two recentlyproposed training methods -- algorithm distillation and decision-pretrainedtransformers. First, assuming model realizability, we prove thesupervised-pretrained transformer will imitate the conditional expectation ofthe expert algorithm given the observed trajectory. The generalization errorwill scale with model capacity and a distribution divergence factor between theexpert and offline algorithms. Second, we show transformers with ReLU attentioncan efficiently approximate near-optimal online reinforcement learningalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, andUCB-VI for tabular Markov decision processes. This provides the firstquantitative analysis of the ICRL capabilities of transformers pretrained fromoffline trajectories.",Licong Lin,2023/10/12,2023/10/12
2303.00001v1,Reward Design with Language Models,http://arxiv.org/abs/2303.00001v1,"Reward design in reinforcement learning (RL) is challenging since specifyinghuman notions of desired behavior may be difficult via reward functions orrequire many expert demonstrations. Can we instead cheaply design rewards usinga natural language interface? This paper explores how to simplify reward designby prompting a large language model (LLM) such as GPT-3 as a proxy rewardfunction, where the user provides a textual prompt containing a few examples(few-shot) or a description (zero-shot) of the desired behavior. Our approachleverages this proxy reward function in an RL framework. Specifically, usersspecify a prompt once at the beginning of training. During training, the LLMevaluates an RL agent's behavior against the desired behavior described by theprompt and outputs a corresponding reward signal. The RL agent then uses thisreward to update its behavior. We evaluate whether our approach can trainagents aligned with user objectives in the Ultimatum Game, matrix games, andthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agentstrained with our framework are well-aligned with the user's objectives andoutperform RL agents trained with reward functions learned via supervisedlearning",Minae Kwon,2023/2/27,2023/2/27
2311.18232v1,LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models,http://arxiv.org/abs/2311.18232v1,"Large language models (LLMs) provide excellent text-generation capabilities,but standard prompting and generation methods generally do not lead tointentional or goal-directed agents and might necessitate considerable prompttuning. This becomes particularly apparent in multi-turn conversations: eventhe best current LLMs rarely ask clarifying questions, engage in explicitinformation gathering, or take actions now that lead to better decisions aftermultiple turns. Reinforcement learning has the potential to leverage thepowerful modeling capabilities of LLMs, as well as their internalrepresentation of textual interactions, to create capable goal-directedlanguage agents. This can enable intentional and temporally extendedinteractions, such as with humans, through coordinated persuasion and carefullycrafted questions, or in goal-directed play through text games to bring aboutdesired final outcomes. However, enabling this requires the community todevelop stable and reliable reinforcement learning algorithms that caneffectively train LLMs. Developing such algorithms requires tasks that cangauge progress on algorithm design, provide accessible and reproducibleevaluations for multi-turn interactions, and cover a range of task propertiesand challenges in improving reinforcement learning algorithms. Our paperintroduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,together with an open-source research framework containing a basic toolkit forgetting started on multi-turn RL with offline value-based and policy-based RLmethods. Our benchmark consists of 8 different language tasks, which requiremultiple rounds of language interaction and cover a range of tasks inopen-ended dialogue and text games.",Marwa Abdulhai,2023/11/30,2023/11/30
0811.3077v2,Analysis of the N=4 Hubbard ring using a counting operator,http://arxiv.org/abs/0811.3077v2,We prove three theorems about the use of a counting operator to study thespectrum of model Hamiltonians. We analytically calculate the eigenvalues ofthe Hubbard ring with four lattice positions and apply our theorems to describethe observed level crossings.,Tobias Verhulst,2008/11/19,2009/2/12
2303.09314v2,TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection,http://arxiv.org/abs/2303.09314v2,"Multimodal hate detection, which aims to identify harmful content online suchas memes, is crucial for building a wholesome internet environment. Previouswork has made enlightening exploration in detecting explicit hate remarks.However, most of their approaches neglect the analysis of implicit harm, whichis particularly challenging as explicit text markers and demographic visualcues are often twisted or missing. The leveraged cross-modal attentionmechanisms also suffer from the distributional modality gap and lack logicalinterpretability. To address these semantic gaps issues, we propose TOT: atopology-aware optimal transport framework to decipher the implicit harm inmemes scenario, which formulates the cross-modal aligning problem as solutionsfor optimal transportation plans. Specifically, we leverage an optimaltransport kernel method to capture complementary information from multiplemodalities. The kernel embedding provides a non-linear transformation abilityto reproduce a kernel Hilbert space (RKHS), which reflects significance foreliminating the distributional modality gap. Moreover, we perceive the topologyinformation based on aligned representations to conduct bipartite graph pathreasoning. The newly achieved state-of-the-art performance on two publiclyavailable benchmark datasets, together with further visual analysis,demonstrate the superiority of TOT in capturing implicit cross-modal alignment.",Linhao Zhang,2023/2/27,2023/4/24
0809.2424v2,Universal Rise of Hadronic Total Cross Sections based on Forward pi p and pbarp(pp) Scatterings,http://arxiv.org/abs/0809.2424v2,"Recently there are several evidences of the increase of the total crosssection sigma(tot) to be log2 s consistent with the Froissart unitarity bound,and the COMPETE collaborations in the PDG have further assumed sigma(tot) = Blog2(s/s0) to extend its universal rise with a common value of B for all thehadronic scatterings. However, there is no rigorous proof yet based only onQCD. Therefore, it is worthwhile to prove this universal rise of sigma(tot)even empirically. In this letter we attempt to obtain the value of B for pi pscattering, B(pi p), with reasonable accuracy by taking into account the richpi p data in all the energy regions. We use the finite-energy sum rule(FESR)expressed in terms of the pi p scattering data in the low and intermediateenergies as a constraint between high-energy parameters. We then have searchedfor the simultaneous best fit to the sigma(tot) and rho ratios, the ratios ofthe real to imaginary parts of the forward scattering amplitudes. The lowerenergy data are included in the integral of FESR, the more precisely determinedis the non-leading term such as log s, and then helps to determine the leadingterms like log2 s. We have derived the value of B(pi p) as B(pi p)=0.311 +-0.044mb. This value is to be compared with the value of B for pbarp,ppscattering, B(pp), in our previous analysis[11], B(pp)=0.289 +- 0.023mb. Thus,our result appears to support the universality hypothesis.",Muneyuki Ishida,2008/9/14,2008/11/12
2204.12437v2,On the Equilibria and Bifurcations of a Rotating Double Pendulum,http://arxiv.org/abs/2204.12437v2,"The double pendulum, a simple system of classical mechanics, is widelystudied as an example of, and testbed for, chaotic dynamics. In 2016, Maiti etal. studied a generalization of the simple double pendulum with equalpoint-masses at equal lengths, to a rotating double pendulum, fixed to acoordinate system uniformly rotating about the vertical. In this paper, westudy a considerable generalization of the double pendulum, constructed fromphysical pendula, and ask what equilibrium configurations exist for the systemacross a comparatively large parameter space, as well as what bifurcationsoccur in those equilibria. Elimination algorithms are employed to reducesystems of polynomial equations, which allows for equilibria to be visualized,and also to demonstrate which models within the parameter space exhibitbifurcation. We find the DixonEDF algorithm for the Dixon resultant, written inthe computer algebra system (CAS) Fermat, to be capable to complete thecomputation for the challenging system of equations that representsbifurcation, while attempts with other algorithms were terminated after severalhours.",Jonathan Tot,2022/4/25,2022/5/7
0903.1737v1,Global controllability and stabilization for the nonlinear Schrdinger equation on some compact manifolds of dimension 3,http://arxiv.org/abs/0903.1737v1,"We prove global internal controllability in large time for the nonlinearSchr\""odinger equation on some compact manifolds of dimension 3. The result isproved under some geometrical assumptions : geometric control and uniquecontinuation. We give some examples where they are fulfilled on $\Tot$, $S^3$and $S^2\times S^1$. We prove this by two different methods both inherentlyinteresting. The first one combines stabilization and local controllabilitynear 0. The second one uses successive controls near some trajectories. We alsoget a regularity result about the control if the data are assumed smoother. Ifthe $H^1$ norm is bounded, it gives a local control in $H^1$ with a smallnessassumption only in $L^2$. We use Bourgain spaces.",Camille Laurent,2009/3/10,2009/3/10
2204.06538v2,The dynamics of scalar-field Quintom cosmological models,http://arxiv.org/abs/2204.06538v2,"We shall present a complete (compactified) dynamical systems analysis of theQuintom model comprised of an interacting quintessence scalar field and aphantom. We find a range for the model parameters $\kappa, \lambda$ such thatthere are expanding Quintom cosmologies that undergo two inflationary periods,and this behaviour is not destabilized by spatial curvature. We also discuss aclass of bouncing cosmologies. Finally, the linear cosmological perturbationsare studied.",Jonathan Tot,2022/4/13,2022/11/18
2212.09180v3,Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems,http://arxiv.org/abs/2212.09180v3,"Despite tremendous advancements in dialogue systems, stable evaluation stillrequires human judgments producing notoriously high-variance metrics due totheir inherent subjectivity. Moreover, methods and labels in dialogueevaluation are not fully standardized, especially for open-domain chats, with alack of work to compare and assess the validity of those approaches. The use ofinconsistent evaluation can misinform the performance of a dialogue system,which becomes a major hurdle to enhance it. Thus, a dimensional evaluation ofchat-oriented open-domain dialogue systems that reliably measures severalaspects of dialogue capabilities is desired. This paper presents a novel humanevaluation method to estimate the rates of many dialogue system behaviors. Ourmethod is used to evaluate four state-of-the-art open-domain dialogue systemsand compared with existing approaches. The analysis demonstrates that ourbehavior method is more suitable than alternative Likert-style or comparativeapproaches for dimensional evaluation of these systems.",Sarah E. Finch,2022/12/18,2023/7/28
1801.02862v3,Between an Arena and a Sports Bar: Online Chats of eSports Spectators,http://arxiv.org/abs/1801.02862v3,"Hundreds of thousands of spectators use Twitch.tv to watch The International,a Dota 2 eSports tournament and communicate in massive chats. In this paper, weanalyse crowd behavior in these chats, disentangle features of socialcommunication, such as contextual meanings of emojis and short messages. Weapply structural topic modelling and cross-correlation analysis to investigatetopical and temporal patterns of chat messages and their relation to in-gameevents. We show that in-game events drive the communication in the massive chatand define its emergent topical structure to a various extent. Following thediscussion in communication and social computing literature, we discuss thesefindings in the framework of analysis of communication of physical sportscrowds and outline some limitations of the 'stadium' metaphor, suggesting acomplementary metaphor of 'sports bar' as a useful analytical and designdevice.",Denis Bulygin,2018/1/9,2020/12/11
1403.0531v1,We Tweet Like We Talk and Other Interesting Observations: An Analysis of English Communication Modalities,http://arxiv.org/abs/1403.0531v1,"Modalities of communication for human beings are gradually increasing innumber with the advent of new forms of technology. Many human beings canreadily transition between these different forms of communication with littleor no effort, which brings about the question: How similar are these differentcommunication modalities? To understand technology$\text{'}$s influence onEnglish communication, four different corpora were analyzed and compared:Writing from Books using the 1-grams database from the Google Books project,Twitter, IRC Chat, and transcribed Talking. Multi-word confusion matricesrevealed that Talking has the most similarity when compared to the other modesof communication, while 1-grams were the least similar form of communicationanalyzed. Based on the analysis of word usage, word usage frequencydistributions, and word class usage, among other things, Talking is also themost similar to Twitter and IRC Chat. This suggests that communicating usingTwitter and IRC Chat evolved from Talking rather than Writing. When wecommunicate online, even though we are writing, we do not Tweet or Chat how wewrite books; we Tweet and Chat how we Speak. Nonfiction and Fiction writingwere clearly differentiable from our analysis with Twitter and Chat being muchmore similar to Fiction than Nonfiction writing. These hypotheses were thentested using author and journalists Cory Doctorow. Mr. Doctorow$\text{'}$sWriting, Twitter usage, and Talking were all found to have very similarvocabulary usage patterns as the amalgamized populations, as long as thewriting was Fiction. However, Mr. Doctorow$\text{'}$s Nonfiction writing isdifferent from 1-grams and other collected Nonfiction writings. This data couldperhaps be used to create more entertaining works of Nonfiction.",Josiah P. Zayner,2014/3/3,2014/3/3
1507.04024v2,Analyzing the activity of a person in a chat by combining network analysis and fuzzy logic,http://arxiv.org/abs/1507.04024v2,"Chat-log data that contains information about sender and receiver of thestatements sent around in the chat can be readily turned into a directedtemporal multi-network representation. In the resulting network, the activityof a chat member can, for example, be operationalized as his degree (number ofdistinct interaction partners) or his strength (total number of interactions).However, the data itself contains more information that is not readilyrepresentable in the network, e.g., the total number of words used by a memberor the reaction time to what the members said. As degree and strength, thesevalues can be seen as a way to operationalize the idea of activity of achat-log member. This paper deals with the question of how the overall activityof a member can be assessed, given multiple and probably opposing criteria byusing a fuzzy operator. We then present a new way of visualizing the resultsand show how to apply it to the network representation of chat-log data.Finally, we discuss how this approach can be used to deal with otherconflicting situations, like the different rankings produced by differentcentrality indices.",Sude Tavassoli,2015/7/14,2015/7/16
1910.13008v1,Sketch-Fill-A-R: A Persona-Grounded Chit-Chat Generation Framework,http://arxiv.org/abs/1910.13008v1,"Human-like chit-chat conversation requires agents to generate responses thatare fluent, engaging and consistent. We propose Sketch-Fill-A-R, a frameworkthat uses a persona-memory to generate chit-chat responses in three phases.First, it generates dynamic sketch responses with open slots. Second, itgenerates candidate responses by filling slots with parts of its stored personatraits. Lastly, it ranks and selects the final response via a language modelscore. Sketch-Fill-A-R outperforms a state-of-the-art baseline bothquantitatively (10-point lower perplexity) and qualitatively (preferred by 55%heads-up in single-turn and 20% higher in consistency in multi-turn userstudies) on the Persona-Chat dataset. Finally, we extensively analyzeSketch-Fill-A-R's responses and human feedback, and show it is more consistentand engaging by using more relevant responses and questions.",Michael Shum,2019/10/28,2019/10/28
2202.13645v1,MSCTD: A Multimodal Sentiment Chat Translation Dataset,http://arxiv.org/abs/2202.13645v1,"Multimodal machine translation and textual chat translation have receivedconsiderable attention in recent years. Although the conversation in itsnatural form is usually multimodal, there still lacks work on multimodalmachine translation in conversations. In this work, we introduce a new tasknamed Multimodal Chat Translation (MCT), aiming to generate more accuratetranslations with the help of the associated dialogue history and visualcontext. To this end, we firstly construct a Multimodal Sentiment ChatTranslation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairsin 14,762 bilingual dialogues and 30,370 English-German utterance pairs in3,079 bilingual dialogues. Each utterance pair, corresponding to the visualcontext that reflects the current conversational scene, is annotated with asentiment label. Then, we benchmark the task by establishing multiple baselinesystems that incorporate multimodal and sentiment features for MCT. Preliminaryexperiments on four language directions (English-Chinese and English-German)verify the potential of contextual and multimodal information fusion and thepositive impact of sentiment on the MCT task. Additionally, as a by-product ofthe MSCTD, it also provides two new benchmarks on multimodal dialogue sentimentanalysis. Our work can facilitate research on both multimodal chat translationand multimodal dialogue sentiment analysis.",Yunlong Liang,2022/2/28,2022/2/28
2306.16322v1,Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,http://arxiv.org/abs/2306.16322v1,"Large language models (LLMs) have demonstrated impressive performance onvarious downstream tasks without requiring fine-tuning, including ChatGPT, achat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite havinga lower training proportion compared to English, these models also exhibitremarkable capabilities in other languages. In this study, we assess theperformance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:sentiment analysis, translation, transliteration, paraphrasing, part of speechtagging, summarization, and diacritization. Our findings reveal that GPT-4outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct anextensive analysis of the sentiment analysis task, providing insights into howLLMs achieve exceptional results on a challenging dialectal dataset.Additionally, we introduce a new Python interfacehttps://github.com/ARBML/Taqyim that facilitates the evaluation of these taskseffortlessly.",Zaid Alyafeai,2023/6/28,2023/6/28
2401.12672v1,ChatGraph: Chat with Your Graphs,http://arxiv.org/abs/2401.12672v1,"Graph analysis is fundamental in real-world applications. Traditionalapproaches rely on SPARQL-like languages or clicking-and-dragging interfaces tointeract with graph data. However, these methods either require users topossess high programming skills or support only a limited range of graphanalysis functionalities. To address the limitations, we propose a largelanguage model (LLM)-based framework called ChatGraph. With ChatGraph, userscan interact with graphs through natural language, making it easier to use andmore flexible than traditional approaches. The core of ChatGraph lies ingenerating chains of graph analysis APIs based on the understanding of thetexts and graphs inputted in the user prompts. To achieve this, ChatGraphconsists of three main modules: an API retrieval module that searches forrelevant APIs, a graph-aware LLM module that enables the LLM to comprehendgraphs, and an API chain-oriented finetuning module that guides the LLM ingenerating API chains.",Yun Peng,2024/1/23,2024/1/23
2312.04746v1,Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos,http://arxiv.org/abs/2312.04746v1,"The gigapixel scale of whole slide images (WSIs) poses a challenge forhistopathology multi-modal chatbots, requiring a global WSI analysis fordiagnosis, compounding evidence from different WSI patches. Current visualinstruction datasets, generated through large language models, focus oncreating question/answer pairs for individual image patches, which may lackdiagnostic capacity on their own in histopathology, further complicated by theabsence of spatial grounding in histopathology image captions. To bridge thisgap, we introduce Quilt-Instruct, a large-scale dataset of 107,131histopathology-specific instruction question/answer pairs, that is collected byleveraging educational histopathology videos from YouTube, which providesspatial localization of captions by automatically extracting narrators' cursormovements. In addition, we provide contextual reasoning by extracting diagnosisand supporting facts from the entire video content to guide the extrapolativereasoning of GPT-4. Using Quilt-Instruct, we train Quilt-LLaVA, which canreason beyond the given single image patch, enabling diagnostic reasoning andthe capability of spatial awareness. To evaluate Quilt-LLaVA, we propose acomprehensive evaluation dataset created from 985 images and 1283human-generated question-answers. We also thoroughly evaluate Quilt-LLaVA usingpublic histopathology datasets, where Quilt-LLaVA significantly outperformsSOTA by over 10% on relative GPT-4 score and 4% and 9% on open and closed setVQA. Our code, data, and model are publicly available at quilt-llava.github.io.",Mehmet Saygin Seyfioglu,2023/12/7,2023/12/7
2401.00579v1,Exploring the Effectiveness of Instruction Tuning in Biomedical Language Processing,http://arxiv.org/abs/2401.00579v1,"Large Language Models (LLMs), particularly those similar to ChatGPT, havesignificantly influenced the field of Natural Language Processing (NLP). Whilethese models excel in general language tasks, their performance indomain-specific downstream tasks such as biomedical and clinical Named EntityRecognition (NER), Relation Extraction (RE), and Medical Natural LanguageInference (NLI) is still evolving. In this context, our study investigates thepotential of instruction tuning for biomedical language processing, applyingthis technique to two general LLMs of substantial scale. We present acomprehensive, instruction-based model trained on a dataset that consists ofapproximately $200,000$ instruction-focused samples. This dataset represents acarefully curated compilation of existing data, meticulously adapted andreformatted to align with the specific requirements of our instruction-basedtasks. This initiative represents an important step in utilising such models toachieve results on par with specialised encoder-only models like BioBERT andBioClinicalBERT for various classical biomedical NLP tasks. Our work includesan analysis of the dataset's composition and its impact on model performance,providing insights into the intricacies of instruction tuning. By sharing ourcodes, models, and the distinctively assembled instruction-based dataset, weseek to encourage ongoing research and development in this area.",Omid Rohanian,2023/12/31,2023/12/31
2103.03809v3,PalmTree: Learning an Assembly Language Model for Instruction Embedding,http://arxiv.org/abs/2103.03809v3,"Deep learning has demonstrated its strengths in numerous binary analysistasks, including function boundary detection, binary code search, functionprototype inference, value set analysis, etc. When applying deep learning tobinary analysis tasks, we need to decide what input should be fed into theneural network model. More specifically, we need to answer how to represent aninstruction in a fixed-length vector. The idea of automatically learninginstruction representations is intriguing, however the existing schemes fail tocapture the unique characteristics of disassembly. These schemes ignore thecomplex intra-instruction structures and mainly rely on control flow in whichthe contextual information is noisy and can be influenced by compileroptimizations.  In this paper, we propose to pre-train an assembly language model calledPalmTree for generating general-purpose instruction embeddings by conductingself-supervised training on large-scale unlabeled binary corpora. PalmTreeutilizes three pre-training tasks to capture various characteristics ofassembly language. These training tasks overcome the problems in existingschemes, thus can help to generate high-quality representations. We conductboth intrinsic and extrinsic evaluations, and compare PalmTree with otherinstruction embedding schemes. PalmTree has the best performance for intrinsicmetrics, and outperforms the other instruction embedding schemes for alldownstream tasks.",Xuezixiang Li,2021/1/21,2021/9/14
1807.04375v2,"AtDelfi: Automatically Designing Legible, Full Instructions For Games",http://arxiv.org/abs/1807.04375v2,"This paper introduces a fully automatic method for generating video gametutorials. The AtDELFI system (AuTomatically DEsigning Legible, FullInstructions for games) was created to investigate procedural generation ofinstructions that teach players how to play video games. We present arepresentation of game rules and mechanics using a graph system as well as atutorial generation method that uses said graph representation. We demonstratethe concept by testing it on games within the General Video Game ArtificialIntelligence (GVG-AI) framework; the paper discusses tutorials generated foreight different games. Our findings suggest that a graph representation schemeworks well for simple arcade style games such as Space Invaders and Pacman, butit appears that tutorials for more complex games might require higher-levelunderstanding of the game than just single mechanics.",Michael Cerny Green,2018/7/11,2018/9/17
2312.17448v1,Tracking with Human-Intent Reasoning,http://arxiv.org/abs/2312.17448v1,"Advances in perception modeling have significantly improved the performanceof object tracking. However, the current methods for specifying the targetobject in the initial frame are either by 1) using a box or mask template, orby 2) providing an explicit language description. These manners are cumbersomeand do not allow the tracker to have self-reasoning ability. Therefore, thiswork proposes a new tracking task -- Instruction Tracking, which involvesproviding implicit tracking instructions that require the trackers to performtracking automatically in video frames. To achieve this, we investigate theintegration of knowledge and reasoning capabilities from a LargeVision-Language Model (LVLM) for object tracking. Specifically, we propose atracker called TrackGPT, which is capable of performing complex reasoning-basedtracking. TrackGPT first uses LVLM to understand tracking instructions andcondense the cues of what target to track into referring embeddings. Theperception component then generates the tracking results based on theembeddings. To evaluate the performance of TrackGPT, we construct aninstruction tracking benchmark called InsTrack, which contains over onethousand instruction-video pairs for instruction tuning and evaluation.Experiments show that TrackGPT achieves competitive performance on referringvideo object segmentation benchmarks, such as getting a new state-of the-artperformance of 66.5 $\mathcal{J}\&\mathcal{F}$ on Refer-DAVIS. It alsodemonstrates a superior performance of instruction tracking under newevaluation protocols. The code and models are available at\href{https://github.com/jiawen-zhu/TrackGPT}{https://github.com/jiawen-zhu/TrackGPT}.",Jiawen Zhu,2023/12/29,2023/12/29
2108.12227v1,Recent Developments in Program Synthesis with Evolutionary Algorithms,http://arxiv.org/abs/2108.12227v1,"The automatic generation of computer programs is one of the main applicationswith practical relevance in the field of evolutionary computation. With programsynthesis techniques not only software developers could be supported in theireveryday work but even users without any programming knowledge could beempowered to automate repetitive tasks and implement their own newfunctionality. In recent years, many novel program synthesis approaches basedon evolutionary algorithms have been proposed and evaluated on common benchmarkproblems. Therefore, we identify in this work the relevant evolutionary programsynthesis approaches and provide an in-depth analysis of their performance. Themost influential approaches we identify are stack-based, grammar-guided, aswell as linear genetic programming. Further, we find that these approachesperform well on benchmark problems if there is a simple mapping from the giveninput to the correct output. On problems where this mapping is complex, e.g.,if the problem consists of several sub-problems or requires iteration/recursionfor a correct solution, results tend to be worse. Consequently, for futurework, we encourage researchers not only to use a program's output for assessingthe quality of a solution but also the way towards a solution (e.g., correctlysolved sub-problems).",Dominik Sobania,2021/8/27,2021/8/27
2306.03460v1,Natural Language Commanding via Program Synthesis,http://arxiv.org/abs/2306.03460v1,"We present Semantic Interpreter, a natural language-friendly AI system forproductivity software such as Microsoft Office that leverages large languagemodels (LLMs) to execute user intent across application features. While LLMsare excellent at understanding user intent expressed as natural language, theyare not sufficient for fulfilling application-specific user intent thatrequires more than text-to-text transformations. We therefore introduce theOffice Domain Specific Language (ODSL), a concise, high-level languagespecialized for performing actions in and interacting with entities in Officeapplications. Semantic Interpreter leverages an Analysis-Retrieval promptconstruction method with LLMs for program synthesis, translating naturallanguage user utterances to ODSL programs that can be transpiled to applicationAPIs and then executed. We focus our discussion primarily on a researchexploration for Microsoft PowerPoint.",Apurva Gandhi,2023/6/6,2023/6/6
1903.00712v2,2LS: Heap Analysis and Memory Safety (Competition Contribution),http://arxiv.org/abs/1903.00712v2,"2LS is a framework for analysis of sequential C programs that can verify andrefute program assertions and termination. The 2LS framework is built upon theCPROVER infrastructure and implements template-based synthesis techniques, e.g.to find invariants and ranking functions, and incremental loop unwindingtechniques to find counterexamples and k-induction proofs. The mainimprovements in this year's version are the ability of 2LS to analyse programsrequiring combined reasoning about shape and content of dynamic datastructures, and an instrumentation for memory safety properties.",Viktor Malik,2019/3/2,2020/1/3
2105.09221v1,Program Synthesis as Dependency Quantified Formula Modulo Theory,http://arxiv.org/abs/2105.09221v1,"Given a specification $\varphi(X,Y)$ over inputs $X$ and output $Y$, definedover a background theory $\mathbb{T}$, the problem of program synthesis is todesign a program $f$ such that $Y=f(X)$ satisfies the specification $\varphi$.Over the past decade, syntax-guided synthesis (SyGuS) has emerged as a dominantapproach for program synthesis where in addition to the specification$\varphi$, the end-user also specifies a grammar $L$ to aid the underlyingsynthesis engine. This paper investigates the feasibility of synthesistechniques without grammar, a sub-class defined as $\mathbb{T}$-constrainedsynthesis.  We show that $\mathbb{T}$-constrained synthesis can be reduced toDQF($\mathbb{T}$), i.e., to the problem of finding a witness of a DependencyQuantified Formula Modulo Theory. When the underlying theory is the theory ofbitvectors, the corresponding DQF(BV) problem can be further reduced toDependency Quantified Boolean Formulas (DQBF). We rely on the progress in DQBFsolving to design DQBF-based synthesizers that outperform the domain-specificprogram synthesis techniques, thereby positioning DQBF as a core representationlanguage for program synthesis. Our empirical analysis shows that$\mathbb{T}$-constrained synthesis can achieve significantly better performancethan syntax-guided approaches. Furthermore, the general-purpose DQBF solversperform on par with domain-specific synthesis techniques.",Priyanka Golia,2021/5/19,2021/5/19
1510.06788v2,Prodirect Manipulation: Bidirectional Programming for the Masses,http://arxiv.org/abs/1510.06788v2,"Software interfaces today generally fall at either end of a spectrum. On oneend are programmable systems, which allow expert users (i.e. programmers) towrite software artifacts that describe complex abstractions, but programs aredisconnected from their eventual output. On the other end are domain-specificgraphical user interfaces (GUIs), which allow end users (i.e. non-programmers)to easily create varied content but present insurmountable walls when a desiredfeature is not built-in. Both programmatic and direct manipulation havedistinct strengths, but users must typically choose one over the other or usesome ad-hoc combination of systems. Our goal, put simply, is to bridge thisdivide.  We envision novel software systems that tightly couple programmatic anddirect manipulation --- a combination we dub prodirect manipulation --- for avariety of use cases. This will require advances in a broad range of softwareengineering disciplines, from program analysis and program synthesis technologyto user interface design and evaluation. In this extended abstract, we proposetwo general strategies --- real-time program synthesis and domain-specificsynthesis of general-purpose programs --- that may prove fruitful forovercoming the technical challenges. We also discuss metrics that will beimportant in evaluating the usability and utility of prodirect manipulationsystems.",Ravi Chugh,2015/10/22,2016/2/24
2306.05499v1,Prompt Injection attack against LLM-integrated Applications,http://arxiv.org/abs/2306.05499v1,"Large Language Models (LLMs), renowned for their superior proficiency inlanguage comprehension and generation, stimulate a vibrant ecosystem ofapplications around them. However, their extensive assimilation into variousservices introduces significant security risks. This study deconstructs thecomplexities and implications of prompt injection attacks on actualLLM-integrated applications. Initially, we conduct an exploratory analysis onten commercial applications, highlighting the constraints of current attackstrategies in practice. Prompted by these limitations, we subsequentlyformulate HouYi, a novel black-box prompt injection attack technique, whichdraws inspiration from traditional web injection attacks. HouYi iscompartmentalized into three crucial elements: a seamlessly-incorporatedpre-constructed prompt, an injection prompt inducing context partition, and amalicious payload designed to fulfill the attack objectives. Leveraging HouYi,we unveil previously unknown and severe attack outcomes, such as unrestrictedarbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYion 36 actual LLM-integrated applications and discern 31 applicationssusceptible to prompt injection. 10 vendors have validated our discoveries,including Notion, which has the potential to impact millions of users. Ourinvestigation illuminates both the possible risks of prompt injection attacksand the possible tactics for mitigation.",Yi Liu,2023/6/8,2023/6/8
2312.17601v1,The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems: A Scoping Survey,http://arxiv.org/abs/2312.17601v1,"This scoping survey focuses on our current understanding of the design spacefor task-oriented LLM systems and elaborates on definitions and relationshipsamong the available design parameters. The paper begins by defining a minimaltask-oriented LLM system and exploring the design space of such systems througha thought experiment contemplating the performance of diverse LLM systemconfigurations (involving single LLMs, single LLM-based agents, and multipleLLM-based agent systems) on a complex software development task andhypothesizes the results. We discuss a pattern in our results and formulatethem into three conjectures. While these conjectures may be partly based onfaulty assumptions, they provide a starting point for future research. Thepaper then surveys a select few design parameters: covering and organizingresearch in LLM augmentation, prompting techniques, and uncertainty estimation,and discussing their significance. The paper notes the lack of focus oncomputational and energy efficiency in evaluating research in these areas. Oursurvey findings provide a basis for developing the concept of linear andnon-linear contexts, which we define and use to enable an agent-centricprojection of prompting techniques providing a lens through which promptingtechniques can be viewed as multi-agent systems. The paper discusses theimplications of this lens, for the cross-pollination of research between LLMprompting and LLM-based multi-agent systems; and also, for the generation ofsynthetic training data based on existing prompting techniques in research. Inall, the scoping survey presents seven conjectures that can help guide futureresearch efforts.",Dhruv Dhamani,2023/12/29,2023/12/29
2203.12481v3,Prompt-based System for Personality and Interpersonal Reactivity Prediction,http://arxiv.org/abs/2203.12481v3,"This paper describes our proposed method for the Workshop on ComputationalApproaches to Subjectivity, Sentiment & Social Media Analysis (WASSA) 2022shared task on Personality Prediction (PER) and Reactivity Index Prediction(IRI). In this paper, we adopt the prompt-based learning method with thepre-trained language model to accomplish these tasks. Specifically, the promptis designed to provide knowledge of the extra personalized information forenhancing the pre-trained model. Data augmentation and model ensemble areadopted for obtaining better results. Moreover, we also provided the onlinesoftware demonstration and the codes of the software for further research.",Bin Li,2022/3/23,2022/5/19
2210.11603v2,3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows,http://arxiv.org/abs/2210.11603v2,"Text-to-image AI are capable of generating novel images for inspiration, buttheir applications for 3D design workflows and how designers can build 3Dmodels using AI-provided inspiration have not yet been explored. To investigatethis, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, aplugin that generates 2D image inspiration for 3D design. 3DALL-E allows usersto construct text and image prompts based on what they are modeling. In a studywith 13 designers, we found that designers saw great potential in 3DALL-Ewithin their workflows and could use text-to-image AI to produce referenceimages, prevent design fixation, and inspire design considerations. Weelaborate on prompting patterns observed across 3D modeling tasks and providemeasures of prompt complexity observed across participants. From our findings,we discuss how 3DALL-E can merge with existing generative design workflows andpropose prompt bibliographies as a form of human-AI design history.",Vivian Liu,2022/10/20,2023/7/31
2310.03253v1,Molecule Design by Latent Prompt Transformer,http://arxiv.org/abs/2310.03253v1,"This paper proposes a latent prompt Transformer model for solving challengingoptimization problems such as molecule design, where the goal is to findmolecules with optimal values of a target chemical or biological property thatcan be computed by an existing software. Our proposed model consists of threecomponents. (1) A latent vector whose prior distribution is modeled by a Unettransformation of a Gaussian white noise vector. (2) A molecule generationmodel that generates the string-based representation of molecule conditional onthe latent vector in (1). We adopt the causal Transformer model that takes thelatent vector in (1) as prompt. (3) A property prediction model that predictsthe value of the target property of a molecule based on a non-linear regressionon the latent vector in (1). We call the proposed model the latent promptTransformer model. After initial training of the model on existing moleculesand their property values, we then gradually shift the model distributiontowards the region that supports desired values of the target property for thepurpose of molecule design. Our experiments show that our proposed modelachieves state of the art performances on several benchmark molecule designtasks.",Deqian Kong,2023/10/5,2023/10/5
2303.14310v1,GPT is becoming a Turing machine: Here are some ways to program it,http://arxiv.org/abs/2303.14310v1,"We demonstrate that, through appropriate prompting, GPT-3 family of modelscan be triggered to perform iterative behaviours necessary to execute (ratherthan just write or recall) programs that involve loops, including severalpopular algorithms found in computer science curricula or software developerinterviews. We trigger execution and description of Iterations by RegimentingSelf-Attention (IRSA) in one (or a combination) of three ways: 1) Using strongrepetitive structure in an example of an execution path of a target program forone particular input, 2) Prompting with fragments of execution paths, and 3)Explicitly forbidding (skipping) self-attention to parts of the generated text.On a dynamic program execution, IRSA leads to larger accuracy gains thanreplacing the model with the much more powerful GPT-4. IRSA has promisingapplications in education, as the prompts and responses resemble studentassignments in data structures and algorithms classes. Our findings holdimplications for evaluating LLMs, which typically target the in-contextlearning: We show that prompts that may not even cover one full task examplecan trigger algorithmic behaviour, allowing solving problems previously thoughtof as hard for LLMs, such as logical puzzles. Consequently, prompt design playsan even more critical role in LLM performance than previously recognized.",Ana Jojic,2023/3/25,2023/3/25
2308.15645v2,AskIt: Unified Programming Interface for Programming with Large Language Models,http://arxiv.org/abs/2308.15645v2,"Large Language Models (LLMs) exhibit a unique phenomenon known as emergentabilities, demonstrating adeptness across numerous tasks, from textsummarization to code generation. While these abilities open up novel avenuesin software design and crafting, their incorporation presents substantialchallenges. Developers face decisions regarding the use of LLMs for directlyperforming tasks within applications as well as for generating and executingcode to accomplish these tasks. Moreover, effective prompt design becomes acritical concern, given the necessity of extracting data from natural languageoutputs. To address these complexities, this paper introduces AskIt, adomain-specific language (DSL) specifically designed for LLMs. AskIt simplifiesLLM integration by providing a unified interface that not only allows fordirect task execution using LLMs but also supports the entire cycle of codegeneration and execution. This dual capability is achieved through (1)type-guided output control, (2) template-based function definitions, and (3)prompt generation for both usage modes. Our evaluations underscore AskIt'seffectiveness. Across 50 tasks, AskIt generated concise prompts, achieving a16.14 % reduction in prompt length compared to benchmarks. Additionally, byenabling a seamless transition between using LLMs directly in applications andfor generating code, AskIt achieved significant efficiency improvements, asobserved in our GSM8K benchmark experiments. The implementations of AskIt inTypeScript and Python are available at https://github.com/katsumiok/ts-askitand https://github.com/katsumiok/pyaskit, respectively.",Katsumi Okuda,2023/8/29,2023/12/27
2312.17485v1,The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model,http://arxiv.org/abs/2312.17485v1,"Automatic program repair (APR) techniques have the potential to reduce manualefforts in uncovering and repairing program defects during the code review (CR)process. However, the limited accuracy and considerable time costs associatedwith existing APR approaches hinder their adoption in industrial practice. Onekey factor is the under-utilization of review comments, which provide valuableinsights into defects and potential fixes. Recent advancements in LargeLanguage Models (LLMs) have enhanced their ability to comprehend natural andprogramming languages, enabling them to generate patches based on reviewcomments. This paper conducts a comprehensive investigation into the effectiveutilization of LLMs for repairing CR defects. In this study, various promptsare designed and compared across mainstream LLMs using two distinct datasetsfrom human reviewers and automated checkers. Experimental results demonstrate aremarkable repair rate of 72.97% with the best prompt, highlighting asubstantial improvement in the effectiveness and practicality of automaticrepair techniques.",Zelin Zhao,2023/12/29,2023/12/29
2210.14699v2,"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?",http://arxiv.org/abs/2210.14699v2,"Language models are promising solutions for tackling increasing complexproblems. In software engineering, they recently attracted attention in codeassistants, with programs automatically written in a given programming languagefrom a programming task description in natural language. They have thepotential to save time and effort when writing code. However, these systems arecurrently poorly understood, preventing them from being used optimally. In thispaper, we investigate the various input parameters of two language models, andconduct a study to understand if variations of these input parameters (e.g.programming task description and the surrounding context, creativity of thelanguage model, number of generated solutions) can have a significant impact onthe quality of the generated programs. We design specific operators for varyinginput parameters and apply them over two code assistants (Copilot and Codex)and two benchmarks representing algorithmic problems (HumanEval and LeetCode).Our results showed that varying the input parameters can significantly improvethe performance of language models. However, there is a tight dependency whenvarying the temperature, the prompt and the number of generated solutions,making potentially hard for developers to properly control the parameters toobtain an optimal result. This work opens opportunities to propose (automated)strategies for improving performance.",Jean-Baptiste Dderlein,2022/10/26,2023/2/15
2310.06342v1,Contrastive Prompt Learning-based Code Search based on Interaction Matrix,http://arxiv.org/abs/2310.06342v1,"Code search aims to retrieve the code snippet that highly matches the givenquery described in natural language. Recently, many code pre-trainingapproaches have demonstrated impressive performance on code search. However,existing code search methods still suffer from two performance constraints:inadequate semantic representation and the semantic gap between naturallanguage (NL) and programming language (PL). In this paper, we propose CPLCS, acontrastive prompt learning-based code search method based on the cross-modalinteraction mechanism. CPLCS comprises:(1) PL-NL contrastive learning, whichlearns the semantic matching relationship between PL and NL representations;(2) a prompt learning design for a dual-encoder structure that can alleviatethe problem of inadequate semantic representation; (3) a cross-modalinteraction mechanism to enhance the fine-grained mapping between NL and PL. Weconduct extensive experiments to evaluate the effectiveness of our approach ona real-world dataset across six programming languages. The experiment resultsdemonstrate the efficacy of our approach in improving semantic representationquality and mapping ability between PL and NL.",Yubo Zhang,2023/10/10,2023/10/10
2201.03346v2,Better Modeling the Programming World with Code Concept Graphs-augmented Multi-modal Learning,http://arxiv.org/abs/2201.03346v2,"The progress made in code modeling has been tremendous in recent years thanksto the design of natural language processing learning approaches based onstate-of-the-art model architectures. Nevertheless, we believe that the currentstate-of-the-art does not focus enough on the full potential that data maybring to a learning process in software engineering. Our vision articulates onthe idea of leveraging multi-modal learning approaches to modeling theprogramming world. In this paper, we investigate one of the underlying idea ofour vision whose objective based on concept graphs of identifiers aims atleveraging high-level relationships between domain concepts manipulated throughparticular language constructs. In particular, we propose to enhance anexisting pretrained language model of code by joint-learning it with a graphneural network based on our concept graphs. We conducted a preliminaryevaluation that shows gain of effectiveness of the models for code search usinga simple joint-learning method and prompts us to further investigate ourresearch vision.",Martin Weyssow,2022/1/10,2022/2/21
2303.07519v3,Architext: Language-Driven Generative Architecture Design,http://arxiv.org/abs/2303.07519v3,"Architectural design is a highly complex practice that involves a widediversity of disciplines, technologies, proprietary design software, expertise,and an almost infinite number of constraints, across a vast array of designtasks. Enabling intuitive, accessible, and scalable design processes is animportant step towards performance-driven and sustainable design for all. Tothat end, we introduce Architext, a novel semantic generation assistive tool.Architext enables design generation with only natural language prompts, givento large-scale Language Models, as input. We conduct a thorough quantitativeevaluation of Architext's downstream task performance, focusing on semanticaccuracy and diversity for a number of pre-trained language models ranging from120 million to 6 billion parameters. Architext models are able to learn thespecific design task, generating valid residential layouts at a near 100% rate.Accuracy shows great improvement when scaling the models, with the largestmodel (GPT-J) yielding impressive accuracy ranging between 25% to over 80% fordifferent prompt categories. We open source the finetuned Architext models andour synthetic dataset, hoping to inspire experimentation in this exciting areaof design research.",Theodoros Galanos,2023/3/13,2023/5/3
2310.00483v1,Prompting Code Interpreter to Write Better Unit Tests on Quixbugs Functions,http://arxiv.org/abs/2310.00483v1,"Unit testing is a commonly-used approach in software engineering to test thecorrectness and robustness of written code. Unit tests are tests designed totest small components of a codebase in isolation, such as an individualfunction or method. Although unit tests have historically been written by humanprogrammers, recent advancements in AI, particularly LLMs, have showncorresponding advances in automatic unit test generation. In this study, weexplore the effect of different prompts on the quality of unit tests generatedby Code Interpreter, a GPT-4-based LLM, on Python functions provided by theQuixbugs dataset, and we focus on prompting due to the ease with which userscan make use of our findings and observations. We find that the quality of thegenerated unit tests is not sensitive to changes in minor details in theprompts provided. However, we observe that Code Interpreter is often able toeffectively identify and correct mistakes in code that it writes, suggestingthat providing it runnable code to check the correctness of its outputs wouldbe beneficial, even though we find that it is already often able to generatecorrectly-formatted unit tests. Our findings suggest that, when promptingmodels similar to Code Interpreter, it is important to include the basicinformation necessary to generate unit tests, but minor details are not asimportant.",Vincent Li,2023/9/30,2023/9/30
1212.5461v2,Interactive Ant Colony Optimisation (iACO) for Early Lifecycle Software Design,http://arxiv.org/abs/1212.5461v2,"Software design is crucial to successful software development, yet is ademanding multi-objective problem for software engineers. In an attempt toassist the software designer, interactive (i.e. human in-the-loop)meta-heuristic search techniques such as evolutionary computing have beenapplied and show promising results. Recent investigations have also shown thatAnt Colony Optimization (ACO) can outperform evolutionary computing as apotential search engine for interactive software design. With a limitedcomputational budget, ACO produces superior candidate design solutions in asmaller number of iterations. Building on these findings, we propose a novelinteractive ACO (iACO) approach to assist the designer in early lifecyclesoftware design, in which the search is steered jointly by subjective designerevaluation as well as machine fitness functions relating the structuralintegrity and surrogate elegance of software designs. Results show that iACO isspeedy, responsive and highly effective in enabling interactive, dynamicmulti-objective search in early lifecycle software design. Study participantsrate the iACO search experience as compelling. Results of machine learning offitness measure weightings indicate that software design elegance does indeedplay a significant role in designer evaluation of candidate software design. Weconclude that the evenness of the number of attributes and methods amongclasses (NAC) is a significant surrogate elegance measure, which in turnsuggests that this evenness of distribution, when combined with structuralintegrity, is an implicit but crucial component of effective early lifecyclesoftware design.",Christopher L. Simons,2012/12/21,2014/6/23
2011.04516v1,Data model as agile basis for evolving calibration software,http://arxiv.org/abs/2011.04516v1,"We design the imaging data calibration and reduction software for MICADO, theFirst Light near-IR instrument on the Extremely Large Telescope. In thisprocess we have hit the limit of what can be achieved with a detailed softwaredesign that is primarily captured in pdf/word documents.  Trade-offs between hardware and calibration software are required to meetstringent science requirements. To support such trade-offs, more software needsto be developed in the early phases of the project: simulators, archives,prototype recipes and pipelines. This requires continuous and efficientexchange of evolving designs between the software and hardware groups, which ishard to achieve with manually maintained documents. This, and maintaining theconsistency between the design documents and various software components ispossible with a machine readable version of the design.  We construct a detailed design that is readable by both software and humans.From this the design documentation, prototype pipelines and data archives aregenerated automatically. We present the implementation of such an approach forthe calibration software detailed design for the ELT MICADO imager which isbased on expertise and lessons learned in earlier projects (e.g. OmegaCAM,MUSE, Euclid).",Hugo Buddelmeijer,2020/11/9,2020/11/9
2003.00290v1,Enumerating Hardware-Software Splits with Program Rewriting,http://arxiv.org/abs/2003.00290v1,"A core problem in hardware-software codesign is in the sheer size of thedesign space. Without a set ISA to constrain the hardware-software interface,the design space explodes. This work presents a strategy for managing themassive hardware-software design space within the domain of machine learninginference workloads and accelerators. We first propose EngineIR, a new languagefor representing machine learning hardware and software in a single program.Then, using equality graphs -- a data structure from the compilers literature-- we suggest a method for efficiently enumerating the design space byperforming rewrites over our representation.",Gus Smith,2020/2/29,2020/2/29
2101.02373v3,Architectural Patterns for the Design of Federated Learning Systems,http://arxiv.org/abs/2101.02373v3,"Federated learning has received fast-growing interests from academia andindustry to tackle the challenges of data hungriness and privacy in machinelearning. A federated learning system can be viewed as a large-scaledistributed system with different components and stakeholders as numerousclient devices participate in federated learning. Designing a federatedlearning system requires software system design thinking apart from machinelearning knowledge. Although much effort has been put into federated learningfrom the machine learning technique aspects, the software architecture designconcerns in building federated learning systems have been largely ignored.Therefore, in this paper, we present a collection of architectural patterns todeal with the design challenges of federated learning systems. Architecturalpatterns present reusable solutions to a commonly occurring problem within agiven context during software architecture design. The presented patterns arebased on the results of a systematic literature review and include three clientmanagement patterns, four model management patterns, three model trainingpatterns, and four model aggregation patterns. The patterns are associated tothe particular state transitions in a federated learning model lifecycle,serving as a guidance for effective use of the patterns in the design offederated learning systems.",Sin Kit Lo,2021/1/7,2021/6/18
2302.05530v1,Machine Learning Based Approach to Recommend MITRE ATT&CK Framework for Software Requirements and Design Specifications,http://arxiv.org/abs/2302.05530v1,"Engineering more secure software has become a critical challenge in the cyberworld. It is very important to develop methodologies, techniques, and tools fordeveloping secure software. To develop secure software, software developersneed to think like an attacker through mining software repositories. These aimto analyze and understand the data repositories related to softwaredevelopment. The main goal is to use these software repositories to support thedecision-making process of software development. There are differentvulnerability databases like Common Weakness Enumeration (CWE), CommonVulnerabilities and Exposures database (CVE), and CAPEC. We utilized a databasecalled MITRE. MITRE ATT&CK tactics and techniques have been used in variousways and methods, but tools for utilizing these tactics and techniques in theearly stages of the software development life cycle (SDLC) are lacking. In thispaper, we use machine learning algorithms to map requirements to the MITREATT&CK database and determine the accuracy of each mapping depending on thedata split.",Nicholas Lasky,2023/2/10,2023/2/10
1401.6365v1,User Interface Design for E-Learning Software,http://arxiv.org/abs/1401.6365v1,"User interface (UI) is point of interaction between user and computersoftware. The success and failure of a software application depends on UserInterface Design (UID). Possibility of using a software, easily using andlearning are issues influenced by UID. The UI is significant in designing ofeducational software (e-Learning). Principles and concepts of learning shouldbe considered in addition to UID principles in UID for e-learning. In thisregard, to specify the logical relationship between education, learning, UIDand multimedia at first we readdress the issues raised in previous studies. Itis followed by examining the principle concepts of e-learning and UID. Then, wewill see how UID contributes to e-learning through the educational softwarebuilt by authors. Also we show the way of using UI to improve learning andmotivating the learners and to improve the time efficiency of using e-learningsoftware.",Behnam Faghih,2014/1/24,2014/1/24
1910.04736v2,Studying Software Engineering Patterns for Designing Machine Learning Systems,http://arxiv.org/abs/1910.04736v2,"Machine-learning (ML) techniques have become popular in the recent years. MLtechniques rely on mathematics and on software engineering. Researchers andpractitioners studying best practices for designing ML application systems andsoftware to address the software complexity and quality of ML techniques. Suchdesign practices are often formalized as architecture patterns and designpatterns by encapsulating reusable solutions to commonly occurring problemswithin given contexts. However, to the best of our knowledge, there has been nowork collecting, classifying, and discussing these software-engineering (SE)design patterns for ML techniques systematically. Thus, we set out to collectgood/bad SE design patterns for ML techniques to provide developers with acomprehensive and ordered classification of such patterns. We report herepreliminary results of a systematic-literature review (SLR) of good/bad designpatterns for ML.",Hironori Washizaki,2019/10/10,2019/10/11
1201.3978v1,Learners' Quanta based Design of a Learning Management System,http://arxiv.org/abs/1201.3978v1,In this paper IEEE Learning Technology System Architecture (LTSA) for LMSsoftware has been analyzed. It has been observed that LTSA is too abstract tobe adapted in a uniform way by LMS developers. A Learners' Quanta based highlevel design that satisfies the IEEE LTSA standard has been proposed for futuredevelopment of efficient LMS software. A hybrid model of learning fitting intoLTSA model has also been proposed while designing.,Souvik Sengupta,2012/1/19,2012/1/19
2301.05069v1,Open Design Case Study -- A Crowdsourcing Effort to Curate Software Design Case Studies,http://arxiv.org/abs/2301.05069v1,"Case study-based learning has been successfully integrated into variouscourses, including software engineering education. In the context of softwaredesign courses, the use of case studies often entails sharing of realsuccessful or failed software development. Using examples of real-world casestudies allows educators to reinforce the applicability and usefulness offundamental design concepts, relate the importance of evaluating designtrade-offs with respect to stakeholders' requirements, and highlight theimportance of upfront design where students that lack industrial experiencetend to overlook. However, the use of real-world case studies is notstraightforward because 1.) there is a lack of open source repositories forreal software design case studies and 2.) even if case studies are available,they are often reported without a standardized format, which may hinder thealignment between the case and the desired learning outcomes. To address thelack of software design case studies for educational purposes, we propose theidea of Open Design Case Study, a repository to crowdsource, curate, andrecruit other educators to contribute case studies for teaching software designcourses. The platform will also allow educators and students to share,brainstorm, and discuss design solutions based on case studies shared publiclyon the repository.",Chun Yong Chong,2023/1/12,2023/1/12
2010.02075v1,Learned Hardware/Software Co-Design of Neural Accelerators,http://arxiv.org/abs/2010.02075v1,"The use of deep learning has grown at an exponential rate, giving rise tonumerous specialized hardware and software systems for deep learning. Becausethe design space of deep learning software stacks and hardware accelerators isdiverse and vast, prior work considers software optimizations separately fromhardware architectures, effectively reducing the search space. Unfortunately,this bifurcated approach means that many profitable design points are neverexplored. This paper instead casts the problem as hardware/software co-design,with the goal of automatically identifying desirable points in the joint designspace. The key to our solution is a new constrained Bayesian optimizationframework that avoids invalid solutions by exploiting the highly constrainedfeatures of this design space, which are semi-continuous/semi-discrete. Weevaluate our optimization framework by applying it to a variety of neuralmodels, improving the energy-delay product by 18% (ResNet) and 40% (DQN) overhand-tuned state-of-the-art systems, as well as demonstrating strong results onother neural network architectures, such as MLPs and Transformers.",Zhan Shi,2020/10/5,2020/10/5
2011.00998v2,A Review On Software Defects Prediction Methods,http://arxiv.org/abs/2011.00998v2,"Software quality is one of the essential aspects of a software. Withincreasing demand, software designs are becoming more complex, increasing theprobability of software defects. Testers improve the quality of software byfixing defects. Hence the analysis of defects significantly improves softwarequality. The complexity of software also results in a higher number of defects,and thus manual detection can become a very time-consuming process. This gaveresearchers incentives to develop techniques for automatic software defectsdetection. In this paper, we try to analyze the state of the art machinelearning algorithms' performance for software defect classification. We usedseven datasets from the NASA promise dataset repository for this research work.The performance of Neural Networks and Gradient Boosting classifier dominatedother algorithms.",Mitt Shah,2020/10/30,2020/11/17
2210.04794v1,Towards a case-based learning approach to support software architecture education,http://arxiv.org/abs/2210.04794v1,"Software architecture education remains challenging for instructors,students, and software industry professionals. Several initiatives have beenproposed to mitigate the inherent challenges, including games, supportingtools, collaborative courses, and hands-on projects. Case-based learning hasbeen introduced in software architecture, and its benefits are recognized.However, choosing the right cases that cover the stated learning objectives anddeveloping learning activities to achieve high-order learning are alsochallenging. The main goal of this paper is to present a case-based learningapproach that guides the development of learning objectives, the finding andselection of real-world software architecture cases, and the design ofinstructional activities. We applied our approach in software architecturerelated courses during the past few years. The results show that it canleverage the ways to adequately explore cases for educational purposes whilealso motivating instructors and students to the software architectureeducation.",Brauner R. N. Oliveira,2022/9/12,2022/9/12
1803.10587v1,A First Implementation of a Design Thinking Workshop During a Mobile App Development Project Course,http://arxiv.org/abs/1803.10587v1,"Due to their characteristics, millennials prefer learning-by-doing and sociallearning, such as project-based learning. However, software developmentprojects require not only technical skills but also creativity; Design Thinkingcan serve such purpose. We conducted a workshop following the Design Thinkingapproach of the d.school, to help students generating ideas for a mobile appdevelopment project course. On top of the details for implementing theworkshop, we report our observations, lessons learned, and provide suggestionsfor further implementation.",Yen Dieu Pham,2018/3/28,2018/3/28
2012.01708v4,Feature-Based Software Design Pattern Detection,http://arxiv.org/abs/2012.01708v4,"Software design patterns are standard solutions to common problems insoftware design and architecture. Knowing that a particular module implements adesign pattern is a shortcut to design comprehension. Manually detecting designpatterns is a time consuming and challenging task, therefore, researchers haveproposed automatic design pattern detection techniques. However, thesetechniques show low performance for certain design patterns. In this work, weintroduce a design pattern detection approach, DPD_F that improves theperformance over the state-of-the-art by using code features with machinelearning classifiers to automatically train a design pattern detector. DPD_Fcreates a semantic representation of Java source code using the code featuresand the call graph, and applies the \textit{Word2Vec} algorithm on the semanticrepresentation to construct the word-space geometric model of the Java sourcecode. DPD$_F$ then builds a Machine Learning classifier trained on a labelleddataset and identifies software design patterns with over 80% Precision andover 79\% Recall. Additionally, we have compared DPD_F with two existing designpattern detection techniques namely FeatureMaps & MARPLE-DPD. Empirical resultsdemonstrate that our approach outperforms the state-of-the-art approaches byapproximately 35% and 15% respectively in terms of Precision. The run-timeperformance also supports the practical applicability of our classifier.",Najam Nazar,2020/12/3,2021/12/2
1508.03348v2,Looking at Software Sustainability and Productivity Challenges from NSF,http://arxiv.org/abs/1508.03348v2,"This paper is a contribution to the Computational Science & EngineeringSoftware Sustainability and Productivity Challenges (CSESSP Challenges)Workshop (https://www.nitrd.gov/csessp/), sponsored by the Networking andInformation Technology Research and Development (NITRD) Software Design andProductivity (SDP) Coordinating Group, held October 15th-16th 2015 inWashington DC, USA. It introduces the role of software at the National ScienceFoundation (NSF) and the NSF Software Infrastructure for Sustained Innovation(SI2) program, then describes challenges that the SI2 program has identified,including funding models, career paths, incentives, training, interdisciplinarywork, portability, and dissemination, as well as lesson that have been learned.",Daniel S. Katz,2015/8/13,2015/8/17
2305.16126v1,Automatic off-line design of robot swarms: exploring the transferability of control software and design methods across different platforms,http://arxiv.org/abs/2305.16126v1,"Automatic off-line design is an attractive approach to implementing robotswarms. In this approach, a designer specifies a mission for the swarm, and anoptimization process generates suitable control software for the individualrobots through computer-based simulations. Most relevant literature has focusedon effectively transferring control software from simulation to physicalrobots. For the first time, we investigate (i) whether control softwaregenerated via automatic design is transferable across robot platforms and (ii)whether the design methods that generate such control software are themselvestransferable. We experiment with two ground mobile platforms with equivalentcapabilities. Our measure of transferability is based on the performance dropobserved when control software and/or design methods are ported from oneplatform to another. Results indicate that while the control software generatedvia automatic design is transferable in some cases, better performance can beachieved when a transferable method is directly applied to the new platform.",Miquel Kegeleirs,2023/5/25,2023/5/25
1901.04020v1,A Framework for Evaluating Model-Driven Self-adaptive Software Systems,http://arxiv.org/abs/1901.04020v1,"In the last few years, Model Driven Development (MDD), Component-basedSoftware Development (CBSD), and context-oriented software have becomeinteresting alternatives for the design and construction of self-adaptivesoftware systems. In general, the ultimate goal of these technologies is to beable to reduce development costs and effort, while improving the modularity,flexibility, adaptability, and reliability of software systems. An analysis ofthese technologies shows them all to include the principle of the separation ofconcerns, and their further integration is a key factor to obtaininghigh-quality and self-adaptable software systems. Each technology identifiesdifferent concerns and deals with them separately in order to specify thedesign of the self-adaptive applications, and, at the same time, supportsoftware with adaptability and context-awareness. This research studies thedevelopment methodologies that employ the principles of model-drivendevelopment in building self-adaptive software systems. To this aim, thisarticle proposes an evaluation framework for analysing and evaluating thefeatures of model-driven approaches and their ability to support software withself-adaptability and dependability in highly dynamic contextual environment.Such evaluation framework can facilitate the software developers on selecting adevelopment methodology that suits their software requirements and reduces thedevelopment effort of building self-adaptive software systems. This studyhighlights the major drawbacks of the propped model-driven approaches in therelated works, and emphasise on considering the volatile aspects ofself-adaptive software in the analysis, design and implementation phases of thedevelopment methodologies. In addition, we argue that the developmentmethodologies should leave the selection of modelling languages and modellingtools to the software developers.",Basel Magableh,2019/1/13,2019/1/13
2009.05714v1,Designing a Serious Game: Teaching Developers to Embed Privacy into Software Systems,http://arxiv.org/abs/2009.05714v1,"Software applications continue to challenge user privacy when users interactwith them. Privacy practices (e.g. Data Minimisation (DM), Privacy by Design(PbD) or General Data Protection Regulation (GDPR)) and related ""privacyengineering"" methodologies exist and provide clear instructions for developersto implement privacy into software systems they develop that preserve userprivacy. However, those practices and methodologies are not yet a commonpractice in the software development community. There has been no previousresearch focused on developing ""educational"" interventions such as seriousgames to enhance software developers' coding behaviour. Therefore, thisresearch proposes a game design framework as an educational tool for softwaredevelopers to improve (secure) coding behaviour, so they can developprivacy-preserving software applications that people can use. The elements ofthe proposed framework were incorporated into a gaming application scenariothat enhances the software developers' coding behaviour through theirmotivation. The proposed work not only enables the development ofprivacy-preserving software systems but also helping the software developmentcommunity to put privacy guidelines and engineering methodologies intopractice.",Nalin Asanka Gamagedara Arachchilage,2020/9/12,2020/9/12
1508.06805v1,Allowing Software Developers to Debug HLS Hardware,http://arxiv.org/abs/1508.06805v1,"High-Level Synthesis (HLS) is emerging as a mainstream design methodology,allowing software designers to enjoy the benefits of a hardware implementation.Significant work has led to effective compilers that produce high-qualityhardware designs from software specifications. However, in order to fullybenefit from the promise of HLS, a complete ecosystem that provides the abilityto analyze, debug, and optimize designs is essential. This ecosystem has to beaccessible to software designers. This is challenging, since softwaredevelopers view their designs very differently than how they are physicallyimplemented on-chip. Rather than individual sequential lines of code, theimplementation consists of gates operating in parallel across multiple clockcycles. In this paper, we report on our efforts to create an ecosystem thatallows software designers to debug HLS-generated circuits in a familiar manner.We have implemented our ideas in a debug framework that will be included in thenext release of the popular LegUp high-level synthesis tool.",Jeffrey Goeders,2015/8/27,2015/8/27
1709.01304v1,"Abstractness, specificity, and complexity in software design",http://arxiv.org/abs/1709.01304v1,"Abstraction is one of the fundamental concepts of software design.Consequently, the determination of an appropriate abstraction level for themultitude of artefacts that form a software system is an integral part ofsoftware engineering. However, the very nature of abstraction in softwaredesign and particularly its interrelation with equally important concepts likecomplexity, specificity or genericity are not fully understood today. As a steptowards a better understanding of the trade-offs involved, this paper proposesa distinction of abstraction into two types that have different effects on thespecificity and the complexity of artefacts. We discuss the roles of the twotypes of abstraction in software design and explain the interrelations betweenabstractness, specificity, and complexity. Furthermore, we illustrate thebenefit of the proposed distinction with multiple examples and describeconsequences of our findings for software design activities.",Stefan Wagner,2017/9/5,2017/9/5
0710.4641v1,UML 2.0 - Overview and Perspectives in SoC Design,http://arxiv.org/abs/0710.4641v1,"The design productivity gap requires more efficient design methods. Softwaresystems have faced the same challenge and seem to have mastered it with theintroduction of more abstract design methods. The UML has become the standardfor software systems modeling and thus the foundation of new design methods.Although the UML is defined as a general purpose modeling language, itsapplication to hardware and hardware/software codesign is very limited. Inorder to successfully apply the UML at these fields, it is essential tounderstand its capabilities and to map it to a new domain.",Tim Schattkowsky,2007/10/25,2007/10/25
cs/0607022v1,Ten Incredibly Dangerous Software Ideas,http://arxiv.org/abs/cs/0607022v1,This is a rough draft synopsis of a book presently in preparation. This bookprovides a systematic critique of the software industry. This critique isaccomplished using classical methods in practical design science.,G. A. Maney,2006/7/7,2006/7/7
0905.4613v1,Athos - The C# GUI Generator,http://arxiv.org/abs/0905.4613v1,"This application comes to help software architects and developers during thelong process between user's stories, designing the application's structure andactually coding it.",Daniela Ilea,2009/5/28,2009/5/28
1906.08351v1,Towards Lakosian Multilingual Software Design Principles,http://arxiv.org/abs/1906.08351v1,"Large software systems often comprise programs written in differentprogramming languages. In the case when cross-language interoperability isaccomplished with a Foreign Function Interface (FFI), for example pybind11,Boost.Python, Emscripten, PyV8, or JNI, among many others, common softwareengineering tools, such as call-graph analysis, are obstructed by the opacityof the FFI. This complicates debugging and fosters potential inefficiency andsecurity problems. One contributing issue is that there is little rigoroussoftware design advice for multilingual software. In this paper, we present ourprogress towards a more rigorous design approach to multilingual software. Theapproach is based on the existing approach to the design of large-scale C++systems developed by Lakos. The Lakosian approach is one of the few designmethodologies to address physical design rather than just logical design. Usingthe MLSA toolkit developed in prior work for analysis of multilingual software,we focus in on one FFI -- the pybind11 FFI. An extension to the Lakosian C++design rules is proposed to address multilingual software that uses pybind11.Using a sample of 50 public GitHub repositories that use pybind11, we measurehow many repositories would currently satisfy these rules. We conclude with aproposed generalization of the pybind11-based rules for any multilingualsoftware using an FFI interface.",Damian M. Lyons,2019/6/19,2019/6/19
1905.09364v1,FQL: An Extensible Feature Query Language and Toolkit on Searching Software Characteristics for HPC Applications,http://arxiv.org/abs/1905.09364v1,"The amount of large-scale scientific computing software is dramaticallyincreasing. In this work, we designed a new language, named feature querylanguage (FQL), to collect and extract software features from a quick staticcode analysis. We designed and implemented an FQL toolkit to automaticallydetect and present the software features using an extensible query repository.Several large-scale, high performance computing (HPC) scientific codes havebeen used in the paper to demonstrate the HPC-related feature extraction andinformation collection. Although we emphasized the HPC features in the study,the toolkit can be easily extended to answer general software featurequestions, such as coding pattern and hardware dependency.",Weijian Zheng,2019/5/22,2019/5/22
2111.01501v1,Constructing a software requirements specification and design for electronic IT news magazine system,http://arxiv.org/abs/2111.01501v1,"Requirements engineering process intends to obtain software services andconstraints. This process is essential to meet the customer's needs andexpectations. This process includes three main activities in general. These aredetecting requirements by interacting with software stakeholders, transferringthese requirements into a standard document, and examining that therequirements really define the software that the client needs. Functionalrequirements are services that the software should deliver to the end-user. Inaddition, functional requirements describe how the software should respond tospecific inputs, and how the software should behave in certain circumstances.This paper aims to develop a software requirements specification document ofthe electronic IT news magazine system. The electronic magazine provides usersto post and view up-to-date IT news. Still, there is a lack in the literatureof comprehensive studies about the construction of the electronic magazinesoftware specification and design in conformance with the contemporary softwaredevelopment processes. Moreover, there is a need for a suitable researchframework to support the requirements engineering process. The novelty of thispaper is the construction of software specification and design of theelectronic magazine by following the Al-Msie'deen research framework. All thedocuments of software requirements specification and design have beenconstructed to conform to the agile usage-centered design technique and theproposed research framework. A requirements specification and design aresuggested and followed for the construction of the electronic magazinesoftware. This study proved that involving users extensively in the process ofsoftware requirements specification and design will lead to the creation ofdependable and acceptable software systems.",Ra'Fat Al-Msie'deen,2021/11/2,2021/11/2
1910.00903v1,New Failure Rate Model for Iterative Software Development Life Cycle Process,http://arxiv.org/abs/1910.00903v1,"Software reliability models are one of the most generally used mathematicaltool for estimation of reliability, failure rate and number of remaining faultsin the software. Existing software reliability models are designed to followwaterfall software development life cycle process. These existing models do nottake advantage of iterative software development process. In this paper, a newfailure rate model centered on iterative software development life cycleprocess has been developed. It aims to integrate a new modulation factor forincorporating varying needs in each phase of iterative software developmentprocess. It comprises imperfect debugging with the possibility of faultintroduction and removal of multiple faults in an interval as iterativedevelopment of the software proceeds. The proposed model has been validated ontwelve iterations of Eclipse software failure dataset and nine iterations ofJava Development toolkit (JDT) software failure dataset. Parameter estimationfor the proposed model has been done by hybrid Particle Swarm Optimization andGravitational Search Algorithm. Experimental results in-terms ofgoodness-of-fit shows that proposed model has outperformed Jelinski Moranda,Shick Wolverton, Goel Okummotto Imperfect debugging, GS Mahapatra, ModifiedShick Wolverton in 83.33 % of iterations for eclipse dataset and 77.77% ofiterations for JDT dataset.",Sangeeta,2019/10/2,2019/10/2
1508.02812v1,A Game of Attribute Decomposition for Software Architecture Design,http://arxiv.org/abs/1508.02812v1,"Attribute-driven software architecture design aims to provide decisionsupport by taking into account the quality attributes of softwares. A centralquestion in this process is: What architecture design best fulfills thedesirable software requirements? To answer this question, a system designerneeds to make tradeoffs among several potentially conflicting qualityattributes. Such decisions are normally ad-hoc and rely heavily on experiences.We propose a mathematical approach to tackle this problem. Game theorynaturally provides the basic language: Players represent requirements, andstrategies involve setting up coalitions among the players. In this way wepropose a novel model, called decomposition game, for attribute-driven design.We present its solution concept based on the notion of cohesion andexpansion-freedom and prove that a solution always exists. We then investigatethe computational complexity of obtaining a solution. The game model and thealgorithms may serve as a general framework for providing useful guidance forsoftware architecture design. We present our results through running examplesand a case study on a real-life software project.",Jiamou Liu,2015/8/12,2015/8/12
1303.6529v2,Random generation of optimal saturated designs,http://arxiv.org/abs/1303.6529v2,"Efficient algorithms for searching for optimal saturated designs are widelyavailable. They maximize a given efficiency measure (such as D-optimality) andprovide an optimum design. Nevertheless, they do not guarantee a \emph{global}optimal design. Indeed, they start from an initial random design and find alocal optimal design. If the initial design is changed the optimum found will,in general, be different. A natural question arises. Should we stop at thedesign found or should we run the algorithm again in search of a better design?This paper uses very recent methods and software for discovery probability tosupport the decision to continue or stop the sampling. A software tool writtenin SAS has been developed.",Roberto Fontana,2013/3/26,2013/3/28
2111.13992v1,NanoFrame: A web-based DNA wireframe design tool for 3D structures,http://arxiv.org/abs/2111.13992v1,"The rapid development of the DNA nanotechnology field has been facilitated byadvances in CAD software. However, as more complex concepts arose, the lagbetween the needs and software capabilities appeared. Further derailed bymanual installation and software incompatibility across different platforms andoften tedious library management issues, the software has become hard-to-usefor many.  Here we present NanoFrame, a web-based DNA wireframe design tool for making3D nanostructures from a single scaffold. Within this software, we devisedalgorithms for DNA routing, staple breaking, and wireframe cage opening which,while modeled for cuboid structure, can be generalized to a variety of platonicand Archimedean shapes. In addition, NanoFrame provides a platform for editingauto-generated staple sequences and saving work online.",Samson Petrosyan,2021/11/27,2021/11/27
1312.2344v1,Request and notification Pattern for an internet banking System,http://arxiv.org/abs/1312.2344v1,"The quality of software is enhanced by using the design patterns. The designpatterns are the reusable component used in the development of the software,which delivers improved quality software to the end users. The researchers havedeveloped design patterns for user interface, e-commerce applications, mobileapplications, text classification and so on. There are no design patterns forinternet banking applications, but there is analysis pattern for banking. Thismotivated to mine the design patterns for internet banking application. It canbe mined from the document of Business Process Management (BPM). In this paperthe request and notification are two patterns, that have been presented, whichhave been mined from internet banking.",A. Meiappane,2013/12/9,2013/12/9
1003.5455v1,Towards physical laws for software architecture,http://arxiv.org/abs/1003.5455v1,"Starting from the pioneering works on software architecture preciousguidelines have emerged to indicate how computer programs should be organized.For example the ""separation of concerns"" suggests to split a program intomodules that overlap in functionality as little as possible. However theserecommendations are mainly conceptual and are thus hard to express in aquantitative form. Hence software architecture relies on the individualexperience and skill of the designers rather than on quantitative laws. In thisarticle I apply the methods developed for the classification of information onthe World-Wide-Web to study the organization of Open Source programs in anattempt to establish the statistical laws governing software architecture.",A. D. Chepelianskii,2010/3/29,2010/3/29
2106.09844v1,Conclusion Stability for Natural Language Based Mining of Design Discussions,http://arxiv.org/abs/2106.09844v1,"Developer discussions range from in-person hallway chats to comment chains onbug reports. Being able to identify discussions that touch on software designwould be helpful in documentation and refactoring software. Design mining isthe application of machine learning techniques to correctly label a givendiscussion artifact, such as a pull request, as pertaining (or not) to design.In this paper we demonstrate a simple example of how design mining works. Wethen show how conclusion stability is poor on different artifact types anddifferent projects. We show two techniques -- augmentation and contextspecificity -- that greatly improve the conclusion stability and cross-projectrelevance of design mining. Our new approach achieves AUC of 0.88 on withindataset classification and 0.80 on the cross-dataset classification task.",Alvi Mahadi,2021/6/17,2021/6/17
2003.04781v2,Architectural Software Patterns for the Development of IoT Smart Applications,http://arxiv.org/abs/2003.04781v2,"Software developers usually start coding an application with no formalarchitecture in mind and relying on intuition and experience instead of onwell-known design patters. A different approach is recommended for thedevelopment of IoT smart applications due to its high complexity that combinessensors, actuators, communication technologies, and big data analytics, as wellas its distributed nature that spans for different layers of field, fog, andcloud infrastructure. Literature reports many experiences of softwaredevelopment for IoT smart applications. However, architectural solutions arepresented with no rationale for the choice of software components and the waythey relate to each other. This paper proposes a classification for softwarecomponents and their relationships in order to model a software architecturefor a particular IoT smart application. Three smart applications for cities,buildings, and agriculture were selected as examples of using some components,connectors, and well-known design patterns. Finally, the problems andchallenges involved in the choice of software architectures for IoT arediscussed.",Fabrizio Borelli,2020/3/10,2020/3/17
2301.03709v1,Transfer learning for conflict and duplicate detection in software requirement pairs,http://arxiv.org/abs/2301.03709v1,"Consistent and holistic expression of software requirements is important forthe success of software projects. In this study, we aim to enhance theefficiency of the software development processes by automatically identifyingconflicting and duplicate software requirement specifications. We formulate theconflict and duplicate detection problem as a requirement pair classificationtask. We design a novel transformers-based architecture, SR-BERT, whichincorporates Sentence-BERT and Bi-encoders for the conflict and duplicateidentification task. Furthermore, we apply supervised multi-stage fine-tuningto the pre-trained transformer models. We test the performance of differenttransfer models using four different datasets. We find that sequentiallytrained and fine-tuned transformer models perform well across the datasets withSR-BERT achieving the best performance for larger datasets. We also explore thecross-domain performance of conflict detection models and adopt a rule-basedfiltering approach to validate the model classifications. Our analysisindicates that the sentence pair classification approach and the proposedtransformer-based natural language processing strategies can contributesignificantly to achieving automation in conflict and duplicate detection",Garima Malik,2023/1/9,2023/1/9
1903.04909v1,Towards Software Analytics: Modeling Maintenance Activities,http://arxiv.org/abs/1903.04909v1,"Lehman's Laws teach us that a software system will become progressively lesssatisfying to its users over time, unless it is continually adapted to meet newneeds. Understanding software maintenance can potentially relieve many of thepains currently experienced by practitioners in the industry and assist inreducing uncertainty, improving cost-effectiveness, reliability and more. Theresearch community classifies software maintenance into 3 main activities:Corrective: fault fixing; Perfective: system improvements; Adaptive: newfeature introduction.  In this work we seek to model software maintenance activities and design acommit classification method capable of yielding a high quality classificationmodel. We performed a comparative analysis of our method and existingtechniques based on 11 popular open source projects from which we had manuallyclassified 1151 commits, over 100 commits from each of the studied projects.The model we devised was able to achieve an accuracy of 76% and Kappa of 63%(considered '""Good"" in this context) for the test dataset, an improvement ofover 20 percentage points, and a relative improvement of ~40% in the context ofcross-project classification.  We then leverage our commit classification method to demonstrate twoapplications: (1) a tool aimed at providing an intuitive visualization ofsoftware maintenance activities over time, and (2) an in-depth analysis of therelationship between maintenance activities and unit tests.",Stanislav Levin,2019/3/9,2019/3/9
2001.01424v1,Cross-Dataset Design Discussion Mining,http://arxiv.org/abs/2001.01424v1,"Being able to identify software discussions that are primarily about design,which we call design mining, can improve documentation and maintenance ofsoftware systems. Existing design mining approaches have good classificationperformance using natural language processing (NLP) techniques, but theconclusion stability of these approaches is generally poor. A classifiertrained on a given dataset of software projects has so far not worked well ondifferent artifacts or different datasets. In this study, we replicate andsynthesize these earlier results in a meta-analysis. We then apply recent workin transfer learning for NLP to the problem of design mining. However, for ourdatasets, these deep transfer learning classifiers perform no better than lesscomplex classifiers. We conclude by discussing some reasons behind the transferlearning approach to design mining.",Alvi Mahadi,2020/1/6,2020/1/6
2112.12834v1,Software Engineering Education Knowledge Versus Industrial Needs,http://arxiv.org/abs/2112.12834v1,"Contribution: Determine and analyze the gap between software practitioners'education outlined in the 2014IEEE/ACM Software Engineering Education Knowledge(SEEK) and industrial needs pointed by Wikipedia articles referenced in StackOverflow (SO) posts.  Background: Previous work has uncovered deficiencies in the coverage ofcomputer fundamentals, people skills, software processes, and human-computerinteraction, suggesting rebalancing.  Research Questions: 1) To what extent are developers' needs, in terms ofWikipedia articles referenced in SO posts, covered by the SEEK knowledge units?2) How does the popularity of Wikipedia articles relate to their SEEK coverage?3) What areas of computing knowledge can be better covered by the SEEKknowledge units? 4) Why are Wikipedia articles covered by the SEEK knowledgeunits cited on SO?  Methodology: Wikipedia articles were systematically collected from SO posts.The most cited were manually mapped to the SEEK knowledge units, assessedaccording to their degree of coverage. Articles insufficiently covered by theSEEK were classified by hand using the 2012 ACM Computing ClassificationSystem. A sample of posts referencing sufficiently covered articles wasmanually analyzed. A survey was conducted on software practitioners to validatethe study findings.  Findings: SEEK appears to cover sufficiently computer science fundamentals,software design and mathematical concepts, but less so areas like the WorldWide Web, software engineering components, and computer graphics. Developersseek advice, best practices and explanations about software topics, and codereview assistance. Future SEEK models and the computing education could divedeeper in information systems, design, testing, security, and soft skills.",Georgios Liargkovas,2021/12/23,2021/12/23
2304.02489v1,Architectural Support for Software Performance in Continuous Software Engineering: A Systematic Mapping Study,http://arxiv.org/abs/2304.02489v1,"The continuous software engineering paradigm is gaining popularity in moderndevelopment practices, where the interleaving of design and runtime activitiesis induced by the continuous evolution of software systems. In this context,performance assessment is not easy, but recent studies have shown thatarchitectural models evolving with the software can support this goal. In thispaper, we present a mapping study aimed at classifying existing scientificcontributions that deal with the architectural support for performance-targetedcontinuous software engineering. We have applied the systematic mappingmethodology to an initial set of 215 potentially relevant papers and selected66 primary studies that we have analyzed to characterize and classify thecurrent state of research. This classification helps to focus on the mainaspects that are being considered in this domain and, mostly, on the emergingfindings and implications for future research",Romina Eramo,2023/4/5,2023/4/5
1210.6621v2,Privacy Design Strategies,http://arxiv.org/abs/1210.6621v2,"In this paper we define the notion of a privacy design strategy. Thesestrategies help IT architects to support privacy by design early in thesoftware development life cycle, during concept development and analysis. Usingcurrent data protection legislation as point of departure we derive thefollowing eight privacy design strategies: minimise, hide, separate, aggregate,inform, control, enforce, and demonstrate. The strategies also provide a usefulclassification of privacy design patterns and the underlying privacy enhancingtechnologies. We therefore believe that these privacy design strategies are notonly useful when designing privacy friendly systems, but also helpful whenevaluating the privacy impact of existing IT systems.",Jaap-Henk Hoepman,2012/10/24,2013/5/6
2205.14248v1,Towards a Design Framework for TNN-Based Neuromorphic Sensory Processing Units,http://arxiv.org/abs/2205.14248v1,Temporal Neural Networks (TNNs) are spiking neural networks that exhibitbrain-like sensory processing with high energy efficiency. This work presentsthe ongoing research towards developing a custom design framework for designingefficient application-specific TNN-based Neuromorphic Sensory Processing Units(NSPUs). This paper examines previous works on NSPU designs for UCR time-seriesclustering and MNIST image classification applications. Current ideas for acustom design framework and tools that enable efficient software-to-hardwaredesign flow for rapid design space exploration of application-specific NSPUswhile leveraging EDA tools to obtain post-layout netlist andpower-performance-area (PPA) metrics are described. Future research directionsare also outlined.,Prabhu Vellaisamy,2022/5/27,2022/5/27
1709.05867v1,Combinational neural network using Gabor filters for the classification of handwritten digits,http://arxiv.org/abs/1709.05867v1,A classification algorithm that combines the components of k-nearestneighbours and multilayer neural networks has been designed and tested. Withthis method the computational time required for training the dataset has beenreduced substancially. Gabor filters were used for the feature extraction toensure a better performance. This algorithm is tested with MNIST dataset and itwill be integrated as a module in the object recognition software which iscurrently under development.,N. Joshi,2017/9/18,2017/9/18
1312.2949v1,A Survey of Embedded Software Profiling Methodologies,http://arxiv.org/abs/1312.2949v1,"Embedded Systems combine one or more processor cores with dedicated logicrunning on an ASIC or FPGA to meet design goals at reasonable cost. It isachieved by profiling the application with variety of aspects like performance,memory usage, cache hit versus cache miss, energy consumption, etc. Out ofthese, performance estimation is more important than others. With everincreasing system complexities, it becomes quite necessary to carry outperformance estimation of embedded software implemented in a particularprocessor for fast design space exploration. Such profiled data also guides thedesigner how to partition the system for Hardware (HW) and Software (SW)environments. In this paper, we propose a classification for currentlyavailable Embedded Software Profiling Tools, and we present different academicand industrial approaches in this context. Based on these observations, it willbe easy to identify such common principles and needs which are required for atrue Software Profiling Tool for a particular application.",Rajendra Patel,2013/12/10,2013/12/10
2310.12289v1,Deep Incremental Learning of Imbalanced Data for Just-In-Time Software Defect Prediction,http://arxiv.org/abs/2310.12289v1,"This work stems from three observations on prior Just-In-Time Software DefectPrediction (JIT-SDP) models. First, prior studies treat the JIT-SDP problemsolely as a classification problem. Second, prior JIT-SDP studies do notconsider that class balancing processing may change the underlyingcharacteristics of software changeset data. Third, only a single source ofconcept drift, the class imbalance evolution is addressed in prior JIT-SDPincremental learning models.  We propose an incremental learning framework called CPI-JIT for JIT-SDP.First, in addition to a classification modeling component, the frameworkincludes a time-series forecast modeling component in order to learn temporalinterdependent relationship in the changesets. Second, the framework features apurposefully designed over-sampling balancing technique based on SMOTE andPrincipal Curves called SMOTE-PC. SMOTE-PC preserves the underlyingdistribution of software changeset data.  In this framework, we propose an incremental deep neural network model calledDeepICP. Via an evaluation using \numprojs software projects, we show that: 1)SMOTE-PC improves the model's predictive performance; 2) to some softwareprojects it can be beneficial for defect prediction to harness temporalinterdependent relationship of software changesets; and 3) principal curvessummarize the underlying distribution of changeset data and reveals a newsource of concept drift that the DeepICP model is proposed to adapt to.",Yunhua Zhao,2023/10/18,2023/10/18
2305.16680v1,Automated Summarization of Stack Overflow Posts,http://arxiv.org/abs/2305.16680v1,"Software developers often resort to Stack Overflow (SO) to fill theirprogramming needs. Given the abundance of relevant posts, navigating them andcomparing different solutions is tedious and time-consuming. Recent work hasproposed to automatically summarize SO posts to concise text to facilitate thenavigation of SO posts. However, these techniques rely only on informationretrieval methods or heuristics for text summarization, which is insufficientto handle the ambiguity and sophistication of natural language. This paperpresents a deep learning based framework called ASSORT for SO postsummarization. ASSORT includes two complementary learning methods, ASSORT_S andASSORT_{IS}, to address the lack of labeled training data for SO postsummarization. ASSORT_S is designed to directly train a novel ensemble learningmodel with BERT embeddings and domainspecific features to account for theunique characteristics of SO posts. By contrast, ASSORT_{IS} is designed toreuse pre-trained models while addressing the domain shift challenge when notraining data is present (i.e., zero-shot learning). Both ASSORT_S andASSORT_{IS} outperform six existing techniques by at least 13% and 7%respectively in terms of the F1 score. Furthermore, a human study shows thatparticipants significantly preferred summaries generated by ASSORT_S andASSORT_{IS} over the best baseline, while the preference difference betweenASSORT_S and ASSORT_{IS} was small.",Bonan Kou,2023/5/26,2023/5/26
2103.08778v1,Accessibility in Software Practice: A Practitioner's Perspective,http://arxiv.org/abs/2103.08778v1,"Being able to access software in daily life is vital for everyone, and thusaccessibility is a fundamental challenge for software development. However,given the number of accessibility issues reported by many users, e.g., in appreviews, it is not clear if accessibility is widely integrated into currentsoftware projects and how software projects address accessibility issues. Inthis paper, we report a study of the critical challenges and benefits ofincorporating accessibility into software development and design. We applied amixed qualitative and quantitative approach for gathering data from 15interviews and 365 survey respondents from 26 countries across five continentsto understand how practitioners perceive accessibility development and designin practice. We got 44 statements grouped into eight topics on accessibilityfrom practitioners' viewpoints and different software development stages. Ourstatistical analysis reveals substantial gaps between groups, e.g.,practitioners have Direct v.s. Indirect accessibility relevant work experiencewhen they reviewed the summarized statements. These gaps might hinder thequality of accessibility development and design, and we use our findings toestablish a set of guidelines to help practitioners be aware of accessibilitychallenges and benefit factors. We also propose some remedies to resolve thegaps and to highlight key future research directions.",Tingting Bi,2021/3/16,2021/3/16
1705.07331v1,"Recent Developments In DEMIRCI, The RFQ Design Software",http://arxiv.org/abs/1705.07331v1,"The RFQ design tool DEMIRCI aims to provide fast and accurate simulation of alight ion accelerating cavity and of the ion beam in it. It is a modern toolwith a graphical user interface leading to a ""point and click"" method to helpthe designer. This article summarizes the recent developments of DEMIRCIsoftware such as the addition of beam dynamics and 8-term potential coefficientcalculations. Its results are compared to other software available on themarket, to show the attained compatibility level. Finally the future prospectsare discussed.",Emre elebi,2017/5/20,2017/5/20
2309.05074v2,LiSum: Open Source Software License Summarization with Multi-Task Learning,http://arxiv.org/abs/2309.05074v2,"Open source software (OSS) licenses regulate the conditions under which userscan reuse, modify, and distribute the software legally. However, there existvarious OSS licenses in the community, written in a formal language, which aretypically long and complicated to understand. In this paper, we conducted a661-participants online survey to investigate the perspectives and practices ofdevelopers towards OSS licenses. The user study revealed an indeed need for anautomated tool to facilitate license understanding. Motivated by the user studyand the fast growth of licenses in the community, we propose the first studytowards automated license summarization. Specifically, we released the firsthigh quality text summarization dataset and designed two tasks, i.e., licensetext summarization (LTS), aiming at generating a relatively short summary foran arbitrary license, and license term classification (LTC), focusing on theattitude inference towards a predefined set of key license terms (e.g.,Distribute). Aiming at the two tasks, we present LiSum, a multi-task learningmethod to help developers overcome the obstacles of understanding OSS licenses.Comprehensive experiments demonstrated that the proposed jointly trainingobjective boosted the performance on both tasks, surpassing state-of-the-artbaselines with gains of at least 5 points w.r.t. F1 scores of foursummarization metrics and achieving 95.13% micro average F1 score forclassification simultaneously. We released all the datasets, the replicationpackage, and the questionnaires for the community.",Linyu Li,2023/9/10,2023/9/22
1309.1796v1,VisIt: Experiences with Sustainable Software,http://arxiv.org/abs/1309.1796v1,"The success of the VisIt visualization system has been wholly dependent uponthe culture and practices of software development that have fostered itswelcome by users and embrace by developers and researchers. In the followingpaper, we, the founding developers and designers of VisIt, summarize some ofthe major efforts, both successful and unsuccessful, that we have undertaken inthe last thirteen years to foster community, encourage research, create asustainable open-source development model, measure impact, and supportproduction software. We also provide commentary about the career paths that ourdevelopment work has engendered.",Sean Ahern,2013/9/7,2013/9/7
1810.02765v1,Autonomous agile teams: Challenges and future directions for research,http://arxiv.org/abs/1810.02765v1,"According to the principles articulated in the agile manifesto, motivated andempowered software developers relying on technical excellence and simpledesigns, create business value by delivering working software to users atregular short intervals. These principles have spawned many practices. At thecore of these practices is the idea of autonomous, self-managing, orself-organizing teams whose members work at a pace that sustains theircreativity and productivity. This article summarizes the main challenges facedwhen implementing autonomous teams and the topics and research questions thatfuture research should address.",Viktoria Stray,2018/10/5,2018/10/5
1911.10457v1,Architecture Models Refinements for Software Development of Critical Real-time Embedded Systems,http://arxiv.org/abs/1911.10457v1,"Cyber Physical Systems are systems controlled or monitored by computer-basedprograms, tightly integrated networks, sensors, and actuators. Softwaredevelopment of CPS has become so difficult that it represents most of the costof CPS production. In addition, it is interesting to note that the integration,verification and validation of software in CPS require more efforts than theanalysis, design, and implementation activities. The main reason is that theseactivities are conducted late in the development process and issues discoveredat this stage of the process will require to rework artifacts produced in theprevious activities (i.e. analysis, design and/or implementation). In thisdocument, we present our work aiming to improve the reliability of softwaredevelopment in the domain of CPS. In this context, we define the reliability ofthe development process as its capacity to deliver intermediate artifacts forwhich the rework effort would be as small as possible. This problem is verydifficult for general purpose software (i.e. used on desktop computers orservers), and even more difficult for software in CPS. The main reason is thatsoftware in CPS is often critical, real-time and embedded on domain specificexecution platforms. As a consequence, non-functional properties (also calledquality attributes) of software applications in CPS are often as important anddifficult to satisfy as the logical correctness of these applications. In orderto the improve the reliability of software development in the domain of CPS, wepropose a Model Driven Engineering (MDE) method based on step-wise refinementsof software architecture descriptions. The results obtained with this methodare summarized in this habilitation thesis.",Etienne Borde,2019/11/24,2019/11/24
2307.11305v1,Quantum Software Analytics: Opportunities and Challenges,http://arxiv.org/abs/2307.11305v1,"Quantum computing systems depend on the principles of quantum mechanics toperform multiple challenging tasks more efficiently than their classicalcounterparts. In classical software engineering, the software life cycle isused to document and structure the processes of design, implementation, andmaintenance of software applications. It helps stakeholders understand how tobuild an application. In this paper, we summarize a set of software analyticstopics and techniques in the development life cycle that can be leveraged andintegrated into quantum software application development. The results of thiswork can assist researchers and practitioners in better understanding thequantum-specific emerging development activities, challenges, and opportunitiesin the next generation of quantum software.",Thong Hoang,2023/7/21,2023/7/21
2103.11561v1,ConfInLog: Leveraging Software Logs to Infer Configuration Constraints,http://arxiv.org/abs/2103.11561v1,"Misconfigurations have become the dominant causes of software failures inrecent years, drawing tremendous attention for their increasing prevalence andseverity. Configuration constraints can preemptively avoid misconfiguration bydefining the conditions that configuration options should satisfy.Documentation is the main source of configuration constraints, but it might beincomplete or inconsistent with the source code. In this regard, priorresearches have focused on obtaining configuration constraints from softwaresource code through static analysis. However, the difficulty in pointeranalysis and context comprehension prevents them from collecting accurate andcomprehensive constraints. In this paper, we observed that software logs oftencontain configuration constraints. We conducted an empirical study andsummarized patterns of configuration-related log messages. Guided by the study,we designed and implemented ConfInLog, a static tool to infer configurationconstraints from log messages. ConfInLog first selects configuration-relatedlog messages from source code by using the summarized patterns, then infersconstraints from log messages based on the summarized natural languagepatterns. To evaluate the effectiveness of ConfInLog, we applied our tool onseven popular open-source software systems. ConfInLog successfully inferred 22to 163 constraints, in which 59.5% to 61.6% could not be inferred by thestate-of-the-art work. Finally, we submitted 67 documentation patches regardingthe constraints inferred by ConfInLog. The constraints in 29 patches have beenconfirmed by the developers, among which 10 patches have been accepted.",Shulin Zhou,2021/3/22,2021/3/22
2103.11599v1,Project-Level Encoding for Neural Source Code Summarization of Subroutines,http://arxiv.org/abs/2103.11599v1,"Source code summarization of a subroutine is the task of writing a short,natural language description of that subroutine. The description usually servesin documentation aimed at programmers, where even brief phrase (e.g.""compresses data to a zip file"") can help readers rapidly comprehend what asubroutine does without resorting to reading the code itself. Techniques basedon neural networks (and encoder-decoder model designs in particular) haveestablished themselves as the state-of-the-art. Yet a problem widely recognizedwith these models is that they assume the information needed to create asummary is present within the code being summarized itself - an assumptionwhich is at odds with program comprehension literature. Thus a current researchfrontier lies in the question of encoding source code context into neuralmodels of summarization. In this paper, we present a project-level encoder toimprove models of code summarization. By project-level, we mean that we createa vectorized representation of selected code files in a software project, anduse that representation to augment the encoder of state-of-the-art neural codesummarization techniques. We demonstrate how our encoder improves severalexisting models, and provide guidelines for maximizing improvement whilecontrolling time and resource costs in model size.",Aakash Bansal,2021/3/22,2021/3/22
1404.3785v1,Reducing the Barrier to Entry of Complex Robotic Software: a MoveIt! Case Study,http://arxiv.org/abs/1404.3785v1,"Developing robot agnostic software frameworks involves synthesizing thedisparate fields of robotic theory and software engineering whilesimultaneously accounting for a large variability in hardware designs andcontrol paradigms. As the capabilities of robotic software frameworks increase,the setup difficulty and learning curve for new users also increase. If theentry barriers for configuring and using the software on robots is too high,even the most powerful of frameworks are useless. A growing need exists inrobotic software engineering to aid users in getting started with, andcustomizing, the software framework as necessary for particular roboticapplications. In this paper a case study is presented for the best practicesfound for lowering the barrier of entry in the MoveIt! framework, anopen-source tool for mobile manipulation in ROS, that allows users to 1)quickly get basic motion planning functionality with minimal initial setup, 2)automate its configuration and optimization, and 3) easily customize itscomponents. A graphical interface that assists the user in configuring MoveIt!is the cornerstone of our approach, coupled with the use of an existingstandardized robot model for input, automatically generated robot-specificconfiguration files, and a plugin-based architecture for extensibility. Thesebest practices are summarized into a set of barrier to entry design principlesapplicable to other robotic software. The approaches for lowering the entrybarrier are evaluated by usage statistics, a user survey, and compared againstour design objectives for their effectiveness to users.",David Coleman,2014/4/15,2014/4/15
1602.02296v1,Report on the Third Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE3),http://arxiv.org/abs/1602.02296v1,"This report records and discusses the Third Workshop on Sustainable Softwarefor Science: Practice and Experiences (WSSSPE3). The report includes adescription of the keynote presentation of the workshop, which served as anoverview of sustainable scientific software. It also summarizes a set oflightning talks in which speakers highlighted to-the-point lessons andchallenges pertaining to sustaining scientific software. The final and maincontribution of the report is a summary of the discussions, future steps, andfuture organization for a set of self-organized working groups on topicsincluding developing pathways to funding scientific software; constructinguseful common metrics for crediting software stakeholders; identifyingprinciples for sustainable software engineering design; reaching out toresearch software organizations around the world; and building communities forsoftware sustainability. For each group, we include a point of contact and alanding page that can be used by those who want to join that group's futureactivities. The main challenge left by the workshop is to see if the groupswill execute these activities that they have scheduled, and how the WSSSPEcommunity can encourage this to happen.",Daniel S. Katz,2016/2/6,2016/2/6
1511.00914v2,DEMIRCI: An RFQ Design Software,http://arxiv.org/abs/1511.00914v2,"The development and production of radio frequency quadrupoles, which are usedfor accelerating low-energy ions to high energies, continues since 1970s. Thedevelopment of RFQ design software packages, which can provide ease of use witha graphical interface, can visualize the behavior of the ion beam inside theRFQ, and can run on both Unix and Windows platforms, has become inevitable dueto increasing interest around the world. In this context, a new RFQ designsoftware package, DEMIRCI, has been under development. To meet the userexpectations, a number of new features have been recently added to DEMIRCI.Apart from being usable via both graphical interface and command line, DEMIRCIhas been enriched with beam dynamics calculations. This new module gives usersthe possibility to define and track an input beam and to monitor its behavioralong the RFQ. Additionally, the Windows OS has been added to the list ofsupported platforms. Finally, the addition of more realistic 8 term potentialresults has been ongoing. This note will summarize the latest developments andresults from DEMIRCI RFQ design software.",B. Yasatekin,2015/11/3,2016/3/21
2202.09785v1,DualSC: Automatic Generation and Summarization of Shellcode via Transformer and Dual Learning,http://arxiv.org/abs/2202.09785v1,"A shellcode is a small piece of code and it is executed to exploit a softwarevulnerability, which allows the target computer to execute arbitrary commandsfrom the attacker through a code injection attack. Similar to the purpose ofautomated vulnerability generation techniques, the automated generation ofshellcode can generate attack instructions, which can be used to detectvulnerabilities and implement defensive measures. While the automatedsummarization of shellcode can help users unfamiliar with shellcode and networkinformation security understand the intent of shellcode attacks. In this study,we propose a novel approach DualSC to solve the automatic shellcode generationand summarization tasks. Specifically, we formalize automatic shellcodegeneration and summarization as dual tasks, use a shallow Transformer for modelconstruction, and design a normalization method Adjust QKNorm to adapt theselow-resource tasks (i.e., insufficient training data). Finally, to alleviatethe out-of-vocabulary problem, we propose a rulebased repair component toimprove the performance of automatic shellcode generation. In our empiricalstudy, we select a highquality corpus Shellcode IA32 as our empirical subject.This corpus was gathered from two real-world projects based on the line-by-linegranularity. We first compare DualSC with six state-of-the-art baselines fromthe code generation and code summarization domains in terms of four performancemeasures. The comparison results show the competitiveness of DualSC. Then, weverify the effectiveness of the component setting in DualSC. Finally, weconduct a human study to further verify the effectiveness of DualSC.",Guang Yang,2022/2/20,2022/2/20
0710.4755v1,Model Reuse through Hardware Design Patterns,http://arxiv.org/abs/0710.4755v1,"Increasing reuse opportunities is a well-known problem for software designersas well as for hardware designers. Nonetheless, current software and hardwareengineering practices have embraced different approaches to this problem.Software designs are usually modelled after a set of proven solutions torecurrent problems called design patterns. This approach differs from thecomponent-based reuse usually found in hardware designs: design patterns do notspecify unnecessary implementation details. Several authors have alreadyproposed translating structural design patterns concepts to hardware design. Inthis paper we extend the discussion to behavioural design patterns.Specifically, we describe how the hardware version of the Iterator can be usedto enhance model reuse.",Fernando Rincon,2007/10/25,2007/10/25
1801.06059v1,Tamil Open-Source Landscape - Opportunities and Challenges,http://arxiv.org/abs/1801.06059v1,"We report in this paper, Tamil open-source software community is a vibrantplace with software developers, font designers, translators, voice-overartists, and general user testers, who come together for love of theirlanguage, and promotion of critical thinking, and modern language usage inTamil. We identify a need for institutional support at various stages fromgrooming software developers in Tamil, to marketing platform for Tamilsoftware. There is bright future for tamil software if we will meet challengesit brings with it.",Muthiah Annamalai,2018/1/16,2018/1/16
2304.02301v1,MUFIN: Improving Neural Repair Models with Back-Translation,http://arxiv.org/abs/2304.02301v1,"Automated program repair is the task of automatically repairing softwarebugs. A promising direction in this field is self-supervised learning, alearning paradigm in which repair models are trained without commitsrepresenting pairs of bug/fix. In self-supervised neural program repair, thosebug/fix pairs are generated in some ways. The main problem is to generateinteresting and diverse pairs that maximize the effectiveness of training. As acontribution to this problem, we propose to use back-translation, a techniquecoming from neural machine translation. We devise and implement MUFIN, aback-translation training technique for program repair, with specificallydesigned code critics to select high-quality training samples. Our results showthat MUFIN's back-translation loop generates valuable training samples in afully automated, self-supervised manner, generating more than half-a-millionpairs of bug/fix. The code critic design is key because of a fundamentaltrade-off between how restrictive a critic is and how many samples areavailable for optimization during back-translation.",Andr Silva,2023/4/5,2023/4/5
2103.01088v1,Code smells: A Synthetic Narrative Review,http://arxiv.org/abs/2103.01088v1,"Code smells are symptoms of poor design and implementation choices, whichmight hinder comprehension, increase code complexity and fault-proneness anddecrease maintainability of software systems. The aim of our study was toperform a triangulation of bibliometric and thematic analysis on code smellliterature production. The search was performed on Scopus (Elsevier,Netherlands) database using the search string code smells which resulted in 442publications. The Go-to statement was the first bad code smells identified insoftware engineering history in 1968. The literature production trend has beenpositive. The most productive countries were the United States, Italy andBrazil. Eight research themes were identified: Managing software maintenance,Smell detection-based software refactoring, Architectural smells, Improvingsoftware quality with multi-objective approaches, Technical debt and itsinstance, Quality improvement/assurance with mining software repositories,Programming education, Integrating the concepts of anti-pattern, design defectsand design smells. Some research gaps also emerged, namely, New uncataloguedsmell identification; Smell propagation from architectural, design, code totest, and other possible smells; and Identification of good smells. The resultsof our study can help code smell researchers and practitioners understand thebroader aspects of code smells research and its translation to practice.",Peter Kokol,2021/3/1,2021/3/1
cs/0011017v1,Automatic Debugging Support for UML Designs,http://arxiv.org/abs/cs/0011017v1,"Design of large software systems requires rigorous application of softwareengineering methods covering all phases of the software process. Debuggingduring the early design phases is extremely important, because late bug-fixesare expensive.  In this paper, we describe an approach which facilitates debugging of UMLrequirements and designs. The Unified Modeling Language (UML) is a set ofnotations for object-orient design of a software system. We have developed analgorithm which translates requirement specifications in the form of annotatedsequence diagrams into structured statecharts. This algorithm detects conflictsbetween sequence diagrams and inconsistencies in the domain knowledge. Aftersynthesizing statecharts from sequence diagrams, these statecharts usually aresubject to manual modification and refinement. By using the ``backward''direction of our synthesis algorithm, we are able to map modifications made tothe statechart back into the requirements (sequence diagrams) and check forconflicts there. Fed back to the user conflicts detected by our algorithm arethe basis for deductive-based debugging of requirements and domain theory invery early development stages. Our approach allows to generate explanations onwhy there is a conflict and which parts of the specifications are affected.",Johann Schumann,2000/11/13,2000/11/13
2012.01815v2,SemMT: A Semantic-based Testing Approach for Machine Translation Systems,http://arxiv.org/abs/2012.01815v2,"Machine translation has wide applications in daily life. In mission-criticalapplications such as translating official documents, incorrect translation canhave unpleasant or sometimes catastrophic consequences. This motivates recentresearch on testing methodologies for machine translation systems. Existingmethodologies mostly rely on metamorphic relations designed at the textuallevel (e.g., Levenshtein distance) or syntactic level (e.g., the distancebetween grammar structures) to determine the correctness of translationresults. However, these metamorphic relations do not consider whether theoriginal and translated sentences have the same meaning (i.e., Semanticsimilarity). Therefore, in this paper, we propose SemMT, an automatic testingapproach for machine translation systems based on semantic similarity checking.SemMT applies round-trip translation and measures the semantic similaritybetween the original and translated sentences. Our insight is that thesemantics expressed by the logic and numeric constraint in sentences can becaptured using regular expressions (or deterministic finite automata) whereefficient equivalence/similarity checking algorithms are available. Leveragingthe insight, we propose three semantic similarity metrics and implement them inSemMT. The experiment result reveals SemMT can achieve higher effectivenesscompared with state-of-the-art works, achieving an increase of 21% and 23% onaccuracy and F-Score, respectively. We also explore potential improvements thatcan be achieved when proper combinations of metrics are adopted. Finally, wediscuss a solution to locate the suspicious trip in round-trip translation,which may shed lights on further exploration.",Jialun Cao,2020/12/3,2021/10/9
1502.02202v2,Comparison of Strong Gravitational Lens Model Software II. HydraLens: Computer-Assisted Strong Gravitational Lens Model Generation and Translation,http://arxiv.org/abs/1502.02202v2,"The behavior of strong gravitational lens model software in the analysis oflens models is not necessarily consistent among the various software available,suggesting that the use of several models may enhance the understanding of thesystem being studied. Among the publicly available codes, the model input filesare heterogeneous, making the creation of multiple models tedious. An enhancedmethod of creating model files and a method to easily create multiple models,may increase the number of comparison studies. HydraLens simplifies thecreation of model files for four strong gravitational lens model softwarepackages, including Lenstool, Gravlens/Lensmodel, glafic and PixeLens, using acustom designed GUI for each of the four codes that simplifies the entry of themodel for each of these codes, obviating the need for user manuals to set thevalues of the many flags and in each data field. HydraLens is designed in amodular fashion, which simplifies the addition of other strong gravitationallens codes in the future. HydraLens can also translate a model generated forany of these four software packages into any of the other three. Models createdusing HydraLens may require slight modifications, since some information may belost in the translation process. However the computer generated model greatlysimplifies the process of developing multiple lens models. HydraLens mayenhance the number of direct software comparison studies, and also assist inthe education of young investigators in gravitational lens modeling. Futuredevelopment of HydraLens will further enhance its capabilities.",Alan T. Lefor,2015/2/8,2015/2/12
1004.3250v1,Watermarking Java Programs using Dummy Methods with Dynamically Opaque Predicates,http://arxiv.org/abs/1004.3250v1,"Software piracy, the illegal using, copying, and resale of applications is amajor concern for anyone develops software. Software developers also worryabout their applications being reverse engineered by extracting data structuresand algorithms from an application and incorporated into competitor's code. Adefense against software piracy is watermarking, a process that embeds a secretmessage in a cover software. Watermarking is a method that does not aim to stoppiracy copying, but to prove ownership of the software and possibly even thedata structures and algorithms used in the software. The language Java wasdesigned to be compiled into a platform independent bytecode format. Much ofthe information contained in the source code remains in the bytecode, whichmeans that decompilation is easier than with traditional native codes. In thisthesis, we present a technique for watermarking Java programs by using anever-executed dummy method (Monden et.al., 2000) combined with opaquepredicates (Collberg et.al., 1998; Arboit, 2002) and improved with dynamicallyopaque predicates (Palsberg et.al., 2000). This work presents a method toconstruct a dynamic opaque predicates by grouping two or more opaque predicatesaccording to predefined rules. Any software watermarking technique will exhibita trade-off between resilience, data rate, cost, and stealth. To evaluate thequality of a watermarking scheme we must also know how well it stands up todifferent types of attacks. Ideally, we would like our watermarks to survivetranslation (compilation, decompilation, and binary translation), optimization,and obfuscation. Add a single watermark will increasing source code approximate3.854 bytes with dummy method that cover up to 15 characters, two dynamic datastructures, two threads and two opaque predicates. Application loading-timeincrease approximate 6108 milliseconds.",Zaenal Akbar,2010/4/19,2010/4/19
1510.04873v2,Translating Hierarchical Block Diagrams into Composite Predicate Transformers,http://arxiv.org/abs/1510.04873v2,"Simulink is the de facto industrial standard for designing embedded controlsystems. When dealing with the formal verification of Simulink models, we facethe problem of translating the graphical language of Simulink, namely,hierarchical block diagrams (HBDs), into a formalism suitable for verification.In this paper, we study the translation of HBDs into the compositionalrefinement calculus framework for reactive systems. Specifically, we consideras target language an algebra of atomic predicate transformers to capture basicSimulink blocks (both stateless and stateful), composed in series, in parallel,and in feedback. For a given HBD, there are many possible ways to translate itinto a term in this algebra, with different tradeoffs. We explore thesetradeoffs, and present three translation algorithms. We report on a prototypeimplementation of these algorithms in a tool that translates Simulink modelsinto algebra terms implemented in the Isabelle theorem prover. We test our toolon several case studies including a benchmark Simulink model by Toyota. Wecompare the three translation algorithms, with respect to size and readabilityof generated terms, simplifiability of the corresponding formulas, and othermetrics.",Iulia Dragomir,2015/10/16,2015/10/20
1602.02004v1,Code Generation for Event-B,http://arxiv.org/abs/1602.02004v1,"Stepwise refinement and Design-by-Contract are two formal approaches formodelling systems. These approaches are widely used in the development ofsystems. Both approaches have (dis-)advantages. This thesis aims to answer, isit possible to combine both approaches in the development of systems, providingthe user with the benefits of both? We answer this question by translating thestepwise refinement method with Event-B to Design-by-Contract with Java andJML, so users can take full advantage of both formal approaches without losingtheir benefits. This thesis presents a set of syntactic rules that translatesEvent-B to JML-annotated Java code. It also presents the implementation of thesyntactic rules as the EventB2Java tool. We used the tool to translate severalEvent-B models. It generated JML-annotated Java code for all the consideredmodels that serve as initial implementation. We also used EventB2Java for thedevelopment of two software applications. Additionally, we compared EventB2Javaagainst two other tools for Event-B code generation. EventB2Java enables usersto start the software development process in Event-B, where users can model thesystem and prove its consistency, to then transition to JML-annotated Javacode, where users can continue the development process.",Victor Rivera,2016/2/5,2016/2/5
2008.13240v1,Employing Simulation to Facilitate the Design of Dynamic Code Generators,http://arxiv.org/abs/2008.13240v1,"Dynamic Translation (DT) is a sophisticated technique that allows theimplementation of high-performance emulators and high-level-language virtualmachines. In this technique, the guest code is compiled dynamically at runtime.Consequently, achieving good performance depends on several design decisions,including the shape of the regions of code being translated. Researchers andengineers explore these decisions to bring the best performance possible.However, a real DT engine is a very sophisticated piece of software, andmodifying one is a hard and demanding task. Hence, we propose using simulationto evaluate the impact of design decisions on dynamic translators and presentRAIn, an open-source DT simulator that facilitates the test of DT's designdecisions, such as Region Formation Techniques (RFTs). RAIn outputs severalstatistics that support the analysis of how design decisions may affect thebehavior and the performance of a real DT. We validated RAIn running a set ofexperiments with six well known RFTs (NET, MRET2, LEI, NETPlus, NET-R, andNETPlus-e-r) and showed that it can reproduce well-known results from theliterature without the effort of implementing them on a real and complexdynamic translator engine.",Vanderson Martins do Rosario,2020/8/30,2020/8/30
2304.12781v1,SAPHIR: A Pluricultural Authoring Tool to Produce Resources in Support of Education for Sustainable Development,http://arxiv.org/abs/2304.12781v1,"In this paper, we present SAPHIR, a multilingual authoring tool producing aProgressive Web App, usable on computers, tablets, and smartphones, online oroffline. We presented our design process, the architecture of the system, themodel on which it is based, and its main parts: SAPHIR it-self is the mainsoftware proposing activities to children to learn and play; MINE is theauthoring tool used by pedagogical designers and resources translators tocreate and translate resources without requiring any programming skills; TAILLEis dedicated to teachers to whom he provides educational explanations to useSAPHIR with their learners. The different parts were used with both pedagogicaldesigners and students.",Stphanie Jean-Daubias,2023/4/25,2023/4/25
2202.08029v1,Code Search based on Context-aware Code Translation,http://arxiv.org/abs/2202.08029v1,"Code search is a widely used technique by developers during softwaredevelopment. It provides semantically similar implementations from a large codecorpus to developers based on their queries. Existing techniques leverage deeplearning models to construct embedding representations for code snippets andqueries, respectively. Features such as abstract syntactic trees, control flowgraphs, etc., are commonly employed for representing the semantics of codesnippets. However, the same structure of these features does not necessarilydenote the same semantics of code snippets, and vice versa. In addition, thesetechniques utilize multiple different word mapping functions that map querywords/code tokens to embedding representations. This causes diverged embeddingsof the same word/token in queries and code snippets. We propose a novelcontext-aware code translation technique that translates code snippets intonatural language descriptions (called translations). The code translation isconducted on machine instructions, where the context information is collectedby simulating the execution of instructions. We further design a shared wordmapping function using one single vocabulary for generating embeddings for bothtranslations and queries. We evaluate the effectiveness of our technique,called TranCS, on the CodeSearchNet corpus with 1,000 queries. Experimentalresults show that TranCS significantly outperforms state-of-the-art techniquesby 49.31% to 66.50% in terms of MRR (mean reciprocal rank).",Weisong Sun,2022/2/16,2022/2/16
1603.02130v2,From Design Contracts to Component Requirements Verification,http://arxiv.org/abs/1603.02130v2,"During the development and verification of complex airborne systems, avariety of languages and development environments are used for different levelsof the system hierarchy. As a result, there may be manual steps to translaterequirements between these different environments. This paper presents atool-supported export technique that translates high-level requirements fromthe software architecture modeling environment into observers of requirementsthat can be used for verification in the software component environment. Thisallows efficient verification that the component designs comply with theirhigh-level requirements. It also provides an automated tool chain supportingformal verification from system requirements down to low-level softwarerequirements that is consistent with certification guidance for avionicssystems. The effectiveness of the technique has been evaluated and demonstratedon a medical infusion pump and an aircraft wheel braking system.",Jing Liu,2016/3/7,2016/4/22
2008.00544v1,Video Question Answering on Screencast Tutorials,http://arxiv.org/abs/2008.00544v1,"This paper presents a new video question answering task on screencasttutorials. We introduce a dataset including question, answer and contexttriples from the tutorial videos for a software. Unlike other video questionanswering works, all the answers in our dataset are grounded to the domainknowledge base. An one-shot recognition algorithm is designed to extract thevisual cues, which helps enhance the performance of video question answering.We also propose several baseline neural network architectures based on variousaspects of video contexts from the dataset. The experimental resultsdemonstrate that our proposed models significantly improve the questionanswering performances by incorporating multi-modal contexts and domainknowledge.",Wentian Zhao,2020/8/2,2020/8/2
1409.1879v1,Bio-inspired Mechanism and Model Exploration of Software Aging,http://arxiv.org/abs/1409.1879v1,"Software systems situated in network environment may experience performancedegradation, availability decrease and even crash during long time running,which is called software aging. This phenomenon has been studied for more than15 years, but most of the literatures studied software as a black box, none ofthem uncovered the fundamental and widely accepted mechanism of software agingas far as we know. Through analyzing the characteristics between biologicalaging and software aging, we find some interesting common points and bridge thegap between these two seemingly unrelated phenomena. The free radical agingtheory in biological studies is also applicative to explore the mechanism andmodel of software aging. This paper finds an equivalent concept named `softwarefree radical' in software aging to free radical in biological aging. In ourstudy, the accumulation of `software free radical' is a root cause of softwareaging. Using the free radical modeling methodology in biological aging, we givea model for describing the kinetic of software aging based on feedback loops.Although this paper doesn't give enough theoretical proof of the modelingmethod, the practical results show that the feedback loop model can describethe kinetic of software aging precisely. To further validate the agingmechanism, we propose several software rejuvenation strategies focusing oncleaning the `software free radical'. The results show that software aging canbe mitigated effectively by strengthening negative feedback loop or weakeningpositive feedback loop. This paper is the first try to answer the question `Howsoftware ages' through interdisciplinary studies. Leveraging the conclusions inthis paper, people can design better software systems or keep their systems ata high performance level during long time running.",Pengfei Chen,2014/8/27,2014/8/27
2106.08115v1,Archify: A Recommender System of Architectural Design Decisions,http://arxiv.org/abs/2106.08115v1,"Software architectures play a critical role in software quality assurance.However, small and medium companies (SMC) often suffer from the absence ofprofessionals with skills and expertise in software architecture. Thatsituation potentially affects the final quality of the software products andpressures projects budget with extra costs with consulting. This paper presentsa recommender system of architectural design decisions called Archify. The goalis to support SMC companies in part of the effort of architecturally designingtheir products. Archify implements a wizard-styled interface that guides thedeveloper or project manager through a set of specific questions. While theuser answers these questions, Archify buffers a set of correspondingarchitectural decision recommendations. As the final result, the systemrecommends a set of architectural decisions matching the project's needsaccording to the requirements (as provided by the user) of the software underdevelopment. Nineteen professionals from academia and industry evaluatedArchify through two surveys. The findings reveal that 94.7% of the participantsapproved Archify as a supporting tool. Respondents also highlighted the lack oftools supporting software architecture design, remarking the relevance of theproposed system.",Breno Cruvinel Marinho,2021/6/15,2021/6/15
2209.02951v1,Democratizing Domain-Specific Computing,http://arxiv.org/abs/2209.02951v1,"In the past few years, domain-specific accelerators (DSAs), such as Google'sTensor Processing Units, have shown to offer significant performance and energyefficiency over general-purpose CPUs. An important question is whether typicalsoftware developers can design and implement their own customized DSAs, withaffordability and efficiency, to accelerate their applications. This articlepresents our answer to this question.",Yuze Chi,2022/9/7,2022/9/7
2210.01778v1,Semantics-based Privacy by Design for Internet of Things Applications,http://arxiv.org/abs/2210.01778v1,"As Internet of Things (IoT) technologies become more widespread in everydaylife, privacy issues are becoming more prominent. The aim of this research isto develop a personal assistant that can answer software engineers' questionsabout Privacy by Design (PbD) practices during the design phase of IoT systemdevelopment. Semantic web technologies are used to model the knowledgeunderlying PbD measurements, their intersections with privacy patterns, IoTsystem requirements and the privacy patterns that should be applied across IoTsystems. This is achieved through the development of the PARROT ontology,developed through a set of representative IoT use cases relevant for softwaredevelopers. This was supported by gathering Competency Questions (CQs) througha series of workshops, resulting in 81 curated CQs. These CQs were thenrecorded as SPARQL queries, and the developed ontology was evaluated using theCommon Pitfalls model with the help of the Prot\'eg\'e HermiT Reasoner and theOntology Pitfall Scanner (OOPS!), as well as evaluation by external experts.The ontology was assessed within a user study that identified that the PARROTontology can answer up to 58\% of privacy-related questions from softwareengineers.",Lamya Alkhariji,2022/10/4,2022/10/4
2201.12879v1,Making Secure Software Insecure without Changing Its Code: The Possibilities and Impacts of Attacks on the DevOps Pipeline,http://arxiv.org/abs/2201.12879v1,"Companies are misled into thinking they solve their security issues by usinga DevSecOps system. This paper aims to answer the question: Could a DevOpspipeline be misused to transform a securely developed application into aninsecure one? To answer the question, we designed a typical DevOps pipelineutilizing Kubernetes (K8s} as a case study environment and analyzed theapplicable threats. Then, we developed four attack scenarios against the casestudy environment: maliciously abusing the user's privilege of deployingcontainers within the K8s cluster, abusing the Jenkins instance to modify filesduring the continuous integration, delivery, and deployment systems (CI/CD)build phase, modifying the K8s DNS layer to expose an internal IP to externaltraffic, and elevating privileges from an account with create, read, update,and delete (CRUD) privileges to root privileges. The attacks answer theresearch question positively: companies should design and use a secure DevOpspipeline and not expect that using a DevSecOps environment alone is sufficientto deliver secure software.",Nicholas Pecka,2022/1/30,2022/1/30
1707.03904v2,Quasar: Datasets for Question Answering by Search and Reading,http://arxiv.org/abs/1707.03904v2,"We present two new large-scale datasets aimed at evaluating systems designedto comprehend a natural language query and extract its answer from a largecorpus of text. The Quasar-S dataset consists of 37000 cloze-style(fill-in-the-gap) queries constructed from definitions of software entity tagson the popular website Stack Overflow. The posts and comments on the websiteserve as the background corpus for answering the cloze questions. The Quasar-Tdataset consists of 43000 open-domain trivia questions and their answersobtained from various internet sources. ClueWeb09 serves as the backgroundcorpus for extracting these answers. We pose these datasets as a challenge fortwo related subtasks of factoid Question Answering: (1) searching for relevantpieces of text that include the correct answer to a query, and (2) reading theretrieved text to answer the query. We also describe a retrieval system forextracting relevant sentences and documents from the corpus given a query, andinclude these in the release for researchers wishing to only focus on (2). Weevaluate several baselines on both datasets, ranging from simple heuristics topowerful neural models, and show that these lag behind human performance by16.4% and 32.1% for Quasar-S and -T respectively. The datasets are available athttps://github.com/bdhingra/quasar .",Bhuwan Dhingra,2017/7/12,2017/8/9
1704.04798v1,Uncovering Architectural Design Decisions,http://arxiv.org/abs/1704.04798v1,"Over the past three decades, considerable effort has been devoted to thestudy of software architecture. A major portion of this effort has focused onthe originally proposed view of four ""C""s---components, connectors,configurations, and constraints---that are the building blocks of a system'sarchitecture. Despite being simple and appealing, this view has proven to beincomplete and has required further elaboration. To that end, researchers havemore recently tried to approach architectures from another importantperspective---that of design decisions that yield a system's architecture.These more recent efforts have lacked a precise understanding of several keyquestions, however: (1) What is an architectural design decision (definition)?(2) How can architectural design decisions be found in existing systems(identification)? (3) What system decisions are and are not architectural(classification)? (4) How are architectural design decisions manifested in thecode (reification)? (5) How can important architectural decisions be preservedand/or changed as desired (evolution)? This paper presents a technique targetedat answering these questions by analyzing information that is readily availableabout software systems. We applied our technique on over 100 different versionsof two widely adopted open- source systems, and found that it can accuratelyuncover the architectural design decisions embodied in the systems.",Arman Shahbazian,2017/4/16,2017/4/16
2210.02400v1,Emotion Twenty Questions Dialog System for Lexical Emotional Intelligence,http://arxiv.org/abs/2210.02400v1,"This paper presents a web-based demonstration of Emotion Twenty Questions(EMO20Q), a dialog game whose purpose is to study how people describe emotions.EMO20Q can also be used to develop artificially intelligent dialog agents thatcan play the game. In previous work, an EMO20Q agent used a sequential Bayesianmachine learning model and could play the question-asking role. Newertransformer-based neural machine learning models have made it possible todevelop an agent for the question-answering role.  This demo paper describes the recent developments in the question-answeringrole of the EMO20Q game, which requires the agent to respond to more open-endedinputs. Furthermore, we also describe the design of the system, including theweb-based front-end, agent architecture and programming, and updates to earliersoftware used.  The demo system will be available to collect pilot data during the ACIIconference and this data will be used to inform future experiments and systemdesign.",Abe Kazemzadeh,2022/10/5,2022/10/5
2204.00879v1,Co-VQA : Answering by Interactive Sub Question Sequence,http://arxiv.org/abs/2204.00879v1,"Most existing approaches to Visual Question Answering (VQA) answer questionsdirectly, however, people usually decompose a complex question into a sequenceof simple sub questions and finally obtain the answer to the original questionafter answering the sub question sequence(SQS). By simulating the process, thispaper proposes a conversation-based VQA (Co-VQA) framework, which consists ofthree components: Questioner, Oracle, and Answerer. Questioner raises the subquestions using an extending HRED model, and Oracle answers them one-by-one. AnAdaptive Chain Visual Reasoning Model (ACVRM) for Answerer is also proposed,where the question-answer pair is used to update the visual representationsequentially. To perform supervised learning for each model, we introduce awell-designed method to build a SQS for each question on VQA 2.0 and VQA-CP v2datasets. Experimental results show that our method achieves state-of-the-arton VQA-CP v2. Further analyses show that SQSs help build direct semanticconnections between questions and images, provide question-adaptivevariable-length reasoning chains, and with explicit interpretability as well aserror traceability.",Ruonan Wang,2022/4/2,2022/4/2
1812.05164v1,Computer Games Are Serious Business and so is their Quality: Particularities of Software Testing in Game Development from the Perspective of Practitioners,http://arxiv.org/abs/1812.05164v1,"Over the last several decades, computer games started to have a significantimpact on society. However, although a computer game is a type of software, theprocess to conceptualize, produce and deliver a game could involve unusualfeatures. In software testing, for instance, studies demonstrated the hesitanceof professionals to use automated testing techniques with games, due to theconstant changes in requirements and design, and pointed out the need forcreating testing tools that take into account the flexibility required for thegame development process. Goal. This study aims to improve the current body ofknowledge regarding software testing in game development and point out theexisting particularities observed in software testing considering thedevelopment of a computer game. Method. A mixed-method approach based on a casestudy and an opinion survey was applied to collect quantitative and qualitativedata from software professionals regarding the particularities of softwaretesting in game development. Results. We analyzed over 70 messages posted onthree well-established network of question-and-answer communities related tosoftware engineering, software testing and game development and receivedanswers of 38 professionals discussing differences between testing a computergame and a general software, and identified important aspects to be observed bypractitioners in the process of planning, performing and reporting tests inthis context. Conclusion. Considering computer games, software testing mustfocus not only on the common aspects of a general software, but also, track andinvestigate issues that could be related to game balance, game physics andentertainment related-aspects to guarantee the quality of computer games and asuccessful testing process.",Ronnie Santos,2018/12/12,2018/12/12
2304.10182v1,Using Text-to-Image Generation for Architectural Design Ideation,http://arxiv.org/abs/2304.10182v1,"The recent progress of text-to-image generation has been recognized inarchitectural design. Our study is the first to investigate the potential oftext-to-image generators in supporting creativity during the early stages ofthe architectural design process. We conducted a laboratory study with 17architecture students, who developed a concept for a culture center using threepopular text-to-image generators: Midjourney, Stable Diffusion, and DALL-E.Through standardized questionnaires and group interviews, we found that imagegeneration could be a meaningful part of the design process when designconstraints are carefully considered. Generative tools support serendipitousdiscovery of ideas and an imaginative mindset, enriching the design process. Weidentified several challenges of image generators and provided considerationsfor software development and educators to support creativity and emphasizedesigners' imaginative mindset. By understanding the limitations and potentialof text-to-image generators, architects and designers can leverage thistechnology in their design process and education, facilitating innovation andeffective communication of concepts.",Ville Paananen,2023/4/20,2023/4/20
1110.0070v2,"Enhance accuracy in Software cost and schedule estimation by using ""Uncertainty Analysis and Assessment"" in the system modeling process",http://arxiv.org/abs/1110.0070v2,"Accurate software cost and schedule estimation are essential for softwareproject success. Often it referred to as the ""black art"" because of itscomplexity and uncertainty, software estimation is not as difficult or puzzlingas people think. In fact, generating accurate estimates is straightforward-onceyou understand the intensity of uncertainty and framework for the modelingprocess. The mystery to successful software estimation-distilling academicinformation and real-world experience into a practical guide for workingsoftware professionals. Instead of arcane treatises and rigid modelingtechniques, this will guide highlights a proven set of procedures,understandable formulas, and heuristics that individuals and development teamscan apply to their projects to help achieve estimation proficiency with chooseappropriate development approaches In the early stage of software life cycleproject manager are inefficient to estimate the effort, schedule, costestimation and its development approach .This in turn, confuses the manager tobid effectively on software project and choose incorrect development approach.That will directly effect on productivity cycle and increase level ofuncertainty. This becomes a strong cause of project failure. So to avoid suchproblem if we know level and sources of uncertainty in model design, It willdirective the developer to design accurate software cost and scheduleestimation, which are essential for software project success. However once therequired efforts have estimated, little is done to recalibrate and reduce theuncertainty of the initial estimates.",Kardile Vilas Vasantrao,2011/10/1,2012/1/13
2310.14449v1,Qualitative analysis of the relationship between design smells and software engineering challenges,http://arxiv.org/abs/2310.14449v1,"Software design debt aims to elucidate the rectification attempts of thepresent design flaws and studies the influence of those to the cost and time ofthe software. Design smells are a key cause of incurring design debt. Althoughthe impact of design smells on design debt have been predominantly consideredin current literature, how design smells are caused due to not followingsoftware engineering best practices require more exploration. This researchprovides a tool which is used for design smell detection in Java software byanalyzing large volume of source codes. More specifically, 409,539 Lines ofCode (LoC) and 17,760 class files of open source Java software are analyzedhere. Obtained results show desirable precision values ranging from 81.01\% to93.43\%. Based on the output of the tool, a study is conducted to relate thecause of the detected design smells to two software engineering challengesnamely ""irregular team meetings"" and ""scope creep"". As a result, the gainedinformation will provide insight to the software engineers to take necessarysteps of design remediation actions.",Asif Imran,2023/10/22,2023/10/22
2308.09940v1,Evaluating Transfer Learning for Simplifying GitHub READMEs,http://arxiv.org/abs/2308.09940v1,"Software documentation captures detailed knowledge about a software product,e.g., code, technologies, and design. It plays an important role in thecoordination of development teams and in conveying ideas to variousstakeholders. However, software documentation can be hard to comprehend if itis written with jargon and complicated sentence structure. In this study, weexplored the potential of text simplification techniques in the domain ofsoftware engineering to automatically simplify GitHub README files. Wecollected software-related pairs of GitHub README files consisting of 14,588entries, aligned difficult sentences with their simplified counterparts, andtrained a Transformer-based model to automatically simplify difficult versions.To mitigate the sparse and noisy nature of the software-related simplificationdataset, we applied general text simplification knowledge to this field. Sincemany general-domain difficult-to-simple Wikipedia document pairs are alreadypublicly available, we explored the potential of transfer learning by firsttraining the model on the Wikipedia data and then fine-tuning it on the READMEdata. Using automated BLEU scores and human evaluation, we compared theperformance of different transfer learning schemes and the baseline modelswithout transfer learning. The transfer learning model using the bestcheckpoint trained on a general topic corpus achieved the best performance of34.68 BLEU score and statistically significantly higher human annotation scorescompared to the rest of the schemes and baselines. We conclude that usingtransfer learning is a promising direction to circumvent the lack of data anddrift style problem in software README files simplification and achieved abetter trade-off between simplification and preservation of meaning.",Haoyu Gao,2023/8/19,2023/8/19
2308.15179v1,Best performance and reliability for your time: budget-aware search-based optimization of software model refactoring,http://arxiv.org/abs/2308.15179v1,"Context: Software model optimization is a process that automaticallygenerates design alternatives, typically to enhance quantifiable non-functionalproperties of software systems, such as performance and reliability.Multi-objective evolutionary algorithms have shown to be effective in thiscontext for assisting the designer in identifying trade-offs between thedesired non-functional properties. Objective: In this work, we investigate theeffects of imposing a time budget to limit the search for design alternatives,which inevitably affects the quality of the resulting alternatives. Method: Theeffects of time budgets are analyzed by investigating both the quality of thegenerated design alternatives and their structural features when varying thebudget and the genetic algorithm (NSGA-II, PESA2, SPEA2). This is achieved byemploying multi-objective quality indicators and a tree-based representation ofthe search space. Results: The study reveals that the time budget significantlyaffects the quality of Pareto fronts, especially for performance andreliability. NSGA-II is the fastest algorithm, while PESA2 generates thehighest-quality solutions. The imposition of a time budget results instructurally distinct models compared to those obtained without a budget,indicating that the search process is influenced by both the budget andalgorithm selection. Conclusions: In software model optimization, imposing atime budget can be effective in saving optimization time, but designers shouldcarefully consider the trade-off between time and solution quality in thePareto front, along with the structural characteristics of the generatedmodels. By making informed choices about the specific genetic algorithm,designers can achieve different trade-offs.",J. Andres Diaz-Pace,2023/8/29,2023/8/29
cs/0612023v2,Reusing processes and documenting processes: toward an integrated framework,http://arxiv.org/abs/cs/0612023v2,"This paper presents a cognitive typology of reuse processes, and a cognitivetypology of documenting processes. Empirical studies on design with reuse andon software documenting provide evidence for a generalized cognitive model.First, these studies emphasize the cyclical nature of design: cycles ofplanning, writing and revising occur. Second, natural language documentationfollows the hierarchy of cognitive entities manipulated during design.Similarly software reuse involves exploiting various types of knowledgedepending on the phase of design in which reuse is involved. We suggest thatthese observations can be explained based on cognitive models of textprocessing: the van Dijk and Kintsch (1983) model of text comprehension, andthe Hayes and Flower (1980) model of text production. Based on our generalizedcognitive model, we suggest a framework for documenting reusable components.",Franoise Dtienne,2006/12/4,2007/3/2
1409.7165v1,Heterogeneous Metric Learning with Content-based Regularization for Software Artifact Retrieval,http://arxiv.org/abs/1409.7165v1,"The problem of software artifact retrieval has the goal to effectively locatesoftware artifacts, such as a piece of source code, in a large code repository.This problem has been traditionally addressed through the textual query. Inother words, information retrieval techniques will be exploited based on thetextual similarity between queries and textual representation of softwareartifacts, which is generated by collecting words from comments, identifiers,and descriptions of programs. However, in addition to these semanticinformation, there are rich information embedded in source codes themselves.These source codes, if analyzed properly, can be a rich source for enhancingthe efforts of software artifact retrieval. To this end, in this paper, wedevelop a feature extraction method on source codes. Specifically, this methodcan capture both the inherent information in the source codes and the semanticinformation hidden in the comments, descriptions, and identifiers of the sourcecodes. Moreover, we design a heterogeneous metric learning approach, whichallows to integrate code features and text features into the same latentsemantic space. This, in turn, can help to measure the artifact similarity byexploiting the joint power of both code and text features. Finally, extensiveexperiments on real-world data show that the proposed method can help toimprove the performances of software artifact retrieval with a significantmargin.",Liang Wu,2014/9/25,2014/9/25
1207.4474v2,On Model Based Synthesis of Embedded Control Software,http://arxiv.org/abs/1207.4474v2,"Many Embedded Systems are indeed Software Based Control Systems (SBCSs), thatis control systems whose controller consists of control software running on amicrocontroller device. This motivates investigation on Formal Model BasedDesign approaches for control software. Given the formal model of a plant as aDiscrete Time Linear Hybrid System and the implementation specifications (thatis, number of bits in the Analog-to-Digital (AD) conversion)correct-by-construction control software can be automatically generated fromSystem Level Formal Specifications of the closed loop system (that is, safetyand liveness requirements), by computing a suitable finite abstraction of theplant.  With respect to given implementation specifications, the automaticallygenerated code implements a time optimal control strategy (in terms of set-uptime), has a Worst Case Execution Time linear in the number of AD bits $b$, butunfortunately, its size grows exponentially with respect to $b$. In manyembedded systems, there are severe restrictions on the computational resources(such as memory or computational power) available to microcontroller devices.  This paper addresses model based synthesis of control software by tradingsystem level non-functional requirements (such us optimal set-up time, ripple)with software non-functional requirements (its footprint). Our experimentalresults show the effectiveness of our approach: for the inverted pendulumbenchmark, by using a quantization schema with 12 bits, the size of the smallcontroller is less than 6% of the size of the time optimal one.",Vadim Alimguzhin,2012/7/17,2013/2/18
2101.01126v1,Methodology for design of templates of text communication messages for software marketing,http://arxiv.org/abs/2101.01126v1,"A methodology is proposed for design of templates of text communicationmessages that are based on best practices of experts in software marketing,ideas of marketing, communication theory, copywriting, media linguistics,semiotics. Description of the subject area is based on conceptual modeling andproduction systems. For the purposes of testing, the methodology was used asthe basis of a software product. Decision support recommender system for designof communication messages for software marketing.",E. K. Malakhovskaya,2020/12/28,2020/12/28
2312.14725v2,Enhancing Text-to-SQL Translation for Financial System Design,http://arxiv.org/abs/2312.14725v2,"Text-to-SQL, the task of translating natural language questions into SQLqueries, is part of various business processes. Its automation, which is anemerging challenge, will empower software practitioners to seamlessly interactwith relational databases using natural language, thereby bridging the gapbetween business needs and software capabilities. In this paper, we considerLarge Language Models (LLMs), which have achieved state of the art for variousNLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluationmethodologies, as well as input optimization (e.g., prompting). In light of theempirical observations that we have made, we propose two novel metrics thatwere designed to adequately measure the similarity between SQL queries.Overall, we share with the community various findings, notably on how to selectthe right LLM on Text-to-SQL tasks. We further demonstrate that a tree-basededit distance constitutes a reliable metric for assessing the similaritybetween generated SQL queries and the oracle for benchmarking Text2SQLapproaches. This metric is important as it relieves researchers from the needto perform computationally expensive experiments such as executing generatedqueries as done in prior works. Our work implements financial domain use casesand, therefore contributes to the advancement of Text2SQL systems and theirpractical adoption in this domain.",Yewei Song,2023/12/22,2024/1/9
0908.3362v1,The Function of Gesture in an Architectural Design Meeting,http://arxiv.org/abs/0908.3362v1,"This text presents a cognitive-psychology analysis of spontaneous, co-speechgestures in a face-to-face architectural design meeting (A1 in DTRS7). Thelong-term objective is to formulate specifications for remotecollaborative-design systems, especially for supporting the use of differentsemiotic modalities (multi-modal interaction). According to their function fordesign, interaction, and collaboration, we distinguish different gesturefamilies: representational (entity designating or specifying), organisational(management of discourse, interaction, or functional design actions),focalising, discourse and interaction modulating, and disambiguating gestures.Discussion and conclusion concern the following points. It is impossible toattribute fixed functions to particular gesture forms. ""Designating"" gesturesmay also have a design function. The gestures identified in A1 possess acertain generic character. The gestures identified are neither systematicallyirreplaceable, nor optional accessories to speech or drawing. We discuss thepossibilities for gesture in computer-supported collaborative software systems.The paper closes on our contribution to gesture studies and cognitive designresearch.",Willemien Visser,2009/8/24,2009/8/24
2112.00304v1,Software Variants for Hardware Trojan Detection and Resilience in COTS Processors,http://arxiv.org/abs/2112.00304v1,"The commercial off-the-shelf (COTS) component based ecosystem provides anattractive system design paradigm due to the drastic reduction in developmenttime and cost compared to custom solutions. However, it brings in a growingconcern of trustworthiness arising from the possibility of embedded maliciouslogic, or hardware Trojans in COTS components. Existing trust-verificationapproaches are typically not applicable to COTS hardware due to the absence ofgolden models and the lack of observability of internal signals. In this work,we propose a novel approach for runtime Trojan detection and resilience inuntrusted COTS processors through judicious modifications in software. Theproposed approach does not rely on any hardware redundancy or architecturalmodification and hence seamlessly integrates with the COTS-based system designprocess. Trojan resilience is achieved through the execution of multiplefunctionally equivalent software variants. We have developed and implemented asolution for compiler-based automatic generation of program variants,metric-guided selection of variants, and their integration in a singleexecutable. To evaluate the proposed approach, we first analyzed theeffectiveness of program variants in avoiding the activation of a random poolof Trojans. By implementing several Trojans in an OpenRISC 1000 processor, weanalyzed the detectability and resilience during Trojan activation in bothsingle and multiple variants. We also present delay and code size overhead forthe automatically generated variants for several programs and discuss futureresearch directions to reduce the overhead.",Mahmudul Hasan,2021/12/1,2021/12/1
1708.07887v1,RaspiReader: An Open Source Fingerprint Reader Facilitating Spoof Detection,http://arxiv.org/abs/1708.07887v1,"We present the design and prototype of an open source, optical fingerprintreader, called RaspiReader, using ubiquitous components. RaspiReader, alow-cost and easy to assemble reader, provides the fingerprint researchcommunity a seamless and simple method for gaining more control over thesensing component of fingerprint recognition systems. In particular, we positthat this versatile fingerprint reader will encourage researchers to explorenovel spoof detection methods that integrate both hardware and software.RaspiReader's hardware is customized with two cameras for fingerprintacquisition with one camera providing high contrast, frustrated total internalreflection (FTIR) images, and the other camera outputting direct images. Usingboth of these image streams, we extract complementary information which, whenfused together, results in highly discriminative features for fingerprint spoof(presentation attack) detection. Our experimental results demonstrate a markedimprovement over previous spoof detection methods which rely only on FTIRimages provided by COTS optical readers. Finally, fingerprint matchingexperiments between images acquired from the FTIR output of the RaspiReader andimages acquired from a COTS fingerprint reader verify the interoperability ofthe RaspiReader with existing COTS optical readers.",Joshua J. Engelsma,2017/8/25,2017/8/25
1704.06864v1,On the Trade-Off between Computational Load and Reliability for Network Function Virtualization,http://arxiv.org/abs/1704.06864v1,"Network Function Virtualization (NFV) enables the ""softwarization"" of networkfunctions, which are implemented on virtual machines hosted on Commercialoff-the-shelf (COTS) servers. Both the composition of the virtual networkfunctions (VNFs) into a forwarding graph (FG) at the logical layer and theembedding of the FG on the servers need to take into account theless-than-carrier-grade reliability of COTS components. This work investigatesthe trade-off between end-to-end reliability and computational load per servervia the joint design of VNF chain composition (CC) and FG embedding (FGE) underthe assumption of a bipartite FG that consists of controller and regular VNFs.Evaluating the reliability criterion within a probabilistic model, analyticalinsights are first provided for a simplified disconnected FG. Then, a blockcoordinate descent method based on mixed-integer linear programming is proposedto tackle the joint optimization of CC and FGE. Via simulation results, it isobserved that a joint design of CC and FGE leads to substantial performancegains compared to separate optimization approaches.",Jinkyu Kang,2017/4/23,2017/4/23
2203.10390v1,RT-WiFi on Software-Defined Radio: Design and Implementation,http://arxiv.org/abs/2203.10390v1,"Applying high-speed real-time wireless technologies in industrialapplications has the great potential to reduce the deployment and maintenancecosts compared to their wired counterparts. Wireless technologies enhance themobility and reduce the communication jitter and delay for mobile industrialequipment, such as mobile collaborative robots. Unfortunately, most existingwireless solutions employed in industrial fields either cannot support thedesired high-speed communications or cannot guarantee deterministic, real-timeperformance. A more recent wireless technology, RT-WiFi, achieves a goodbalance between high-speed data rates and deterministic communicationperformance. It is however developed on commercial-of-the-shelf (COTS)hardware, and takes considerable effort and hardware expertise to maintain andupgrade. To address these problems, this paper introduces the software-definedradio (SDR)-based RT-WiFi solution which we call SRT-WiFi. SRT-WiFi providesfull-stack configurability for high-speed real-time wireless communications. Wepresent the overall system architecture of SRT-WiFi and discuss its keyfunctions which achieve better timing performance and solve the queuemanagement and rate adaptation issues compared to COTS hardware-based RT-WiFi.To achieve effective network management with rate adaptation in multi-clusterSRT-WiFi, a novel scheduling problem is formulated and an effective algorithmis proposed to solve the problem. A multi-cluster SRT-WiFi testbed is developedto validate the design, and extensive experiments are performed to evaluate theperformance at both device and system levels.",Zelin Yun,2022/3/19,2022/3/19
1701.06484v1,"COTS software in science operations, is it worth it?",http://arxiv.org/abs/1701.06484v1,"Often, perhaps not often enough, we choose Common Off the Shelf (COTS)software for integration in our systems. These range from repositories todatabases and tools we use on a daily basis. It is very hard to assess theeffectiveness of these choices. While none of us would consider a projectspecific word processing solution when LaTeX (or even Word) many will considerwriting their own data management systems. We will look at some of the COTS wehave used and attempt to explain how we came to the decision and if it wasworth it.",William O'Mullane,2016/11/11,2016/11/11
2201.09454v1,Design of Fieldable Cross-Layer Optimized Network using Embedded Software Defined Radios: Survey and Novel Architecture with Field Trials,http://arxiv.org/abs/2201.09454v1,"The proliferation of wireless devices and their ever increasing influence onour day-to-day life is very evident and seems irreplaceable. This exponentialgrowth in demand, both in terms of the number of devices and Quality of Service(QoS) had spawned the concept of cross-layer optimization several years ago.The primary goal of the cross-layer approach was to liberate the strictboundary between the layers of the traditional Open Systems Interconnection(OSI) protocol stack. The initial decade focused on establishing thetheoretical feasibility of this revolutionary concept and gauging theeffectiveness and limits of this idea. During the next phase, the advent ofsoftware defined radios (SDR) accelerated the growth of this domain due to itsadded flexibility. Yet, there has been a gaping abyss between solutionsdesigned in theory and ones deployed in practice. To establish this, we firstpresent an elaborate survey of the cross-layer protocol stack literature. Next,we briefly discuss how a commercial off-the-shelf (COTS), low SWaP (Size,Weight, and Power) embedded SDR (e-SDR) was transformed into a standalone,fieldable transceiver. Thereafter, we provide the software design ethos thatfocuses on efficiency and flexibility such that the optimization objectives andcross-layer interactions can be reconfigured rapidly. To demonstrate ourclaims, we provide results from extensive outdoor over-the-air experiments invarious settings with up to 10-node network topologies. The results from thefield trials demonstrate high reliability, throughput, and dynamic routingcapability. To the best of our knowledge, this is the first time in literature,a COTS e-SDR has been leveraged to successfully design a cross-layer optimizedtransceiver that is capable of forming an ad hoc network that provides highthroughput and high reliability in a ruggedized, weatherized, and fieldableform factor.",Jithin Jagannath,2022/1/24,2022/1/24
1109.0350v2,On surfaces in three dimensional contact manifolds,http://arxiv.org/abs/1109.0350v2,"In this paper, we introduce two notions on a surface in a contact manifold.The first one is called degree of transversality (DOT) which measures thetransversality between the tangent spaces of a surface and the contact planes.The second quantity, called curvature of transversality (COT), is designed togive a comparison principle for DOT along characteristic curves under bounds onCOT. In particular, this gives estimates on lengths of characteristic curvesassuming COT is bounded below by a positive constant.  We show that surfaces with constant COT exist and we classify all graphs inthe Heisenberg group with vanishing COT. This is accomplished by showing thatthe equation for graphs with zero COT can be decomposed into two first orderPDEs, one of which is the backward invisicid Burgers' equation. Finally we showthat the p-minimal graph equation in the Heisenberg group also has such adecomposition. Moreover, we can use this decomposition to write down anexplicit formula of a solution near a regular point.",Paul Woon Yin Lee,2011/9/2,2012/6/13
1703.04525v1,Computer of Things a Proposal to Speed up IoT Development,http://arxiv.org/abs/1703.04525v1,"This paper propose and predict the need for a new line of computer productionthat can facilitate and accelerate the improvements of things and systemstowards IoT networks. The proposed computer that is named Computer of Thing,CoT, will speed up the establishment of smart world in a synchronized way withsimilar standards, communication protocols, and hardware and software. Also,the need for a new standardization body in addition to those who exist isstated that will motivate governments to invest more on IoT development.However, to show the importance of proposed CoT, a brief review on IoT presentstatus is performed and then some terminologies and classification of IoTnetworks is presented. This classification helps manufacturers to gain a properview for their future products development. Then, observing from productionpoint of view the need for CoT is highlighted. Finally, as smart systems maywork in different dimensions of applications via internet or intranetconnectivity, the basic specifications of proposed CoT are presented.Consequently, due to nature of CoTs, a new multi- dimension multi-hierarchycontrol strategy is proposed.",Alireza Ahadpour Shal,2017/3/1,2017/3/1
2010.07680v1,Demonstration of a Cloud-based Software Framework for Video Analytics Application using Low-Cost IoT Devices,http://arxiv.org/abs/2010.07680v1,"The design of products and services such as a Smart doorbell, demonstratingvideo analytics software/algorithm functionality, is expected to address a newkind of requirements such as designing a scalable solution while consideringthe trade-off between cost and accuracy; a flexible architecture to deploy newAI-based models or update existing models, as user requirements evolve; as wellas seamlessly integrating different kinds of user interfaces and devices. Toaddress these challenges, we propose a smart doorbell that orchestrates videoanalytics across Edge and Cloud resources. The proposal uses AWS as a baseplatform for implementation and leverages Commercially AvailableOff-The-Shelf(COTS) affordable devices such as Raspberry Pi in the form of anEdge device.",Bhavin Joshi,2020/9/29,2020/9/29
1402.2373v1,Visualization of Object Oriented Modeling from the Perspective of Set theory,http://arxiv.org/abs/1402.2373v1,"Language is a medium for communication of our thoughts. Natural language istoo wide to conceive and formulate the thoughts and ideas in a precise way. Asscience and technology grows, the necessity of languages arouses through whichthe thoughts are expressed in a better manner. Set Theory is such amathematical language for expressing the thought of interest in a realisticway. It is well suited for presenting object oriented solution model, sincethis implementation methodology analyzes and modulates the requirements in arealistic way. Since the design flaws are one of the factors for softwarefailure, industries are focusing on minimizing the design defects throughbetter solution modeling techniques and quality assessment practices. TheObject Oriented (OO) solution space can be visualized using the language of Settheory with which the design architecture of modules can be well defined. Itprovides a strong base to quantify the relationships within and between themodules, which is a mode for measuring the complexity of solution design of anysoftware projects. This paper provides a visualization of OO modeling from theperspective of Set theory. Thereby, it paves the path for the designers toeffectively design the application which is one of the challenges of a projectdevelopment. Further, this mode of visualization enables one to effectivelymeasure and controls the design complexity leading towards reducing the designflaws and enhanced software quality.",Poornima. U. S.,2014/2/11,2014/2/11
1006.1182v1,A Parsing Scheme for Finding the Design Pattern and Reducing the Development Cost of Reusable Object Oriented Software,http://arxiv.org/abs/1006.1182v1,"Because of the importance of object oriented methodologies, the research indeveloping new measure for object oriented system development is gettingincreased focus. The most of the metrics need to find the interactions betweenthe objects and modules for developing necessary metric and an influentialsoftware measure that is attracting the software developers, designers andresearchers. In this paper a new interactions are defined for object orientedsystem. Using these interactions, a parser is developed to analyze the existingarchitecture of the software. Within the design model, it is necessary fordesign classes to collaborate with one another. However, collaboration shouldbe kept to an acceptable minimum i.e. better designing practice will introducelow coupling. If a design model is highly coupled, the system is difficult toimplement, to test and to maintain overtime. In case of enhancing software, weneed to introduce or remove module and in that case coupling is the mostimportant factor to be considered because unnecessary coupling may make thesystem unstable and may cause reduction in the system's performance. Socoupling is thought to be a desirable goal in software construction, leading tobetter values for external software qualities such as maintainability,reusability and so on. To test this hypothesis, a good measure of classcoupling is needed. In this paper, based on the developed tool called DesignAnalyzer we propose a methodology to reuse an existing system with theobjective of enhancing an existing Object oriented system keeping the couplingas low as possible.",K. M. Azharul Hasan,2010/6/7,2010/6/7
1008.1671v1,A Parsing Scheme for Finding the Design Pattern and Reducing the Development Cost of Reusable Object Oriented Software,http://arxiv.org/abs/1008.1671v1,"Because of the importance of object oriented methodologies, the research indeveloping new measure for object oriented system development is gettingincreased focus. The most of the metrics need to find the interactions betweenthe objects and modules for developing necessary metric and an influentialsoftware measure that is attracting the software developers, designers andresearchers. In this paper a new interactions are defined for object orientedsystem. Using these interactions, a parser is developed to analyze the existingarchitecture of the software. Within the design model, it is necessary fordesign classes to collaborate with one another. However, collaboration shouldbe kept to an acceptable minimum i.e. better designing practice will introducelow coupling. If a design model is highly coupled, the system is difficult toimplement, to test and to maintain overtime. In case of enhancing software, weneed to introduce or remove module and in that case coupling is the mostimportant factor to be considered because unnecessary coupling may make thesystem unstable and may cause reduction in the system's performance. Socoupling is thought to be a desirable goal in software construction, leading tobetter values for external software qualities such as maintainability,reusability and so on. To test this hypothesis, a good measure of classcoupling is needed. In this paper, based on the developed tool called DesignAnalyzer we propose a methodology to reuse an existing system with theobjective of enhancing an existing Object oriented system keeping the couplingas low as possible.",K. M. Azharul Hasan,2010/8/10,2010/8/10
1004.3271v1,A General Simulation Framework for Supply Chain Modeling: State of the Art and Case Study,http://arxiv.org/abs/1004.3271v1,"Nowadays there is a large availability of discrete event simulation softwarethat can be easily used in different domains: from industry to supply chain,from healthcare to business management, from training to complex systemsdesign. Simulation engines of commercial discrete event simulation software usespecific rules and logics for simulation time and events management.Difficulties and limitations come up when commercial discrete event simulationsoftware are used for modeling complex real world-systems (i.e. supply chains,industrial plants). The objective of this paper is twofold: first a state ofthe art on commercial discrete event simulation software and an overview ondiscrete event simulation models development by using general purposeprogramming languages are presented; then a Supply Chain Order PerformanceSimulator (SCOPS, developed in C++) for investigating the inventory managementproblem along the supply chain under different supply chain scenarios isproposed to readers.",Antonio Cimino,2010/4/19,2010/4/19
2303.03012v4,On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study,http://arxiv.org/abs/2303.03012v4,"Recent advances in large language models (LLMs) significantly boost theirusage in software engineering. However, training a well-performing LLM demandsa substantial workforce for data collection and annotation. Moreover, trainingdatasets may be proprietary or partially open, and the process often requires acostly GPU cluster. The intellectual property value of commercial LLMs makesthem attractive targets for imitation attacks, but creating an imitation modelwith comparable parameters still incurs high costs. This motivates us toexplore a practical and novel direction: slicing commercial black-box LLMsusing medium-sized backbone models. In this paper, we explore the feasibilityof launching imitation attacks on LLMs to extract their specialized codeabilities, such as""code synthesis"" and ""code translation."" We systematicallyinvestigate the effectiveness of launching code ability extraction attacksunder different code-related tasks with multiple query schemes, includingzero-shot, in-context, and Chain-of-Thought. We also design response checks torefine the outputs, leading to an effective imitation training process. Ourresults show promising outcomes, demonstrating that with a reasonable number ofqueries, attackers can train a medium-sized backbone model to replicatespecialized code behaviors similar to the target LLMs. We summarize ourfindings and insights to help researchers better understand the threats posedby imitation attacks, including revealing a practical attack surface forgenerating adversarial code examples against LLMs.",Zongjie Li,2023/3/6,2023/10/31
2209.08141v2,Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models,http://arxiv.org/abs/2209.08141v2,"Probabilistic models of language understanding are valuable tools forinvestigating human language use. However, they need to be hand-designed for aparticular domain. In contrast, large language models (LLMs) are trained ontext that spans a wide array of domains, but they lack the structure andinterpretability of probabilistic models. In this paper, we usechain-of-thought prompts to introduce structures from probabilistic models intoLLMs. We explore this approach in the case of metaphor understanding. Ourchain-of-thought prompts lead language models to infer latent variables andreason about their relationships in order to choose appropriate paraphrases formetaphors. The latent variables and relationships chosen are informed bytheories of metaphor understanding from cognitive psychology. We apply theseprompts to the two largest versions of GPT-3 and show that they can improveperformance in a paraphrase selection task.",Ben Prystawski,2022/9/16,2023/5/19
1204.4909v1,Evaluation of the Design Metric to Reduce the Number of Defects in Software Development,http://arxiv.org/abs/1204.4909v1,"Software design is one of the most important and key activities in the systemdevelopment life cycle (SDLC) phase that ensures the quality of software.Different key areas of design are very vital to be taken into considerationwhile designing software. Software design describes how the software system isdecomposed and managed in smaller components. Object-oriented (OO) paradigm hasfacilitated software industry with more reliable and manageable software andits design. The quality of the software design can be measured throughdifferent metrics such as Chidamber and Kemerer (CK) design metrics, MoodMetrics & Lorenz and Kidd metrics. CK metrics is one of the oldest and mostreliable metrics among all metrics available to software industry to evaluateOO design. This paper presents an evaluation of CK metrics to propose animproved CK design metrics values to reduce the defects during software designphase in software. This paper will also describe that whether a significanteffect of any CK design metrics exists on total number of defects per module ornot. This is achieved by conducting survey in two software developmentcompanies.",M. Rizwan Jameel Qureshi,2012/4/22,2012/4/22
2012.05563v1,Combined Intuition and Rationality Increases Software Feature Novelty for Female Software Designers,http://arxiv.org/abs/2012.05563v1,"Overcoming society's complex problems requires novel solutions. Applyingdifferent cognitive styles can promote novelty when designing software aimed atthese problems. Through an experiment with 80 software design practitioners, wefound that female practitioners who had a preference for more than onecognitive style (intuition and rationality) produced the most novel softwarefeatures of all participants.",Carianne Pretorius,2020/12/10,2020/12/10
1805.09485v2,Why developers cannot embed privacy into software systems? An empirical investigation,http://arxiv.org/abs/1805.09485v2,"Pervasive use of software applications continues to challenge user privacywhen users interact with software systems. Even though privacy practices suchas Privacy by Design (PbD), have clear in- structions for software developersto embed privacy into software designs, those practices are yet to become acommon practice among software developers. The difficulty of developing privacypreserv- ing software systems highlights the importance of investigatingsoftware developers and the problems they face when they are asked to embedprivacy into application designs. Software devel- opers are the community whocan put practices such as PbD into action. Therefore, identifying problems theyface when embed- ding privacy into software applications and providingsolutions to those problems are important to enable the development of privacypreserving software systems. This study investigates 36 software developers ina software design task with instructions to embed privacy in order to identifythe problems they face. We derive rec- ommendation guidelines to address theproblems to enable the development of privacy preserving software systems.",Awanthika Senarath,2018/5/24,2018/5/25
2209.08348v1,Some Long-Standing Quality Practices in Software Development,http://arxiv.org/abs/2209.08348v1,"The desire to build quality software systems has been the focus of mostsoftware developers and researchers for decades. This has culminated in thedesign of practices that promote quality in the designed software. Originatingfrom the inception of the traditional software development life cycle (SDLC),through to the object-oriented methods, Iterative development, and now theagile methods, these practices have persisted through different periods. Suchpractices play the same quality role regardless of the perspective of thesoftware development process they are part of. In this paper we review threesoftware development methods representative of the software developmenthistory, with the aim of i) identifying key quality practices, ii) identifyingthe quality role played by the practice in the method, and iii) noting thosequality practices that have persisted through the software development history.The identified quality practices that have persisted throughout the history ofthe software development processes include prototyping, iterative development,incremental development, risk-driven development, phase planning, and phaseretrospection. These results would be useful to method engineers who seek todesign high-quality software development methods as these practices serve ascandidates for inclusion in their development processes. Software developmentpractitioners seeking to design quality software would also benefit fromadopting these practices in developing their software.",Sibonile Moyo,2022/9/17,2022/9/17
2104.00058v1,Investigating Design Anti-pattern and Design Pattern Mutations and Their Change- and Fault-proneness,http://arxiv.org/abs/2104.00058v1,"During software evolution, inexperienced developers may introduce designanti-patterns when they modify their software systems to fix bugs or to add newfunctionalities based on changes in requirements. Developers may also usedesign patterns to promote software quality or as a possible cure for somedesign anti-patterns. Thus, design patterns and design anti-patterns areintroduced, removed, and mutated from one another by developers.  Many studies investigated the evolution of design patterns and designanti-patterns and their impact on software development. However, theyinvestigated design patterns or design anti-patterns in isolation and did notconsider their mutations and the impact of these mutations on software quality.Therefore, we report our study of bidirectional mutations between designpatterns and design anti-patterns and the impacts of these mutations onsoftware change- and fault-proneness.  We analyzed snapshots of seven Java software systems with diverse sizes,evolution histories, and application domains. We built Markov models to capturethe probability of occurrences of the different design patterns and designanti-patterns mutations. Results from our study show that (1) design patternsand design anti-patterns mutate into other design patterns and/or designanti-patterns. They also show that (2) some change types primarily triggermutations of design patterns and design anti-patterns (renaming and changes tocomments, declarations, and operators), and (3) some mutations of designanti-patterns and design patterns are more faulty in specific contexts. Theseresults provide important insights into the evolution of design patterns anddesign anti-patterns and its impact on the change- and fault-proneness ofsoftware systems.",Zeinab,2021/3/31,2021/3/31
2103.13755v1,Quantum Software Models: The Density Matrix for Classical and Quantum Software Systems Design,http://arxiv.org/abs/2103.13755v1,"Linear Software Models enable rigorous linear algebraic procedures formodular design of classical software systems. These procedures apply a spectralapproach to matrix representations - e.g. the Laplacian - of the softwaresystem. Recent intensive research efforts towards quantum computers haveincreased expectations that quantum computing could in due time materialize asa practical alternative to classical computing. It is reasonable to inquireabout quantum software desirable features and prepare in advance modular designprocedures for quantum software systems. However, it does not make sense tohave two totally separate procedures for modular design, one for classicalsoftware systems and another for quantum software systems. This paper claimsthat there should be just a single unified and rigorous design procedure forboth classical and quantum software systems. Our common design procedurestarting point for both classical and quantum software systems is Von Neumannquantum notion of Density Operator and its Density Matrix representation. Thispaper formulates and demonstrates modular design in terms of projectionoperators obtained from a design Density Matrix and shows their equivalence tothe Linear Software Models results of the Laplacian matrix spectrum for theclassical case. The application in practice of the design procedure for bothclassical and quantum software is illustrated by case studies.",Iaakov Exman,2021/3/25,2021/3/25
1207.3872v1,Top Down Approach: SIMULINK Mixed Hardware / Software Design,http://arxiv.org/abs/1207.3872v1,"System-level design methodologies have been introduced as a solution tohandle the design complexity of mixed Hardware / Software systems. In thispaper we describe a system-level design flow starting from Simulinkspecification, focusing on concurrent hardware and software design andverification at four different abstraction levels: System Simulink model,Transaction Simulink model, Macro architecture, and micro architecture. We usedthe MP3 CodeC application, to validate our approach and methodology.",Youssef Atat,2012/7/17,2012/7/17
2203.15396v1,Towards Maintainable Platform Software -- Delivery Cost Control in Continuous Software Development,http://arxiv.org/abs/2203.15396v1,"Modern platform software delivery cost increases rapidly as it usually needsto align with many hardware and silicon's TTMs, feature evolvement and involveshundreds of engineers. In this paper, citing one ultra-large-scale software -Intel Media Driver as an example, we analyze the hotspots leading to deliverycost increase in continuous software development, the challenges on oursoftware design and our experiences on software delivery cost shrink againstthe targeted design enhancements. We expect the identified hotspots can helpmore researchers to form the corresponding research agendas and the experiencesshared can help following practitioners to apply similar enhancements.",Ning Luo,2022/3/29,2022/3/29
1210.1184v1,"Elegant Object-oriented Software Design via Interactive, Evolutionary Computation",http://arxiv.org/abs/1210.1184v1,"Design is fundamental to software development but can be demanding toperform. Thus to assist the software designer, evolutionary computing is beingincreasingly applied using machine-based, quantitative fitness functions toevolve software designs. However, in nature, elegance and symmetry play acrucial role in the reproductive fitness of various organisms. In addition,subjective evaluation has also been exploited in Interactive EvolutionaryComputation (IEC). Therefore to investigate the role of elegance and symmetryin software design, four novel elegance measures are proposed based on theevenness of distribution of design elements. In controlled experiments in adynamic interactive evolutionary computation environment, designers arepresented with visualizations of object-oriented software designs, which theyrank according to a subjective assessment of elegance. For three out of thefour elegance measures proposed, it is found that a significant correlationexists between elegance values and reward elicited. These three elegancemeasures assess the evenness of distribution of (a) attributes and methodsamong classes, (b) external couples between classes, and (c) the ratio ofattributes to methods. It is concluded that symmetrical elegance is in some waysignificant in software design, and that this can be exploited in dynamic,multi-objective interactive evolutionary computation to produce elegantsoftware designs.",Christopher L. Simons,2012/10/3,2012/10/3
1910.05428v1,Design Smell Analysis for Developing and Established Open Source Java Software,http://arxiv.org/abs/1910.05428v1,"Software design smells are design attributes which violate the fundamentaldesign principles. Design smells are a key cause of design debt. Although theactivities of design smell identification and measurement are predominantlyconsidered in current literature, those which identify and communicate whichdesign smells occur more frequently in newly developing software and which onesare more dominant in established software have been studied to a limitedextent. This research describes a mechanism for identifying the design smellsthat are more prevalent in developing and established software respectively. Atool is provided which is used for design smell detection by analyzing largevolumes of source code. More specifically, 164,609 Lines of Code (LoC) and5,712 class files of six developing and 244,930 LoC and 12,048 class files offive established open-source Java software are analyzed. Obtained results showthat out of the 4,020 occurrences of smells that were made for nine preselectedtypes of design smells, 1,643 design smells were detected for developingsoftware, which mainly consisted of four specific types of smells. Forestablished software, 2,397 design smells were observed which predominantlyconsisted of four other types of smells. The remaining design smell was equallyprevalent in both developing and established software. Desirable precisionvalues ranging from 72.9% to 84.1% were obtained for the tool.",Asif Imran,2019/10/11,2019/10/11
1411.2553v1,Measuring the impact of input data on energy consumption of software,http://arxiv.org/abs/1411.2553v1,"The amount of energy consumed during the execution of software, and theability to predict future consumption, is an important factor in the design ofembedded electronic systems. In this technical report I examine factors in theexecution of software that can affect energy consumption. Taking a simpleembedded software benchmark I measure to what extent input data can affectenergy consumption, and propose a method for reflecting this in software energymodels.",Jeremy Morse,2014/11/10,2014/11/10
2108.11903v1,Design Thinking and Creativity of Co-located vs. Globally Distributed Software Developers,http://arxiv.org/abs/2108.11903v1,"Context: Designing software is an activity in which software developers thinkand make design decisions that shape the structure and behavior of softwareproducts. Designing software is one of the least understood softwareengineering activities. In a collaborative design setting, various types ofdistances can lead to challenges and effects that potentially affect howsoftware is designed. Objective: To contribute to a better understanding ofcollaborative software design, we investigate how geographic distance affectsits design thinking and the creativity of its discussions. Method: To this end,we conducted a multiple-case study exploring the design thinking and creativityof co-located and distributed software developers in a collaborative designsetting. Results: Compared to co-located developers, distributed developersspend less time on exploring the problem space, which could be related todifferent socio-technical challenges, such as lack of awareness and commonunderstanding. Distributed development does not seem to affect the creativityof their activities. Conclusion: Developers engaging in collaborative designneed to be aware that problem space exploration is reduced in a distributedsetting. Unless distributed teams take compensatory measures, this couldadversely affect the development. Regarding the effect distance has oncreativity, our results are inconclusive and further studies are needed.",Rodi Jolak,2021/8/26,2021/8/26
0903.0571v1,Adaptation of Black-Box Software Components,http://arxiv.org/abs/0903.0571v1,The globalization of the software market leads to crucial problems forsoftware companies. More competition between software companies arises andleads to the force on companies to develop ever newer software products in evershortened time interval. Therefor the time to market for software systems isshortened and obviously the product life cycle is shortened too[...]Theapproach introduced here presents the novel technique together with asupportive environment that enables developers to cope with the adaptability ofblack-box software components. A supported environment will be designed thatchecks the compatibility of black-box software components with the assistanceof their specifications.,Rolf Andreas Rasenack,2009/3/3,2009/3/3
1302.4061v1,The Sensemaking-Coevolution-Implementation Theory of Software Design,http://arxiv.org/abs/1302.4061v1,"Understanding software design practice is critical to understanding moderninformation systems development. New developments in empirical softwareengineering, information systems design science and the interdisciplinarydesign literature combined with recent advances in process theory andtestability have created a situation ripe for innovation. Consequently, thispaper utilizes these breakthroughs to formulate a process theory of softwaredesign practice: Sensemaking-Coevolution-Implementation Theory explains howcomplex software systems are created by collocated software development teamsin organizations. It posits that an independent agent (design team) creates asoftware system by alternating between three activities: organizing theirperceptions about the context, mutually refining their understandings of thecontext and design space, and manifesting their understanding of the designspace in a technological artifact. This theory development paper defines andillustrates Sensemaking-Coevolution-Implementation Theory, grounds its conceptsand relationships in existing literature, conceptually evaluates the theory andsituates it in the broader context of information systems development.",Paul Ralph,2013/2/17,2013/2/17
2310.14433v1,Investigate how developers and managers view security design in software,http://arxiv.org/abs/2310.14433v1,"Software security requirements have been traditionally considered as anon-functional attribute of the software. However, as more software started toprovide services online, existing mechanisms of using firewalls and otherhardware to secure software have lost their applicability. At the same time,under the current world circumstances, the increase of cyber-attacks onsoftware is ever increasing. As a result, it is important to consider thesecurity requirements of software during its design. To design security in thesoftware, it is important to obtain the views of the developers and managers ofthe software. Also, it is important to evaluate if their viewpoints match ordiffer regarding the security. Conducting this communication through a specificmodel will enable the developers and managers to eliminate any doubts onsecurity design and adopt an effective strategy to build security into thesoftware. In this paper, we analyzed the viewpoints of developers and managersregarding their views on security design. We interviewed a team of 7 developersand 2 managers, who worked in two teams to build a real-life software productthat was recently compromised by a cyber-attack. We obtained their views on thereasons for the successful attack by the malware and took their recommendationson the important aspects to consider regarding security. Based on theirfeedback, we coded their open-ended responses into 4 codes, which werecommended using for other real-life software as well.",Asif Imran,2023/10/22,2023/10/22
2310.13220v1,In-context Learning with Transformer Is Really Equivalent to a Contrastive Learning Pattern,http://arxiv.org/abs/2310.13220v1,"Pre-trained large language models based on Transformers have demonstratedamazing in-context learning (ICL) abilities. Given several demonstrationexamples, the models can implement new tasks without any parameter updates.However, it is still an open question to understand the mechanism of ICL. Inthis paper, we interpret the inference process of ICL as a gradient descentprocess in a contrastive learning pattern. Firstly, leveraging kernel methods,we establish the relationship between gradient descent and self-attentionmechanism under generally used softmax attention setting instead of linearattention setting. Then, we analyze the corresponding gradient descent processof ICL from the perspective of contrastive learning without negative samplesand discuss possible improvements of this contrastive learning pattern, basedon which the self-attention layer can be further modified. Finally, we designexperiments to support our opinions. To the best of our knowledge, our work isthe first to provide the understanding of ICL from the perspective ofcontrastive learning and has the potential to facilitate future model design byreferring to related works on contrastive learning.",Ruifeng Ren,2023/10/20,2023/10/20
2310.08309v1,Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning,http://arxiv.org/abs/2310.08309v1,"Large Language Models (LLMs) have recently gained the In-Context Learning(ICL) ability with the models scaling up, allowing them to quickly adapt todownstream tasks with only a few demonstration examples prepended in the inputsequence. Nonetheless, the current practice of ICL treats all demonstrationexamples equally, which still warrants improvement, as the quality of examplesis usually uneven. In this paper, we investigate how to determine approximatelyoptimal weights for demonstration examples and how to apply them during ICL. Toassess the quality of weights in the absence of additional validation data, wedesign a masked self-prediction (MSP) score that exhibits a strong correlationwith the final ICL performance. To expedite the weight-searching process, wediscretize the continuous weight space and adopt beam search. Withapproximately optimal weights obtained, we further propose two strategies toapply them to demonstrations at different model positions. Experimental resultson 8 text classification tasks show that our approach outperforms conventionalICL by a large margin. Our code are publicly available athttps:github.com/Zhe-Young/WICL.",Zhe Yang,2023/10/12,2023/10/12
2312.01571v1,How to Configure Good In-Context Sequence for Visual Question Answering,http://arxiv.org/abs/2312.01571v1,"Inspired by the success of Large Language Models in dealing with new tasksvia In-Context Learning (ICL) in NLP, researchers have also developed LargeVision-Language Models (LVLMs) with ICL capabilities. However, whenimplementing ICL using these LVLMs, researchers usually resort to the simplestway like random sampling to configure the in-context sequence, thus leading tosub-optimal results. To enhance the ICL performance, in this study, we useVisual Question Answering (VQA) as case study to explore diverse in-contextconfigurations to find the powerful ones. Additionally, through observing thechanges of the LVLM outputs by altering the in-context sequence, we gaininsights into the inner properties of LVLMs, improving our understanding ofthem. Specifically, to explore in-context configurations, we design diverseretrieval methods and employ different strategies to manipulate the retrieveddemonstrations. Through exhaustive experiments on three VQA datasets: VQAv2,VizWiz, and OK-VQA, we uncover three important inner properties of the appliedLVLM and demonstrate which strategies can consistently improve the ICL VQAperformance. Our code is provided in:https://github.com/GaryJiajia/OFv2_ICL_VQA.",Li Li,2023/12/4,2023/12/4
2312.02520v1,Towards More Unified In-context Visual Understanding,http://arxiv.org/abs/2312.02520v1,"The rapid advancement of large language models (LLMs) has accelerated theemergence of in-context learning (ICL) as a cutting-edge approach in thenatural language processing domain. Recently, ICL has been employed in visualunderstanding tasks, such as semantic segmentation and image captioning,yielding promising results. However, existing visual ICL framework can notenable producing content across multiple modalities, which limits theirpotential usage scenarios. To address this issue, we present a new ICLframework for visual understanding with multi-modal output enabled. First, wequantize and embed both text and visual prompt into a unified representationalspace, structured as interleaved in-context sequences. Then a decoder-onlysparse transformer architecture is employed to perform generative modeling onthem, facilitating in-context learning. Thanks to this design, the model iscapable of handling in-context vision understanding tasks with multimodaloutput in a unified pipeline. Experimental results demonstrate that our modelachieves competitive performance compared with specialized models and previousICL baselines. Overall, our research takes a further step toward unifiedmultimodal in-context learning.",Dianmo Sheng,2023/12/5,2023/12/5
1611.04435v2,"The Burrell Schmidt Deep Virgo Survey: Tidal Debris, Galaxy Halos, and Diffuse Intracluster Light in the Virgo Cluster",http://arxiv.org/abs/1611.04435v2,"We present a deep imaging survey of the Virgo Cluster, designed to study theconnection between cluster galaxies and Virgo's diffuse intracluster light(ICL). Our observations span roughly 16 square degrees and reach a 3-sigmadepth of mu(B)=29.5 and mu(V)=28.5 mag/arcsec^2. At these depths, the limitingsystematic uncertainties are astrophysical: scattered starlight from foregroundGalactic dust, and variations in faint background sources. The dust-scatteredstarlight is well-traced by deep far-infrared imaging, making itdistinguishable from true Virgo diffuse light. Our imaging maps the Virgo corearound M87 and the adjacent M86/M84 region, in subcluster B around M49, and inthe more distant W' cloud around NGC 4365. Most of the detected ICL is found inthe Virgo core and within the W' cloud, with little evidence for extensive ICLin subcluster B. The large amount of diffuse light seen in the infalling W'cloud likely illustrates the importance of the group environment for generatingICL. The bulk of the detected ICL is fairly red (B-V=0.7-0.9), indicative ofold stellar populations. We estimate a total Virgo ICL fraction of 7-15%,somewhat smaller than expected for massive, evolved clusters, suggesting thatVirgo is still growing its ICL component. We trace M87's extremely boxy haloout to ~ 150 kpc, and show that the current stripping rate of low luminositygalaxies is insufficient to have built M87's outer halo over a Hubble time.Finally, we identify another large ultra-diffuse galaxy in Virgo, likely in theprocess of being shredded by the cluster tidal field.",J. Christopher Mihos,2016/11/14,2016/12/15
1601.00520v1,The XXL Survey VIII: MUSE characterisation of intracluster light in a z$\sim$0.53 cluster of galaxies,http://arxiv.org/abs/1601.00520v1,"Within a cluster, gravitational effects can lead to the removal of stars fromtheir parent galaxies. Gas hydrodynamical effects can additionally strip gasand dust from galaxies. The properties of the ICL can therefore help constrainthe physical processes at work in clusters by serving as a fossil record of theinteraction history. The present study is designed to characterise this ICL ina ~10^14 M_odot and z~0.53 cluster of galaxies from imaging and spectroscopicpoints of view. By applying a wavelet-based method to CFHT Megacam and WIRCAMimages, we detect significant quantities of diffuse light. These sources werethen spectroscopically characterised with MUSE. MUSE data were also used tocompute redshifts of 24 cluster galaxies and search for cluster substructures.An atypically large amount of ICL has been detected in this cluster. Part ofthe detected diffuse light has a very weak optical stellar component andapparently consists mainly of gas emission, while other diffuse light sourcesare clearly dominated by old stars. Furthermore, emission lines were detectedin several places of diffuse light. Our spectral analysis shows that thisemission likely originates from low-excitation parameter gas. The stellarcontribution to the ICL is about 2.3x10^9 yrs old even though the ICL is notcurrently forming a large number of stars. On the other hand, the contributionof the gas emission to the ICL in the optical is much greater than the stellarcontribution in some regions, but the gas density is likely too low to formstars. These observations favour ram pressure stripping, turbulent viscousstripping, or supernovae winds as the origin of the large amount ofintracluster light. Since the cluster appears not to be in a major mergingphase, we conclude that ram pressure stripping is the most plausible processthat generates the observed ICL sources.",C. Adami,2016/1/4,2016/1/4
2312.12989v1,"Benchmarking and Analyzing In-context Learning, Fine-tuning and Supervised Learning for Biomedical Knowledge Curation: a focused study on chemical entities of biological interest",http://arxiv.org/abs/2312.12989v1,"Automated knowledge curation for biomedical ontologies is key to ensure thatthey remain comprehensive, high-quality and up-to-date. In the era offoundational language models, this study compares and analyzes three NLPparadigms for curation tasks: in-context learning (ICL), fine-tuning (FT), andsupervised learning (ML). Using the Chemical Entities of Biological Interest(ChEBI) database as a model ontology, three curation tasks were devised. ForICL, three prompting strategies were employed with GPT-4, GPT-3.5, BioGPT.PubmedBERT was chosen for the FT paradigm. For ML, six embedding models wereutilized for training Random Forest and Long-Short Term Memory models. Fivesetups were designed to assess ML and FT model performance across differentdata availability scenarios.Datasets for curation tasks included: task 1(620,386), task 2 (611,430), and task 3 (617,381), maintaining a 50:50 positiveversus negative ratio. For ICL models, GPT-4 achieved best accuracy scores of0.916, 0.766 and 0.874 for tasks 1-3 respectively. In a direct comparison, ML(trained on ~260,000 triples) outperformed ICL in accuracy across all tasks.(accuracy differences: +.11, +.22 and +.17). Fine-tuned PubmedBERT performedsimilarly to leading ML models in tasks 1 & 2 (F1 differences: -.014 and+.002), but worse in task 3 (-.048). Simulations revealed performance declinesin both ML and FT models with smaller and higher imbalanced training data.where ICL (particularly GPT-4) excelled in tasks 1 & 3. GPT-4 excelled in tasks1 and 3 with less than 6,000 triples, surpassing ML/FT. ICL underperformedML/FT in task 2.ICL-augmented foundation models can be good assistants forknowledge curation with correct prompting, however, not making ML and FTparadigms obsolete. The latter two require task-specific data to beat ICL. Insuch cases, ML relies on small pretrained embeddings, minimizing computationaldemands.",Emily Groves,2023/12/20,2023/12/20
2305.13299v1,Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations,http://arxiv.org/abs/2305.13299v1,"In-context learning (ICL) is an important paradigm for adapting largelanguage models (LLMs) to new tasks, but the generalization behavior of ICLremains poorly understood. We investigate the inductive biases of ICL from theperspective of feature bias: which feature ICL is more likely to use given aset of underspecified demonstrations in which two features are equallypredictive of the labels. First, we characterize the feature biases of GPT-3models by constructing underspecified demonstrations from a range of NLPdatasets and feature combinations. We find that LLMs exhibit clear featurebiases - for example, demonstrating a strong bias to predict labels accordingto sentiment rather than shallow lexical features, like punctuation. Second, weevaluate the effect of different interventions that are designed to impose aninductive bias in favor of a particular feature, such as adding a naturallanguage instruction or using semantically relevant label words. We find that,while many interventions can influence the learner to prefer a particularfeature, it can be difficult to overcome strong prior biases. Overall, ourresults provide a broader picture of the types of features that ICL may be morelikely to exploit and how to impose inductive biases that are better alignedwith the intended task.",Chenglei Si,2023/5/22,2023/5/22
0707.3014v1,Situations d'apprentissage collectives instrumentes : tude de pratiques dans l'enseignement suprieur,http://arxiv.org/abs/0707.3014v1,"Currently, educational platforms propose many tools of communication,production, labour division or collective work management in order to supportcollective activities. But it is not guaranteed that actors (instructionaldesigners, tutors or learner) are really using them. Our work, describecharacteristics of instrumented learning situations (ICLS) in the highereducation. Our intention is to determine: if ICLS are really existing; whichform they take (in terms of scenario, tools, type of activity...) ; ifrecommendations resulting from research tasks are taken into account byinstructional designers and if the instructional designer prescribed activitiesare really follow by learners or tutors? To answer these questions, we havemade a survey about ICLS actors uses.",Christine Michel,2007/7/20,2007/7/20
2305.19148v3,Mitigating Label Biases for In-context Learning,http://arxiv.org/abs/2305.19148v3,"Various design settings for in-context learning (ICL), such as the choice andorder of the in-context examples, can bias a model toward a particularprediction without being reflective of an understanding of the task. While manystudies discuss these design choices, there have been few systematicinvestigations into categorizing them and mitigating their impact. In thiswork, we define a typology for three types of label biases in ICL for textclassification: vanilla-label bias, context-label bias, and domain-label bias(which we conceptualize and detect for the first time).  Our analysis demonstrates that prior label bias calibration methods fallshort of addressing all three types of biases. Specifically, domain-label biasrestricts LLMs to random-level performance on many tasks regardless of thechoice of in-context examples. To mitigate the effect of these biases, wepropose a simple bias calibration method that estimates a language model'slabel bias using random in-domain words from the task corpus. After controllingfor this estimated bias when making predictions, our novel domain-contextcalibration significantly improves the ICL performance of GPT-J and GPT-3 on awide range of tasks. The gain is substantial on tasks with large domain-labelbias (up to 37% in Macro-F1). Furthermore, our results generalize to modelswith different scales, pretraining methods, and manually-designed taskinstructions, showing the prevalence of label biases in ICL.",Yu Fei,2023/5/28,2023/8/4
1812.04004v2,Dark Energy Survey Year 1 results: Detection of Intra-cluster Light at Redshift $\sim$ 0.25,http://arxiv.org/abs/1812.04004v2,"Using data collected by the Dark Energy Survey (DES), we report the detectionof intracluster light (ICL) with $\sim300$ galaxy clusters in the redshiftrange of 0.2-0.3. We design methods to mask detected galaxies and stars in theimages and stack the cluster light profiles, while accounting for severalsystematic effects (sky subtraction, instrumental point-spread function,cluster selection effects and residual light in the ICL raw detection frombackground and cluster galaxies). The methods allow us to acquire highsignal-to-noise measurements of the ICL and central galaxies (CGs), which weseparate with radial cuts. The ICL appears as faint and diffuse light extendingto at least 1 Mpc from the cluster center, reaching a surface brightness levelof 30 mag arcsec$^{-2}$. The ICL and the cluster CG contribute to $44\%\pm17$\%of the total cluster stellar luminosity within 1 Mpc. The ICL color is overallconsistent with that of the cluster red sequence galaxies, but displays thetrend of becoming bluer with increasing radius. The ICL demonstrates aninteresting self-similarity feature -- for clusters in different richnessranges, their ICL radial profiles are similar after scaling with cluster$R_\mathrm{200m}$, and the ICL brightness appears to be a good tracer of thecluster radial mass distribution. These analyses are based on the DES redMaPPercluster sample identified in the first year of observations.",Y. Zhang,2018/12/10,2019/4/15
2305.00886v1,"Designing Adaptive Developer-Chatbot Interactions: Context Integration, Experimental Studies, and Levels of Automation",http://arxiv.org/abs/2305.00886v1,"The growing demand for software developers and the increasing developmentcomplexity have emphasized the need for support in software engineeringprojects. This is especially relevant in light of advancements in artificialintelligence, such as conversational systems. A significant contributor to thecomplexity of software development is the multitude of tools and methods used,creating various contexts in which software developers must operate. Moreover,there has been limited investigation into the interaction between context-basedchatbots and software developers through experimental user studies. Assistingsoftware developers in their work becomes essential. In particular,understanding the context surrounding software development and integrating thiscontext into chatbots can lead to novel insight into what software developersexpect concerning these human-chatbot interactions and their levels ofautomation. In my research, I study the design of context-based adaptiveinteractions between software developers and chatbots to foster solutions andknowledge to support software developers at work.",Glaucia Melo,2023/5/1,2023/5/1
1808.01614v1,Using Machine Learning Safely in Automotive Software: An Assessment and Adaption of Software Process Requirements in ISO 26262,http://arxiv.org/abs/1808.01614v1,"The use of machine learning (ML) is on the rise in many sectors of softwaredevelopment, and automotive software development is no different. Inparticular, Advanced Driver Assistance Systems (ADAS) and Automated DrivingSystems (ADS) are two areas where ML plays a significant role. In automotivedevelopment, safety is a critical objective, and the emergence of standardssuch as ISO 26262 has helped focus industry practices to address safety in asystematic and consistent way. Unfortunately, these standards were not designedto accommodate technologies such as ML or the type of functionality that isprovided by an ADS and this has created a conflict between the need to innovateand the need to improve safety. In this report, we take steps to address thisconflict by doing a detailed assessment and adaption of ISO 26262 for ML,specifically in the context of supervised learning. First we analyze the keyfactors that are the source of the conflict. Then we assess each softwaredevelopment process requirement (Part 6 of ISO 26262) for applicability to ML.Where there are gaps, we propose new requirements to address the gaps. Finallywe discuss the application of this adapted and extended variant of Part 6 to MLdevelopment scenarios.",Rick Salay,2018/8/5,2018/8/5
2107.02279v2,Design Smells in Deep Learning Programs: An Empirical Study,http://arxiv.org/abs/2107.02279v2,"Nowadays, we are witnessing an increasing adoption of Deep Learning (DL)based software systems in many industries. Designing a DL program requiresconstructing a deep neural network (DNN) and then training it on a dataset.This process requires that developers make multiple architectural (e.g., type,size, number, and order of layers) and configuration (e.g., optimizer,regularization methods, and activation functions) choices that affect thequality of the DL models, and consequently software quality. An under-specifiedor poorly-designed DL model may train successfully but is likely to performpoorly when deployed in production. Design smells in DL programs are poordesign and-or configuration decisions taken during the development of DLcomponents, that are likely to have a negative impact on the performance (i.e.,prediction accuracy) and then quality of DL based software systems. In thispaper, we present a catalogue of 8 design smells for a popular DL architecture,namely deep Feedforward Neural Networks which is widely employed in industrialapplications. The design smells were identified through a review of theexisting literature on DL design and a manual inspection of 659 DL programswith performance issues and design inefficiencies. The smells are specified bydescribing their context, consequences, and recommended refactorings. Toprovide empirical evidence on the relevance and perceived impact of theproposed design smells, we conducted a survey with 81 DL developers. Ingeneral, the developers perceived the proposed design smells as reflective ofdesign or implementation problems, with agreement levels varying between 47\%and 68\%.",Amin Nikanjam,2021/7/5,2021/7/7
1802.02663v1,A Patterns Based Approach for Design of Educational Technologies,http://arxiv.org/abs/1802.02663v1,"Instructional design is a fundamental base for educational technologies as itlays the foundation to facilitate learning and teaching based on pedagogicalunderpinnings. However, most of the educational technologies today face twocore challenges in this context: (i) lack of instructional design as a basis(ii) lack of support for a variety of instructional designs. In order toaddress these challenges, we propose a patterns based approach for design ofeducational technologies. This is in contrast with existing literature thatfocuses either on patterns in education or in software, and not both. The coreidea of our approach is to leverage patterns for modeling instructional designknowledge and to connect it with patterns in software architecture. We discussdifferent categories of patterns in instructional design. We then present thenotion of Pattern-Oriented Instructional Design (POID) as a way to modelinstructional design as a connection of patterns (GoalPattern, ProcessPattern,ContentPattern) and integrate it with Pattern-Oriented Software Architecture(POSA) based on fundamental principles in software engineering. We demonstrateour approach through adult literacy case study (287 million learners, 22 IndianLanguages and a variety of instructional designs). The results of our approach(both web and mobile versions) are available at http://rice.iiit.ac.in and wereadopted by National Literacy Mission Authority of Government of India.",Sridhar Chimalakonda,2018/2/7,2018/2/7
2106.10901v1,"Conversational Agents in Software Engineering: Survey, Taxonomy and Challenges",http://arxiv.org/abs/2106.10901v1,"The use of natural language interfaces in the field of human-computerinteraction is undergoing intense study through dedicated scientific andindustrial research. The latest contributions in the field, including deeplearning approaches like recurrent neural networks, the potential ofcontext-aware strategies and user-centred design approaches, have brought backthe attention of the community to software-based dialogue systems, generallyknown as conversational agents or chatbots. Nonetheless, and given the noveltyof the field, a generic, context-independent overview on the current state ofresearch of conversational agents covering all research perspectives involvedis missing. Motivated by this context, this paper reports a survey of thecurrent state of research of conversational agents through a systematicliterature review of secondary studies. The conducted research is designed todevelop an exhaustive perspective through a clear presentation of theaggregated knowledge published by recent literature within a variety ofdomains, research focuses and contexts. As a result, this research proposes aholistic taxonomy of the different dimensions involved in the conversationalagents' field, which is expected to help researchers and to lay the groundworkfor future research in the field of natural language interfaces.",Quim Motger,2021/6/21,2021/6/21
1509.01872v1,Design Studio 2.0: Augmenting Reflective Architectural Design Learning,http://arxiv.org/abs/1509.01872v1,"Web 2.0 is beyond a jargon describing technological transformation: it refersto new strategies, tools and techniques that encourage and augment informed,creative and social inter(actions). When considered in an educational context,Web 2.0 provides various opportunities for enhanced integration and forimproving the learning processes in information-rich collaborative disciplinessuch as urban planning and architectural design. The dialogue between thedesign students and studio teachers can be mediated in various ways by creatingnovel learning spaces using Web 2.0-based social software and informationaggregation services, and brought to a level where the Web 2.0 environmentsupports, augments and enriches the reflective learning processes. We proposeto call this new setting Design Studio 2.0. We suggest that Design Studio 2.0can provide numerous opportunities which are not fully or easily available in aconventional design studio setting. In this context, we will introduce aweb-based geographic virtual environment model (GEO-VEM) and discuss how wereconfigured and rescaled this model with the objective of supporting aninternational urban design studio by encouraging students to make acollaborative and location-based analysis of a project site (theBrussels-Charleroi Canal). Pursuing the discussion further, we will present ourexperiences and observations of this design studio including web usestatistics, and the results of student attitude surveys. In conclusion, we willreflect the difficulties and challenges of using the GEO-VEM in the DesignStudio in a blended learning context and develop future prospects. As a result,we will introduce a set of key criteria for the development and implementationof an effective e-learning environment as a sustainable platform for supportingthe Design Studio 2.0.",Burak Pak,2015/9/7,2015/9/7
1309.0238v1,API design for machine learning software: experiences from the scikit-learn project,http://arxiv.org/abs/1309.0238v1,"Scikit-learn is an increasingly popular machine learning li- brary. Writtenin Python, it is designed to be simple and efficient, accessible tonon-experts, and reusable in various contexts. In this paper, we present anddiscuss our design choices for the application programming interface (API) ofthe project. In particular, we describe the simple and elegant interface sharedby all learning and processing units in the library and then discuss itsadvantages in terms of composition and reusability. The paper also comments onimplementation details specific to the Python ecosystem and analyzes obstaclesfaced by users and developers of the library.",Lars Buitinck,2013/9/1,2013/9/1
2209.15517v2,Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study,http://arxiv.org/abs/2209.15517v2,"The large-scale pre-trained vision language models (VLM) have shownremarkable domain transfer capability on natural images. However, it remainsunknown whether this capability can also apply to the medical image domain.This paper thoroughly studies the knowledge transferability of pre-trained VLMsto the medical domain, where we show that well-designed medical prompts are thekey to elicit knowledge from pre-trained VLMs. We demonstrate that by promptingwith expressive attributes that are shared between domains, the VLM can carrythe knowledge across domains and improve its generalization. This mechanismempowers VLMs to recognize novel objects with fewer or without image samples.Furthermore, to avoid the laborious manual designing process, we develop threeapproaches for automatic generation of medical prompts, which can injectexpert-level medical knowledge and image-specific information into the promptsfor fine-grained grounding. We conduct extensive experiments on thirteendifferent medical datasets across various modalities, showing that ourwell-designed prompts greatly improve the zero-shot performance compared to thedefault prompts, and our fine-tuned models surpass the supervised models by asignificant margin.",Ziyuan Qin,2022/9/30,2023/2/7
2205.05313v1,Towards Unified Prompt Tuning for Few-shot Text Classification,http://arxiv.org/abs/2205.05313v1,"Prompt-based fine-tuning has boosted the performance of Pre-trained LanguageModels (PLMs) on few-shot text classification by employing task-specificprompts. Yet, PLMs are unfamiliar with prompt-style expressions duringpre-training, which limits the few-shot learning performance on downstreamtasks. It would be desirable if the models can acquire some prompting knowledgebefore adaptation to specific NLP tasks. We present the Unified Prompt Tuning(UPT) framework, leading to better few-shot text classification for BERT-stylemodels by explicitly capturing prompting semantics from non-target NLPdatasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed forjoint prompt learning across different NLP tasks, forcing PLMs to capturetask-invariant prompting knowledge. We further design a self-supervised tasknamed Knowledge-enhanced Selective Masked Language Modeling to improve thePLM's generalization abilities for accurate adaptation to previously unseentasks. After multi-task learning across multiple tasks, the PLM can be betterprompt-tuned towards any dissimilar target tasks in low-resourced settings.Experiments over a variety of NLP tasks show that UPT consistently outperformsstate-of-the-arts for prompt-based fine-tuning.",Jianing Wang,2022/5/11,2022/5/11
cs/0701200v1,Reasoning from a schema and from an analog in software code reuse,http://arxiv.org/abs/cs/0701200v1,"The activity of design involves the decomposition of problems intosubproblems and the development and evaluation of solutions. In many cases,solution development is not done from scratch. Designers often evoke and adaptsolutions developed in the past. These solutions may come from an internalsource, i.e. the memory of the designers, and/or from an external source. Thegoal of this paper is to analyse the characteristics of the cognitivemechanisms, the knowledge and the representations involved in the code reuseactivity performed by experienced programmers. More generally, the focus is thecontrol structure of the reuse activity. Data collected in an experiment inwhich programmers had to design programs are analyzed. Two code reusesituations are distinguished depending on whether or not the processes involvedin reuse start before the elaboration of what acts as a source-solution. Ouranalysis highlights the use of reasoning from a schema and from an analog inthe code reuse activity.",Franoise Detienne,2007/1/31,2007/1/31
1105.3486v1,Xapagy: a cognitive architecture for narrative reasoning,http://arxiv.org/abs/1105.3486v1,"We introduce the Xapagy cognitive architecture: a software system designed toperform narrative reasoning. The architecture has been designed from scratch tomodel and mimic the activities performed by humans when witnessing, reading,recalling, narrating and talking about stories.",Ladislau Blni,2011/5/17,2011/5/17
2208.06393v1,Autonomous Intelligent Software Development,http://arxiv.org/abs/2208.06393v1,"We present an overview of the design and first proof-of-conceptimplementation for AIDA, an autonomous intelligent developer agent thatdevelops software from scratch. AIDA takes a software requirementsspecification and uses reasoning over a semantic knowledge graph to interpretthe requirements, then designs and writes software to satisfy them. AIDA usesboth declarative and procedural knowledge in the core domains of data,algorithms, and code, plus some general knowledge. The reasoning codebase usesthis knowledge to identify needed components, then designs and builds thenecessary information structures around them that become the software. Thesestructures, the motivating requirements, and the resulting source code itselfare all new knowledge that are added to the knowledge graph, becoming availablefor future reasoning. In this way, AIDA also learns as she writes code andbecomes more efficient when writing subsequent code.",Mark Alan Matties,2022/8/12,2022/8/12
1001.4193v1,Studying the Feasibility and Importance of Software Testing: An Analysis,http://arxiv.org/abs/1001.4193v1,"Software testing is a critical element of software quality assurance andrepresents the ultimate review of specification, design and coding. Softwaretesting is the process of testing the functionality and correctness of softwareby running it. Software testing is usually performed for one of two reasons:defect detection, and reliability estimation. The problem of applying softwaretesting to defect detection is that software can only suggest the presence offlaws, not their absence (unless the testing is exhaustive). The problem ofapplying software testing to reliability estimation is that the inputdistribution used for selecting test cases may be flawed. The key to softwaretesting is trying to find the modes of failure - something that requiresexhaustively testing the code on all possible inputs. Software Testing,depending on the testing method employed, can be implemented at any time in thedevelopment process.",S. S. Riaz Ahamed,2010/1/23,2010/1/23
2106.09237v1,Towards Assurance-Driven Architectural Decomposition of Software Systems,http://arxiv.org/abs/2106.09237v1,"Computer systems are so complex, so they are usually designed and analyzed interms of layers of abstraction. Complexity is still a challenge facing logicalreasoning tools that are used to find software design flaws and implementationbugs. Abstraction is also a common technique for scaling those tools to morecomplex systems. However, the abstractions used in the design phase of systemsare in many cases different from those used for assurance. In this paper weargue that different software quality assurance techniques operate on differentaspects of software systems. To facilitate assurance, and for a smoothintegration of assurance tools into the Software Development Lifecycle (SDLC),we present a 4-dimensional meta-architecture that separates computational,coordination, and stateful software artifacts early on in the design stage. Weenumerate some of the design and assurance challenges that can be addressed bythis meta-architecture, and demonstrate it on the high-level design of a simplefile system.",Ramy Shahin,2021/6/17,2021/6/17
2110.03806v2,Toward a Theory of Programming Language and Reasoning Assistant Design: Minimizing Cognitive Load,http://arxiv.org/abs/2110.03806v2,"Current approaches to making programming languages and reasoning assistantsmore effective for people focus on leveraging feedback from users and onevaluating the success of particular techniques. These approaches, althoughhelpful, may not result in systems that are as usable as possible, and may notlead to general design principles. This paper advocates for leveraging theoriesfrom cognitive science, focusing on cognitive load theory, to design moreeffective programming languages and reasoning assistants. Development of thesetheories may enable designers to create more effective programming languagesand reasoning assistants at lower cost.",Michael Coblenz,2021/10/7,2021/10/24
1505.06658v1,PopED lite: an optimal design software for preclinical pharmacokinetic and pharmacodynamic studies,http://arxiv.org/abs/1505.06658v1,"Optimal experimental design approaches are seldom used in pre-clinical drugdiscovery. Main reasons for this lack of use are that available software toolsrequire relatively high insight in optimal design theory, and that thedesign-execution cycle of in vivo experiments is short, making time-consumingoptimizations infeasible. We present the publicly available software PopED litein order to increase the use of optimal design in pre-clinical drug discovery.PopED lite is designed to be simple, fast and intuitive. Simple, to give manyusers access to basic optimal design calculations. Fast, to fit the shortdesign-execution cycle and allow interactive experimental design (test onedesign, discuss proposed design, test another design, etc). Intuitive, so thatthe input to and output from the software can easily be understood by userswithout knowledge of the theory of optimal design. In this way, PopED lite ishighly useful in practice and complements existing tools. Key functionality ofPopED lite is demonstrated by three case studies from real drug discoveryprojects.",Yasunori Aoki,2015/5/25,2015/5/25
2302.06038v1,Towards Understanding Provenance in Industry,http://arxiv.org/abs/2302.06038v1,"Context: Trustworthiness of software has become a first-class concern ofusers (e.g., to understand software-made decisions). Also, there is increasingdemand to demonstrate regulatory compliance of software and end users want tounderstand how software-intensive systems make decisions that affect them.Objective: We aim to provide a step towards understanding provenance needs ofthe software industry to support trustworthy software. Provenance isinformation about entities, activities, and people involved in producing data,software, or output of software, and used to assess software quality,reliability and trustworthiness of digital products and services. Method: Basedon data from in-person and questionnaire-based interviews with professionals inleadership roles we develop an ``influence map'' to analyze who drivesprovenance, when provenance is relevant, what is impacted by provenance and howprovenance can be managed. Results: The influence map helps decision makersnavigate concerns related to provenance. It can also act as a checklist forinitial provenance analyses of systems. It is empirically-grounded and designedbottom-up (based on perceptions of practitioners) rather than top-down (fromregulations or policies). Conclusion: We present an imperfect first steptowards understanding provenance based on current perceptions and offer apreliminary view ahead.",Matthias Galster,2023/2/13,2023/2/13
1006.5804v1,Observation-Driven Configuration of Complex Software Systems,http://arxiv.org/abs/1006.5804v1,"The ever-increasing complexity of software systems makes them hard tocomprehend, predict and tune due to emergent properties and non-deterministicbehaviour. Complexity arises from the size of software systems and the widevariety of possible operating environments: the increasing choice of platformsand communication policies leads to ever more complex performancecharacteristics. In addition, software systems exhibit different behaviourunder different workloads. Many software systems are designed to beconfigurable so that policies can be chosen to meet the needs of variousstakeholders. For complex software systems it can be difficult to accuratelypredict the effects of a change and to know which configuration is mostappropriate. This thesis demonstrates that it is useful to run automatedexperiments that measure a selection of system configurations. Experiments canfind configurations that meet the stakeholders' needs, find interestingbehavioural characteristics, and help produce predictive models of the system'sbehaviour. The design and use of ACT (Automated Configuration Tool) for runningsuch experiments is described, in combination a number of search strategies fordeciding on the configurations to measure. Design Of Experiments (DOE) isdiscussed, with emphasis on Taguchi Methods. These statistical methods havebeen used extensively in manufacturing, but have not previously been used forconfiguring software systems. The novel contribution here is an industrial casestudy, applying the combination of ACT and Taguchi Methods to DC-Directory, aproduct from Data Connection Ltd (DCL). The case study investigated theapplicability of Taguchi Methods for configuring complex software systems.Taguchi Methods were found to be useful for modelling and configuring DC-Directory, making them a valuable addition to the techniques available tosystem administrators and developers.",Aled Sage,2010/6/30,2010/6/30
1610.09240v1,Software Architecture Decision-Making Practices and Challenges: An Industrial Case Study,http://arxiv.org/abs/1610.09240v1,"Software architecture decision-making is critical to the success of asoftware system as software architecture sets the structure of the system,determines its qualities, and has far-reaching consequences throughout thesystem life cycle. The complex nature of the software development context andthe importance of the problem has led the research community to develop severaltechniques, tools, and processes to assist software architects in making betterdecisions. Despite these effort, the adoption of such systematic approachesappears to be quite limited in practice. In addition, the practitioners arealso facing new challenges as different software development methods suggestdifferent approaches for architecture design. In this paper, we study thecurrent software architecture decision-making practices in the industry using acase study conducted among professional software architects in three differentcompanies in Europe. As a result, we identified different software architecturedecision-making practices followed by the software teams as well as theirreasons for following them, the challenges associated with them, and thepossible improvements from the software architects' point of view. Based onthat, we recognized that improving software architecture knowledge managementcan address most of the identified challenges and would result in bettersoftware architecture decision-making.",Sandun Dasanayake,2016/10/28,2016/10/28
1703.06590v1,Proceedings International Workshop on Formal Engineering approaches to Software Components and Architectures,http://arxiv.org/abs/1703.06590v1,"These are the proceedings of the 14th International Workshop on FormalEngineering approaches to Software Components and Architectures (FESCA). Theworkshop was held on April 22, 2017 in Uppsala (Sweden) as a satellite event tothe European Joint Conference on Theory and Practice of Software (ETAPS'17).  The aim of the FESCA workshop is to bring together junior researchers fromformal methods, software engineering, and industry interested in thedevelopment and application of formal modelling approaches as well asassociated analysis and reasoning techniques with practical benefits forsoftware engineering.  In recent years, the growing importance of functional correctness and theincreased relevance of system quality properties (e.g. performance,reliability, security) have stimulated the emergence of analytical andmodelling techniques for the design and development of software systems. Withthe increasing complexity and utilization of today's software systems, FESCAaims at addressing two research questions: (1) what role is played by thesoftware design phase in the systematic addressing of the analytical andmodelling challenges, and (2) how can formal and semi-formal techniques beeffectively applied to make the issues easier to address automatically, withlower human intervention.",Jan Kofro,2017/3/20,2017/3/20
1603.08371v1,Proceedings of the 13th International Workshop on Formal Engineering Approaches to Software Components and Architectures,http://arxiv.org/abs/1603.08371v1,"The aim of the FESCA workshop is to bring together junior researchers fromformal methods, software engineering, and industry interested in thedevelopment and application of formal modelling approaches as well asassociated analysis and reasoning techniques with practical benefits forsoftware engineering.  In recent years, the growing importance of functional correctness and theincreased relevance of system quality properties (e.g. performance,reliability, security) have stimulated the emergence of analytical andmodelling techniques for the design and development of software systems. Withthe increasing complexity and utilization of today's software systems, FESCAaims at addressing two research questions: (1) what role is played by thesoftware design phase in the systematic addressing of the analytical andmodelling challenges, and (2) how can formal and semi-formal techniques beeffectively applied to make the issues easier to address automatically, withlower human intervention. We encourage submissions on (semi-)formal techniquesand their application that aid analysis, design and implementation of softwareapplications, especially those employed in interconnected, communicatingdevices, devices interacting with the physical world, and cyber-physicalsystems.",Jana Kofro,2016/3/28,2016/3/28
2004.00268v1,The Impact of Dynamics of Collaborative Software Engineering on Introverts: A Study Protocol,http://arxiv.org/abs/2004.00268v1,"Background: Collaboration among software engineers through face-to-facediscussions in teams has been promoted since the adoption of agile methods.However, these discussions might demote the contribution of software engineerswho are introverts, possibly leading to sub-optimal solutions and creating workenvironments that benefit extroverts. Objective: We aim to evaluate whetherproviding software engineers with time to work individually and reason about acollective problem is a setting that makes introverts more comfortable tointeract and contribute more, ultimately leading to better solutions. Method:We plan to conduct a between-subjects study, with teams in a control group thatdesign a software architecture in a team discussion meeting and teams in atreatment group in which subjects work individually before engaging in ameeting. We will assess and compare the amount of contribution of introverts,their subjective experiences, and the designed solutions. Limitations: Asextroverts will be present in both groups, we will not be able to conclude thatbetter solutions are solely due to the increased participation of introverts.The analyses of their subjective experience and amount of contributions mightprovide evidence to suggest the reasons for observed differences.",Ingrid Nunes,2020/4/1,2020/4/1
2007.01239v1,Tracking with A Common Tracking Software,http://arxiv.org/abs/2007.01239v1,"In high energy physics (HEP) experiments, the reconstruction of chargedparticle trajectories is one of the most fundamental yet computationallyexpensive parts of event processing. At future hadron colliders such as theHigh-Luminosity Large Hadron Collider (HL-LHC), there can be up to ten thousandparticles per event. This increases the track reconstruction time by a factorabout 5 compared to the current tracking environment. Efficient and fasttracking software is necessary to maintain and improve the trackingperformance. This can benefit from both fast tracking algorithms and moderncomputing architectures with many cores and accelerators.  The Acts (A Common Tracking Software) project encapsulates the current ATLAStracking software into an experiment-independent software designed for moderncomputing architectures. It provides a set of high-level track reconstructiontools agnostic to the details of the detector and magnetic field configuration.Particular emphasis is placed on thread-safety of the code in order to supportconcurrent event processing with context-dependent detector conditions, such asdetector alignments or calibrations. Acts aims in addition to be a research anddevelopment platform for studying innovative tracking techniques and exploitingmodern hardware architectures.",Xiaocong Ai,2020/7/2,2020/7/2
2309.07639v1,Do Not Give Away My Secrets: Uncovering the Privacy Issue of Neural Code Completion Tools,http://arxiv.org/abs/2309.07639v1,"Neural Code Completion Tools (NCCTs) have reshaped the field of softwaredevelopment, which accurately suggest contextually-relevant code snippetsbenefiting from language modeling techniques. However, language models may emitthe training data verbatim during inference with appropriate prompts. Thismemorization property raises privacy concerns of commercial NCCTs about thehard-coded credential leakage, leading to unauthorized access to systems.Therefore, to answer whether NCCTs will inadvertently emit the hard-codedcredential, we propose an evaluation tool called Hard-coded Credential Revealer(HCR). HCR effectively constructs test prompts from GitHub code files withcredentials to trigger memorization phenomenon of commercial NCCTs. Then, HCRextracts credentials with pre-defined format from the responses by fourdesigned filters. We apply HCR to evaluate two representative commercial NCCTs:GitHub Copilot and Amazon CodeWhisperer and successfully extracted 2,702hard-coded credentials from Copilot and 129 secrets from CodeWhisper under theblack-box setting, among which at least 3.6% and 5.4% secrets are real stringsfrom GitHub repositories. Moreover, two operational credentials wereidentified. The experimental results raise the severe privacy concern of thepotential leakage of hard-coded credentials in the training data of commercialNCCTs.",Yizhan Huang,2023/9/14,2023/9/14
2305.11334v1,Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs,http://arxiv.org/abs/2305.11334v1,"We introduce two novel methods, Tree-Search and Self-contextualizing QA,designed to enhance the performance of large language models (LLMs) inquestion-answering tasks. Tree-Search is a sampling technique specificallycreated to extract diverse information from an LLM for a given prompt.Self-contextualizing QA leverages Tree-Search to enable the model to create itsown context using a wide range of information relevant to the prompt, evaluateit explicitly and return a open book answer to the initial prompt . Wedemonstrate that the quality of generated answers improves according to variousmetrics, including accuracy, informativeness, coherence, and consistency, asevaluated by GPT3.5(text-davinci-003). Furthermore, we show that our methodsresult in increased robustness and that performance is positively correlatedwith tree size, benefiting both answer quality and robustness. Finally, wediscuss other promising applications of Tree-Search, highlighting its potentialto enhance a broad range of tasks beyond question-answering.  \noindent We also discuss several areas for future work, including refiningthe Tree-Search and Self-Contextualizing QA methods, improving the coherence ofthe generated context, and investigating the impact of bootstrapping on modelrobustness",Giorgi Kokaia,2023/5/18,2023/5/18
2210.13573v2,Conditionally Risk-Averse Contextual Bandits,http://arxiv.org/abs/2210.13573v2,"Contextual bandits with average-case statistical guarantees are inadequate inrisk-averse situations because they might trade off degraded worst-casebehaviour for better average performance. Designing a risk-averse contextualbandit is challenging because exploration is necessary but risk-aversion issensitive to the entire distribution of rewards; nonetheless we exhibit thefirst risk-averse contextual bandit algorithm with an online regret guarantee.We conduct experiments from diverse scenarios where worst-case outcomes shouldbe avoided, from dynamic pricing, inventory management, and self-tuningsoftware; including a production exascale data processing system.",Mnika Farsang,2022/10/24,2023/7/8
2206.13214v1,Few-Shot Stance Detection via Target-Aware Prompt Distillation,http://arxiv.org/abs/2206.13214v1,"Stance detection aims to identify whether the author of a text is in favorof, against, or neutral to a given target. The main challenge of this taskcomes two-fold: few-shot learning resulting from the varying targets and thelack of contextual information of the targets. Existing works mainly focus onsolving the second issue by designing attention-based models or introducingnoisy external knowledge, while the first issue remains under-explored. In thispaper, inspired by the potential capability of pre-trained language models(PLMs) serving as knowledge bases and few-shot learners, we propose tointroduce prompt-based fine-tuning for stance detection. PLMs can provideessential contextual information for the targets and enable few-shot learningvia prompts. Considering the crucial role of the target in stance detectiontask, we design target-aware prompts and propose a novel verbalizer. Instead ofmapping each label to a concrete word, our verbalizer maps each label to avector and picks the label that best captures the correlation between thestance and the target. Moreover, to alleviate the possible defect of dealingwith varying targets with a single hand-crafted prompt, we propose to distillthe information learned from multiple prompts. Experimental results show thesuperior performance of our proposed model in both full-data and few-shotscenarios.",Yan Jiang,2022/6/27,2022/6/27
2210.15843v1,Bi-Directional Iterative Prompt-Tuning for Event Argument Extraction,http://arxiv.org/abs/2210.15843v1,"Recently, prompt-tuning has attracted growing interests in event argumentextraction (EAE). However, the existing prompt-tuning methods have not achievedsatisfactory performance due to the lack of consideration of entityinformation. In this paper, we propose a bi-directional iterative prompt-tuningmethod for EAE, where the EAE task is treated as a cloze-style task to takefull advantage of entity information and pre-trained language models (PLMs).Furthermore, our method explores event argument interactions by introducing theargument roles of contextual entities into prompt construction. Since templateand verbalizer are two crucial components in a cloze-style prompt, we proposeto utilize the role label semantic knowledge to construct a semantic verbalizerand design three kinds of templates for the EAE task. Experiments on the ACE2005 English dataset with standard and low-resource settings show that theproposed method significantly outperforms the peer state-of-the-art methods.Our code is available at https://github.com/HustMinsLab/BIP.",Lu Dai,2022/10/28,2022/10/28
2208.04135v1,Adversarial Attacks on Image Generation With Made-Up Words,http://arxiv.org/abs/2208.04135v1,"Text-guided image generation models can be prompted to generate images usingnonce words adversarially designed to robustly evoke specific visual concepts.Two approaches for such generation are introduced: macaronic prompting, whichinvolves designing cryptic hybrid words by concatenating subword units fromdifferent languages; and evocative prompting, which involves designing noncewords whose broad morphological features are similar enough to that of existingwords to trigger robust visual associations. The two methods can also becombined to generate images associated with more specific visual concepts. Theimplications of these techniques for the circumvention of existing approachesto content moderation, and particularly the generation of offensive or harmfulimages, are discussed.",Raphal Millire,2022/8/4,2022/8/4
2211.01761v1,PromptEHR: Conditional Electronic Healthcare Records Generation with Prompt Learning,http://arxiv.org/abs/2211.01761v1,"Accessing longitudinal multimodal Electronic Healthcare Records (EHRs) ischallenging due to privacy concerns, which hinders the use of ML for healthcareapplications. Synthetic EHRs generation bypasses the need to share sensitivereal patient records. However, existing methods generate single-modal EHRs byunconditional generation or by longitudinal inference, which falls short of lowflexibility and makes unrealistic EHRs. In this work, we propose to formulateEHRs generation as a text-to-text translation task by language models (LMs),which suffices to highly flexible event imputation during generation. We alsodesign prompt learning to control the generation conditioned by numerical andcategorical demographic features. We evaluate synthetic EHRs quality by twoperplexity measures accounting for their longitudinal pattern (longitudinalimputation perplexity, lpl) and the connections cross modalities(cross-modality imputation perplexity, mpl). Moreover, we utilize twoadversaries: membership and attribute inference attacks for privacy-preservingevaluation. Experiments on MIMIC-III data demonstrate the superiority of ourmethods on realistic EHRs generation (53.1\% decrease of lpl and 45.3\%decrease of mpl on average compared to the best baselines) with low privacyrisks. Software is available at https://github.com/RyanWangZf/PromptEHR.",Zifeng Wang,2022/10/11,2022/10/11
2203.10714v1,A Prompting-based Approach for Adversarial Example Generation and Robustness Enhancement,http://arxiv.org/abs/2203.10714v1,"Recent years have seen the wide application of NLP models in crucial areassuch as finance, medical treatment, and news media, raising concerns of themodel robustness and vulnerabilities. In this paper, we propose a novelprompt-based adversarial attack to compromise NLP models and robustnessenhancement technique. We first construct malicious prompts for each instanceand generate adversarial examples via mask-and-filling under the effect of amalicious purpose. Our attack technique targets the inherent vulnerabilities ofNLP models, allowing us to generate samples even without interacting with thevictim NLP model, as long as it is based on pre-trained language models (PLMs).Furthermore, we design a prompt-based adversarial training method to improvethe robustness of PLMs. As our training method does not actually generateadversarial samples, it can be applied to large-scale training setsefficiently. The experimental results show that our attack method can achieve ahigh attack success rate with more diverse, fluent and natural adversarialexamples. In addition, our robustness enhancement method can significantlyimprove the robustness of models to resist adversarial attacks. Our workindicates that prompting paradigm has great potential in probing somefundamental flaws of PLMs and fine-tuning them for downstream tasks.",Yuting Yang,2022/3/21,2022/3/21
2205.02963v1,Privacy-from-Birth: Protecting Sensed Data from Malicious Sensors with VERSA,http://arxiv.org/abs/2205.02963v1,"There are many well-known techniques to secure sensed data in IoT/CPSsystems, e.g., by authenticating communication end-points, encrypting databefore transmission, and obfuscating traffic patterns. Such techniques protectsensed data from external adversaries while assuming that the sensing deviceitself is secure. Meanwhile, both the scale and frequency of IoT-focusedattacks are growing. This prompts a natural question: how to protect senseddata even if all software on the device is compromised? Ideally, in order toachieve this, sensed data must be protected from its genesis, i.e., from thetime when a physical analog quantity is converted into its digital counterpartand becomes accessible to software. We refer to this property as PfB:Privacy-from-Birth.  In this work, we formalize PfB and design Verified Remote SensingAuthorization (VERSA) -- a provably secure and formally verified architectureguaranteeing that only correct execution of expected and explicitly authorizedsoftware can access and manipulate sensing interfaces, specifically, GeneralPurpose Input/Output (GPIO), which is the usual boundary between analog anddigital worlds on IoT devices. This guarantee is obtained with minimal hardwaresupport and holds even if all device software is compromised. VERSA ensuresthat malware can neither gain access to sensed data on the GPIO-mapped memorynor obtain any trace thereof. VERSA is formally verified and its open-sourcedimplementation targets resource-constrained IoT edge devices, commonly used forsensing. Experimental results show that PfB is both achievable and affordablefor such devices.",Ivan De Oliveira Nunes,2022/5/5,2022/5/5
2401.08725v1,Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks,http://arxiv.org/abs/2401.08725v1,"Recent developments in text-to-image models, particularly Stable Diffusion,have marked significant achievements in various applications. With theseadvancements, there are growing safety concerns about the vulnerability of themodel that malicious entities exploit to generate targeted harmful images.However, the existing methods in the vulnerability of the model mainly evaluatethe alignment between the prompt and generated images, but fall short inrevealing the vulnerability associated with targeted image generation. In thisstudy, we formulate the problem of targeted adversarial attack on StableDiffusion and propose a framework to generate adversarial prompts.Specifically, we design a gradient-based embedding optimization method to craftreliable adversarial prompts that guide stable diffusion to generate specificimages. Furthermore, after obtaining successful adversarial prompts, we revealthe mechanisms that cause the vulnerability of the model. Extensive experimentson two targeted attack tasks demonstrate the effectiveness of our method intargeted attacks. The code can be obtained inhttps://github.com/datar001/Revealing-Vulnerabilities-in-Stable-Diffusion-via-Targeted-Attacks.",Chenyu Zhang,2024/1/16,2024/1/16
2303.14773v2,BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning,http://arxiv.org/abs/2303.14773v2,"With the surge of large-scale pre-trained models (PTMs), fine-tuning thesemodels to numerous downstream tasks becomes a crucial problem. Consequently,parameter efficient transfer learning (PETL) of large models has grasped hugeattention. While recent PETL methods showcase impressive performance, they relyon optimistic assumptions: 1) the entire parameter set of a PTM is available,and 2) a sufficiently large memory capacity for the fine-tuning is equipped.However, in most real-world applications, PTMs are served as a black-box API orproprietary software without explicit parameter accessibility. Besides, it ishard to meet a large memory requirement for modern PTMs. In this work, wepropose black-box visual prompting (BlackVIP), which efficiently adapts thePTMs without knowledge about model architectures and parameters. BlackVIP hastwo components; 1) Coordinator and 2) simultaneous perturbation stochasticapproximation with gradient correction (SPSA-GC). The Coordinator designsinput-dependent image-shaped visual prompts, which improves few-shot adaptationand robustness on distribution/location shift. SPSA-GC efficiently estimatesthe gradient of a target model to update Coordinator. Extensive experiments on16 datasets demonstrate that BlackVIP enables robust adaptation to diversedomains without accessing PTMs' parameters, with minimal memory requirements.Code: \url{https://github.com/changdaeoh/BlackVIP}",Changdae Oh,2023/3/26,2023/7/8
2309.07561v1,Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition,http://arxiv.org/abs/2309.07561v1,"Implicit discourse relation recognition (IDRR) aims at recognizing thediscourse relation between two text segments without an explicit connective.Recently, the prompt learning has just been applied to the IDRR task with greatperformance improvements over various neural network-based approaches. However,the discrete nature of the state-art-of-art prompting approach requires manualdesign of templates and answers, a big hurdle for its practical applications.In this paper, we propose a continuous version of prompt learning together withconnective knowledge distillation, called AdaptPrompt, to reduce manual designefforts via continuous prompting while further improving performance viaknowledge transfer. In particular, we design and train a few virtual tokens toform continuous templates and automatically select the most suitable one bygradient search in the embedding space. We also design an answer-relationmapping rule to generate a few virtual answers as the answer space.Furthermore, we notice the importance of annotated connectives in the trainingdataset and design a teacher-student architecture for knowledge transfer.Experiments on the up-to-date PDTB Corpus V3.0 validate our design objectivesin terms of the better relation recognition performance over thestate-of-the-art competitors.",Bang Wang,2023/9/14,2023/9/14
2401.08683v1,Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models,http://arxiv.org/abs/2401.08683v1,"The design and optimization of hardware have traditionally beenresource-intensive, demanding considerable expertise and dependence onestablished design automation tools. This paper discusses the possibility ofexploiting large language models to streamline the code generation process inhardware design. In contrast to earlier studies, this paper aims to use largelanguage models that accepts high-level design specifications through a singleprompt to generate corresponding Register-Transfer Level (RTL) code. Theability to use large language models on RTL code generation not only expeditesdesign iteration cycles but also facilitates the exploration of design spacesthat have computational challenges for conventional techniques. Through ourevaluation, we demonstrate the shortcoming of existing attention mechanisms,and present the abilities of language models to produce functional, optimized,and industry-standard compliant RTL code when a novel attention mechanism isused. These findings underscore the expanding role of large language models inshaping the future landscape of architectural exploration and automation inhardware design.",Selim Sandal,2024/1/12,2024/1/12
2307.08303v3,Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models,http://arxiv.org/abs/2307.08303v3,"Dense retrieval (DR) converts queries and documents into dense embeddings andmeasures the similarity between queries and documents in vector space. One ofthe challenges in DR is the lack of domain-specific training data. While DRmodels can learn from large-scale public datasets like MS MARCO throughtransfer learning, evidence shows that not all DR models and domains canbenefit from transfer learning equally. Recently, some researchers haveresorted to large language models (LLMs) to improve the zero-shot and few-shotDR models. However, the hard prompts or human-written prompts utilized in theseworks cannot guarantee the good quality of generated weak queries. To tacklethis, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,we leverage soft prompt-tuning to optimize a task-specific soft prompt onlimited ground truth data and then prompt the LLMs to tag unlabeled documentswith weak queries, yielding enough weak document-query pairs to traintask-specific dense retrievers. We design a filter to select high-qualityexample document-query pairs in the prompt to further improve the quality ofweak tagged queries. To the best of our knowledge, there is no prior workutilizing soft prompt tuning to augment DR models. The experiments demonstratethat SPTAR outperforms the unsupervised baselines BM25 and the recentlyproposed LLMs-based augmentation method for DR.",Zhiyuan Peng,2023/7/17,2023/8/29
2303.04998v2,Rethinking Visual Prompt Learning as Masked Visual Token Modeling,http://arxiv.org/abs/2303.04998v2,"Prompt learning has achieved great success in efficiently exploitinglarge-scale pre-trained models in natural language processing (NLP). Itreformulates the downstream tasks as the generative pre-training ones toachieve consistency, thus improving the performance stably. However, whentransferring it to the vision area, current visual prompt learning methods arealmost designed on discriminative pre-trained models, and there is also a lackof careful design to unify the forms of pre-training and downstream tasks. Toexplore prompt learning on the generative pre-trained visual model, as well askeeping the task consistency, we propose Visual Prompt learning as maskedvisual Token Modeling (VPTM) to transform the downstream visual classificationinto the pre-trained masked visual token prediction. In addition, we developthe prototypical verbalizer for mapping the predicted visual token withimplicit semantics to explicit downstream labels. To our best knowledge, VPTMis the first visual prompt method on the generative pre-trained visual model,which achieves consistency between pre-training and downstream visualclassification by task reformulation. Experiments show that VPTM outperformsother visual prompt methods and achieves excellent efficiency. Moreover, thetask consistency of VPTM contributes to the robustness against prompt location,prompt length and prototype dimension, and could be deployed uniformly.",Ning Liao,2023/3/9,2023/12/15
2310.06266v2,CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model,http://arxiv.org/abs/2310.06266v2,"Code Large Language Models (Code LLMs) have gained significant attention inthe industry due to their wide applications in the full lifecycle of softwareengineering. However, the effectiveness of existing models in understandingnon-English inputs for multi-lingual code-related tasks is still far from wellstudied. This paper introduces CodeFuse-13B, an open-sourced pre-trained codeLLM. It is specifically designed for code-related tasks with both English andChinese prompts and supports over 40 programming languages. CodeFuse achievesits effectiveness by utilizing a high quality pre-training dataset that iscarefully filtered by program analyzers and optimized during the trainingprocess. Extensive experiments are conducted using real-world usage scenarios,the industry-standard benchmark HumanEval-x, and the specially designedCodeFuseEval for Chinese prompts. To assess the effectiveness of CodeFuse, weactively collected valuable human feedback from the AntGroup's softwaredevelopment process where CodeFuse has been successfully deployed. The resultsdemonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%,positioning it as one of the top multi-lingual code LLMs with similar parametersizes. In practical scenarios, such as code generation, code translation, codecomments, and testcase generation, CodeFuse performs better than other modelswhen confronted with Chinese prompts.",Peng Di,2023/10/10,2024/1/10
1711.04216v1,"Coordination Technology for Active Support Networks: Context, Needfinding, and Design",http://arxiv.org/abs/1711.04216v1,"Coordination is a key problem for addressing goal-action gaps in many humanendeavors. We define interpersonal coordination as a type of communicativeaction characterized by low interpersonal belief and goal conflict. Suchsituations are particularly well described as having collectively""intelligent"", ""common good"" solutions, viz., ones that almost everyone wouldagree constitute social improvements. Coordination is useful across thespectrum of interpersonal communication -- from isolated individuals toorganizational teams. Much attention has been paid to coordination in teams andorganizations. In this paper we focus on the looser interpersonal structures wecall active support networks (ASNs), and on technology that meets their needs.We describe two needfinding investigations focused on social support, whichexamined (a) four application areas for improving coordination in ASNs: (i)academic coaching, (ii) vocational training, (iii) early learning intervention,and (iv) volunteer coordination; and (b) existing technology relevant to ASNs.We find a thus-far unmet need for personal task management software that allowssmooth integration with an individual's active support network. Based onidentified needs, we then describe an open architecture for coordination thathas been developed into working software. The design includes a set ofcapabilities we call ""social prompting,"" as well as templates for accomplishingmulti-task goals, and an engine that controls coordination in the network. Theresulting tool is currently available and in continuing development. We explainits use in ASNs with an example. Follow-up studies are underway in which thetechnology is being applied in existing support networks.",Stanley J. Rosenschein,2017/11/12,2017/11/12
2002.06306v1,Jelly Bean World: A Testbed for Never-Ending Learning,http://arxiv.org/abs/2002.06306v1,"Machine learning has shown growing success in recent years. However, currentmachine learning systems are highly specialized, trained for particularproblems or domains, and typically on a single narrow dataset. Human learning,on the other hand, is highly general and adaptable. Never-ending learning is amachine learning paradigm that aims to bridge this gap, with the goal ofencouraging researchers to design machine learning systems that can learn toperform a wider variety of inter-related tasks in more complex environments. Todate, there is no environment or testbed to facilitate the development andevaluation of never-ending learning systems. To this end, we propose the JellyBean World testbed. The Jelly Bean World allows experimentation overtwo-dimensional grid worlds which are filled with items and in which agents cannavigate. This testbed provides environments that are sufficiently complex andwhere more generally intelligent algorithms ought to perform better thancurrent state-of-the-art reinforcement learning approaches. It does so byproducing non-stationary environments and facilitating experimentation withmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hopethat this new freely-available software will prompt new research and interestin the development and evaluation of never-ending learning systems and morebroadly, general intelligence systems.",Emmanouil Antonios Platanios,2020/2/15,2020/2/15
2209.02748v1,Educating Educators to Integrate Inclusive Design Across a 4-Year CS Degree Program,http://arxiv.org/abs/2209.02748v1,"How can an entire CS faculty, who together have been teaching the ACMstandard CS curricula, shift to teaching elements of inclusive design across a4-year undergraduate CS program? And will they even want to try? To investigatethese questions, we developed an educate-the-educators curriculum to supportthis shift. The overall goal of the educate-the-educators curriculum was toenable CS faculty to creatively engage with embedding inclusive design intotheir courses in ""minimally invasive"" ways. GenderMag, an inclusive designevaluation method, was selected for use. The curriculum targeted the followinglearning outcomes: to enable CS faculty: (1) to analyze the costs and benefitsof integrating inclusive design into their own course(s); (2) to evaluatesoftware using the GenderMag method, and recognize its use to identifymeaningful issues in software; (3) to integrate inclusive design into existingcourse materials with provided resources and collaboration; and (4) to prepareto engage and guide students on learning GenderMag concepts. We conducted afield study over a spring/summer followed by end-of-fall interviews, duringwhich we worked with 18 faculty members to integrate inclusive design into 13courses. Ten of these faculty then taught 7 of these courses that were on theFall 2021 schedule, across 16 sections. We present the neweducate-the-educators curriculum and report on the faculty's experiences actingupon it over the three-month field study and subsequent interviews. Our resultsshowed that, of the 18 faculty we worked with, 83% chose to modify theircourses; by Fall 2021, faculty across all four years of a CS degree program hadbegun teaching inclusive design concepts. When we followed up with the 10 Fall2021 faculty, 91% of their reported outcomes indicated that the incorporationsof inclusive design concepts in their courses went as well as or better thanexpected.",Lara Letaw,2022/9/6,2022/9/6
1812.00285v1,Learning Curriculum Policies for Reinforcement Learning,http://arxiv.org/abs/1812.00285v1,"Curriculum learning in reinforcement learning is a training methodology thatseeks to speed up learning of a difficult target task, by first training on aseries of simpler tasks and transferring the knowledge acquired to the targettask. Automatically choosing a sequence of such tasks (i.e. a curriculum) is anopen problem that has been the subject of much recent work in this area. Inthis paper, we build upon a recent method for curriculum design, whichformulates the curriculum sequencing problem as a Markov Decision Process. Weextend this model to handle multiple transfer learning algorithms, and show forthe first time that a curriculum policy over this MDP can be learned fromexperience. We explore various representations that make this possible, andevaluate our approach by learning curriculum policies for multiple agents intwo different domains. The results show that our method produces curricula thatcan train agents to perform on a target task as fast or faster than existingmethods.",Sanmit Narvekar,2018/12/1,2018/12/1
1807.02400v2,Beyond Surveys: Analyzing Software Development Artifacts to Assess Teaching Efforts,http://arxiv.org/abs/1807.02400v2,"This Innovative Practice Full Paper presents an approach of using softwaredevelopment artifacts to gauge student behavior and the effectiveness ofchanges to curriculum design. There is an ongoing need to adapt universitycourses to changing requirements and shifts in industry. As an educator it istherefore vital to have access to methods, with which to ascertain the effectsof curriculum design changes. In this paper, we present our approach ofanalyzing software repositories in order to gauge student behavior duringproject work. We evaluate this approach in a case study of a universityundergraduate software development course teaching agile developmentmethodologies. Surveys revealed positive attitudes towards the course and thechange of employed development methodology from Scrum to Kanban. However,surveys were not usable to ascertain the degree to which students had adaptedtheir workflows and whether they had done so in accordance with course goals.Therefore, we analyzed students' software repository data, which representsinformation that can be collected by educators to reveal insights into learningsuccesses and detailed student behavior. We analyze the software repositoriescreated during the last five courses, and evaluate differences in workflowsbetween Kanban and Scrum usage.",Christoph Matthies,2018/7/6,2019/3/20
2110.03032v3,Learning Multi-Objective Curricula for Robotic Policy Learning,http://arxiv.org/abs/2110.03032v3,"Various automatic curriculum learning (ACL) methods have been proposed toimprove the sample efficiency and final performance of deep reinforcementlearning (DRL). They are designed to control how a DRL agent collects data,which is inspired by how humans gradually adapt their learning processes totheir capabilities. For example, ACL can be used for subgoal generation, rewardshaping, environment generation, or initial state generation. However, priorwork only considers curriculum learning following one of the aforementionedpredefined paradigms. It is unclear which of these paradigms are complementary,and how the combination of them can be learned from interactions with theenvironment. Therefore, in this paper, we propose a unified automaticcurriculum learning framework to create multi-objective but coherent curriculathat are generated by a set of parametric curriculum modules. Each curriculummodule is instantiated as a neural network and is responsible for generating aparticular curriculum. In order to coordinate those potentially conflictingmodules in unified parameter space, we propose a multi-task hyper-net learningframework that uses a single hyper-net to parameterize all those curriculummodules. In addition to existing hand-designed curricula paradigms, we furtherdesign a flexible memory mechanism to learn an abstract curriculum, which mayotherwise be difficult to design manually. We evaluate our method on a seriesof robotic manipulation tasks and demonstrate its superiority over otherstate-of-the-art ACL methods in terms of sample efficiency and finalperformance.",Jikun Kang,2021/10/6,2022/10/20
2312.04326v2,iDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image Diffusion Model for Interior Design,http://arxiv.org/abs/2312.04326v2,"With the open-sourcing of text-to-image models (T2I) such as stable diffusion(SD) and stable diffusion XL (SD-XL), there is an influx of models fine-tunedin specific domains based on the open-source SD model, such as in anime,character portraits, etc. However, there are few specialized models in certaindomains, such as interior design, which is attributed to the complex textualdescriptions and detailed visual elements inherent in design, alongside thenecessity for adaptable resolution. Therefore, text-to-image models forinterior design are required to have outstanding prompt-following capabilities,as well as iterative collaboration with design professionals to achieve thedesired outcome. In this paper, we collect and optimize text-image data in thedesign field and continue training in both English and Chinese on the basis ofthe open-source CLIP model. We also proposed a fine-tuning strategy withcurriculum learning and reinforcement learning from CLIP feedback to enhancethe prompt-following capabilities of our approach so as to improve the qualityof image generation. The experimental results on the collected datasetdemonstrate the effectiveness of the proposed approach, which achievesimpressive results and outperforms strong baselines.",Ruyi Gan,2023/12/7,2023/12/19
2302.05838v1,Maneuver Decision-Making For Autonomous Air Combat Through Curriculum Learning And Reinforcement Learning With Sparse Rewards,http://arxiv.org/abs/2302.05838v1,"Reinforcement learning is an effective way to solve the decision-makingproblems. It is a meaningful and valuable direction to investigate autonomousair combat maneuver decision-making method based on reinforcement learning.However, when using reinforcement learning to solve the decision-makingproblems with sparse rewards, such as air combat maneuver decision-making, itcosts too much time for training and the performance of the trained agent maynot be satisfactory. In order to solve these problems, the method based oncurriculum learning is proposed. First, three curricula of air combat maneuverdecision-making are designed: angle curriculum, distance curriculum and hybridcurriculum. These courses are used to train air combat agents respectively, andcompared with the original method without any curriculum. The training resultsshow that angle curriculum can increase the speed and stability of training,and improve the performance of the agent; distance curriculum can increase thespeed and stability of agent training; hybrid curriculum has a negative impacton training, because it makes the agent get stuck at local optimum. Thesimulation results show that after training, the agent can handle thesituations where targets come from different directions, and the maneuverdecision results are consistent with the characteristics of missile.",Yu-Jie Wei,2023/2/12,2023/2/12
2210.17368v1,Teacher-student curriculum learning for reinforcement learning,http://arxiv.org/abs/2210.17368v1,"Reinforcement learning (rl) is a popular paradigm for sequential decisionmaking problems. The past decade's advances in rl have led to breakthroughs inmany challenging domains such as video games, board games, robotics, and chipdesign. The sample inefficiency of deep reinforcement learning methods is asignificant obstacle when applying rl to real-world problems. Transfer learninghas been applied to reinforcement learning such that the knowledge gained inone task can be applied when training in a new task. Curriculum learning isconcerned with sequencing tasks or data samples such that knowledge can betransferred between those tasks to learn a target task that would otherwise betoo difficult to solve. Designing a curriculum that improves sample efficiencyis a complex problem. In this thesis, we propose a teacher-student curriculumlearning setting where we simultaneously train a teacher that selects tasks forthe student while the student learns how to solve the selected task. Our methodis independent of human domain knowledge and manual curriculum design. Weevaluated our methods on two reinforcement learning benchmarks: grid world andthe challenging Google Football environment. With our method, we can improvethe sample efficiency and generality of the student compared to tabula-rasareinforcement learning.",Yanick Schraner,2022/10/31,2022/10/31
2003.08593v3,Curriculum DeepSDF,http://arxiv.org/abs/2003.08593v3,"When learning to sketch, beginners start with simple and flexible shapes, andthen gradually strive for more complex and accurate ones in the subsequenttraining sessions. In this paper, we design a ""shape curriculum"" for learningcontinuous Signed Distance Function (SDF) on shapes, namely Curriculum DeepSDF.Inspired by how humans learn, Curriculum DeepSDF organizes the learning task inascending order of difficulty according to the following two criteria: surfaceaccuracy and sample difficulty. The former considers stringency in supervisingwith ground truth, while the latter regards the weights of hard trainingsamples near complex geometry and fine structure. More specifically, CurriculumDeepSDF learns to reconstruct coarse shapes at first, and then graduallyincreases the accuracy and focuses more on complex local details. Experimentalresults show that a carefully-designed curriculum leads to significantly bettershape reconstructions with the same training data, training epochs and networkarchitecture as DeepSDF. We believe that the application of shape curricula canbenefit the training process of a wide variety of 3D shape representationlearning methods.",Yueqi Duan,2020/3/19,2020/7/16
1909.06844v1,Wield: Systematic Reinforcement Learning With Progressive Randomization,http://arxiv.org/abs/1909.06844v1,"Reinforcement learning frameworks have introduced abstractions to implementand execute algorithms at scale. They assume standardized simulator interfacesbut are not concerned with identifying suitable task representations. Wepresent Wield, a first-of-its kind system to facilitate task design forpractical reinforcement learning. Through software primitives, Wield enablespractitioners to decouple system-interface and deployment-specificconfiguration from state and action design. To guide experimentation, Wieldfurther introduces a novel task design protocol and classification schemecentred around staged randomization to incrementally evaluate modelcapabilities.",Michael Schaarschmidt,2019/9/15,2019/9/15
2006.05181v2,Automated Design Space Exploration for optimised Deployment of DNN on Arm Cortex-A CPUs,http://arxiv.org/abs/2006.05181v2,"The spread of deep learning on embedded devices has prompted the developmentof numerous methods to optimise the deployment of deep neural networks (DNN).Works have mainly focused on: i) efficient DNN architectures, ii) networkoptimisation techniques such as pruning and quantisation, iii) optimisedalgorithms to speed up the execution of the most computational intensive layersand, iv) dedicated hardware to accelerate the data flow and computation.However, there is a lack of research on cross-level optimisation as the spaceof approaches becomes too large to test and obtain a globally optimisedsolution. Thus, leading to suboptimal deployment in terms of latency, accuracy,and memory. In this work, we first detail and analyse the methods to improvethe deployment of DNNs across the different levels of software optimisation.Building on this knowledge, we present an automated exploration framework toease the deployment of DNNs. The framework relies on a Reinforcement Learningsearch that, combined with a deep learning inference framework, automaticallyexplores the design space and learns an optimised solution that speeds up theperformance and reduces the memory on embedded CPU platforms. Thus, we presenta set of results for state-of-the-art DNNs on a range of Arm Cortex-A CPUplatforms achieving up to 4x improvement in performance and over 2x reductionin memory with negligible loss in accuracy with respect to the BLASfloating-point implementation.",Miguel de Prado,2020/6/9,2020/12/15
2203.05608v1,A modular and flexible data acquisition system for a cosmic rays detector network,http://arxiv.org/abs/2203.05608v1,"In this paper, we describe a modular data acquisition system developed as thefoundation of a cosmic ray detector network. Each detector setup (henceforthreferred as a station) is composed of an independent hardware device that canbe controlled and read-out through the Internet. This device is designed toacquire and process the signal of up to eight different detector planes. Eachof these detector planes uses plastic scintillator slabs that are opticallycoupled to silicon photomultipliers (SiPM). Within a single station, differentgeometries and plane orientations are possible using the same baseline design.The main readout is based on a programmable system-on-a-chip (PSoC), a flexibleand re-configurable commodity hardware that is used to implement the triggerand timing logic. A Time to Digital Converter (TDC) is used to determine theprecise timing of the event relative to a GPS timing signal and to estimate thesignal amplitude through the Time-over-Threshold (ToT) method. An auxiliary setof sensors provide environmental information and station detector planesorientation that, together with other operation data, are periodically sent toa server using the MQTT protocol. Data is cached using an in-memory databasefor online monitoring and further persisted into a SQL database for offlineanalysis. The server framework is based in software application containersallowing easy replication of the server infrastructure.",Guilherme Tomio Saito,2022/3/10,2022/3/10
2201.12137v1,CMOS pixel sensors optimized for large ionizing dynamic,http://arxiv.org/abs/2201.12137v1,"Monolithic active pixel sensors (MAPS) are now well established as atechnology for tracking charged particles, especially when low material budgetis desirable. For such applications, sensors focus on spatial resolution andpixels with digital output or modest charge measurement ability are wellsuited. Within the European Union STRONG-2020 project, which focuses onexperiments using hadrons, the TIIMM (Tracking and Ions Identifications withMinimal Material budget) joint research activity intends to expand granularMAPS capacity to energy-loss ({\Delta}E) measurement for ion speciesidentification. The TIIMM prototypes are developed in the Tower Jazz 180 nmCMOS image sensor (CIS) process. The Time-Over-Threshold (ToT) method isapplied to the sensor for the energy-loss measurement. The main design detailsand the preliminary test results from laboratory measurements of the initialTIIMM prototype are presented in this work.",W. Ren,2022/1/24,2022/1/24
2309.17179v1,Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training,http://arxiv.org/abs/2309.17179v1,"Large language models (LLMs) typically employ sampling or beam search,accompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning anddecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning viaPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizingtree-search algorithms to guide multi-step reasoning. These methods mainlyfocus on LLMs' reasoning ability during inference and heavily rely onhuman-designed prompts to activate LLM as a value function, which lacks generalapplicability and scalability. To address these limitations, we present anAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematicallyillustrating how tree-search with a learned value function can guide LLMs'decoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging alearned value function, our approach can be generally applied to differenttasks beyond reasoning (such as RLHF alignment), and LLMs of any size, withoutprompting advanced, large-scale models. (2) It can guide LLM's decoding duringboth inference and training. Empirical evaluations across reasoning, planning,and RLHF alignment tasks validate the effectiveness of TS-LLM, even on treeswith a depth of 64.",Xidong Feng,2023/9/29,2023/9/29
1209.1399v1,Video Chat with Multiple Cameras,http://arxiv.org/abs/1209.1399v1,"The dominant paradigm for video chat employs a single camera at each end ofthe conversation, but some conversations can be greatly enhanced by usingmultiple cameras at one or both ends. This paper provides the first rigorousinvestigation of multi-camera video chat, concentrating especially on theability of users to switch between views at either end of the conversation. Auser study of 23 individuals analyzes the advantages and disadvantages ofpermitting a user to switch between views at a remote location. Benchmarkexperiments employing up to four webcams simultaneously demonstrate thatmulti-camera video chat is feasible on consumer hardware. The paper alsopresents the design of MultiCam, a software package permitting multi-cameravideo chat. Some important trade-offs in the design of MultiCam are discussed,and typical usage scenarios are analyzed.",John MacCormick,2012/9/6,2012/9/6
2312.05471v1,Fine-Grained Analysis of Team Collaborative Dialogue,http://arxiv.org/abs/2312.05471v1,"Natural language analysis of human collaborative chat dialogues is anunderstudied domain with many unique challenges: a large number of dialogue actlabels, underspecified and dynamic tasks, interleaved topics, and long-rangecontextual dependence. While prior work has studied broad metrics of teamdialogue and associated performance using methods such as LSA, there has beenlittle effort in generating fine-grained descriptions of team dynamics andindividual performance from dialogue. We describe initial work towardsdeveloping an explainable analytics tool in the software development domainusing Slack chats mined from our organization, including generation of a novel,hierarchical labeling scheme; design of descriptive metrics based on thefrequency of occurrence of dialogue acts; and initial results using atransformer + CRF architecture to incorporate long-range context.",Ian Perera,2023/12/9,2023/12/9
1802.03422v1,State of the Practice for GIS Software,http://arxiv.org/abs/1802.03422v1,"We present a reproducible method to analyze the state of software developmentpractices in a given scientific domain and apply this method to GeographicInformation Systems (GIS). The analysis is based on grading a set of 30 GISproducts using a template of 56 questions based on 13 software qualities. Theproducts range in scope and purpose from a complete desktop GIS systems, tostand-alone tools, to programming libraries/packages. The final ranking of theproducts is determined using the Analytic Hierarchy Process (AHP), amulticriteria decision making method that focuses on relative comparisonsbetween products, rather than directly measuring qualities. The results revealconcerns regarding the correctness, maintainability, transparency andreproducibility of some GIS software. Three recommendations are presented asfeedback to the GIS community: 1) Ensure each project has a requirementsspecification document, 2) Provide a wealth of support methods, such as an IRC(Internet Relay Chat) channel, a Stack Exchange tag for new questions, oropening the issue tracker for support requests, as well as the more traditionalemail-based methods, and, 3) Design product websites for maximum transparency(of the development process), for open source projects, provide a developer'sguide.",W. Spencer Smith,2018/2/9,2018/2/9
1802.05173v1,A Family of Software Product Lines in Educational Technologies,http://arxiv.org/abs/1802.05173v1,"Rapid advances in education domain demand the design and customization ofeducational technologies for a large scale and variety of evolvingrequirements. Here, scale is the number of systems to be developed and varietystems from a diversified range of instructional designs such as varied goals,processes, content, teacher styles, learner styles and, also for eLearningSystems for 22 Indian Languages and variants. In this paper, we present afamily of software product lines as an approach to address this challenge ofmodeling a family of instructional designs as well as a family of eLearningSystems and demonstrate it for the case of adult literacy in India (287 millionlearners). We present a multi-level product line that connects product lines atmultiple levels of granularity in education domain. We then detail two concreteproduct lines (http://rice.iiit.ac.in), one that generates instructional designeditors and two, which generates a family of eLearning Systems based onflexible instructional designs. Finally, we demonstrate our approach bygenerating eLearning Systems for Hindi and Telugu languages (both web andandroid versions), which led to significant cost savings of 29 person monthsfor 9 eLearning Systems.",Sridhar Chimalakonda,2018/2/14,2018/2/14
2306.05128v2,"Formalizing, Verifying and Applying ISA Security Guarantees as Universal Contracts",http://arxiv.org/abs/2306.05128v2,"Progress has recently been made on specifying instruction set architectures(ISAs) in executable formalisms rather than through prose. However, to date,those formal specifications are limited to the functional aspects of the ISAand do not cover its security guarantees. We present a novel, general methodfor formally specifying an ISAs security guarantees to (1) balance the needs ofISA implementations (hardware) and clients (software), (2) can besemi-automatically verified to hold for the ISA operational semantics,producing a high-assurance mechanically-verifiable proof, and (3) supportinformal and formal reasoning about security-critical software in the presenceof adversarial code. Our method leverages universal contracts: softwarecontracts that express bounds on the authority of arbitrary untrusted code.Universal contracts can be kept agnostic of software abstractions, and strikethe right balance between requiring sufficient detail for reasoning aboutsoftware and preserving implementation freedom of ISA designers and CPUimplementers. We semi-automatically verify universal contracts against Sailimplementations of ISA semantics using our Katamaran tool; a semi-automaticseparation logic verifier for Sail which produces machine-checked proofs forsuccessfully verified contracts. We demonstrate the generality of our method byapplying it to two ISAs that offer very different security primitives: (1)MinimalCaps: a custom-built capability machine ISA and (2) a (somewhatsimplified) version of RISC-V with PMP. We verify a femtokernel using thesecurity guarantee we have formalized for RISC-V with PMP.",Sander Huyghebaert,2023/6/8,2024/1/8
1709.05703v1,AI Programmer: Autonomously Creating Software Programs Using Genetic Algorithms,http://arxiv.org/abs/1709.05703v1,"In this paper, we present the first-of-its-kind machine learning (ML) system,called AI Programmer, that can automatically generate full software programsrequiring only minimal human guidance. At its core, AI Programmer uses geneticalgorithms (GA) coupled with a tightly constrained programming language thatminimizes the overhead of its ML search space. Part of AI Programmer's noveltystems from (i) its unique system design, including an embedded, hand-craftedinterpreter for efficiency and security and (ii) its augmentation of GAs toinclude instruction-gene randomization bindings and programminglanguage-specific genome construction and elimination techniques. We provide adetailed examination of AI Programmer's system design, several examplesdetailing how the system works, and experimental data demonstrating itssoftware generation capabilities and performance using only mainstream CPUs.",Kory Becker,2017/9/17,2017/9/17
1209.0297v1,From Lagrangians to Events: Computer Tutorial at the MC4BSM-2012 Workshop,http://arxiv.org/abs/1209.0297v1,"This is a written account of the computer tutorial offered at the SixthMC4BSM workshop at Cornell University, March 22-24, 2012. The tools coveredduring the tutorial include: FeynRules, LanHEP, MadGraph, CalcHEP, Pythia 8,Herwig++, and Sherpa. In the tutorial, we specify a simple extension of theStandard Model, at the level of a Lagrangian. The software tools are then usedto automatically generate a set of Feynman rules, compute the invariant matrixelement for a sample process, and generate both parton-level and fullyhadronized/showered Monte Carlo event samples. The tutorial is designed to beself-paced, and detailed instructions for all steps are included in thiswrite-up. Installation instructions for each tool on a variety of popularplatforms are also provided.",Stefan Ask,2012/9/3,2012/9/3
2202.12379v1,Learning to Combine Instructions in LLVM Compiler,http://arxiv.org/abs/2202.12379v1,"Instruction combiner (IC) is a critical compiler optimization pass, whichreplaces a sequence of instructions with an equivalent and optimizedinstruction sequence at basic block level. There can be thousands ofinstruction-combining patterns which need to be frequently updated as newcoding idioms/applications and novel hardware evolve over time. This results infrequent updates to the IC optimization pass thereby incurring considerablehuman effort and high software maintenance costs. To mitigate these challengesassociated with the traditional IC, we design and implement a NeuralInstruction Combiner (NIC) and demonstrate its feasibility by integrating itinto the standard LLVM compiler optimization pipeline. NIC leverages neuralsequence-to-sequence (Seq2Seq) models for generating optimized encoded IRsequence from the unoptimized encoded IR sequence. To the best of ourknowledge, ours is the first work demonstrating the feasibility of a neuralinstruction combiner built into a full-fledged compiler pipeline. Given thenovelty of this task, we built a new dataset for training our NIC neural model.We show that NIC achieves exact match results percentage of 72% for optimizedsequences as compared to traditional IC and neural machine translation metricBleu precision score of 0.94, demonstrating its feasibility in a productioncompiler pipeline.",Sandya Mannarswamy,2022/2/22,2022/2/22
2311.01487v1,What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning,http://arxiv.org/abs/2311.01487v1,"Visual instruction tuning is an essential approach to improving the zero-shotgeneralization capability of Multi-modal Large Language Models (MLLMs). A surgeof visual instruction datasets with various focuses and characteristics havebeen proposed recently, enabling MLLMs to achieve surprising results onevaluation benchmarks. To develop more capable MLLMs, in this paper, we aim toinvestigate a more fundamental question: ``what makes for good visualinstructions?''. By conducting a comprehensive empirical study, we find thatinstructions focused on complex visual reasoning tasks are particularlyeffective in improving the performance of MLLMs on evaluation benchmarks.Building upon this finding, we design a systematic approach to automaticallycreating high-quality complex visual reasoning instructions. Our approachemploys a synthesis-complication-reformulation paradigm, leveraging multiplestages to gradually increase the complexity of the instructions whileguaranteeing quality. Based on this approach, we create the synthetic visualreasoning instruction dataset consisting of 32K examples, namely ComVint, andfine-tune four MLLMs on it. Experimental results demonstrate that our datasetconsistently enhances the performance of all the compared MLLMs, e.g.,improving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and28.8%, respectively. Our code and data are publicly available at the link:https://github.com/RUCAIBox/ComVint.",Yifan Du,2023/11/2,2023/11/2
1810.04610v3,"uops.info: Characterizing Latency, Throughput, and Port Usage of Instructions on Intel Microarchitectures",http://arxiv.org/abs/1810.04610v3,"Modern microarchitectures are some of the world's most complex man-madesystems. As a consequence, it is increasingly difficult to predict, explain,let alone optimize the performance of software running on suchmicroarchitectures. As a basis for performance predictions and optimizations,we would need faithful models of their behavior, which are, unfortunately,seldom available.  In this paper, we present the design and implementation of a tool toconstruct faithful models of the latency, throughput, and port usage of x86instructions. To this end, we first discuss common notions of instructionthroughput and port usage, and introduce a more precise definition of latencythat, in contrast to previous definitions, considers dependencies betweendifferent pairs of input and output operands. We then develop novel algorithmsto infer the latency, throughput, and port usage based onautomatically-generated microbenchmarks that are more accurate and precise thanexisting work.  To facilitate the rapid construction of optimizing compilers and tools forperformance prediction, the output of our tool is provided in amachine-readable format. We provide experimental results for processors of allgenerations of Intel's Core architecture, i.e., from Nehalem to Coffee Lake,and discuss various cases where the output of our tool differs considerablyfrom prior work.",Andreas Abel,2018/10/10,2019/3/5
1901.04982v1,Mechanism to Mitigate AVX-Induced Frequency Reduction,http://arxiv.org/abs/1901.04982v1,"Modern Intel CPUs reduce their frequency when executing wide vectoroperations (AVX2 and AVX-512 instructions), as these instructions increasepower consumption. The frequency is only increased again two milliseconds afterthe last code section containing such instructions has been executed in orderto prevent excessive numbers of frequency changes. Due to this delay,intermittent use of wide vector operations can slow down the rest of the systemsignificantly. For example, previous work has shown the performance of webservers to be reduced by up to 10% if the SSL library uses AVX-512 vectorinstructions. These performance variations are hard to predict during softwaredevelopment as the performance impact of vectorization depends on the specificworkload.  We describe a mechanism to reduce the slowdown caused by wide vectorinstructions without requiring extensive changes to existing software. Ourdesign allows the developer to mark problematic AVX code regions. The schedulerthen restricts execution of this code to a subset of the cores so that onlythese cores' frequency is affected. Threads are automatically migrated to asuitable core whenever necessary. We identify a suitable load balancing policyto ensure good utilization of all available cores. Our approach is able toreduce the performance variability caused by AVX2 and AVX-512 instructions byover 70%.",Mathias Gottschlag,2018/12/20,2018/12/20
1611.03372v1,A stochastically verifiable autonomous control architecture with reasoning,http://arxiv.org/abs/1611.03372v1,A new agent architecture called Limited Instruction Set Agent (LISA) isintroduced for autonomous control. The new architecture is based on previousimplementations of AgentSpeak and it is structurally simpler than itspredecessors with the aim of facilitating design-time and run-time verificationmethods. The process of abstracting the LISA system to two different types ofdiscrete probabilistic models (DTMC and MDP) is investigated and illustrated.The LISA system provides a tool for complete modelling of the agent and theenvironment for probabilistic verification. The agent program can beautomatically compiled into a DTMC or a MDP model for verification with Prism.The automatically generated Prism model can be used for both design-time andrun-time verification. The run-time verification is investigated andillustrated in the LISA system as an internal modelling mechanism forprediction of future outcomes.,Paolo Izzo,2016/11/10,2016/11/10
2010.04811v1,Modeling Black-Box Components with Probabilistic Synthesis,http://arxiv.org/abs/2010.04811v1,"This paper is concerned with synthesizing programs based on black-boxoracles: we are interested in the case where there exists an executableimplementation of a component or library, but its internal structure isunknown. We are provided with just an API or function signature, and aim tosynthesize a program with equivalent behavior.  To attack this problem, we detail Presyn: a program synthesizer designed forflexible interoperation with existing programs and compiler toolchains. Presynuses high-level imperative control-flow structures and a pair of cooperatingpredictive models to efficiently narrow the space of potential programs. Thesemodels can be trained effectively on small corpora of synthesized examples.  We evaluate Presyn against five leading program synthesizers on a collectionof 112 synthesis benchmarks collated from previous studies and real-worldsoftware libraries. We show that Presyn is able to synthesize a wider range ofprograms than each of them with less human input. We demonstrate theapplication of our approach to real-world code and software engineeringproblems with two case studies: accelerator library porting and detection ofduplicated library reimplementations.",Bruce Collie,2020/10/9,2020/10/9
2311.07599v1,Testing LLMs on Code Generation with Varying Levels of Prompt Specificity,http://arxiv.org/abs/2311.07599v1,"Large language models (LLMs) have demonstrated unparalleled prowess inmimicking human-like text generation and processing. Among the myriad ofapplications that benefit from LLMs, automated code generation is increasinglypromising. The potential to transform natural language prompts into executablecode promises a major shift in software development practices and paves the wayfor significant reductions in manual coding efforts and the likelihood ofhuman-induced errors. This paper reports the results of a study that evaluatesthe performance of various LLMs, such as Bard, ChatGPT-3.5, ChatGPT-4, andClaude-2, in generating Python for coding problems. We focus on how levels ofprompt specificity impact the accuracy, time efficiency, and space efficiencyof the generated code. A benchmark of 104 coding problems, each with four typesof prompts with varying degrees of tests and specificity, was employed toexamine these aspects comprehensively. Our results indicate significantvariations in performance across different LLMs and prompt types, and its keycontribution is to reveal the ideal prompting strategy for creating accuratePython functions. This study lays the groundwork for further research in LLMcapabilities and suggests practical implications for utilizing LLMs inautomated code generation tasks and test-driven development.",Lincoln Murr,2023/11/10,2023/11/10
2312.04087v1,VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal Models,http://arxiv.org/abs/2312.04087v1,"With recent advancements in Large Multimodal Models (LMMs) across variousdomains, a novel prompting method called visual referring prompting hasemerged, showing significant potential in enhancing human-computer interactionwithin multimodal systems. This method offers a more natural and flexibleapproach to human interaction with these systems compared to traditional textdescriptions or coordinates. However, the categorization of visual referringprompting remains undefined, and its impact on the performance of LMMs has yetto be formally examined. In this study, we conduct the first comprehensiveanalysis of LMMs using a variety of visual referring prompting strategies. Weintroduce a benchmark dataset called VRPTEST, comprising 3 different visualtasks and 2,275 images, spanning diverse combinations of prompt strategies.Using VRPTEST, we conduct a comprehensive evaluation of eight versions ofprominent open-source and proprietary foundation models, including two earlyversions of GPT-4V. We develop an automated assessment framework based onsoftware metamorphic testing techniques to evaluate the accuracy of LMMswithout the need for human intervention or manual labeling. We find that thecurrent proprietary models generally outperform the open-source ones, showingan average accuracy improvement of 22.70%; however, there is still potentialfor improvement. Moreover, our quantitative analysis shows that the choice ofprompt strategy significantly affects the accuracy of LMMs, with variationsranging from -17.5% to +7.3%. Further case studies indicate that an appropriatevisual referring prompting strategy can improve LMMs' understanding of contextand location information, while an unsuitable one might lead to answerrejection. We also provide insights on minimizing the negative impact of visualreferring prompting on LMMs.",Zongjie Li,2023/12/7,2023/12/7
2211.02709v1,A Prompt-based Few-shot Learning Approach to Software Conflict Detection,http://arxiv.org/abs/2211.02709v1,"A software requirement specification (SRS) document is an essential part ofthe software development life cycle which outlines the requirements that asoftware program in development must satisfy. This document is often specifiedby a diverse group of stakeholders and is subject to continual change, makingthe process of maintaining the document and detecting conflicts betweenrequirements an essential task in software development. Notably, projects thatdo not address conflicts in the SRS document early on face considerableproblems later in the development life cycle. These problems incur substantialcosts in terms of time and money, and these costs often become insurmountablebarriers that ultimately result in the termination of a software projectaltogether. As a result, early detection of SRS conflicts is critical toproject sustainability. The conflict detection task is approached in numerousways, many of which require a significant amount of manual intervention fromdevelopers, or require access to a large amount of labeled, task-specifictraining data. In this work, we propose using a prompt-based learning approachto perform few-shot learning for conflict detection. We compare our results tosupervised learning approaches that use pretrained language models, such asBERT and its variants. Our results show that prompting with just 32 labeledexamples can achieve a similar level of performance in many key metrics to thatof supervised learning on training sets that are magnitudes larger in size. Incontrast to many other conflict detection approaches, we make no assumptionsabout the type of underlying requirements, allowing us to analyze pairings ofboth functional and non-functional requirements. This allows us to omit thepotentially expensive task of filtering out non-functional requirements fromour dataset.",Robert K. Helmeczi,2022/11/4,2022/11/4
2304.11938v2,Is ChatGPT the Ultimate Programming Assistant -- How far is it?,http://arxiv.org/abs/2304.11938v2,"Recently, the ChatGPT LLM has received great attention: it can be used as abot for discussing source code, prompting it to suggest changes, providedescriptions or even generate code. Typical demonstrations generally focus onexisting benchmarks, which may have been used in model training (i.e., dataleakage). To assess the feasibility of using an LLM as a useful assistant botfor programmers, we must assess its realistic capabilities on unseen problemsas well as its capabilities on various tasks. In this paper, we present anempirical study of ChatGPT's potential as a fully automated programmingassistant, focusing on the tasks of code generation, program repair, and codesummariziation. The study investigates ChatGPT's performance on commonprogramming problems and compares it with state-of-the-art approaches on twobenchmarks. Among several findings, our study shows that ChatGPT is effectivein dealing with common programming problems. However, our experiments alsoreveal limitations in terms of its attention span: detailed descriptions willconstrain the focus of ChatGPT and prevent it from leveraging its vastknowledge to solve the actual problem. Surprisingly, we have identified theability of ChatGPT to reason the original intention of the code. We expectfuture work to build on this insight for dealing with the open question of theoracle problem. Our findings contribute interesting insights to the developmentof LLMs for programming assistance, notably by demonstrating the importance ofprompt engineering, and providing a better understanding of ChatGPT's practicalapplications for software engineering.",Haoye Tian,2023/4/24,2023/8/31
2311.16429v1,The Transformative Influence of Large Language Models on Software Development,http://arxiv.org/abs/2311.16429v1,"The increasing adoption and commercialization of generalized Large LanguageModels (LLMs) have profoundly impacted various aspects of our daily lives.Initially embraced by the computer science community, the versatility of LLMshas found its way into diverse domains. In particular, the software engineeringrealm has witnessed the most transformative changes. With LLMs increasinglyserving as AI Pair Programming Assistants spurred the development ofspecialized models aimed at aiding software engineers. Although this newparadigm offers numerous advantages, it also presents critical challenges andopen problems. To identify the potential and prevailing obstacles, wesystematically reviewed contemporary scholarly publications, emphasizing theperspectives of software developers and usability concerns. Preliminaryfindings underscore pressing concerns about data privacy, bias, andmisinformation. Additionally, we identified several usability challenges,including prompt engineering, increased cognitive demands, and mistrust.Finally, we introduce 12 open problems that we have identified through oursurvey, covering these various domains.",Sajed Jalil,2023/11/28,2023/11/28
2204.04741v5,Is GitHub's Copilot as Bad as Humans at Introducing Vulnerabilities in Code?,http://arxiv.org/abs/2204.04741v5,"Several advances in deep learning have been successfully applied to thesoftware development process. Of recent interest is the use of neural languagemodels to build tools, such as Copilot, that assist in writing code. In thispaper we perform a comparative empirical analysis of Copilot-generated codefrom a security perspective. The aim of this study is to determine if Copilotis as bad as human developers. We investigate whether Copilot is just as likelyto introduce the same software vulnerabilities as human developers. Using adataset of C/C++ vulnerabilities, we prompt Copilot to generate suggestions inscenarios that led to the introduction of vulnerabilities by human developers.The suggestions are inspected and categorized in a 2-stage process based onwhether the original vulnerability or fix is reintroduced. We find that Copilotreplicates the original vulnerable code about 33% of the time while replicatingthe fixed code at a 25% rate. However this behaviour is not consistent: Copilotis more likely to introduce some types of vulnerabilities than others and isalso more likely to generate vulnerable code in response to prompts thatcorrespond to older vulnerabilities. Overall, given that in a significantnumber of cases it did not replicate the vulnerabilities previously introducedby human developers, we conclude that Copilot, despite performing differentlyacross various vulnerability types, is not as bad as human developers atintroducing vulnerabilities in code.",Owura Asare,2022/4/10,2024/1/6
2307.02435v1,Exploring Continual Learning for Code Generation Models,http://arxiv.org/abs/2307.02435v1,"Large-scale code generation models such as Codex and CodeT5 have achievedimpressive performance. However, libraries are upgraded or deprecated veryfrequently and re-training large-scale language models is computationallyexpensive. Therefore, Continual Learning (CL) is an important aspect thatremains underexplored in the code domain. In this paper, we introduce abenchmark called CodeTask-CL that covers a wide range of tasks, including codegeneration, translation, summarization, and refinement, with different inputand output programming languages. Next, on our CodeTask-CL benchmark, wecompare popular CL techniques from NLP and Vision domains. We find thateffective methods like Prompt Pooling (PP) suffer from catastrophic forgettingdue to the unstable training of the prompt selection mechanism caused by starkdistribution shifts in coding tasks. We address this issue with our proposedmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes trainingby enforcing constraints on the prompt selection mechanism and leads to a21.54% improvement over Prompt Pooling. Along with the benchmark, we establisha training pipeline that can be used for CL on code models, which we believecan motivate further development of CL methods for code models. Our code isavailable at https://github.com/amazon-science/codetaskcl-pptf",Prateek Yadav,2023/7/5,2023/7/5
2101.11218v1,What We Can Learn From Visual Artists About Software Development,http://arxiv.org/abs/2101.11218v1,"This paper explores software's role in visual art production by examining howartists use and develop software. We conducted interviews with professionalartists who were collaborating with software developers, learning softwaredevelopment, and building and maintaining software. We found artists weremotivated to learn software development for intellectual growth and access totechnical communities. Artists valued efficient workflows through skilledmanual execution and personal software development, but avoided high-levelforms of software automation. Artists identified conflicts between theirpriorities and those of professional developers and computational artcommunities, which influenced how they used computational aesthetics in theirwork. These findings contribute to efforts in systems engineering research tointegrate end-user programming and creativity support across software andphysical media, suggesting opportunities for artists as collaborators. Artists'experiences writing software can guide technical implementations ofdomain-specific representations, and their experiences in interdisciplinaryproduction can aid inclusive community building around computational tools.",Jingyi Li,2021/1/27,2021/1/27
2109.05843v1,OSS effort estimation using software features similarity and developer activity-based metrics,http://arxiv.org/abs/2109.05843v1,"Software development effort estimation (SDEE) generally involves leveragingthe information about the effort spent in developing similar software in thepast. Most organizations do not have access to sufficient and reliable forms ofsuch data from past projects. As such, the existing SDEE methods suffer fromlow usage and accuracy.  We propose an efficient SDEE method for open source software, which providesaccurate and fast effort estimates. The significant contributions of our paperare i) Novel SDEE software metrics derived from developer activity informationof various software repositories, ii) SDEE dataset comprising the SDEE metrics'values derived from $\approx13,000$ GitHub repositories from 150 differentsoftware categories, iii) an effort estimation tool based on SDEE metrics and asoftware description similarity model. Our software description similaritymodel is basically a machine learning model trained using the Paragraph Vectorsalgorithm on the software product descriptions of GitHub repositories. Giventhe software description of a newly-envisioned software, our tool yields aneffort estimate for developing it.  Our method achieves the highest Standard Accuracy score of 87.26% (withcliff's $\delta$=0.88 at 99.999% confidence level) and 42.7% with the AutomaticTransformed Linear Baseline model. Our software artifacts are available athttps://doi.org/10.5281/zenodo.5095723.",Ritu Kapur,2021/9/13,2021/9/13
2005.00760v4,A Comprehensive Study on Challenges in Deploying Deep Learning Based Software,http://arxiv.org/abs/2005.00760v4,"Deep learning (DL) becomes increasingly pervasive, being used in a wide rangeof software applications. These software applications, named as DL basedsoftware (in short as DL software), integrate DL models trained using a largedata corpus with DL programs written based on DL frameworks such as TensorFlowand Keras. A DL program encodes the network structure of a desirable DL modeland the process by which the model is trained using the training data. To helpdevelopers of DL software meet the new challenges posed by DL, enormousresearch efforts in software engineering have been devoted. Existing studiesfocus on the development of DL software and extensively analyze faults in DLprograms. However, the deployment of DL software has not been comprehensivelystudied. To fill this knowledge gap, this paper presents a comprehensive studyon understanding challenges in deploying DL software. We mine and analyze 3,023relevant posts from Stack Overflow, a popular Q&A website for developers, andshow the increasing popularity and high difficulty of DL software deploymentamong developers. We build a taxonomy of specific challenges encountered bydevelopers in the process of DL software deployment through manual inspectionof 769 sampled posts and report a series of actionable implications forresearchers, developers, and DL framework vendors.",Zhenpeng Chen,2020/5/2,2020/11/11
2311.00691v1,Software Repositories and Machine Learning Research in Cyber Security,http://arxiv.org/abs/2311.00691v1,"In today's rapidly evolving technological landscape and advanced softwaredevelopment, the rise in cyber security attacks has become a pressing concern.The integration of robust cyber security defenses has become essential acrossall phases of software development. It holds particular significance inidentifying critical cyber security vulnerabilities at the initial stages ofthe software development life cycle, notably during the requirement phase.Through the utilization of cyber security repositories like The Common AttackPattern Enumeration and Classification (CAPEC) from MITRE and the CommonVulnerabilities and Exposures (CVE) databases, attempts have been made toleverage topic modeling and machine learning for the detection of theseearly-stage vulnerabilities in the software requirements process. Past researchthemes have returned successful outcomes in attempting to automatevulnerability identification for software developers, employing a mixture ofunsupervised machine learning methodologies such as LDA and topic modeling.Looking ahead, in our pursuit to improve automation and establish connectionsbetween software requirements and vulnerabilities, our strategy entailsadopting a variety of supervised machine learning techniques. This arrayencompasses Support Vector Machines (SVM), Na\""ive Bayes, random forest, neuralnetworking and eventually transitioning into deep learning for ourinvestigation. In the face of the escalating complexity of cyber security, thequestion of whether machine learning can enhance the identification ofvulnerabilities in diverse software development scenarios is a paramountconsideration, offering crucial assistance to software developers in developingsecure software.",Mounika Vanamala,2023/11/1,2023/11/1
2303.03659v1,Scalable and Cost-effective Data Flow Analysis for Distributed Software: Algorithms and Applications,http://arxiv.org/abs/2303.03659v1,"More and more distributed software systems are being developed and deployedtoday. Like other software, distributed software systems also need very strongquality assurance support. Distributed software is often very large/complex,has distributed components, and does not have a global clock. All thesecharacteristics make it very challenging to analyze the information flow ofsuch systems to support the software quality assurance. One challenge is thatexisting dynamic analysis techniques hardly scale to large distributed softwaresystems in the real world. It is also challenging to develop cost-effectivedynamic analysis approaches. There are also applicability and portabilitychallenges for dynamic analysis algorithms/applications of distributedsoftware. My dissertation addresses these challenges via three novel approachesto data flow analysis for distributed software. My first approach is based onmeasuring interprocess communications to understand distributed softwarebehaviors and predict distributed software quality. Then, I developed aparticular approach that can actually pinpoint sensitive information viamulti-staged and refinement-based dynamic information flow analysis fordistributed software. Finally, I explored dynamic dependence analysis fordistributed systems, utilizing reinforcement learning to automatically adjustanalysis configurations for scalability and better cost-effectivenesstradeoffs.",Xiaoqin Fu,2023/3/7,2023/3/7
1904.08239v1,Happiness and the productivity of software engineers,http://arxiv.org/abs/1904.08239v1,"Software companies and startups often follow the idea of flourishinghappiness among developers. Perks, playground rooms, free breakfast, remoteoffice options, sports facilities near the companies, company retreats, youname it. The rationale is that happy developers should be more productive andalso retained.  But is it the case that happy software engineers are more productive?Moreover, are perks the way to go to make developers happy? Are developershappy at all? What are the consequences of unhappiness among softwareengineers?  These questions are important to ask both from the perspective ofproductivity and from the perspective of sustainable software development andwell-being in the workplace. Managers, team leaders, as well as team membersshould be interested in these concerns.  This chapter provides an overview of our studies on the happiness of softwaredevelopers. You will learn why it is important to make software developershappy, how happy they really are, what makes them unhappy, and what is expectedregarding happiness and productivity while developing software.",Daniel Graziotin,2019/4/16,2019/4/16
2002.02056v1,Design of the Inspection Process Using the GitHub Flow in Project Based Learning for Software Engineering and Its Practice,http://arxiv.org/abs/2002.02056v1,"Project based learning (PBL) for software development (we call it softwaredevelopment PBL) has garnered attention as a practical educational method. Anumber of studies have reported on the introduction of social coding tools suchas GitHub, in software development PBL. In education, it is important to givefeedback (advice, error corrections, and so on) to learners, especially insoftware development PBL because almost all learners tackle practical softwaredevelopment from the viewpoint of technical and managerial aspects for thefirst time. This study regards inspection that is conducted in general softwaredevelopment activities as an opportunity to provide feedback and proposes theinspection process using the pull request on GitHub. By applying the proposedprocess to an actual software development PBL, we enable giving feedback to theaccurate locations of artifacts the learners created.",Yutsuki Miyashita,2020/2/6,2020/2/6
2102.03670v1,Recommending More Efficient Workflows to Software Developers,http://arxiv.org/abs/2102.03670v1,"Existing recommendation systems can help developers improve their softwaredevelopment abilities by recommending new programming tools, such as arefactoring tool or a program navigation tool. However, simply recommendingtools in isolation may not, in and of itself, allow developers to successfullycomplete their tasks. In this paper, I introduce a new recommendation systemthat recommends workflows, or sequences of tools, to developers. By learningmore efficient workflows, the system could make software developers moreefficient.",Dylan Bates,2021/2/6,2021/2/6
1412.3289v1,Optimization of Software Quality Using Management and Technical Review Techniques,http://arxiv.org/abs/1412.3289v1,"Optimizing the quality of software is a function of the degree of reviewsmade during the early life of a software development process. Reviews detecterrors and potential errors early in the software development process. Theerrors detected during the early life cycle of software are least expensive tocorrect. Efficient involvement in software inspections and technical reviews,help developers improve their own skills, thereby mitigating the occurrence oferrors in the later stage of software development process. The ideas gatheredon this paper point that a properly implemented program of technical andmanagement reviews drastically reduces the time as well as the cost requiredfor testing, debugging, and reworking, and dramatically improves the quality ofthe resulting product. This paper, Optimization of Software Quality usingmanagement and technical Review Techniques, provides its readers with theopportunity to learn about and experience using this indispensable softwarequality tools.",Inibehe Emmanuel Akpannah,2014/12/10,2014/12/10
1607.03748v1,Analysis of Software Delivery Process Shortcomings and Architectural Pitfalls,http://arxiv.org/abs/1607.03748v1,"This paper highlights the common pitfalls of overcomplicating the softwarearchitecture, development and delivery process by examining two enterpriselevel web application products built using Microsoft.Net framework. The aim ofthis paper is to identify, discuss and analyze architectural, development anddeployment issues and learn lessons using real world examples from the chosensoftware products as case studies.",Amol Patwardhan,2016/7/9,2016/7/9
1710.07014v1,"Comparative Analysis of Software Development Methods between Parallel, V-Shaped and Iterative",http://arxiv.org/abs/1710.07014v1,"Any organization that will develop software is faced with a difficult choiceof choosing the right software development method. Whereas the softwaredevelopment methods used, play a significant role in the overall softwaredevelopment process. Software development methods are needed so that thesoftware development process can be systematic so that it is not only completedwithin the right time frame but also must have good quality. There are variousmethods of software development in System Development Lyfe Cycle (SDLC). EachSDLC method provides a general guiding line about different softwaredevelopment and has different characteristics. Each method of softwaredevelopment has its drawbacks and advantages so that the selection of softwaredevelopment methods should be compatible with the capacity of the softwaredeveloped. This paper will compare three different software developmentmethods: V-Shaped Model, Parallel Development Model, and Iterative Model withthe aim of providing an understanding of software developers to choose theright method.",Suryanto Nugroho,2017/10/19,2017/10/19
cs/0306080v1,BOA: Framework for Automated Builds,http://arxiv.org/abs/cs/0306080v1,"Managing large-scale software products is a complex software engineeringtask. The automation of the software development, release and distributionprocess is most beneficial in the large collaborations, where the big number ofdevelopers, multiple platforms and distributed environment are typical factors.This paper describes Build and Output Analyzer framework and its componentsthat have been developed in CMS to facilitate software maintenance and improvesoftware quality. The system allows to generate, control and analyze varioustypes of automated software builds and tests, such as regular rebuilds of thedevelopment code, software integration for releases and installation of theexisting versions.",N. Ratnikova,2003/6/14,2003/6/14
2107.10375v1,The Factors of Code Reviewing Process to Ensure Software Quality,http://arxiv.org/abs/2107.10375v1,"In the era of revolution, the development of softwares are increasing daily.The quality of software impacts the most in software development. To ensure thequality of the software it needs to be reviewed and updated. The effectivenessof the code review is that it ensures the quality of software and makes itupdated. Code review is the best process that helps the developers to develop asystem errorless. This report contains two different code review papers to beevaluated and find the influences that can affect the code reviewing process.The reader can easily understand the factor of the code review process which isdirectly associated with software quality assurance.",Shaykh Siddique,2021/7/21,2021/7/21
1708.06900v2,Systematic Innovation Mounted Software Development Process and Intuitive Project Management Framework for Lean Startups,http://arxiv.org/abs/1708.06900v2,"This paper provides a new process which integrates an inventive problemsolving method into one modern software development program, making it part ofthe software development process. The research question is how to improvesoftware development process which tech startups could adopt with minor projectmanagement skills. The Systematic Innovation Mounted Software DevelopmentProcess, a combination of Agile and Systematic Innovation, provides analternative development process which is targeted to adapt idea generation intosoftware products. The intuitive project management framework helps technologydriven companies to manage their software projects more effectively. Theimplication and aim of this research are providing the guideline to help theentrepreneurs for managing their project properly. The Systematic Innovationmodel helps to generate new ideas and innovative ways to solve problems withthe collaboration with the existing Agile model. The new software developmentprocess and associated techniques could impact the current software developmentindustry significantly, especially software startup companies, because thesepowerful tools can help reduce managerial workloads of the companies and givethem more time to remain focused on their key technologies.",Song-Kyoo Kim,2017/8/23,2019/11/26
1002.2197v1,Test Case Generation using Mutation Operators and Fault Classification,http://arxiv.org/abs/1002.2197v1,"Software testing is the important phase of software development process. But,this phase can be easily missed by software developers because of their limitedtime to complete the project. Since, software developers finish their softwarenearer to the delivery time; they dont get enough time to test their program bycreating effective test cases. . One of the major difficulties in softwaretesting is the generation of test cases that satisfy the given adequacycriterion Moreover, creating manual test cases is a tedious work for softwaredevelopers in the final rush hours. A new approach which generates test casescan help the software developers to create test cases from softwarespecifications in early stage of software development (before coding) and aswell as from program execution traces from after software development (aftercoding). Heuristic techniques can be applied for creating quality test cases.Mutation testing is a technique for testing software units that has greatpotential for improving the quality of testing, and to assure the highreliability of software. In this paper, a mutation testing based test casesgeneration technique has been proposed to generate test cases from programexecution trace, so that the test cases can be generated after coding. Thepaper details about the mutation testing implementation to generate test cases.The proposed algorithm has been demonstrated for an example.",Mrs. R. Jeevarathinam,2010/2/10,2010/2/10
2010.03896v1,A practical guide towards agile test-driven development for scientific software projects,http://arxiv.org/abs/2010.03896v1,"Software testing has received much attention over the last years and hasreached such critical importance that agile software development practices putsoftware testing at its core. Agile software development is successfullyapplied in large-scale industrial software developments but due to its granularresponsibilities with roles assigned to various members of the developmentteam, these practices may not be applicable to scientific code development,especially in an academic environment, where it is not uncommon that thecodebase is developed, maintained and used by a single person. Even forcollaborative scientific software development, financed through externalgrants, the end-users are typically still part of the development team. This isin contrast to how software is developed in many industries, where thedevelopment team and end-users are two separate entities. There are, however,many good code development practices that can be adopted for scientificsoftware projects. Specifically, the intention of this article is to take thecentrepiece of agile software development and tailor it to scientific andacademic, single-user code development. In this study, a c++ starter project isdeveloped and made available, based on the meson build system, which providesnative support for software testing. It is used to show how a simple linearalgebra application, found in many scientific and academic applications, can bedeveloped and how simple unit, integration and system tests can be created thatare managed through the meson build system. In this way, we are able tominimise software defects and reduce the risk to interpret incorrect datagenerated by erroneous software that may result in the wrong conclusions to bedrawn. Each layer of testing presents one additional layer of protection and wewill explore how these may be incorporated with minimum overhead to producebug-free software.",Tom-Robin Teschner,2020/10/8,2020/10/8
2008.02987v1,Why are Developers Struggling to Put GDPR into Practice when Developing Privacy-Preserving Software Systems?,http://arxiv.org/abs/2008.02987v1,"The use of software applications is inevitable as they provide differentservices to users. The software applications collect, store users' data, andsometimes share with the third party, even without the user consent. One canargue that software developers do not implement privacy into the softwareapplications they develop or take GDPR (General Data Protection Law) law intoaccount. Failing to do this, may lead to software applications that open upprivacy breaches (e.g. data breach). The GDPR law provides a set of guidelinesfor developers and organizations on how to protect user data when they areinteracting with software applications. Previous research has attempted toinvestigate what hinders developers from embedding privacy into softwaresystems. However, there has been no detailed investigation on why they cannotdevelop privacy-preserving systems taking GDPR into consideration, which isimperative to develop software applications that preserve privacy. Therefore,this paper investigates the issues that hinder software developers fromimplementing software applications taking GDPR law on-board. Our study findingsrevealed that developers are not familiar with GDPR principles. Even some ofthem are, they lack knowledge of the GDPR principles and their techniques touse when developing privacy-preserving software systems",Abdulrahman Alhazmi,2020/8/7,2020/8/7
2210.09825v1,Agile Practices for Quantum Software Development: Practitioners Perspectives,http://arxiv.org/abs/2210.09825v1,"Quantum software systems are emerging software engineering (SE) genre thatexploit principles of quantum bits (Qubit) and quantum gates (Qgates) to solvecomplex computing problems that today classic computers can not effectively doin a reasonable time. According to its proponents, agile software developmentpractices have the potential to address many of the problems endemic to thedevelopment of quantum software. However, there is a dearth of evidenceconfirming if agile practices suit and can be adopted by software teams as theyare in the context of quantum software development. To address this lack, weconducted an empirical study to investigate the needs and challenges of usingagile practices to develop quantum software. While our semi-structuredinterviews with 26 practitioners across 10 countries highlighted theapplicability of agile practices in this domain, the interview findings alsorevealed new challenges impeding the effective incorporation of thesepractices. Our research findings provide a springboard for furthercontextualization and seamless integration of agile practices with developingthe next generation of quantum software.",Arif Ali Khan,2022/10/18,2022/10/18
1905.13455v1,Technical Debt in Data-Intensive Software Systems,http://arxiv.org/abs/1905.13455v1,"The ever-increasing amount, variety as well as generation and processingspeed of today's data pose a variety of new challenges for developingData-Intensive Software Systems (DISS). As with developing other kinds ofsoftware systems, developing DISS is often done under severe pressure andstrict schedules. Thus, developers of DISS often have to make technicalcompromises to meet business concerns. This position paper proposes aconceptual model that outlines where Technical Debt (TD) can emerge andproliferate within such data-centric systems by separating a DISS into threeparts (Software Systems, Data Storage Systems and Data). Further, the paperillustrates the proliferation of Database Schema Smells as TD items within arelational database-centric software system based on two examples.",Harald Foidl,2019/5/31,2019/5/31
1605.02265v2,"Software search is not a science, even among scientists: A survey of how scientists and engineers find software",http://arxiv.org/abs/1605.02265v2,"Improved software discovery is a prerequisite for greater software reuse:after all, if someone cannot find software for a particular task, they cannotreuse it. Understanding people's approaches and preferences when they look forsoftware could help improve facilities for software discovery. We surveyedpeople working in several scientific and engineering fields to betterunderstand their approaches and selection criteria. We found that even amonghighly-trained people, the rudimentary approaches of relying on general Websearches, the opinions of colleagues, and the literature were still the mostcommonly used. However, those who were involved in software developmentdiffered from nondevelopers in their use of social help sites, software projectrepositories, software catalogs, and organization-specific mailing lists orforums. For example, software developers in our sample were more likely tosearch in community sites such as Stack Overflow even when seeking ready-to-runsoftware rather than source code, and likewise, asking colleagues wassignificantly more important when looking for ready-to-run software. Our surveyalso provides insight into the criteria that matter most to people when theyare searching for ready-to-run software. Finally, our survey also identifiessome factors that can prevent people from finding software.",Michael Hucka,2016/5/8,2018/5/28
1711.07863v1,Finding an Effective Classification Technique to Develop a Software Team Composition Model,http://arxiv.org/abs/1711.07863v1,"Ineffective software team composition has become recognized as a prominentaspect of software project failures. Reports from results extracted fromdifferent theoretical personality models have produced contradicting fits,validity challenges, and missing guidance during software development personnelselection. It is also believed that the technique/s used while developing amodel can impact the overall results. Thus, this study aims to: 1) discover aneffective classification technique to solve the problem, and 2) develop a modelfor composition of the software development team. The model developed wascomposed of three predictors: team role, personality types, and gendervariables; it also contained one outcome: team performance variable. Thetechniques used for model development were logistic regression, decision tree,and Rough Sets Theory (RST). Higher prediction accuracy and reduced patterncomplexity were the two parameters for selecting the effective technique. Basedon the results, the Johnson Algorithm (JA) of RST appeared to be an effectivetechnique for a team composition model. The study has proposed a set of 24decision rules for finding effective team members. These rules involve genderclassification to highlight the appropriate personality profile for softwaredevelopers. In the end, this study concludes that selecting an appropriateclassification technique is one of the most important factors in developingeffective models.",Abdul Rehman Gilal,2017/11/21,2017/11/21
1701.05789v2,Consequences of Unhappiness While Developing Software,http://arxiv.org/abs/1701.05789v2,"The growing literature on affect among software developers mostly reports onthe linkage between happiness, software quality, and developer productivity.Understanding the positive side of happiness -- positive emotions and moods --is an attractive and important endeavor. Scholars in industrial andorganizational psychology have suggested that also studying the negative side-- unhappiness -- could lead to cost-effective ways of enhancing workingconditions, job performance, and to limiting the occurrence of psychologicaldisorders. Our comprehension of the consequences of (un)happiness amongdevelopers is still too shallow, and is mainly expressed in terms ofdevelopment productivity and software quality. In this paper, we attempt touncover the experienced consequences of unhappiness among software developers.Using qualitative data analysis of the responses given by 181 questionnaireparticipants, we identified 49 consequences of unhappiness while doing softwaredevelopment. We found detrimental consequences on developers' mentalwell-being, the software development process, and the produced artifacts. Ourclassification scheme, available as open data, will spawn new happinessresearch opportunities of cause-effect type, and it can act as a guideline forpractitioners for identifying damaging effects of unhappiness and for fosteringhappiness on the job.",Daniel Graziotin,2017/1/20,2017/2/24
2205.12080v1,Application of Orthogonal Defect Classification for Software Reliability Analysis,http://arxiv.org/abs/2205.12080v1,"The modernization of existing and new nuclear power plants with digitalinstrumentation and control systems (DI&C) is a recent and highly trendingtopic. However, there lacks strong consensus on best-estimate reliabilitymethodologies by both the United States (U.S.) Nuclear Regulatory Commission(NRC) and the industry. In this work, we develop an approach calledOrthogonal-defect Classification for Assessing Software Reliability (ORCAS) toquantify probabilities of various software failure modes in a DI&C system. Themethod utilizes accepted industry methodologies for quality assurance that areverified by experimental evidence. In essence, the approach combines a semanticfailure classification model with a reliability growth model to predict theprobability of failure modes of a software system. A case study was conductedon a representative I&C platform (ChibiOS) running a smart sensor acquisitionsoftware developed by Virginia Commonwealth University (VCU). The testing andevidence collection guidance in ORCAS was applied, and defects were uncoveredin the software. Qualitative evidence, such as modified condition decisioncoverage, was used to gauge the completeness and trustworthiness of theassessment while quantitative evidence was used to determine the softwarefailure probabilities. The reliability of the software was then estimated andcompared to existing operational data of the sensor device. It is demonstratedthat by using ORCAS, a semantic reasoning framework can be developed to justifyif the software is reliable (or unreliable) while still leveraging the strengthof the existing methods.",Edward Chen,2022/5/24,2022/5/24
1402.2376v1,Prediction of Human Performance Capability during Software Development using Classification,http://arxiv.org/abs/1402.2376v1,"The quality of human capital is crucial for software companies to maintaincompetitive advantages in knowledge economy era. Software companies recognizesuperior talent as a business advantage. They increasingly recognize thecritical linkage between effective talent and business success. However,software companies suffering from high turnover rates often find it hard torecruit the right talents. There is an urgent need to develop a personnelselection mechanism to find the talents who are the most suitable for theirsoftware projects. Data mining techniques assures exploring the informationfrom the historical projects depending on which the project manager can makedecisions for producing high quality software. This study aims to fill the gapby developing a data mining framework based on decision tree and associationrules to refocus on criteria for personnel selection. An empirical study wasconducted in a software company to support their hiring decision for projectmembers. The results demonstrated that there is a need to refocus on selectioncriteria for quality objectives. Better selection criteria was identified bypatterns obtained from data mining models by integrating knowledge fromsoftware project database and authors research techniques.",Sangita Gupta,2014/2/11,2014/2/11
2305.16615v1,"AIBugHunter: A Practical Tool for Predicting, Classifying and Repairing Software Vulnerabilities",http://arxiv.org/abs/2305.16615v1,"Many ML-based approaches have been proposed to automatically detect,localize, and repair software vulnerabilities. While ML-based methods are moreeffective than program analysis-based vulnerability analysis tools, few havebeen integrated into modern IDEs, hindering practical adoption. To bridge thiscritical gap, we propose AIBugHunter, a novel ML-based software vulnerabilityanalysis tool for C/C++ languages that is integrated into Visual Studio Code.AIBugHunter helps software developers to achieve real-time vulnerabilitydetection, explanation, and repairs during programming. In particular,AIBugHunter scans through developers' source code to (1) locatevulnerabilities, (2) identify vulnerability types, (3) estimate vulnerabilityseverity, and (4) suggest vulnerability repairs. In this article, we propose anovel multi-objective optimization (MOO)-based vulnerability classificationapproach and a transformer-based estimation approach to help AIBugHunteraccurately identify vulnerability types and estimate severity. Our empiricalexperiments on a large dataset consisting of 188K+ C/C++ functions confirm thatour proposed approaches are more accurate than other state-of-the-art baselinemethods for vulnerability classification and estimation. Furthermore, weconduct qualitative evaluations including a survey study and a user study toobtain software practitioners' perceptions of our AIBugHunter tool and assessthe impact that AIBugHunter may have on developers' productivity in securityaspects. Our survey study shows that our AIBugHunter is perceived as usefulwhere 90% of the participants consider adopting our AIBugHunter. Last but notleast, our user study shows that our AIBugHunter could possibly enhancedevelopers' productivity in combating cybersecurity issues during softwaredevelopment.",Michael Fu,2023/5/26,2023/5/26
2311.09727v1,Analysis of Comments Given in Documents Inspection in Software Development PBL and Investigation of the Impact on Students,http://arxiv.org/abs/2311.09727v1,"This study considers inspection conducted in software development PBL aslearning feedback and investigates the impact of each inspection comment onstudents. The authors have already collected most inspection comments for notonly requirements specification but also UML diagrams on GitHub. The authorsdevelop a tool that collects comments given in Figma to GitHub. We examine theimpact on students of each classification of inspection comments based on thepost-lesson questionnaire submitted by the students. Finally, we present thebenefits that classification of inspection comments can bring to PBL anddiscuss automatic comment classification by machine learning enabled bytext-based comments and the concept of software development PBL supportapplication enabled by automatic classification of inspection comments.",Oh Sato,2023/11/16,2023/11/16
1804.02153v1,Towards Identifying Paid Open Source Developers - A Case Study with Mozilla Developers,http://arxiv.org/abs/1804.02153v1,"Open source development contains contributions from both hired and volunteersoftware developers. Identification of this status is important when weconsider the transferability of research results to the closed source softwareindustry, as they include no volunteer developers. While many studies havetaken the employment status of developers into account, this information isoften gathered manually due to the lack of accurate automatic methods. In thispaper, we present an initial step towards predicting paid and unpaid opensource development using machine learning and compare our results withautomatic techniques used in prior work. By relying on code source repositorymeta-data from Mozilla, and manually collected employment status, we built adataset of the most active developers, both volunteer and hired by Mozilla. Wedefine a set of metrics based on developers' usual commit time pattern and usedifferent classification methods (logistic regression, classification tree, andrandom forest). The results show that our proposed method identify paid andunpaid commits with an AUC of 0.75 using random forest, which is higher thanthe AUC of 0.64 obtained with the best of the previously used automaticmethods.",Malick Claes,2018/4/6,2018/4/6
1601.03998v1,A Model-Driven Engineering Approach for ROS using Ontological Semantics,http://arxiv.org/abs/1601.03998v1,"This paper presents a novel ontology-driven software engineering approach forthe development of industrial robotics control software. It introduces theReApp architecture that synthesizes model-driven engineering with semantictechnologies to facilitate the development and reuse of ROS-based componentsand applications. In ReApp, we show how different ontological classificationsystems for hardware, software, and capabilities help developers in discoveringsuitable software components for their tasks and in applying them correctly.The proposed model-driven tooling enables developers to work at higherabstraction levels and fosters automatic code generation. It is underpinned byontologies to minimize discontinuities in the development workflow, with anintegrated development environment presenting a seamless interface to the user.First results show the viability and synergy of the selected approach whensearching for or developing software with reuse in mind.",Stefan Zander,2016/1/15,2016/1/15
1709.08439v1,Agile Software Development Methods: Review and Analysis,http://arxiv.org/abs/1709.08439v1,"Agile - denoting ""the quality of being agile, readiness for motion,nimbleness, activity, dexterity in motion"" - software development methods areattempting to offer an answer to the eager business community asking forlighter weight along with faster and nimbler software development processes.This is especially the case with the rapidly growing and volatile Internetsoftware industry as well as for the emerging mobile application environment.The new agile methods have evoked substantial amount of literature and debates.However, academic research on the subject is still scarce, as most of existingpublications are written by practitioners or consultants. The aim of thispublication is to begin filling this gap by systematically reviewing theexisting literature on agile software development methodologies. Thispublication has three purposes. First, it proposes a definition and aclassification of agile software development approaches. Second, it analysesten software development methods that can be characterized as being ""agile""against the defined criterion. Third, it compares these methods and highlightstheir similarities and differences. Based on this analysis, future researchneeds are identified and discussed.",Pekka Abrahamsson,2017/9/25,2017/9/25
2206.06918v1,varFEM: variational formulation based programming for finite element methods in Matlab,http://arxiv.org/abs/2206.06918v1,"This paper summarizes the development of varFEM, which provides a realizationof the programming style in FreeFEM by using the Matlab language.",Yue Yu,2022/6/14,2022/6/14
2311.09881v1,The Software Genome Project: Venture to the Genomic Pathways of Open Source Software and Its Applications,http://arxiv.org/abs/2311.09881v1,"With the boom in modern software development, open-source software has becomean integral part of various industries, driving progress in computer science.However, the immense complexity and diversity of the open-source ecosystem alsopose a series of challenges, including issues of quality, security, management,maintenance, compliance, and sustainability. Existing open-source governanceapproaches, while excelling in community building and collaboration, still faceshortcomings in decentralized management, security, and maintenance. To addressthese challenges, inspired by the Human Genome Project, we treat the softwaresource code as software DNA and propose the \textbf{Software Genome Project},which is geared towards the secure monitoring and exploitation of open-sourcesoftware. By identifying and labeling integrated and classified code featuresat a fine-grained level, and effectively identifying safeguards for functionalimplementations and non-functional requirements at different levels ofgranularity, Software Genome Project builds a complete set of software genomemaps to help developers and managers gain a deeper understanding of softwarecomplexity and diversity. By dissecting and summarizing functional andundesirable genes, Software Genome Project helps facilitate targeted softwareremediation and optimization, provides valuable insight and understanding ofthe entire software ecosystem, and supports critical development tasks such astechnology selection and open source governance. This project is expected todrive the evolution of software development towards more efficient, reliable,and sustainable software solutions.",Yueming Wu,2023/11/16,2023/11/16
2111.13962v1,Leveraging Unsupervised Learning to Summarize APIs Discussed in Stack Overflow,http://arxiv.org/abs/2111.13962v1,"Automated source code summarization is a task that generates summarizedinformation about the purpose, usage, and--or implementation of methods andclasses to support understanding of these code entities. Multiple approachesand techniques have been proposed for supervised and unsupervised learning incode summarization, however, they were mostly focused on generating a summaryfor a piece of code. In addition, very few works have leveraged unofficialdocumentation. This paper proposes an automatic and novel approach forsummarizing Android API methods discussed in Stack Overflow that we consider asunofficial documentation in this research. Our approach takes the API method'sname as an input and generates a natural language summary based on StackOverflow discussions of that API method. We have conducted a survey thatinvolves 16 Android developers to evaluate the quality of our automaticallygenerated summaries and compare them with the official Android documentation.Our results demonstrate that while developers find the official documentationmore useful in general, the generated summaries are also competitive, inparticular for offering implementation details, and can be used as acomplementary source for guiding developers in software development andmaintenance tasks.",AmirHossein Naghshzan,2021/11/27,2021/11/27
2108.11601v2,Retrieval Augmented Code Generation and Summarization,http://arxiv.org/abs/2108.11601v2,"Software developers write a lot of source code and documentation duringsoftware development. Intrinsically, developers often recall parts of sourcecode or code summaries that they had written in the past while implementingsoftware or documenting them. To mimic developers' code or summary generationbehavior, we propose a retrieval augmented framework, REDCODER, that retrievesrelevant code or summaries from a retrieval database and provides them as asupplement to code generation or summarization models. REDCODER has a couple ofuniqueness. First, it extends the state-of-the-art dense retrieval technique tosearch for relevant code or summaries. Second, it can work with retrievaldatabases that include unimodal (only code or natural language description) orbimodal instances (code-description pairs). We conduct experiments andextensive analysis on two benchmark datasets of code generation andsummarization in Java and Python, and the promising results endorse theeffectiveness of our proposed retrieval augmented framework.",Md Rizwan Parvez,2021/8/26,2021/9/10
2311.03364v1,BDD-Based Framework with RL Integration: An approach for videogames automated testing,http://arxiv.org/abs/2311.03364v1,"Testing plays a vital role in software development, but in the realm of videogames, the process differs from traditional software development practices.Game developers typically rely on human testers who are provided withchecklists to evaluate various elements. While major game developers alreadyemploy automated testing using script-based bots, the increasing complexity ofvideo games is pushing the limits of scripted solutions, necessitating theadoption of more advanced testing strategies. To assist game studios inenhancing the quality of their games through automated testing, we propose theintegration of Behavior Driven Development (BDD) with Reinforcement Learning(RL). This positional paper summarizes our proposal and framework underdevelopment.",Vincent Mastain,2023/10/8,2023/10/8
2001.00491v2,Dataset of Video Game Development Problems,http://arxiv.org/abs/2001.00491v2,"Different from traditional software development, there is little informationabout the software-engineering process and techniques in video-gamedevelopment. One popular way to share knowledge among the video-gamedevelopers' community is the publishing of postmortems, which are documentssummarizing what happened during the video-game development project. However,these documents are written without formal structure and often providingdisparate information. Through this paper, we provide developers andresearchers with grounded dataset describing software-engineering problems invideo-game development extracted from postmortems. We created the dataset usingan iterative method through which we manually coded more than 200 postmortemsspanning 20 years (1998 to 2018) and extracted 1,035 problems related tosoftware engineering while maintaining traceability links to the postmortems.We grouped the problems in 20 different types. This dataset is useful tounderstand the problems faced by developers during video-game development,providing researchers and practitioners a starting point to study video-gamedevelopment in the context of software engineering.",Cristiano Politowski,2020/1/2,2020/9/5
1802.02971v2,"Comment Generation for Source Code: State of the Art, Challenges and Opportunities",http://arxiv.org/abs/1802.02971v2,"Researches have shown that most effort of today's software development ismaintenance and evolution. Developers often use integrated developmentenvironments, debuggers, and tools for code search, testing, and programunderstanding to reduce the tedious tasks. One way to make software developmentmore efficient is to make the program more readable. There have been manyapproaches proposed and developed for this purpose. Among these approaches,comment generation for source code is gaining more and more attention and hasbecome a popular research area. In this paper, the state of art in commentgeneration research area are summarized and the challenges and futureopportunities are discussed.",Xiaoran Wang,2018/1/5,2018/9/7
2012.05987v1,Guiding Development Work Across a Software Ecosystem by Visualizing Usage Data,http://arxiv.org/abs/2012.05987v1,"Software is increasingly produced in the form of ecosystems, collections ofinterdependent components maintained by a distributed community. Theseecosystems act as network organizations, not markets, and thus often lackactionable price-like signals about how the software is used and what impact ithas. We introduce a tool, the Scientific Software Network Map, that collectsand displays summarized usage data tailored to the needs of actors in softwareecosystems. We performed a contextualized walkthrough of the Map with producersand stewards in six scientific software ecosystems that use the R language. Wefound that they work to maximize diversity rather than quantity of uses, and tominimize coordination costs. We also found that summarized usage data would beuseful for justifying ecosystem work to funding agencies; and we discovered avariety of more granular usage needs that would help in adding or maintainingfeatures.",Christopher Bogart,2020/12/10,2020/12/10
2301.03447v1,Automatic Standardization of Arabic Dialects for Machine Translation,http://arxiv.org/abs/2301.03447v1,"Based on an annotated multimedia corpus, television series Mar{\=a}y{\=a}2013, we dig into the question of ''automatic standardization'' of Arabicdialects for machine translation. Here we distinguish between rule-basedmachine translation and statistical machine translation. Machine translationfrom Arabic most of the time takes standard or modern Arabic as the sourcelanguage and produces quite satisfactory translations thanks to theavailability of the translation memories necessary for training the models. Thecase is different for the translation of Arabic dialects. The productions aremuch less efficient. In our research we try to apply machine translationmethods to a dialect/standard (or modern) Arabic pair to automatically producea standard Arabic text from a dialect input, a process we call ''automaticstandardization''. we opt here for the application of ''statistical models''because ''automatic standardization'' based on rules is more hard with the lackof ''diglossic'' dictionaries on the one hand and the difficulty of creatinglinguistic rules for each dialect on the other. Carrying out this researchcould then lead to combining ''automatic standardization'' software andautomatic translation software so that we take the output of the first softwareand introduce it as input into the second one to obtain at the end a qualitymachine translation. This approach may also have educational applications suchas the development of applications to help understand different Arabic dialectsby transforming dialectal texts into standard Arabic.",Abidrabbo Alnassan,2023/1/9,2023/1/9
2209.13372v1,CSRE4SOC (CSR evaluation for software companies),http://arxiv.org/abs/2209.13372v1,"Software development companies are increasingly concerned about their impacton the environment. This is translated into the incorporation of actionsrelated to software sustainability in their Corporate Social Responsibility(CSR) document. CSR reflects a company's obligations to society and theenvironment. However, we have found that companies do not always have thenecessary knowledge to be able to include actions related to softwaresustainability. Moreover, there is still a lot of work to be done, as thenumber of actions they incorporate is often insufficient. Taking all this intoaccount, we consider it essential for software development companies to have atool that allows them to assess their level of software sustainability, basedon the actions of their CSR, and to automatically provide them with a series ofimprovements to advance their level of software sustainability. Therefore, thispaper introduces CSRE4SOC, a tool for the evaluation and monitoring of thesoftware sustainability level of software development companies according totheir CSR.",Elisa Jimenez,2022/9/27,2022/9/27
1901.09781v1,An open-source software platform for translational photoacoustic research and its application to motion-corrected blood oxygenation estimation,http://arxiv.org/abs/1901.09781v1,"Photoacoustic (PA) imaging systems based on clinical linear ultrasound arrayshave become increasingly popular in translational PA research. Such systems canbe more easily integrated in a clinical workflow due to the simultaneous accessto ultrasonic imaging and their familiarity of use to clinicians. In contrastto more complex setups, hand held linear probes can be applied to a largevariety of clinical use cases. However, most translational work with suchscanners is based on proprietary development and as such not accessible to thecommunity. In this contribution, we present a custom-built, hybrid,multispectral, real-time photoacoustic and ultrasonic imaging system with alinear array probe that is controlled by software developed within the MedicalImaging Interaction Toolkit (MITK) a highly customizable and extendableopen-source software platform. Our software offers direct control of both thelaser and the ultrasonic system and may serve as a starting point for varioustranslational research projects and developments. To demonstrate theapplicability of the platform, we used it to implement a new method for bloodoxygenation estimation in the presence of non-rigid inter-frame motion causedby pulsing arteries. Initial results from experiments with healthy humanvolunteers demonstrate the suitability of the method with the sample clinicalapplication of imaging the common carotid artery as well as peripheralextremity vessels.",Thomas Kirchner,2019/1/28,2019/1/28
1701.08485v1,Auto-Documenation for Software Development,http://arxiv.org/abs/1701.08485v1,"Software documentation is an essential but labor intensive task that oftenrequires a dedicated team of developers to ensure coverage and accuracy. Gooddocumentation will help shorten the development cycle and improve the overallteam efficiency as well as maintainability. In today's crowd-driven developmentenvironment, good documentation can go a long way in building a developercommunity from scratch. To that end, we took the first steps in building a toolcalled Autodoc that can assist software developers in writing betterdocumentation faster. Autodoc goes beyond traditional boilerplate templategeneration. Our integrated tool uses Deep Learning methods to construct asemantic understanding of the code. Just like machine translation in naturallanguages, Autodoc can translate snippets of code to comments, and insert themas short summaries inside the docstring. We also demonstrate the integration ofAutodoc as an IDE plugin as well as a web hook from within software hostingplatforms when submitting auto-documented code to user's Git repository.",Thomas Zheng,2017/1/30,2017/1/30
1311.6224v1,Linking Software Development and Business Strategy Through Measurement,http://arxiv.org/abs/1311.6224v1,"Most of today's products and services are software-based. Organizations thatdevelop software want to maintain and improve their competitiveness bycontrolling software-related risks. To do this, they need to align theirbusiness goals with software development strategies and translate them intoquantitative project management. There is also an increasing need to justifycost and resources for software and system development and other IT services bydemonstrating their impact on an organisation's higher-level goals. For both,linking business goals and software-related efforts in an organization isnecessary. However, this is a challenging task, and there is a lack of methodsaddressing this gap. The GQM+Strategies approach effectively links goals andstrategies on all levels of an organization by means of goal-orientedmeasurement. The approach is based on rationales for deciding about optionswhen operationalizing goals and for evaluating the success of strategies withrespect to goals.",Victor R. Basili,2013/11/25,2013/11/25
physics/0111056v1,Converting Equipment Control Software from Pascal to C/C++,http://arxiv.org/abs/physics/0111056v1,"The equipment control (EC) software of the GSI accelerators has been writtenentirely in Pascal. Modern software development is based on C++ or Java. To beprepared for the future, we decided to convert the EC software from Pascal to Cin a first step. Considering the large amount of software, this is doneautomatically as far as possible. The paper describes our experiences gainedusing a Pascal to C translator, Perl scripts, and, of course, some manualinteraction.",Ludwig Hechler,2001/11/9,2001/11/9
2303.10131v1,She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models,http://arxiv.org/abs/2303.10131v1,"Implicit gender bias in software development is a well-documented issue, suchas the association of technical roles with men. To address this bias, it isimportant to understand it in more detail. This study uses data miningtechniques to investigate the extent to which 56 tasks related to softwaredevelopment, such as assigning GitHub issues and testing, are affected byimplicit gender bias embedded in large language models. We systematicallytranslated each task from English into a genderless language and back, andinvestigated the pronouns associated with each task. Based on translating eachtask 100 times in different permutations, we identify a significant disparityin the gendered pronoun associations with different tasks. Specifically,requirements elicitation was associated with the pronoun ""he"" in only 6% ofcases, while testing was associated with ""he"" in 100% of cases. Additionally,tasks related to helping others had a 91% association with ""he"" while the sameassociation for tasks related to asking coworkers was only 52%. These findingsreveal a clear pattern of gender bias related to software development tasks andhave important implications for addressing this issue both in the training oflarge language models and in broader society.",Christoph Treude,2023/3/17,2023/3/17
1805.04342v1,Semiotic internationalization and localization of computer programs,http://arxiv.org/abs/1805.04342v1,"Localization, the process--part of translation studies--of adapting a programto a new linguistic community, is often intended in the relatively narrow senseof translating the messages and labels of the program into the target language.Correspondingly, internationalization, the discipline--which is part ofsoftware engineering--of putting in place all the measures that will makelocalization easier, is also limited in scope.  In this paper we analyze the various systems through which a programcommunicates with a person (icons, buttons, actions, interface layout, etc.)and find that most of them, far from being iconic, are in reality symbolicsemiotic systems related to the culture in which or for which the program wasdeveloped (typically American programmers of western office workers). Based onthese findings, we argue that during the localization process, the translatorshould have the option to translate them all, that is, to adapt the wholeinterface and its founding metaphors to the cultural environment in which theprogram is deployed.  This conclusion will result in a greater role for internationalization in thesoftware development process, and we outline a few architectural principlesthat should be considered when creating a program for a multi-cultural market.",Simone Santini,2018/5/11,2018/5/11
2109.10194v1,TranslateLocally: Blazing-fast translation running on the local CPU,http://arxiv.org/abs/2109.10194v1,"Every day, millions of people sacrifice their privacy and browsing habits inexchange for online machine translation. Companies and governments withconfidentiality requirements often ban online translation or pay a premium todisable logging. To bring control back to the end user and demonstrate speed,we developed translateLocally. Running locally on a desktop or laptop CPU,translateLocally delivers cloud-like translation speed and quality even on 10year old hardware. The open-source software is based on Marian and runs onLinux, Windows, and macOS.",Nikolay Bogoychev,2021/9/21,2021/9/21
1205.3025v2,Current practice in software development for computational neuroscience and how to improve it,http://arxiv.org/abs/1205.3025v2,"Almost all research work in computational neuroscience involves software. Asresearchers try to understand ever more complex systems, there is a continualneed for software with new capabilities. Because of the wide range of questionsbeing investigated, new software is often developed rapidly by individuals orsmall groups. In these cases, it can be hard to demonstrate that the softwaregives the right results. Software developers are often open about the code theyproduce and willing to share it, but there is little appreciation amongpotential users of the great diversity of software development practices andend results, and how this affects the suitability of software tools for use inresearch projects. To help clarify these issues, we have reviewed a range ofsoftware tools and asked how the culture and practice of software developmentaffects their validity and trustworthiness. We identified four key questionsthat can be used to categorize software projects and correlate them with thetype of product that results. The first question addresses what is beingproduced. The other three concern why, how, and by whom the work is done. Theanswers to these questions show strong correlations with the nature of thesoftware being produced, and its suitability for particular purposes. Based onour findings, we suggest ways in which current software development practice incomputational neuroscience can be improved and propose checklists to helpdevelopers, reviewers and scientists to assess the quality whether particularpieces of software are ready for use in research.",Marc-Oliver Gewaltig,2012/5/14,2013/11/20
1909.02616v2,An Empirical Study on the Characteristics of Question-Answering Process on Developer Forums,http://arxiv.org/abs/1909.02616v2,"Developer forums are one of the most popular and useful Q&A websites on APIusages. The analysis of API forums can be a critical resource for the automatedquestion and answer approaches. In this paper, we empirically study three APIforums including Twitter, eBay, and AdWords, to investigate the characteristicsof question-answering process. We observe that +60% of the posts on all threeforums were answered by providing API method names or documentation. +85% ofthe questions were answered by API development teams and the answers from APIdevelopment teams drew fewer follow-up questions. Our results provide empiricalevidences for us in a future work to build automated solutions to answerdeveloper questions on API forums.",Yi Li,2019/9/5,2019/9/9
2308.09573v1,How Do Java Developers Reuse StackOverflow Answers in Their GitHub Projects?,http://arxiv.org/abs/2308.09573v1,"StackOverflow (SO) is a widely used question-and-answer (Q\&A) website forsoftware developers and computer scientists. GitHub is an online developmentplatform used for storing, tracking, and collaborating on software projects.Prior work relates the information mined from both platforms to link useraccounts or compare developers' activities across platforms. However, not muchwork is done to characterize the SO answers reused by GitHub projects. For thispaper, we did an empirical study by mining the SO answers reused by Javaprojects available on GitHub. We created a hybrid approach of clone detection,keyword-based search, and manual inspection, to identify the answer(s) actuallyleveraged by developers. Based on the identified answers, we further studiedtopics of the discussion threads, answer characteristics (e.g., scores, ages,code lengths, and text lengths), and developers' reuse practices.  We observed that most reused answers offer programs to implement specificcoding tasks. Among all analyzed SO discussion threads, the reused answersoften have relatively higher scores, older ages, longer code, and longer textthan unused answers. In only 9% of scenarios (40/430), developers fully copiedanswer code for reuse. In the remaining scenarios, they reused partial code orcreated brand new code from scratch. Our study characterized 130 SO discussionthreads referred to by Java developers in 357 GitHub projects. Our empiricalfindings can guide SO answerers to provide better answers, and shed lights onfuture research related to SO and GitHub.",Juntong Chen,2023/8/18,2023/8/18
2310.02104v1,An empirical study of ChatGPT-3.5 on question answering and code maintenance,http://arxiv.org/abs/2310.02104v1,"Ever since the launch of ChatGPT in 2022, a rising concern is whether ChatGPTwill replace programmers and kill jobs. Motivated by this widespread concern,we conducted an empirical study to systematically compare ChatGPT againstprogrammers in question-answering and software-maintaining. We reused a datasetintroduced by prior work, which includes 130 StackOverflow (SO) discussionthreads referred to by the Java developers of 357 GitHub projects. We mainlyinvestigated three research questions (RQs). First, how does ChatGPT comparewith programmers when answering technical questions? Second, how do developersperceive the differences between ChatGPT's answers and SO answers? Third, howdoes ChatGPT compare with humans when revising code for maintenance requests?  For RQ1, we provided the 130 SO questions to ChatGPT, and manually comparedChatGPT answers with the accepted/most popular SO answers in terms ofrelevance, readability, informativeness, comprehensiveness, and reusability.For RQ2, we conducted a user study with 30 developers, asking each developer toassess and compare 10 pairs of answers, without knowing the information source(i.e., ChatGPT or SO). For RQ3, we distilled 48 software maintenance tasks from48 GitHub projects citing the studied SO threads. We queried ChatGPT to revisea given Java file, and to incorporate the code implementation for anyprescribed maintenance requirement. Our study reveals interesting phenomena:For the majority of SO questions (97/130), ChatGPT provided better answers; in203 of 300 ratings, developers preferred ChatGPT answers to SO answers; ChatGPTrevised code correctly for 22 of the 48 tasks. Our research will expandpeople's knowledge of ChatGPT capabilities, and shed light on future adoptionof ChatGPT by the software industry.",Md Mahir Asef Kabir,2023/10/3,2023/10/3
2110.00361v1,An analysis of open source software licensing questions in Stack Exchange sites,http://arxiv.org/abs/2110.00361v1,"Free and open source software is widely used in the creation of softwaresystems, whereas many organisations choose to provide their systems as opensource. Open source software carries licenses that determine the conditionsunder which the original software can be used. Appropriate use of licensesrequires relevant expertise by the practitioners, and has an important legalangle. Educators and employers need to ensure that developers have thenecessary training to understand licensing risks and how they can be addressed.At the same time, it is important to understand which issues practitioners facewhen they are using a specific open source license, when they are developingnew open source software products or when they are reusing open sourcesoftware. In this work, we examine questions posed about open source softwarelicensing using data from the following Stack Exchange sites: Stack Overflow,Software Engineering, Open Source and Law. We analyse the indication ofspecific licenses and topics in the questions, investigate the attention theposts receive and trends over time, whether appropriate answers are providedand which type of questions are asked. Our results indicate that practitionersneed, among other, clarifications about licensing specific software when otherlicenses are used, and for understanding license content. The results of thestudy can be useful for educators and employers, organisations that areauthoring open source software licenses and developers for understanding theissues faced when using licenses, whereas they are relevant to other softwareengineering research areas, such as software reusability.",Maria Papoutsoglou,2021/10/1,2021/10/1
2109.13172v2,An empirical study of question discussions on Stack Overflow,http://arxiv.org/abs/2109.13172v2,"Stack Overflow provides a means for developers to exchange knowledge. Whilemuch previous research on Stack Overflow has focused on questions and answers(Q&A), recent work has shown that discussions in comments also contain richinformation. On Stack Overflow, discussions through comments and chat rooms canbe tied to questions or answers. In this paper, we conduct an empirical studythat focuses on the nature of question discussions. We observe that: (1)Question discussions occur at all phases of the Q&A process, with mostbeginning before the first answer is received. (2) Both askers and answerersactively participate in question discussions; the likelihood of theirparticipation increases as the number of comments increases. (3) There is astrong correlation between the number of question comments and the questionanswering time (i.e., more discussed questions receive answers more slowly);also, questions with a small number of comments are likely to be answered morequickly than questions with no discussion. Our findings suggest that questiondiscussions contain a rich trove of data that is integral to the Q&A processeson Stack Overflow. We further suggest how future research can leverage theinformation in question discussions, along with the commonly studied Q&Ainformation.",Wenhan Zhu,2021/9/27,2022/7/19
1803.02300v1,A Gold Standard for Emotion Annotation in Stack Overflow,http://arxiv.org/abs/1803.02300v1,"Software developers experience and share a wide range of emotions throughouta rich ecosystem of communication channels. A recent trend that has emerged inempirical software engineering studies is leveraging sentiment analysis ofdevelopers' communication traces. We release a dataset of 4,800 questions,answers, and comments from Stack Overflow, manually annotated for emotions. Ourdataset contributes to the building of a shared corpus of annotated resourcesto support research on emotion awareness in software development.",Nicole Novielli,2018/3/6,2018/3/6
2108.11752v1,AppSecure.nrw Software Security Study,http://arxiv.org/abs/2108.11752v1,"In recent years, the World Economic Forum has identified software security asthe most significant technological risk to the world's population, assoftware-intensive systems process critical data and provide critical services.This raises the question of the extent to which German companies are addressingsoftware security in developing and operating their software products. Thispaper reports on the results of an extensive study among developers, productowners, and managers to answer this question. Our results show that ensuringsecurity is a multi-faceted challenge for companies, involving low awareness,inaccurate self-assessment, and a lack of competence on the topic of securesoftware development among all stakeholders. The current situation in softwaredevelopment is therefore detrimental to the security of software products inthe medium and long term.",Stefan Dziwok,2021/8/25,2021/8/25
2310.10921v1,Intelligent Software Tooling for Improving Software Development,http://arxiv.org/abs/2310.10921v1,"Software has eaten the world with many of the necessities and quality of lifeservices people use requiring software. Therefore, tools that improve thesoftware development experience can have a significant impact on the world suchas generating code and test cases, detecting bugs, question and answering,etc., The success of Deep Learning (DL) over the past decade has shown hugeadvancements in automation across many domains, including Software Developmentprocesses. One of the main reasons behind this success is the availability oflarge datasets such as open-source code available through GitHub or imagedatasets of mobile Graphical User Interfaces (GUIs) with RICO and ReDRAW to betrained on. Therefore, the central research question my dissertation exploresis: In what ways can the software development process be improved throughleveraging DL techniques on the vast amounts of unstructured softwareengineering artifacts?",Nathan Cooper,2023/10/17,2023/10/17
2302.05794v1,Mutation-Based Adversarial Attacks on Neural Text Detectors,http://arxiv.org/abs/2302.05794v1,"Neural text detectors aim to decide the characteristics that distinguishneural (machine-generated) from human texts. To challenge such detectors,adversarial attacks can alter the statistical characteristics of the generatedtext, making the detection task more and more difficult. Inspired by theadvances of mutation analysis in software development and testing, in thispaper, we propose character- and word-based mutation operators for generatingadversarial samples to attack state-of-the-art natural text detectors. Thisfalls under white-box adversarial attacks. In such attacks, attackers haveaccess to the original text and create mutation instances based on thisoriginal text. The ultimate goal is to confuse machine learning models andclassifiers and decrease their prediction accuracy.",Gongbo Liang,2023/2/11,2023/2/11
1504.06742v2,Improving software team collaboration with Synchronized Software Development,http://arxiv.org/abs/1504.06742v2,"Effective collaboration is a key factor in the success of a software projectdeveloped by a team. In this work, we suggest the approach of SynchronizedSoftware Development (SSD), which promotes a new mechanism of collaboration ingeneral, and for code synchronization in particular. In SSD, code changes madeby one developer are automatically propagated to others as long as they keepthe code free of compilation errors. Changes that introduce compilation errorsare not propagated until the errors are fixed. Moreover, other developers arerestricted from concurrently editing the entities involved in these changes.While in this state, developers are, however, free to modify the rest of theentities. The novelty of our approach is that it actively synchronizesdevelopers with the latest error free version of the source code, preventingpossible conflicts and merges that may arise due to concurrent changes made byfellow team members. SSD also allows for a more transparent an practically nearreal time awareness of new code that is being introduced by multipledevelopers. We built CSI (Code Synchronizing Intelligence), a prototypedemonstrating key features of SSD.",Stanislav Levin,2015/4/25,2015/4/28
2308.12267v1,Bugsplainer: Leveraging Code Structures to Explain Software Bugs with Neural Machine Translation,http://arxiv.org/abs/2308.12267v1,"Software bugs cost the global economy billions of dollars each year and takeup ~50% of the development time. Once a bug is reported, the assigned developerattempts to identify and understand the source code responsible for the bug andthen corrects the code. Over the last five decades, there has been significantresearch on automatically finding or correcting software bugs. However, therehas been little research on automatically explaining the bugs to thedevelopers, which is essential but a highly challenging task. In this paper, wepropose Bugsplainer, a novel web-based debugging solution that generatesnatural language explanations for software bugs by learning from a large corpusof bug-fix commits. Bugsplainer leverages code structures to reason about a bugand employs the fine-tuned version of a text generation model, CodeT5, togenerate the explanations.  Tool video: https://youtu.be/xga-ScvULpk",Parvez Mahbub,2023/8/23,2023/8/23
2101.06733v1,Profiling Software Developers with Process Mining and N-Gram Language Models,http://arxiv.org/abs/2101.06733v1,"Context: Profiling developers is challenging since many factors, such astheir skills, experience, development environment and behaviors, may influencea detailed analysis and the delivery of coherent interpretations.  Objective: We aim at profiling software developers by mining their softwaredevelopment process. To do so, we performed a controlled experiment where, inthe realm of a Python programming contest, a group of developers had the samewell-defined set of requirements specifications and a well-defined sprintschedule. Events were collected from the PyCharm IDE, and from the Mooshakautomatic jury where subjects checked-in their code.  Method: We used n-gram language models and text mining to characterizedevelopers' profiles, and process mining algorithms to discover their overallworkflows and extract the correspondent metrics for further evaluation.  Results: Findings show that we can clearly characterize with a coherentrationale most developers, and distinguish the top performers from the oneswith more challenging behaviors. This approach may lead ultimately to thecreation of a catalog of software development process smells.  Conclusions: The profile of a developer provides a software project manager aclue for the selection of appropriate tasks he/she should be assigned. With theincreasing usage of low and no-code platforms, where coding is automaticallygenerated from an upper abstraction layer, mining developer's actions in thedevelopment platforms is a promising approach to early detect not onlybehaviors but also assess project complexity and model effort.",Joo Caldeira,2021/1/17,2021/1/17
1807.02263v1,TextRank Based Search Term Identification for Software Change Tasks,http://arxiv.org/abs/1807.02263v1,"During maintenance, software developers deal with a number of software changerequests. Each of those requests is generally written using natural languagetexts, and it involves one or more domain related concepts. A developer needsto map those concepts to exact source code locations within the project inorder to implement the requested change. This mapping generally starts with asearch within the project that requires one or more suitable search terms.Studies suggest that the developers often perform poorly in coming up with goodsearch terms for a change task. In this paper, we propose and evaluate a novelTextRank-based technique that automatically identifies and suggests searchterms for a software change task by analyzing its task description. Experimentswith 349 change tasks from two subject systems and comparison with one of thelatest and closely related state-of-the-art approaches show that our techniqueis highly promising in terms of suggestion accuracy, mean average precision andrecall.",Mohammad Masudur Rahman,2018/7/6,2018/7/6
2104.14261v1,Quantum Computing Platforms: Assessing the Impact on Quality Attributes and SDLC Activities,http://arxiv.org/abs/2104.14261v1,"Practical quantum computing is rapidly becoming a reality. To harness quantumcomputers' real potential in software applications, one needs to have anin-depth understanding of all such characteristics of quantum computingplatforms (QCPs), relevant from the Software Engineering (SE) perspective.Restrictions on copying, deletion, the transmission of qubit states, a harddependency on quantum algorithms are few, out of many, examples of QCPcharacteristics that have significant implications for building quantumsoftware.  Thus, developing quantum software requires a paradigm shift in thinking bysoftware engineers. This paper presents the key findings from the SEperspective, resulting from an in-depth examination of state-of-the-art QCPsavailable today. The main contributions that we present include i) Proposing ageneral architecture of the QCPs, ii) Proposing a programming model fordeveloping quantum software, iii) Determining architecturally significantcharacteristics of QCPs, and \textbf{iv)} Determining the impact of thesecharacteristics on various Quality Attributes (QAs) and Software DevelopmentLife Cycle (SDLC) activities.  We show that the nature of QCPs makes them useful mainly in specializedapplication areas such as scientific computing. Except for performance andscalability, most of the other QAs (e.g., maintainability, testability, andreliability) are adversely affected by different characteristics of a QCP.",Balwinder Sodhi,2021/4/29,2021/4/29
2106.05658v2,Conditional COT-GAN for Video Prediction with Kernel Smoothing,http://arxiv.org/abs/2106.05658v2,"Causal Optimal Transport (COT) results from imposing a temporal causalityconstraint on classic optimal transport problems, which naturally generates anew concept of distances between distributions on path spaces. The firstapplication of the COT theory for sequential learning was given in Xu et al.(2020), where COT-GAN was introduced as an adversarial algorithm to trainimplicit generative models optimized for producing sequential data. Relying on(Xu et al., 2020), the contribution of the present paper is twofold. First, wedevelop a conditional version of COT-GAN suitable for sequence prediction. Thismeans that the dataset is now used in order to learn how a sequence will evolvegiven the observation of its past evolution. Second, we improve on theconvergence results by working with modifications of the empirical measures viakernel smoothing due to (Pflug and Pichler (2016)). The resulting kernelconditional COT-GAN algorithm is illustrated with an application for videoprediction.",Tianlin Xu,2021/6/10,2022/1/27
2306.00550v1,Chain-Of-Thought Prompting Under Streaming Batch: A Case Study,http://arxiv.org/abs/2306.00550v1,"Recently, Large Language Models (LLMs) have demonstrated remarkablecapabilities. Chain-of-Thought (CoT) has been proposed as a way of assistingLLMs in performing complex reasoning. However, developing effective prompts canbe a challenging and labor-intensive task. Many studies come out of some way toautomatically construct CoT from test data. Most of them assume that all testdata is visible before testing and only select a small subset to generaterationales, which is an unrealistic assumption. In this paper, we present acase study on how to construct and optimize chain-of-thought prompting usingbatch data in streaming settings.",Yuxin Tang,2023/6/1,2023/6/1
2005.09535v1,Backstabber's Knife Collection: A Review of Open Source Software Supply Chain Attacks,http://arxiv.org/abs/2005.09535v1,"A software supply chain attack is characterized by the injection of maliciouscode into a software package in order to compromise dependent systems furtherdown the chain. Recent years saw a number of supply chain attacks that leveragethe increasing use of open source during software development, which isfacilitated by dependency managers that automatically resolve, download andinstall hundreds of open source packages throughout the software life cycle.This paper presents a dataset of 174 malicious software packages that were usedin real-world attacks on open source software supply chains, and which weredistributed via the popular package repositories npm, PyPI, and RubyGems. Thosepackages, dating from November 2015 to November 2019, were manually collectedand analyzed. The paper also presents two general attack trees to provide astructured overview about techniques to inject malicious code into thedependency tree of downstream users, and to execute such code at differenttimes and under different conditions. This work is meant to facilitate thefuture development of preventive and detective safeguards by open source andresearch communities.",Marc Ohm,2020/5/19,2020/5/19
2308.08784v1,CodeCoT and Beyond: Learning to Program and Test like a Developer,http://arxiv.org/abs/2308.08784v1,"In natural language processing, transformer-based large language models(LLMs) like GPT-x models developed by OpenAI have revolutionized the landscape.Despite their impressive capabilities, these models often encounter challengeswhen handling tasks that differ from their training data, resulting incompromised performance. To address this, few-shot learning has emerged as avaluable technique, allowing LLMs to adapt with minimal task-specific data. Oneinnovative strategy, known as Chain-of-Thought Prompting (CoT), has beenintroduced to guide LLMs in revealing cognitive processes during multi-stepreasoning. In this paper, we propose Code Chain-of-Thought~(CodeCoT), whichconsists of two components: the Vanilla CodeCoT and the Self-exam CodeCoT. Thelatter incorporates self-examination, empowering the model to iterativelygenerate code, formulate test cases, and refine its outputs. Specifically, theprocess entails the generation of test examples by the model corresponding tothe code it is tasked to implement. If it fails on the test examples, then itregenerates the code based on the erroneous code and associated error types.Through comprehensive experiments, we observed that both techniquessignificantly enhance code generation accuracy across various LLM variants. Ourevaluation results reveal that CodeCoT improves the code generationeffectiveness, including an unprecedented pass@1 accuracy of 79.27\% using theSelf-exam CodeCoT approach on the gpt-3.5-turbo-0613 model in the HumanEvaldataset.",Dong Huang,2023/8/17,2023/8/17
1309.1810v1,Niche Modeling: Ecological Metaphors for Sustainable Software in Science,http://arxiv.org/abs/1309.1810v1,This position paper is aimed at providing some history and provocations forthe use of an ecological metaphor to describe software developmentenvironments. We do not claim that the ecological metaphor is the best or onlyway of looking at software - rather we want to ask if it can indeed be aproductive and thought provoking one.,Nicholas Weber,2013/9/7,2013/9/7
2112.10165v2,What are Weak Links in the npm Supply Chain?,http://arxiv.org/abs/2112.10165v2,"Modern software development frequently uses third-party packages, raising theconcern of supply chain security attacks. Many attackers target popular packagemanagers, like npm, and their users with supply chain attacks. In 2021 therewas a 650% year-on-year growth in security attacks by exploiting Open SourceSoftware's supply chain. Proactive approaches are needed to predict packagevulnerability to high-risk supply chain attacks. The goal of this work is tohelp software developers and security specialists in measuring npm supply chainweak link signals to prevent future supply chain attacks by empiricallystudying npm package metadata.  In this paper, we analyzed the metadata of 1.63 million JavaScript npmpackages. We propose six signals of security weaknesses in a software supplychain, such as the presence of install scripts, maintainer accounts associatedwith an expired email domain, and inactive packages with inactive maintainers.One of our case studies identified 11 malicious packages from the installscripts signal. We also found 2,818 maintainer email addresses associated withexpired domains, allowing an attacker to hijack 8,494 packages by taking overthe npm accounts. We obtained feedback on our weak link signals through asurvey responded to by 470 npm package developers. The majority of thedevelopers supported three out of our six proposed weak link signals. Thedevelopers also indicated that they would want to be notified about weak linkssignals before using third-party packages. Additionally, we discussed eight newsignals suggested by package developers.",Nusrat Zahan,2021/12/19,2022/2/14
1905.12922v1,A Study on Software Metrics and its Impact on Software Quality,http://arxiv.org/abs/1905.12922v1,"Software metrics offer a quantitative basis for predicting the softwaredevelopment process. In this way, software quality can be improved very easily.Software quality should be achieved to satisfy the customer with decreasing thesoftware cost and improve there liability of the software product. In thisresearch, we have discussed how the software metrics affect the quality of thesoftware and which stages of its development software metrics have applied. Wediscussed the different software metrics and how these metrics have an impacton software quality and reliability. These techniques have been used forimproving the quality of software and increase the revenue.",Junaid Rashid,2019/5/30,2019/5/30
2012.15153v1,Importance of Secure Software Development Processes and Tools for Developers,http://arxiv.org/abs/2012.15153v1,"In this research paper of secure software systems, authors have discussedwhat the proper development process is when it comes to creating a securesoftware, which will be suited for developers and relevent stakeholders alike.Secure Software Development Process for Developers is of crucial importance forsoftware engineers as more and more software-based devices are becomingcommonly available, and cloud services are evolving which require for thesoftware to be constantly connected to the internet. With this in mind, SecureSoftware Development needs to be transformed to something most developers canrely upon to make applied software safe and have the capability to mitigateagainst potential attacks by hackers. Furthermore, in this paper, existingSecure Software Development Process ideas and implementations are reviewed andinvestigated using the research paper pool available online. Thereafter, anapproach is proposed to enhance the security aspect in software developmentprocess to resolve security issues. Lastly, the paper concludes with finalremarks on practical implementation of security features in softwaredevelopment phases for production of secure and reliable software programs andsystems.",Muhammad Danish Roshaidie,2020/12/30,2020/12/30
1611.05789v1,Applying Software Craftsmanship Practices to a Scrum Project: an Experience Report,http://arxiv.org/abs/1611.05789v1,The Software Craftsmanship manifesto has defined values and principles thatsoftware development teams should follow to deliver quality software thatfulfills functional and non-functional requirements without dealing with highamounts of technical debt. Software craftsmanship approach to softwaredevelopment prioritizes technical practices in order to provide a clean codebase. This work analyzes a set of practices that can be applied to a Scrumproject that aims to incorporate Software Craftsmanship values. The processimplementation described may be a useful contribution for software developmentteams who also intend to implement Software Craftsmanship on their projects.,Percival Lucena,2016/11/17,2016/11/17
1607.06324v2,Modeling Software Development Methodologies: A Logic Based Approach,http://arxiv.org/abs/1607.06324v2,"In the last two decades, the growing trend of software development industryhas made different aspects of software engineering more interesting for thecomputer science research community. Software development life-cycle is one ofthese aspects that has a significant impact on the success/failure of softwaredevelopment projects. Since each software development methodology relativelyprovides its own software development life-cycle, encoding software developmentlife-cycle in a workflow representation language can help developers toproperly manage their software projects. In addition, such encoding can also beused in CASE tools. In this report, we consider the software developmentlife-cycle as a workflow that can be represented by semantic web and rule basedlanguages. Such consideration let one analyze the properties of the life-cycle.Specifically, we take a well-known agent oriented software developmentmethodology and show that its corresponding life-cycle can be specified byTransaction Logic easily and concisely. Finally, the compact and clearrepresentation of the life-cycle in Transaction Logic can be used in CASE toolsto guide software developers.",Farzad Mahdikhani,2016/7/20,2016/8/3
2109.10971v1,Developers Perception of Peer Code Review in Research Software Development,http://arxiv.org/abs/2109.10971v1,"Background: Research software is software developed by and/or used byresearchers, across a wide variety of domains, to perform their research.Because of the complexity of research software, developers cannot conductexhaustive testing. As a result, researchers have lower confidence in thecorrectness of the output of the software. Peer code review, a standardsoftware engineering practice, has helped address this problem in other typesof software. Aims: Peer code review is less prevalent in research software thanit is in other types of software. In addition, the literature does not containany studies about the use of peer code review in research software. Therefore,through analyzing developers perceptions, the goal of this work is tounderstand the current practice of peer code review in the development ofresearch software, identify challenges and barriers associated with peer codereview in research software, and present approaches to improve the peer codereview in research software. Method: We conducted interviews and a communitysurvey of research software developers to collect information about theircurrent peer code review practices, difficulties they face, and how theyaddress those difficulties. Results: We received 84 unique responses from theinterviews and surveys. The results show that while research software teamsreview a large amount of their code, they lack formal process, properorganization, and adequate people to perform the reviews. Conclusions: Use ofpeer code review is promising for improving the quality of research softwareand thereby improving the trustworthiness of the underlying research results.In addition, by using peer code review, research software developers producemore readable and understandable code, which will be easier to maintain.",Nasir U. Eisty,2021/9/22,2021/9/22
1804.09044v1,Toward a Better Understanding of How to Develop Software Under Stress - Drafting the Lines for Future Research,http://arxiv.org/abs/1804.09044v1,"The software is often produced under significant time constraints. Our ideais to understand the effects of various software development practices on theperformance of developers working in stressful environments, and identify thebest operating conditions for software developed under stressful conditionscollecting data through questionnaires, non-invasive software measurement toolsthat can collect measurable data about software engineers and the software theydevelop, without intervening their activities, and biophysical sensors and thentry to recreated also in different processes or key development practices suchconditions.",Joseph Alexander Brown,2018/4/24,2018/4/24
2312.17358v1,An Introduction to Adaptive Software Security,http://arxiv.org/abs/2312.17358v1,"This paper presents the adaptive software security model, an innovativeapproach integrating the MAPE-K loop and the Software Development Life Cycle(SDLC). It proactively embeds security policies throughout development,reducing vulnerabilities from different levels of software engineering. Threeprimary contributions-MAPE-K integration, SDLC embedding, and analyticalinsights-converge to create a comprehensive approach for strengthening softwaresystems against security threats. This research represents a paradigm shift,adapting security measures with agile software development and ensuringcontinuous improvement in the face of evolving threats. The model emerges as arobust solution, addressing the crucial need for adaptive software securitystrategies in modern software development. We analytically discuss theadvantages of the proposed model.",Mehran Alidoost Nia,2023/12/28,2023/12/28
2208.12164v1,Sistematic mapping protocol - estimation accuracy on software development using agile technologies,http://arxiv.org/abs/2208.12164v1,"Protocol for a Systematic Mapping of the Literature, which aims to identifyand classify the estimations techniques used in software development agilemethodologies based on the results found, and to compare their estimationaccuracies against those obtained in traditional software developmentmethodologies.",Marcelo Fransoy,2022/8/25,2022/8/25
1309.1783v2,DUNE as an Example of Sustainable Open Source Scientific Software Development,http://arxiv.org/abs/1309.1783v2,"In this paper we describe how DUNE, an open source scientific softwareframework, is developed. Having a sustainable software framework for thesolution of partial differential equations is the main driver of DUNE'sdevelopment. We take a look how DUNE strives to stay sustainable software.",Makus Blatt,2013/9/6,2013/9/15
1612.03109v1,A comprehensive safety engineering approach for software-intensive systems based on STPA,http://arxiv.org/abs/1612.03109v1,"Formal verification and testing are complementary approaches which are usedin the development process to verify the functional correctness of software.However, the correctness of software cannot ensure the safe operation ofsafety-critical software systems. The software must be verified against itssafety requirements which are identified by safety analysis, to ensure thatpotential hazardous causes cannot occur. The complexity of software makesdefining appropriate software safety requirements with traditional safetyanalysis techniques difficult. STPA (Systems-Theoretic Processes Analysis) is aunique safety analysis approach that has been developed to identify systemhazards, including the software-related hazards. This paper presents acomprehensive safety engineering approach based on STPA, including softwaretesting and model checking approaches for the purpose of developing safesoftware. The proposed approach can be embedded within a defined softwareengineering process or applied to existing software systems, allow software andsafety engineers integrate the analysis of software risks with theirverification. The application of the proposed approach is illustrated with anautomotive software controller.",Asim Abdulkhaleq,2016/12/9,2016/12/9
1008.3321v1,Software Development Standard and Software Engineering Practice: A Case Study of Bangladesh,http://arxiv.org/abs/1008.3321v1,"Improving software process to achieve high quality in a software developmentorganization is the key factor to success. Bangladeshi software firms have notexperienced much in this particular area in comparison to other countries. TheISO 9001 and CMM standard has become a basic part of software development. Themain objectives of our study are: 1) To understand the software developmentprocess uses by the software developer firms in Bangladesh 2) To identify thedevelopment practices based on established quality standard and 3) To establisha standardized and coherent process for the development of software for aspecific project. It is revealed from this research that software industries ofBangladesh are lacking in target set for software process and improvement,involvement of quality control activities, and standardize business expertisepractice. This paper investigates the Bangladeshi software industry in thelight of the above challenges.",Zerina Begum,2010/8/19,2010/8/19
1602.07306v1,Disentangling the ICL with the CHEFs: Abell 2744 as a case study,http://arxiv.org/abs/1602.07306v1,"Measurements of the intracluster light (ICL) are still prone tomethodological ambiguities and there are multiple techniques in the literaturefor that purpose, mostly based on the binding energy, the local densitydistribution, or the surface brightness. A common issue with these methods isthe a priori assumption of a number of hypotheses on either the ICL morphology,its surface brightness level or some properties of the brightest cluster galaxy(BCG). The discrepancy on the results is high, and numerical simulations justbound the ICL fraction in present-day galaxy clusters to the range 10-50%. Wedeveloped a new algorithm based on the Chebyshev-Fourier functions (CHEFs) toestimate the ICL fraction without relying on any a priori assumption on thephysical or geometrical characteristics of the ICL. We are able to not onlydisentangle the ICL from the galatic luminosity but mark out the limits of theBCG from the ICL in a natural way. We test our tecnique with the recentlyreleased data of the cluster Abell 2744, observed by the Frontier Fieldsprogram. The complexity of this multiple merging cluster system and theformidable depth of these images make it a challenging test case to prove theefficiency of our algorithm. We found a final ICL fraction of 19.17+-2.87%,which is very consistent with numerical simulations.",Y. Jimenez-Teja,2016/2/23,2016/2/23
1402.3410v1,Wmixnet: Software for Clustering the Nodes of Binary and Valued Graphs using the Stochastic Block Model,http://arxiv.org/abs/1402.3410v1,"Clustering the nodes of a graph allows the analysis of the topology of anetwork.  The stochastic block model is a clustering method based on a probabilisticmodel. Initially developed for binary networks it has recently been extended tovalued networks possibly with covariates on the edges.  We present an implementation of a variational EM algorithm. It is writtenusing C++, parallelized, available under a GNU General Public License (version3), and can select the optimal number of clusters using the ICL criteria. Itallows us to analyze networks with ten thousand nodes in a reasonable amount oftime.",Jean-Benoist Leger,2014/2/14,2014/2/14
2311.18016v1,Preparing for low surface brightness science with the Vera C. Rubin Observatory: A Comparison of Observable and Simulated Intracluster Light Fractions,http://arxiv.org/abs/2311.18016v1,"Intracluster Light (ICL) provides an important record of the interactionsgalaxy clusters have undergone. However, we are limited in our understanding byour measurement methods. To address this we measure the fraction of clusterlight that is held in the Brightest Cluster Galaxy and ICL (BCG+ICL fraction)and the ICL alone (ICL fraction) using observational methods (SurfaceBrightness Threshold-SB, Non-Parametric Measure-NP, Composite Models-CM,Multi-Galaxy Fitting-MGF) and new approaches under development (WaveletDecomposition-WD) applied to mock images of 61 galaxy clusters (14<log10M_200c/M_solar <14.5) from four cosmological hydrodynamical simulations. Wecompare the BCG+ICL and ICL fractions from observational measures with thoseusing simulated measures (aperture and kinematic separations). The ICLfractions measured by kinematic separation are significantly larger thanobserved fractions. We find the measurements are related and provide equationsto estimate kinematic ICL fractions from observed fractions. The differentobservational techniques give consistent BCG+ICL and ICL fractions but arebiased to underestimating the BCG+ICL and ICL fractions when compared withaperture simulation measures. Comparing the different methods and algorithms wefind that the MGF algorithm is most consistent with the simulations, and CM andSB methods show the smallest projection effects for the BCG+ICL and ICLfractions respectively. The Ahad (CM), MGF and WD algorithms are best set up toprocess larger samples, however, the WD algorithm in its current form issusceptible to projection effects. We recommend that new algorithms using thesemethods are explored to analyse the massive samples that Rubin Observatory'sLegacy Survey of Space and Time will provide.",Sarah Brough,2023/11/29,2023/11/29
2307.00259v2,InstructEval: Systematic Evaluation of Instruction Selection Methods,http://arxiv.org/abs/2307.00259v2,"In-context learning (ICL) performs tasks by prompting a large language model(LLM) using an instruction and a small set of annotated examples calleddemonstrations. Recent work has shown that precise details of the inputs usedin the ICL prompt significantly impact performance, which has incentivizedinstruction selection algorithms. The effect of instruction-choice however isseverely underexplored, with existing analyses restricted to shallow subsets ofmodels and tasks, limiting the generalizability of their insights. We developInstructEval, an ICL evaluation suite to conduct a thorough assessment of thesetechniques. The suite includes 13 open-sourced LLMs of varying scales from fourmodel families, and covers nine tasks across three categories. Using the suite,we evaluate the relative performance of seven popular instruction selectionmethods over five metrics relevant to ICL. Our experiments reveal that usingcurated manually-written instructions or simple instructions without anytask-specific descriptions often elicits superior ICL performance overall thanthat of automatic instruction-induction methods, pointing to a lack ofgeneralizability among the latter. We release our evaluation suite forbenchmarking instruction selection approaches and enabling more generalizablemethods in this space.",Anirudh Ajith,2023/7/1,2023/7/16
2401.12097v1,An Empirical Analysis of In-context Learning Abilities of LLMs for MT,http://arxiv.org/abs/2401.12097v1,"In-context learning (ICL) has consistently demonstrated superior performanceover zero-shot performance in large language models (LLMs). However, theunderstanding of the dynamics of ICL and the aspects that influence downstreamperformance remains limited, especially for natural language generation (NLG)tasks. This work aims to address this gap by investigating the ICL capabilitiesof LLMs and studying the impact of different aspects of the in-contextdemonstrations for the task of machine translation (MT). Our preliminaryinvestigations aim to discern whether in-context learning (ICL) ispredominantly influenced by demonstrations or instructions by applying diverseperturbations to in-context demonstrations while preserving the taskinstruction. We observe varying behavior to perturbed examples across differentmodel families, notably with BLOOM-7B derivatives being severely influenced bynoise, whereas Llama 2 derivatives not only exhibit robustness but also tend toshow enhancements over the clean baseline when subject to perturbeddemonstrations. This suggests that the robustness of ICL may be governed byseveral factors, including the type of noise, perturbation direction (source ortarget), the extent of pretraining of the specific model, and fine-tuning fordownstream tasks if applicable. Further investigation is warranted to develop acomprehensive understanding of these factors in future research.",Pranjal A. Chitale,2024/1/22,2024/1/22
1409.1197v1,Upper-Level Physics Students' Perceptions of Physicists,http://arxiv.org/abs/1409.1197v1,"As part of a longitudinal study into identity development in upper-levelphysics students, we used a phenomenographic research method to examinestudents' perceptions of what it means to be a physicist. The results revealedfour different categories. We find a clear distinction in the exclusivitystudents associate with being a physicist and the differences in the importanceof research and its association with being a physicist. A relationship betweenperceptions of physicists and goal orientation is indicated.",Paul W. Irving,2014/9/3,2014/9/3
2107.13259v1,TransAction: ICL-SJTU Submission to EPIC-Kitchens Action Anticipation Challenge 2021,http://arxiv.org/abs/2107.13259v1,"In this report, the technical details of our submission to the EPIC-KitchensAction Anticipation Challenge 2021 are given. We developed a hierarchicalattention model for action anticipation, which leverages Transformer-basedattention mechanism to aggregate features across temporal dimension,modalities, symbiotic branches respectively. In terms of Mean Top-5 Recall ofaction, our submission with team name ICL-SJTU achieved 13.39% for overalltesting set, 10.05% for unseen subsets and 11.88% for tailed subsets.Additionally, it is noteworthy that our submission ranked 1st in terms of verbclass in all three (sub)sets.",Xiao Gu,2021/7/28,2021/7/28
2102.05608v1,A Cognitive and Machine Learning-Based Software Development Paradigm Supported by Context,http://arxiv.org/abs/2102.05608v1,"Advances in the use of cognitive and machine learning (ML) enabled systemsfuel the quest for novel approaches and tools to support software developers inexecuting their tasks. First, as software development is a complex and dynamicactivity, these tasks are highly dependent on the characteristics of thesoftware project and its context, and developers need comprehensive support interms of information and guidance based on the task context. Second, there is alack of methods based on conversational-guided agents that consider cognitiveaspects such as paying attention and remembering. Third, there is also a lackof techniques that make use of historical implicit or tacit data to infer newknowledge about the project tasks such as related tasks, task experts, relevantinformation needed for task completion and warnings, and navigation aspects ofthe process such as what tasks to perform next and optimal task sequencing.Based on these challenges, this paper introduces a novel paradigm forhuman-machine software support based on context, cognitive assistance, andmachine learning, and briefly describes ongoing research activities to realizethis paradigm. The research takes advantage of the synergy among emergentmethods provided in context-aware software processes, cognitive computing suchas chatbots, and machine learning such as recommendation systems. These novelparadigms have the potential to transform the way software developmentcurrently occurs by allowing developers to receive valuable information andguidance in real-time while they are participating in projects.",Glaucia Melo,2021/2/10,2021/2/10
1910.08167v1,Context-Augmented Software Development Projects: Literature Review and Preliminary Framework,http://arxiv.org/abs/1910.08167v1,"Software development is a complex activity which depends on diversetechnologies and people's expertise. The approaches to developing softwarehighly depend on these different characteristics, which are the contextdevelopers are subject to. This context contains massive knowledge, and notcapturing it means knowledge is continuously lost. Although extensivelyresearched, context in software development is still not explicit, nor proposedinto a broader view of the context needed by software developers and tools.Therefore, developers' productivity is affected, as the ability to reuse thisrich context is hampered. This paper proposes a literature review on contextfor software development, through nine research questions. The purpose of thisstudy is making the discovered context explicit into an integrated view andproposing a platform to aid software development using context information. Webelieve supporting contextual knowledge through its representation and miningfor recommendation and real-time provision can significantly improve big datasoftware project development.",Glaucia Melo,2019/10/17,2019/10/17
1901.00324v1,Agile Development at Scale: The Next Frontier,http://arxiv.org/abs/1901.00324v1,"Agile methods have transformed the way software is developed, emphasizingactive end-user involvement, tolerance to change, and evolutionary delivery ofproducts. The first special issue on agile development described the methods asfocusing on ""feedback and change"". These methods have led to major changes inhow software is developed. Scrum is now the most common framework fordevelopment in most countries, and other methods like extreme programming (XP)and elements of lean software development and Kanban are widely used. Whatstarted as a bottom-up movement amongst software practitioners and consultantshas been taken up by major international consulting companies who prescribeagile development, particularly for contexts where learning and innovation arekey. Agile development methods have attracted interest primarily in softwareengineering, but also in a number of other disciplines including informationsystems and project management.  The agile software development methods were originally targeted towardssmall, co-located development teams, but are increasingly applied in othercontexts. They were initially used to develop Web systems and internal ITsystems, but are now used in a range of domains, including mission-criticalsystems. Methods that were designed for single teams of 5-9 developers havebeen adapted for use in projects with tens of teams, hundreds of developers,which can involve integration with hundreds of existing systems and affecthundreds of thousands of users.",Torgeir Dingsyr,2019/1/2,2019/1/2
2310.13648v1,Using ChatGPT throughout the Software Development Life Cycle by Novice Developers,http://arxiv.org/abs/2310.13648v1,"This study investigates the impact of ChatGPT -- a generative AI-based tool-- on undergraduate students' software development experiences. Through athree-month project involving seven undergraduate students, ChatGPT wasemployed as a supporting tool, and their experiences were systematicallysurveyed before and after the projects. The research aims to answer four keyquestions related to ChatGPT's effectiveness, advantages, limitations, impacton learning, and challenges faced. The findings revealed significant skill gapsamong undergraduate students, underscoring the importance of addressingeducational deficiencies in software development. ChatGPT was found to have apositive influence on various phases of the software development life cycle,leading to enhanced efficiency, accuracy, and collaboration. ChatGPT alsoconsistently improved participants' foundational understanding and soft skillsin software development. These findings underscore the significance ofintegrating AI tools like ChatGPT into undergraduate students education,particularly to bridge skill gaps and enhance productivity. However, a nuancedapproach to technology reliance is essential, acknowledging the variability inopinions and the need for customization. Future research should explorestrategies to optimize ChatGPT's application across development contexts,ensuring it maximizes learning while addressing specific challenges.",Muhammad Waseem,2023/10/20,2023/10/20
2106.14598v1,Software quality: A Historical and Synthetic Content Analysis,http://arxiv.org/abs/2106.14598v1,"Interconnected computers and software systems have become an indispensablepart of people's lives, therefore software quality research is becoming moreand more important. There have been multiple attempts to synthesize knowledgegained in software quality research, however, they were focused mainly onsingle aspects of software quality and not to structure the knowledge in aholistic way. The aim of our study was to close this gap. The software qualitypublications were harvested from the Scopus bibliographic database. Themetadata was exported first to CRexlporer, which was employed to identifyhistorical roots, and next to VOSViewer, which was used as a part of thesynthetic content analysis. In our study we defined synthetic context analysisas a triangulation of bibliometrics and content analysis. Our search resultedin 14451 publications. The performance bibliometric study showed that theproduction of research publications relating to software quality is currentlyfollowing an exponential growth trend and that the software quality researchcommunity is growing. The most productive country was the United States and themost productive Institution The Florida Atlantic University. The syntheticcontent analysis revealed that the published knowledge can be structured into10 themes, the most important being the themes regarding software qualityimprovement with enhancing software engineering, advanced software testing, andimproved defect and fault prediction with machine learning and data mining.According to the analysis of the hot topics, it seems that future research willbe directed into developing and using a full specter of new artificialintelligence tools (not just machine learning and data mining) and focusing onhow to assure software quality in agile development paradigms.",Peter Kokol,2021/6/28,2021/6/28
2011.03751v1,Software engineering for artificial intelligence and machine learning software: A systematic literature review,http://arxiv.org/abs/2011.03751v1,"Artificial Intelligence (AI) or Machine Learning (ML) systems have beenwidely adopted as value propositions by companies in all industries in order tocreate or extend the services and products they offer. However, developingAI/ML systems has presented several engineering problems that are differentfrom those that arise in, non-AI/ML software development. This study aims toinvestigate how software engineering (SE) has been applied in the developmentof AI/ML systems and identify challenges and practices that are applicable anddetermine whether they meet the needs of professionals. Also, we assessedwhether these SE practices apply to different contexts, and in which areas theymay be applicable. We conducted a systematic review of literature from 1990 to2019 to (i) understand and summarize the current state of the art in this fieldand (ii) analyze its limitations and open challenges that will drive futureresearch. Our results show these systems are developed on a lab context or alarge company and followed a research-driven development process. The mainchallenges faced by professionals are in areas of testing, AI software quality,and data management. The contribution types of most of the proposed SEpractices are guidelines, lessons learned, and tools.",Elizamary Nascimento,2020/11/7,2020/11/7
2309.04797v1,A Full-fledged Commit Message Quality Checker Based on Machine Learning,http://arxiv.org/abs/2309.04797v1,"Commit messages (CMs) are an essential part of version control. By providingimportant context in regard to what has changed and why, they strongly supportsoftware maintenance and evolution. But writing good CMs is difficult and oftenneglected by developers. So far, there is no tool suitable for practice thatautomatically assesses how well a CM is written, including its meaning andcontext. Since this task is challenging, we ask the research question: how wellcan the CM quality, including semantics and context, be measured with machinelearning methods? By considering all rules from the most popular CM qualityguideline, creating datasets for those rules, and training and evaluatingstate-of-the-art machine learning models to check those rules, we can answerthe research question with: sufficiently well for practice, with the lowestF$_1$ score of 82.9\%, for the most challenging task. We develop a full-fledgedopen-source framework that checks all these CM quality rules. It is useful forresearch, e.g., automatic CM generation, but most importantly for softwarepractitioners to raise the quality of CMs and thus the maintainability andevolution speed of their software.",David Farag,2023/9/9,2023/9/9
2205.00149v1,Quality Assurance in the Context of Contemporary Software Practice,http://arxiv.org/abs/2205.00149v1,We review the literature on the nature of quality assurance in the context ofcomnplex systems developed using iterative and incremental approaches.,Stephen G. MacDonell,2022/4/30,2022/4/30
1006.0878v1,Developing E-Learning Materials for Software Development Course,http://arxiv.org/abs/1006.0878v1,"Software Development is a core second-year course currently offered toundergraduate students at Victoria University at its five local andinternational campuses. The project aims to redesign the existing coursecurriculum to support student-centred teaching and learning. It is intended toprovide a learning context in which learners can reflect on new material,discuss their tentative understandings with others, actively search for newinformation, develop skills in communication and collaboration, and buildconceptual connections to their existing knowledge base. The key feature of thecross-campus curriculum innovation is the use of Blackboard, short forBlackboard Learning System, to assist in course content organization and onlinedelivery. A well-defined and integrated case study is used throughout thecourse to provide realistic practical experience of software development. Itallows students to take control of their own learning while at the same timeproviding support to those students who have particular learning difficulties.In this paper, the developed curriculum and the learning outcome are described.The e-Learning material and various Blackboard tools used for teaching andlearning activities are presented. Finally, conclusion is drawn from classroomexperience.",Hao Shi,2010/6/4,2010/6/4
2001.03338v3,The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring,http://arxiv.org/abs/2001.03338v3,"Refactoring is the process of changing the internal structure of software toimprove its quality without modifying its external behavior. Empirical studieshave repeatedly shown that refactoring has a positive impact on theunderstandability and maintainability of software systems. However, beforecarrying out refactoring activities, developers need to identify refactoringopportunities. Currently, refactoring opportunity identification heavily relieson developers' expertise and intuition. In this paper, we investigate theeffectiveness of machine learning algorithms in predicting softwarerefactorings. More specifically, we train six different machine learningalgorithms (i.e., Logistic Regression, Naive Bayes, Support Vector Machine,Decision Trees, Random Forest, and Neural Network) with a dataset comprisingover two million refactorings from 11,149 real-world projects from the Apache,F-Droid, and GitHub ecosystems. The resulting models predict 20 differentrefactorings at class, method, and variable-levels with an accuracy oftenhigher than 90%. Our results show that (i) Random Forests are the best modelsfor predicting software refactoring, (ii) process and ownership metrics seem toplay a crucial role in the creation of better models, and (iii) modelsgeneralize well in different contexts.",Maurcio Aniche,2020/1/10,2020/9/11
2301.11719v4,The Exploration of Knowledge-Preserving Prompts for Document Summarisation,http://arxiv.org/abs/2301.11719v4,"Despite the great development of document summarisation techniques nowadays,factual inconsistencies between the generated summaries and the original textsstill occur from time to time. This study explores the possibility of adoptingprompts to incorporate factual knowledge into generated summaries. Wespecifically study prefix-tuning that uses a set of trainable continuous prefixprompts together with discrete natural language prompts to aid summarygeneration. Experimental results demonstrate that the trainable prefixes canhelp the summarisation model extract information from discrete promptsprecisely, thus generating knowledge-preserving summaries that are factuallyconsistent with the discrete prompts. The ROUGE improvements of the generatedsummaries indicate that explicitly adding factual knowledge into thesummarisation process could boost the overall performance, showing greatpotential for applying it to other natural language processing tasks.",Chen Chen,2023/1/27,2023/5/17
2302.13793v1,"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness",http://arxiv.org/abs/2302.13793v1,"Generative pre-trained language models (GPLMs) like ChatGPT encode in themodel's parameters knowledge the models observe during the pre-training phase.This knowledge is then used at inference to address the task specified by theuser in their prompt. For example, for the question-answering task, the GPLMsleverage the knowledge and linguistic patterns learned at training to producean answer to a user question. Aside from the knowledge encoded in the modelitself, answers produced by GPLMs can also leverage knowledge provided in theprompts. For example, a GPLM can be integrated into a retrieve-then-generateparadigm where a search engine is used to retrieve documents relevant to thequestion; the content of the documents is then transferred to the GPLM via theprompt. In this paper we study the differences in answer correctness generatedby ChatGPT when leveraging the model's knowledge alone vs. in combination withthe prompt knowledge. We study this in the context of consumers seeking healthadvice from the model. Aside from measuring the effectiveness of ChatGPT inthis context, we show that the knowledge passed in the prompt can overturn theknowledge encoded in the model and this is, in our experiments, to thedetriment of answer correctness. This work has important implications for thedevelopment of more robust and transparent question-answering systems based ongenerative pre-trained language models.",Guido Zuccon,2023/2/23,2023/2/23
2312.05276v1,Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation,http://arxiv.org/abs/2312.05276v1,"Nowadays, the rapid development of mobile economy has promoted theflourishing of online marketing campaigns, whose success greatly hinges on theefficient matching between user preferences and desired marketing campaignswhere a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG)could serve as the critical ""bridge"" for preference propagation. In this paper,we seek to carefully prompt a Large Language Model (LLM) with domain-levelknowledge as a better marketing-oriented knowledge miner for marketing-orientedknowledge graph construction, which is however non-trivial, suffering fromseveral inevitable issues in real-world marketing scenarios, i.e.,uncontrollable relation generation of LLMs,insufficient prompting ability of asingle prompt, the unaffordable deployment cost of LLMs. To this end, wepropose PAIR, a novel Progressive prompting Augmented mIning fRamework forharvesting marketing-oriented knowledge graph with LLMs. In particular, wereduce the pure relation generation to an LLM based adaptive relation filteringprocess through the knowledge-empowered prompting technique. Next, we steerLLMs for entity expansion with progressive prompting augmentation,followed by areliable aggregation with comprehensive consideration of both self-consistencyand semantic relatedness. In terms of online serving, we specialize in a smalland white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-qualitycorpus provided by a strong teacher-LLM. Extensive experiments and practicalapplications in audience targeting verify the effectiveness of the proposed(Light)PAIR.",Chunjing Gan,2023/12/8,2023/12/8
2009.01660v1,Software Effort Estimation using parameter tuned Models,http://arxiv.org/abs/2009.01660v1,"Software estimation is one of the most important activities in the softwareproject. The software effort estimation is required in the early stages ofsoftware life cycle. Project Failure is the major problem undergoing nowadaysas seen by software project managers. The imprecision of the estimation is thereason for this problem. Assize of software size grows, it also makes a systemcomplex, thus difficult to accurately predict the cost of software developmentprocess. The greatest pitfall of the software industry was the fast-changingnature of software development which has made it difficult to developparametric models that yield high accuracy for software development in alldomains. We need the development of useful models that accurately predict thecost of developing a software product. This study presents the novel analysisof various regression models with hyperparameter tuning to get the effectivemodel. Nine different regression techniques are considered for modeldevelopment",Akanksha Baghel,2020/8/25,2020/8/25
2209.10131v1,"A Systematic Literature Review of Soft Computing Techniques for Software Maintainability Prediction: State-of-the-Art, Challenges and Future Directions",http://arxiv.org/abs/2209.10131v1,"The software is changing rapidly with the invention of advanced technologiesand methodologies. The ability to rapidly and successfully upgrade software inresponse to changing business requirements is more vital than ever. For thelong-term management of software products, measuring software maintainabilityis crucial. The use of soft computing techniques for software maintainabilityprediction has shown immense promise in software maintenance process byproviding accurate prediction of software maintainability. To better understandthe role of soft computing techniques for software maintainability prediction,we aim to provide a systematic literature review of soft computing techniquesfor software maintainability prediction. Firstly, we provide a detailedoverview of software maintainability. Following this, we explore thefundamentals of software maintainability and the reasons for adopting softcomputing methodologies for predicting software maintainability. Later, weexamine the soft computing approaches employed in the process of softwaremaintainability prediction. Furthermore, we discuss the difficulties andpotential solutions associated with the use of soft computing techniques topredict software maintainability. Finally, we conclude the review with somepromising future directions to drive further research innovations anddevelopments in this promising area.",Gokul Yenduri,2022/9/21,2022/9/21
2110.13034v1,Introducing Traceability in GitHub for Medical Software Development,http://arxiv.org/abs/2110.13034v1,"Assuring traceability from requirements to implementation is a key elementwhen developing safety critical software systems. Traditionally, thistraceability is ensured by a waterfall-like process, where phases follow eachother, and tracing between different phases can be managed. However, newsoftware development paradigms, such as continuous software engineering andDevOps, which encourage a steady stream of new features, committed bydevelopers in a seemingly uncontrolled fashion in terms of former phasing,challenge this view. In this paper, we introduce our approach that addstraceability capabilities to GitHub, so that the developers can act like theynormally do in GitHub context but produce the documentation needed by theregulatory purposes in the process.",Vlad Stirbu,2021/10/25,2021/10/25
1805.05508v1,Task Interruption in Software Development Projects: What Makes some Interruptions More Disruptive than Others?,http://arxiv.org/abs/1805.05508v1,"Multitasking has always been an inherent part of software development and isknown as the primary source of interruptions due to task switching in softwaredevelopment teams. Developing software involves a mix of analytical andcreative work, and requires a significant load on brain functions, such asworking memory and decision making. Thus, task switching in the context ofsoftware development imposes a cognitive load that causes software developersto lose focus and concentration while working thereby taking a toll onproductivity. To investigate the disruptiveness of task switching andinterruptions in software development projects, and to understand the reasonsfor and perceptions of the disruptiveness of task switching we used amixed-methods approach including a longitudinal data analysis on 4,910 recordedtasks of 17 professional software developers, and a survey of 132 softwaredevelopers. We found that, compared to task-specific factors (e.g. priority,level, and temporal stage), contextual factors such as interruption type (e.g.self/external), time of day, and task type and context are a more potentdeterminant of task switching disruptiveness in software development tasks.Furthermore, while most survey respondents believe external interruptions aremore disruptive than self-interruptions, the results of our retrospectiveanalysis reveals otherwise. We found that self-interruptions (i.e. voluntarytask switchings) are more disruptive than external interruptions and have anegative effect on the performance of the interrupted tasks. Finally, we usethe results of both studies to provide a set of comparative vulnerability andinteraction patterns which can be used as a mean to guide decision-making andforecasting the consequences of task switching in software development teams.",Zahra Shakeri Hossein Abad,2018/5/15,2018/5/15
2308.00686v1,Mining Reviews in Open Source Code for Developers Trail: A Process Mining Approach,http://arxiv.org/abs/2308.00686v1,"Audit trails are evidential indications of activities performers in any logs.Modern reactive systems such as transaction processing systems, managementinformation systems, decision support systems and even executive managementsystems log activities of users as they perform their daily tasks for a numberof reasons and perhaps one of the most important is security. In order toefficiently monitor and manage privacy and access to information, the trails ascaptured and recorded in these logs play a pivotal role in this regard. In OpenSource realm, however, this is not the case. Although the objective with freesoftware is to allow for access, free distribution and the rights to modifycoding, having such audit trails can help to trace and understand how activemembers of these communities are and the type of activities they perform. Inthis paper, we propose using process mining to construct logs using as muchdata as can be found in open source repositories in order to produce a processmodel, also called a workflow net that graphical depicts the sequentialoccurrence of developers activities. Our method is exhibited through a simplealgorithm called Act-Trace.",Patrick Mukala,2023/7/16,2023/7/16
2107.07485v1,A Hybrid Simulation Model for Open Software Development Processes,http://arxiv.org/abs/2107.07485v1,"Open software development provides software organizations access to infiniteonline resource supply. The resource supply is a pool of unknown workers whowork from different location and time zone and are interested in performingvarious type of tasks. Improper task execution in such dynamic and competitiveenvironment leads to zero task registration, zero task submissions or lowqualified submissions due to unforeseen reasons such as uncertainty in workers'behavior and performance. Therefore, to ensure effectiveness of open softwaredevelopment, there is a need for improved understanding and visibility intocharacteristics associated with attracting reliable workers in making qualifiedsubmissions and reducing task failure.",Razieh Saremi,2021/7/15,2021/7/15
1902.02610v2,"To the Attention of Mobile Software Developers: Guess What, Test your App!",http://arxiv.org/abs/1902.02610v2,"Software testing is an important phase in the software development life-cyclebecause it helps in identifying bugs in a software system before it is shippedinto the hand of its end users. There are numerous studies on how developerstest general-purpose software applications. The idiosyncrasies of mobilesoftware applications, however, set mobile apps apart from general-purposesystems (e.g., desktop, stand-alone applications, web services). This paperinvestigates working habits and challenges of mobile software developers withrespect to testing. A key finding of our exhaustive study, using 1000 Androidapps, demonstrates that mobile apps are still tested in a very ad hoc way, iftested at all. However, we show that, as in other types of software, testingincreases the quality of apps (demonstrated in user ratings and number of codeissues). Furthermore, we find evidence that tests are essential when it comesto engaging the community to contribute to mobile open source software. Wediscuss reasons and potential directions to address our findings. Yet anotherrelevant finding of our study is that Continuous Integration and ContinuousDeployment (CI/CD) pipelines are rare in the mobile apps world (only 26% of theapps are developed in projects employing CI/CD) --- we argue that one of themain reasons is due to the lack of exhaustive and automatic testing.",Luis Cruz,2019/2/7,2019/2/14
2006.02370v1,Exploring Context-Aware Conversational Agents in Software Development,http://arxiv.org/abs/2006.02370v1,"Software development is a complex endeavor that depends on a wide variety ofcontextual factors involving a large amount of distributed information. Thisknowledge could include: technology-related tasks, software operatingenvironments and stakeholder requirements. A major roadblock to using thisknowledge in software development is that most of this information is implicitand captured in the developers' minds (tacit) or spread through volumes ofdocumentation. Developers, as they work often have to maintain mental models ofthese tasks as they produce the software. As a result, context can be easilylost or forgotten and developers often use trial-and-error approaches whilefinishing the project. This study aims at analyzing whether supporting softwaredevelopers with a chatbot during task execution can improve the overalldevelopment experience. The chatbot can assist the developers in executingdifferent tasks based on implicit contextual information. We propose animplementation to explore the viability of using textual chatbots to assistdevelopers automatically and proactively with software development projectactivities that recur.",Glaucia Melo,2020/6/3,2020/6/3
2311.18452v1,"Developer Experiences with a Contextualized AI Coding Assistant: Usability, Expectations, and Outcomes",http://arxiv.org/abs/2311.18452v1,"In the rapidly advancing field of artificial intelligence, softwaredevelopment has emerged as a key area of innovation. Despite the plethora ofgeneral-purpose AI assistants available, their effectiveness diminishes incomplex, domain-specific scenarios. Noting this limitation, both the academiccommunity and industry players are relying on contextualized coding AIassistants. These assistants surpass general-purpose AI tools by integratingproprietary, domain-specific knowledge, offering precise and relevantsolutions. Our study focuses on the initial experiences of 62 participants whoused a contextualized coding AI assistant -- named StackSpot AI -- in acontrolled setting. According to the participants, the assistants' use resultedin significant time savings, easier access to documentation, and the generationof accurate codes for internal APIs. However, challenges associated with theknowledge sources necessary to make the coding assistant access more contextualinformation as well as variable responses and limitations in handling complexcodes were observed. The study's findings, detailing both the benefits andchallenges of contextualized AI assistants, underscore their potential torevolutionize software development practices, while also highlighting areas forfurther refinement.",Gustavo Pinto,2023/11/30,2023/11/30
2308.13062v1,ZeroLeak: Using LLMs for Scalable and Cost Effective Side-Channel Patching,http://arxiv.org/abs/2308.13062v1,"Security critical software, e.g., OpenSSL, comes with numerous side-channelleakages left unpatched due to a lack of resources or experts. The situationwill only worsen as the pace of code development accelerates, with developersrelying on Large Language Models (LLMs) to automatically generate code. In thiswork, we explore the use of LLMs in generating patches for vulnerable code withmicroarchitectural side-channel leakages. For this, we investigate thegenerative abilities of powerful LLMs by carefully crafting prompts following azero-shot learning approach. All generated code is dynamically analyzed byleakage detection tools, which are capable of pinpointing information leakageat the instruction level leaked either from secret dependent accesses orbranches or vulnerable Spectre gadgets, respectively. Carefully crafted promptsare used to generate candidate replacements for vulnerable code, which are thenanalyzed for correctness and for leakage resilience. From a cost/performanceperspective, the GPT4-based configuration costs in API calls a mere few centsper vulnerability fixed. Our results show that LLM-based patching is far morecost-effective and thus provides a scalable solution. Finally, the framework wepropose will improve in time, especially as vulnerability detection tools andLLMs mature.",M. Caner Tol,2023/8/24,2023/8/24
2310.11868v1,To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now,http://arxiv.org/abs/2310.11868v1,"The recent advances in diffusion models (DMs) have revolutionized thegeneration of complex and diverse images. However, these models also introducepotential safety hazards, such as the production of harmful content andinfringement of data copyrights. Although there have been efforts to createsafety-driven unlearning methods to counteract these challenges, doubts remainabout their capabilities. To bridge this uncertainty, we propose an evaluationframework built upon adversarial attacks (also referred to as adversarialprompts), in order to discern the trustworthiness of these safety-drivenunlearned DMs. Specifically, our research explores the (worst-case) robustnessof unlearned DMs in eradicating unwanted concepts, styles, and objects,assessed by the generation of adversarial prompts. We develop a noveladversarial learning approach called UnlearnDiff that leverages the inherentclassification capabilities of DMs to streamline the generation of adversarialprompts, making it as simple for DMs as it is for image classification attacks.This technique streamlines the creation of adversarial prompts, making theprocess as intuitive for generative modeling as it is for image classificationassaults. Through comprehensive benchmarking, we assess the unlearningrobustness of five prevalent unlearned DMs across multiple tasks. Our resultsunderscore the effectiveness and efficiency of UnlearnDiff when compared tostate-of-the-art adversarial prompting methods. Codes are available athttps://github.com/OPTML-Group/Diffusion-MU-Attack. WARNING: This papercontains model outputs that may be offensive in nature.",Yimeng Zhang,2023/10/18,2023/10/18
2308.14969v2,Uncovering the Hidden Cost of Model Compression,http://arxiv.org/abs/2308.14969v2,"In the era of resource-intensive foundation models, efficient adaptation indownstream tasks has become paramount. Visual Prompting (VP), inspired byprompting in Large Language Models (LLMs), has emerged as a key transferlearning method in computer vision. Aligned with the growing significance ofefficiency, research in model compression has become pivotal to alleviate thecomputational burden in both training and deploying over-parameterized neuralnetworks. A key goal in model compression is the development of sparse modelscapable of matching or surpassing the performance of their over-parameterized,dense counterparts. While prior research has explored the impact of modelsparsity on transfer learning, its effects on visual prompting-based transferremain unclear. This study addresses this gap, revealing that model sparsityadversely affects the performance of visual prompting-based transfer,particularly in low-data-volume scenarios. Furthermore, our findings highlightthe negative influence of sparsity on the calibration of downstreamvisual-prompted models. This empirical exploration calls for a nuancedunderstanding beyond accuracy in sparse settings, opening avenues for furtherresearch in Visual Prompting for sparse models. Code and logs can be accessedat https://github.com/landskape-ai/Reprogram_LT .",Diganta Misra,2023/8/29,2023/11/27
2304.06957v1,MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation,http://arxiv.org/abs/2304.06957v1,"CLIP (Contrastive Language-Image Pretraining) is well-developed foropen-vocabulary zero-shot image-level recognition, while its applications inpixel-level tasks are less investigated, where most efforts directly adopt CLIPfeatures without deliberative adaptations. In this work, we first demonstratethe necessity of image-pixel CLIP feature adaption, then provide Multi-ViewPrompt learning (MVP-SEG) as an effective solution to achieve image-pixeladaptation and to solve open-vocabulary semantic segmentation. Concretely,MVP-SEG deliberately learns multiple prompts trained by our OrthogonalConstraint Loss (OCLoss), by which each prompt is supervised to exploit CLIPfeature on different object parts, and collaborative segmentation masksgenerated by all prompts promote better segmentation. Moreover, MVP-SEGintroduces Global Prompt Refining (GPR) to further eliminate class-wisesegmentation noise. Experiments show that the multi-view prompts learned fromseen categories have strong generalization to unseen categories, and MVP-SEG+which combines the knowledge transfer stage significantly outperforms previousmethods on several benchmarks. Moreover, qualitative results justify thatMVP-SEG does lead to better focus on different local parts.",Jie Guo,2023/4/14,2023/4/14
2304.11384v3,Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning,http://arxiv.org/abs/2304.11384v3,"Code comment generation aims at generating natural language descriptions fora code snippet to facilitate developers' program comprehension activities.Despite being studied for a long time, a bottleneck for existing approaches isthat given a code snippet, they can only generate one comment while developersusually need to know information from diverse perspectives such as what is thefunctionality of this code snippet and how to use it. To tackle thislimitation, this study empirically investigates the feasibility of utilizinglarge language models (LLMs) to generate comments that can fulfill developers'diverse intents. Our intuition is based on the facts that (1) the code and itspairwise comment are used during the pre-training process of LLMs to build thesemantic connection between the natural language and programming language, and(2) comments in the real-world projects, which are collected for thepre-training, usually contain different developers' intents. We thus postulatethat the LLMs can already understand the code from different perspectives afterthe pre-training. Indeed, experiments on two large-scale datasets demonstratethe rationale of our insights: by adopting the in-context learning paradigm andgiving adequate prompts to the LLM (e.g., providing it with ten or moreexamples), the LLM can significantly outperform a state-of-the-art supervisedlearning approach on generating comments with multiple intents. Results alsoshow that customized strategies for constructing the prompts andpost-processing strategies for reranking the results can both boost the LLM'sperformances, which shed light on future research directions for using LLMs toachieve comment generation.",Mingyang Geng,2023/4/22,2023/6/14
2002.09716v3,Bayesian Computing in the Undergraduate Statistics Curriculum,http://arxiv.org/abs/2002.09716v3,"Bayesian statistics has gained great momentum since the computationaldevelopments of the 1990s. Gradually, advances in Bayesian methodology andsoftware have made Bayesian techniques much more accessible to appliedstatisticians and, in turn, have potentially transformed Bayesian education atthe undergraduate level. This article provides an overview on the variousoptions for implementing Bayesian computational methods motivated to achieveparticular learning outcomes. The advantages and disadvantages of eachcomputational method are described based on the authors' experience in usingthese methods in the classroom. The goal is to present guidance on the choiceof computation for the instructors who are introducing Bayesian methods intheir undergraduate statistics curriculum.",Jim Albert,2020/2/22,2020/11/3
1308.1908v2,A New Approach to Developing Interactive Software Modules through Graduate Education,http://arxiv.org/abs/1308.1908v2,"Educational technology has attained significant importance as a mechanism forsupporting experiential learning of science concepts. However, the growth ofthis mechanism is limited by the significant time and technical expertiseneeded to develop such products, particularly in specialized fields of science.We sought to test whether interactive, educational, online software modules canbe developed effectively by students as a curriculum component of an advancedscience course. We discuss a set of fifteen such modules developed by HarvardUniversity graduate students to demonstrate various concepts related toastronomy and physics. Their successful development of these modulesdemonstrates that online software tools for education and outreach onspecialized topics can be produced while simultaneously fulfillingproject-based learning objectives. We describe a set of technologies suitablefor module development and present in detail four examples of modules developedby the students. We offer recommendations for incorporating educationalsoftware development within a graduate curriculum and conclude by discussingthe relevance of this novel approach to new online learning environments likeedX",Nathan E. Sanders,2013/8/8,2013/10/16
2310.19109v2,Dynamic Task and Weight Prioritization Curriculum Learning for Multimodal Imagery,http://arxiv.org/abs/2310.19109v2,"This paper explores post-disaster analytics using multimodal deep learningmodels trained with curriculum learning method. Studying post-disasteranalytics is important as it plays a crucial role in mitigating the impact ofdisasters by providing timely and accurate insights into the extent of damageand the allocation of resources. We propose a curriculum learning strategy toenhance the performance of multimodal deep learning models. Curriculum learningemulates the progressive learning sequence in human education by training deeplearning models on increasingly complex data. Our primary objective is todevelop a curriculum-trained multimodal deep learning model, with a particularfocus on visual question answering (VQA) capable of jointly processing imageand text data, in conjunction with semantic segmentation for disaster analyticsusing theFloodNet\footnote{https://github.com/BinaLab/FloodNet-Challenge-EARTHVISION2021}dataset. To achieve this, U-Net model is used for semantic segmentation andimage encoding. A custom built text classifier is used for visual questionanswering. Existing curriculum learning methods rely on manually defineddifficulty functions. We introduce a novel curriculum learning approach termedDynamic Task and Weight Prioritization (DATWEP), which leverages agradient-based method to automatically decide task difficulty during curriculumlearning training, thereby eliminating the need for explicit difficultycomputation. The integration of DATWEP into our multimodal model showsimprovement on VQA performance. Source code is available athttps://github.com/fualsan/DATWEP.",Huseyin Fuat Alsan,2023/10/29,2023/11/7
2307.08859v1,Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach,http://arxiv.org/abs/2307.08859v1,"A curriculum is a planned sequence of learning materials and an effective onecan make learning efficient and effective for both humans and machines. Recentstudies developed effective data-driven curriculum learning approaches fortraining graph neural networks in language applications. However, existingcurriculum learning approaches often employ a single criterion of difficulty intheir training paradigms. In this paper, we propose a new perspective oncurriculum learning by introducing a novel approach that builds on graphcomplexity formalisms (as difficulty criteria) and model competence duringtraining. The model consists of a scheduling scheme which derives effectivecurricula by accounting for different views of sample difficulty and modelcompetence during training. The proposed solution advances existing research incurriculum learning for graph neural networks with the ability to incorporate afine-grained spectrum of graph difficulty criteria in their training paradigms.Experimental results on real-world link prediction and node classificationtasks illustrate the effectiveness of the proposed approach.",Nidhi Vakil,2023/7/17,2023/7/17
2108.09696v1,Spatial Transformer Networks for Curriculum Learning,http://arxiv.org/abs/2108.09696v1,"Curriculum learning is a bio-inspired training technique that is widelyadopted to machine learning for improved optimization and better training ofneural networks regarding the convergence rate or obtained accuracy. The mainconcept in curriculum learning is to start the training with simpler tasks andgradually increase the level of difficulty. Therefore, a natural question ishow to determine or generate these simpler tasks. In this work, we takeinspiration from Spatial Transformer Networks (STNs) in order to form aneasy-to-hard curriculum. As STNs have been proven to be capable of removing theclutter from the input images and obtaining higher accuracy in imageclassification tasks, we hypothesize that images processed by STNs can be seenas easier tasks and utilized in the interest of curriculum learning. To thisend, we study multiple strategies developed for shaping the trainingcurriculum, using the data generated by STNs. We perform various experiments oncluttered MNIST and Fashion-MNIST datasets, where on the former, we obtain animprovement of $3.8$pp in classification accuracy compared to the baseline.",Fatemeh Azimi,2021/8/22,2021/8/22
2309.00751v1,Let the Models Respond: Interpreting Language Model Detoxification Through the Lens of Prompt Dependence,http://arxiv.org/abs/2309.00751v1,"Due to language models' propensity to generate toxic or hateful responses,several techniques were developed to align model generations with users'preferences. Despite the effectiveness of such methods in improving the safetyof model interactions, their impact on models' internal processes is stillpoorly understood. In this work, we apply popular detoxification approaches toseveral language models and quantify their impact on the resulting models'prompt dependence using feature attribution methods. We evaluate theeffectiveness of counter-narrative fine-tuning and compare it withreinforcement learning-driven detoxification, observing differences in promptreliance between the two methods despite their similar detoxificationperformances.",Daniel Scalena,2023/9/1,2023/9/1
2206.07353v1,Rethinking Reinforcement Learning for Recommendation: A Prompt Perspective,http://arxiv.org/abs/2206.07353v1,"Modern recommender systems aim to improve user experience. As reinforcementlearning (RL) naturally fits this objective -- maximizing an user's reward persession -- it has become an emerging topic in recommender systems. DevelopingRL-based recommendation methods, however, is not trivial due to the\emph{offline training challenge}. Specifically, the keystone of traditional RLis to train an agent with large amounts of online exploration making lots of`errors' in the process. In the recommendation setting, though, we cannotafford the price of making `errors' online. As a result, the agent needs to betrained through offline historical implicit feedback, collected under differentrecommendation policies; traditional RL algorithms may lead to sub-optimalpolicies under these offline training settings.  Here we propose a new learning paradigm -- namely Prompt-Based ReinforcementLearning (PRL) -- for the offline training of RL-based recommendation agents.While traditional RL algorithms attempt to map state-action input pairs totheir expected rewards (e.g., Q-values), PRL directly infers actions (i.e.,recommended items) from state-reward inputs. In short, the agents are trainedto predict a recommended item given the prior interactions and an observedreward value -- with simple supervised learning. At deployment time, thishistorical (training) data acts as a knowledge base, while the state-rewardpairs are used as a prompt. The agents are thus used to answer the question:\emph{ Which item should be recommended given the prior interactions \& theprompted reward value}? We implement PRL with four notable recommendationmodels and conduct experiments on two real-world e-commerce datasets.Experimental results demonstrate the superior performance of our proposedmethods.",Xin Xin,2022/6/15,2022/6/15
2307.11105v1,Technical Challenges of Deploying Reinforcement Learning Agents for Game Testing in AAA Games,http://arxiv.org/abs/2307.11105v1,"Going from research to production, especially for large and complex softwaresystems, is fundamentally a hard problem. In large-scale game production, oneof the main reasons is that the development environment can be very differentfrom the final product. In this technical paper we describe an effort to add anexperimental reinforcement learning system to an existing automated gametesting solution based on scripted bots in order to increase its capacity. Wereport on how this reinforcement learning system was integrated with the aim toincrease test coverage similar to [1] in a set of AAA games includingBattlefield 2042 and Dead Space (2023). The aim of this technical paper is toshow a use-case of leveraging reinforcement learning in game production andcover some of the largest time sinks anyone who wants to make the same journeyfor their game may encounter. Furthermore, to help the game industry to adoptthis technology faster, we propose a few research directions that we believewill be valuable and necessary for making machine learning, and especiallyreinforcement learning, an effective tool in game production.",Jonas Gillberg,2023/7/19,2023/7/19
2007.08220v1,DRIFT: Deep Reinforcement Learning for Functional Software Testing,http://arxiv.org/abs/2007.08220v1,"Efficient software testing is essential for productive software developmentand reliable user experiences. As human testing is inefficient and expensive,automated software testing is needed. In this work, we propose a ReinforcementLearning (RL) framework for functional software testing named DRIFT. DRIFToperates on the symbolic representation of the user interface. It usesQ-learning through Batch-RL and models the state-action value function with aGraph Neural Network. We apply DRIFT to testing the Windows 10 operating systemand show that DRIFT can robustly trigger the desired software functionality ina fully automated manner. Our experiments test the ability to perform singleand combined tasks across different applications, demonstrating that ourframework can efficiently test software with a large range of testingobjectives.",Luke Harries,2020/7/16,2020/7/16
2104.11489v3,Autonomous Vehicles that Alert Humans to Take-Over Controls: Modeling with Real-World Data,http://arxiv.org/abs/2104.11489v3,"With increasing automation in passenger vehicles, the study of safe andsmooth occupant-vehicle interaction and control transitions is key. In thisstudy, we focus on the development of contextual, semantically meaningfulrepresentations of the driver state, which can then be used to determine theappropriate timing and conditions for transfer of control between driver andvehicle. To this end, we conduct a large-scale real-world controlled data studywhere participants are instructed to take-over control from an autonomous agentunder different driving conditions while engaged in a variety of distractingactivities. These take-over events are captured using multiple driver-facingcameras, which when labelled result in a dataset of control transitions andtheir corresponding take-over times (TOTs). We then develop and train TOTmodels that operate sequentially on mid to high-level features produced bycomputer vision algorithms operating on different driver-facing camera views.The proposed TOT model produces continuous predictions of take-over timeswithout delay, and shows promising qualitative and quantitative results incomplex real-world scenarios.",Akshay Rangesh,2021/4/23,2021/7/22
2308.08341v2,Analytical description of the time-over-threshold method based on the time properties of plastic scintillators equipped with silicon photomultipliers,http://arxiv.org/abs/2308.08341v2,"A new high-granular compact time-of-flight neutron detector for theidentification and energy measurement of neutrons produced in nucleus-nucleusinteractions at the BM@N experiment, Dubna, Russia, at energies up to 4 AGeV isunder development. The detector consists of approximately 2000 fast plasticscintillators, each with dimensions of 40$\times$40$\times$25 mm$^3$, equipedwith SiPM (Silicon Photomultiplier) with an active area of 6$\times$6 mm$^2$.The signal readout from these scintillators will employ a single-thresholdmultichannel Time-to-Digital Converter (TDC) to measure their response time andamplitude using the time-over-threshold (ToT) method. This article focuses onthe analytical description of the signals from the plastic scintillatordetectors equipped with silicon photomultipliers. This description is crucialfor establishing the ToT-amplitude relationship and implementing slewingcorrection techniques to improve the time resolution of the detector. Themethodology presented in this paper demonstrates that a time resolution at the70 ps level can be achieved for the fast plastic scintillator coupled withsilicon photomultiplier with epitaxial quenching resistors.",N. Karpushkin,2023/8/16,2023/10/8
2107.12932v2,"Predicting Take-over Time for Autonomous Driving with Real-World Data: Robust Data Augmentation, Models, and Evaluation",http://arxiv.org/abs/2107.12932v2,"Understanding occupant-vehicle interactions by modeling control transitionsis important to ensure safe approaches to passenger vehicle automation. Modelswhich contain contextual, semantically meaningful representations of driverstates can be used to determine the appropriate timing and conditions fortransfer of control between driver and vehicle. However, such models rely onreal-world control take-over data from drivers engaged in distractingactivities, which is costly to collect. Here, we introduce a scheme for dataaugmentation for such a dataset. Using the augmented dataset, we develop andtrain take-over time (TOT) models that operate sequentially on mid andhigh-level features produced by computer vision algorithms operating ondifferent driver-facing camera views, showing models trained on the augmenteddataset to outperform the initial dataset. The demonstrated model featuresencode different aspects of the driver state, pertaining to the face, hands,foot and upper body of the driver. We perform ablative experiments on featurecombinations as well as model architectures, showing that a TOT model supportedby augmented data can be used to produce continuous estimates of take-overtimes without delay, suitable for complex real-world scenarios.",Akshay Rangesh,2021/7/27,2022/11/12
0907.2922v1,"Nonlinear power spectrum in the presence of massive neutrinos: perturbation theory approach, galaxy bias and parameter forecasts",http://arxiv.org/abs/0907.2922v1,"Future or ongoing galaxy redshift surveys can put stringent constraints onneutrinos masses via the high-precision measurements of galaxy power spectrum,when combined with cosmic microwave background (CMB) information. In this paperwe develop a method to model galaxy power spectrum in the weakly nonlinearregime for a mixed dark matter (CDM plus finite-mass neutrinos) model, based onperturbation theory (PT) whose validity is well tested by simulations for a CDMmodel. In doing this we carefully study various aspects of the nonlinearclustering and then arrive at a useful approximation allowing for a quickcomputation of the nonlinear power spectrum as in the CDM case. The nonlineargalaxy bias is also included in a self-consistent manner within the PTframework. Thus the use of our PT model can give a more robust understanding ofthe measured galaxy power spectrum as well as allow for higher sensitivity toneutrino masses due to the gain of Fourier modes beyond the linear regime.Based on the Fisher matrix formalism, we find that BOSS or Stage-III typesurvey, when combined with Planck CMB information, gives a precision of totalneutrino mass constraint, sigma(m_nu,tot) 0.1eV, while Stage-IV type survey mayachieve sigma(m_nu,tot) 0.05eV, i.e. more than a 1-sigma detection of neutrinomasses. We also discuss possible systematic errors on dark energy parameterscaused by the neutrino mass uncertainty. The significant correlation betweenneutrino mass and dark energy parameters is found, if the information on powerspectrum amplitude is included. More importantly, for Stage-IV type survey, abest-fit dark energy model may be biased and falsely away from the underlyingtrue model by more than the 1-sigma statistical errors, if neutrino mass isignored in the model fitting.",Shun Saito,2009/7/16,2009/7/16
2104.13713v1,Individual Differences Limit Predicting Well-being and Productivity Using Software Repositories: A Longitudinal Industrial Study,http://arxiv.org/abs/2104.13713v1,"Reports of poor work well-being and fluctuating productivity in softwareengineering have been reported in both academic and popular sources.Understanding and predicting these issues through repository analysis mighthelp manage software developers' well-being. Our objective is to link data fromsoftware repositories, that is commit activity, communication, expressedsentiments, and job events, with measures of well-being obtained with a dailyexperience sampling questionnaire. To achieve our objective, we studied asingle software project team for eight months in the software industry.Additionally, we performed semi-structured interviews to explain our results.The acquired quantitative data are analyzed with generalized linearmixed-effects models with autocorrelation structure. We find that individualvariance accounts for most of the $R^2$ values in models predicting developers'experienced well-being and productivity. In other words, using softwarerepository variables to predict developers' well-being or productivity ischallenging due to individual differences. Prediction models developed for eachdeveloper individually work better, with fixed effects $R^2$ value of up to0.24. The semi-structured interviews give insights into the well-being ofsoftware developers and the benefits of chat interaction. Our study suggeststhat individualized prediction models are needed for well-being andproductivity prediction in software development.",Miikka Kuutila,2021/4/28,2021/4/28
1903.02443v2,An Additional Set of (Automated) Eyes: Chatbots for Agile Retrospectives,http://arxiv.org/abs/1903.02443v2,"Recent advances in natural-language processing and data analysis allowsoftware bots to become virtual team members, providing an additional set ofautomated eyes and additional perspectives for informing and supportingteamwork. In this paper, we propose employing chatbots in the domain ofsoftware development with a focus on supporting analyses and measurements ofteams' project data. The software project artifacts produced by agile teamsduring regular development activities, e.g. commits in a version controlsystem, represent detailed information on how a team works and collaborates.Analyses of this data are especially relevant for agile retrospective meetings,where adaptations and improvements to the executed development process arediscussed. Development teams can use these measurements to track the progressof identified improvement actions over development iterations. Chatbots providea convenient user interface for interacting with the outcomes of retrospectivesand the associated measurements in a chat-based channel that is already beingemployed by team members.",Christoph Matthies,2019/3/6,2019/3/11
2309.05542v1,Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications,http://arxiv.org/abs/2309.05542v1,"Language model applications are becoming increasingly popular and complex,often including features like tool usage and retrieval augmentation. However,existing frameworks for such applications are often opinionated, deciding fordevelopers how their prompts ought to be formatted and imposing limitations oncustomizability and reproducibility. To solve this we present Kani: alightweight, flexible, and model-agnostic open-source framework for buildinglanguage model applications. Kani helps developers implement a variety ofcomplex features by supporting the core building blocks of chat interaction:model interfacing, chat management, and robust function calling. All Kani corefunctions are easily overridable and well documented to empower developers tocustomize functionality for their own needs. Kani thus serves as a useful toolfor researchers, hobbyists, and industry professionals alike to acceleratetheir development while retaining interoperability and fine-grained control.",Andrew Zhu,2023/9/11,2023/9/11
1201.4142v1,Identifying Coordination Problems in Software Development: Finding Mismatches between Software and Project Team Structures,http://arxiv.org/abs/1201.4142v1,"Today's dynamic and iterative development environment brings significantchallenges for software project management. In distributed project settings,""management by walking around"" is no longer an option and project managers maymiss out on key project insights. The TESNA (TEchnical Social Network Analysis)method and tool aims to provide project managers both a method and a tool forgaining insights and taking corrective action. TESNA achieves this by analysinga project's evolving social and technical network structures using data frommultiple sources, including CVS, email and chat repositories. Using patterntheory, TESNA helps to identify areas where the current state of the project'ssocial and technical networks conflicts with what patterns suggest. We refer tosuch a conflict as a Socio-Technical Structure Clash (STSC). In this paper wereport on our experience of using TESNA to identify STSCs in a corporateenvironment through the mining of software repositories. We find multipleinstances of three STSCs (Conway's Law, Code Ownership and ProjectCoordination) in many of the on-going development projects, thereby validatingthe method and tool that we have developed.",Chintan Amrit,2012/1/19,2012/1/19
2302.00169v1,"Streaming Software Development: Accountability, Community, and Learning",http://arxiv.org/abs/2302.00169v1,"People use the Internet to learn new skills, stay connected with friends, andfind new communities to engage with. Live streaming platforms like Twitch.tv,YouTube Live, and Facebook Gaming provide a place where all three of theseactivities intersect and enable users to live-stream themselves playing a videogame or live-coding software and game development, as well as the ability toparticipate in chat while watching someone else engage in an activity. Throughfifteen interviews with software and game development streamers, we investigatewhy people choose to stream themselves programming and if they perceivethemselves improving their programming skills by live streaming. We found thatthe motivations to stream included accountability, self-education, community,and visibility of the streamers' work, and streamers perceived a positiveinfluence on their ability to write source code. Our findings implicate thatalternative learning methods like live streaming programming are a beneficialtool in the age of the virtual classroom. This work also contributes to andextends research efforts surrounding educational live streaming andcollaboration in developer communities.",Ella Kokinda,2023/2/1,2023/2/1
2008.03649v1,Code Building Genetic Programming,http://arxiv.org/abs/2008.03649v1,"In recent years the field of genetic programming has made significantadvances towards automatic programming. Research and development ofcontemporary program synthesis methods, such as PushGP and Grammar GuidedGenetic Programming, can produce programs that solve problems typicallyassigned in introductory academic settings. These problems focus on a narrow,predetermined set of simple data structures, basic control flow patterns, andprimitive, non-overlapping data types (without, for example, inheritance orcomposite types). Few, if any, genetic programming methods for programsynthesis have convincingly demonstrated the capability of synthesizingprograms that use arbitrary data types, data structures, and specificationsthat are drawn from existing codebases. In this paper, we introduce CodeBuilding Genetic Programming (CBGP) as a framework within which this can bedone, by leveraging programming language features such as reflection andfirst-class specifications. CBGP produces a computational graph that can beexecuted or translated into source code of a host language. To demonstrate thenovel capabilities of CBGP, we present results on new benchmarks that usenon-primitive, polymorphic data types as well as some standard programsynthesis benchmarks.",Edward Pantridge,2020/8/9,2020/8/9
2007.05060v3,Program Synthesis with Pragmatic Communication,http://arxiv.org/abs/2007.05060v3,"Program synthesis techniques construct or infer programs from user-providedspecifications, such as input-output examples. Yet most specifications,especially those given by end-users, leave the synthesis problem radicallyill-posed, because many programs may simultaneously satisfy the specification.Prior work resolves this ambiguity by using various inductive biases, such as apreference for simpler programs. This work introduces a new inductive biasderived by modeling the program synthesis task as rational communication,drawing insights from recursive reasoning models of pragmatics. Given aspecification, we score a candidate program both on its consistency with thespecification, and also whether a rational speaker would chose this particularspecification to communicate that program. We develop efficient algorithms forsuch an approach when learning from input-output examples, and build apragmatic program synthesizer over a simple grid-like layout domain. A userstudy finds that end-user participants communicate more effectively with thepragmatic program synthesizer over a non-pragmatic one.",Yewen Pu,2020/7/9,2020/10/21
2310.05727v1,The Program Testing Ability of Large Language Models for Code,http://arxiv.org/abs/2310.05727v1,"Recent development of large language models (LLMs) for code like CodeX andCodeT5+ demonstrates tremendous promise in achieving code intelligence. Theirability of synthesizing code that completes a program for performing apre-defined task has been intensively tested and verified on benchmark datasetsincluding HumanEval and MBPP. Yet, evaluation of these LLMs from moreperspectives (than just program synthesis) is also anticipated, consideringtheir broad scope of applications in software engineering. In this paper, weexplore the ability of LLMs for testing programs/code. By performing thoroughanalyses of recent LLMs for code in program testing, we show a series ofintriguing properties of these models and demonstrate how program testingability of LLMs can be improved. Following recent work which utilizes generatedtest cases to enhance program synthesis, we further leverage our findings inimproving the quality of the synthesized programs and show +11.77% and +4.22%higher code pass rates on HumanEval+ comparing with the GPT-3.5-turbo baselineand the recent state-of-the-art, respectively.",Weimin Xiong,2023/10/9,2023/10/9
2302.09923v1,Prompt Stealing Attacks Against Text-to-Image Generation Models,http://arxiv.org/abs/2302.09923v1,"Text-to-Image generation models have revolutionized the artwork designprocess and enabled anyone to create high-quality images by entering textdescriptions called prompts. Creating a high-quality prompt that consists of asubject and several modifiers can be time-consuming and costly. In consequence,a trend of trading high-quality prompts on specialized marketplaces hasemerged. In this paper, we propose a novel attack, namely prompt stealingattack, which aims to steal prompts from generated images by text-to-imagegeneration models. Successful prompt stealing attacks direct violate theintellectual property and privacy of prompt engineers and also jeopardize thebusiness model of prompt trading marketplaces. We first perform a large-scaleanalysis on a dataset collected by ourselves and show that a successful promptstealing attack should consider a prompt's subject as well as its modifiers. Wethen propose the first learning-based prompt stealing attack, PromptStealer,and demonstrate its superiority over two baseline methods quantitatively andqualitatively. We also make some initial attempts to defend PromptStealer. Ingeneral, our study uncovers a new attack surface in the ecosystem created bythe popular text-to-image generation models. We hope our results can help tomitigate the threat. To facilitate research in this field, we will share ourdataset and code with the community.",Xinyue Shen,2023/2/20,2023/2/20
2309.01065v2,"Optimizing Mobile-Edge AI-Generated Everything (AIGX) Services by Prompt Engineering: Fundamental, Framework, and Case Study",http://arxiv.org/abs/2309.01065v2,"As the next-generation paradigm for content creation, AI-Generated Content(AIGC), i.e., generating content automatically by Generative AI (GAI) based onuser prompts, has gained great attention and success recently. With theever-increasing power of GAI, especially the emergence of Pretrained FoundationModels (PFMs) that contain billions of parameters and prompt engineeringmethods (i.e., finding the best prompts for the given task), the applicationrange of AIGC is rapidly expanding, covering various forms of information forhuman, systems, and networks, such as network designs, channel coding, andoptimization solutions. In this article, we present the concept of mobile-edgeAI-Generated Everything (AIGX). Specifically, we first review the buildingblocks of AIGX, the evolution from AIGC to AIGX, as well as practical AIGXapplications. Then, we present a unified mobile-edge AIGX framework, whichemploys edge devices to provide PFM-empowered AIGX services and optimizes suchservices via prompt engineering. More importantly, we demonstrate thatsuboptimal prompts lead to poor generation quality, which adversely affectsuser satisfaction, edge network performance, and resource utilization.Accordingly, we conduct a case study, showcasing how to train an effectiveprompt optimizer using ChatGPT and investigating how much improvement ispossible with prompt engineering in terms of user experience, quality ofgeneration, and network performance.",Yinqiu Liu,2023/9/3,2023/11/15
2310.00085v2,PEACE: Prompt Engineering Automation for CLIPSeg Enhancement in Aerial Robotics,http://arxiv.org/abs/2310.00085v2,"From industrial to space robotics, safe landing is an essential component forflight operations. With the growing interest in artificial intelligence, wedirect our attention to learning based safe landing approaches. This paperextends our previous work, DOVESEI, which focused on a reactive UAV system byharnessing the capabilities of open vocabulary image segmentation. Prompt-basedsafe landing zone segmentation using an open vocabulary based model is no morejust an idea, but proven to be feasible by the work of DOVESEI. However, aheuristic selection of words for prompt is not a reliable solution since itcannot take the changing environment into consideration and detrimentalconsequences can occur if the observed environment is not well represented bythe given prompt. Therefore, we introduce PEACE (Prompt Engineering Automationfor CLIPSeg Enhancement), powering DOVESEI to automate the prompt generationand engineering to adapt to data distribution shifts. Our system is capable ofperforming safe landing operations with collision avoidance at altitudes as lowas 20 meters using only monocular cameras and image segmentation. We takeadvantage of DOVESEI's dynamic focus to circumvent abrupt fluctuations in theterrain segmentation between frames in a video stream. PEACE shows promisingimprovements in prompt generation and engineering for aerial images compared tothe standard prompt used for CLIP and CLIPSeg. Combining DOVESEI and PEACE, oursystem was able improve successful safe landing zone selections by 58.62%compared to using only DOVESEI. All the source code is open source andavailable online.",Haechan Mark Bong,2023/9/29,2023/12/8
2305.11095v3,Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization,http://arxiv.org/abs/2305.11095v3,"We investigate the emergent abilities of the recently proposed web-scalespeech model Whisper, by adapting it to unseen tasks with prompt engineering.We selected three tasks: audio-visual speech recognition (AVSR), code-switchedspeech recognition (CS-ASR), and speech translation (ST) on unseen languagepairs. We design task-specific prompts, by either leveraging anotherlarge-scale model, or simply manipulating the special tokens in the defaultprompts. Experiments show that compared to the default prompts, our proposedprompts improve performance by 10% to 45% on the three zero-shot tasks, andeven outperform SotA supervised models on some datasets. In addition, ourexperiments reveal many interesting properties of Whisper, including itsrobustness to prompts, bias on accents, and the multilingual understanding inits latent space. Code is available athttps://github.com/jasonppy/PromptingWhisper",Puyuan Peng,2023/5/18,2023/8/16
2305.18507v2,Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models,http://arxiv.org/abs/2305.18507v2,"Large language models (LLMs) have scaled up to unlock a wide range of complexreasoning tasks with the aid of various prompting methods. However, currentprompting methods generate natural language intermediate steps to helpreasoning, which can cause imperfect task reduction and confusion. To mitigatesuch limitations, we explore code prompting, a neural symbolic prompting methodwith both zero-shot and few-shot versions which triggers code as intermediatesteps. We conduct experiments on 7 widely-used benchmarks involving symbolicreasoning and arithmetic reasoning. Code prompting generally outperformschain-of-thought (CoT) prompting. To further understand the performance andlimitations of code prompting, we perform extensive ablation studies and erroranalyses, and identify several exclusive advantages of using symbolicpromptings compared to natural language. We also consider the ensemble of codeprompting and CoT prompting to combine the strengths of both. Finally, we showthrough experiments how code annotations and their locations affect codeprompting.",Yi Hu,2023/5/29,2023/10/7
2401.10065v1,Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs,http://arxiv.org/abs/2401.10065v1,"Reasoning is a fundamental component for achieving language understanding.Among the multiple types of reasoning, conditional reasoning, the ability todraw different conclusions depending on some condition, has been understudiedin large language models (LLMs). Recent prompting methods, such as chain ofthought, have significantly improved LLMs on reasoning tasks. Nevertheless,there is still little understanding of what triggers reasoning abilities inLLMs. We hypothesize that code prompts can trigger conditional reasoning inLLMs trained on text and code. We propose a chain of prompts that transforms anatural language problem into code and prompts the LLM with the generated code.Our experiments find that code prompts exhibit a performance boost between 2.6and 7.7 points on GPT 3.5 across multiple datasets requiring conditionalreasoning. We then conduct experiments to discover how code prompts elicitconditional reasoning abilities and through which features. We observe thatprompts need to contain natural language text accompanied by high-quality codethat closely represents the semantics of the instance text. Furthermore, weshow that code prompts are more efficient, requiring fewer demonstrations, andthat they trigger superior state tracking of variables or key entities.",Haritz Puerto,2024/1/18,2024/1/18
2304.13250v1,Exploring the Curious Case of Code Prompts,http://arxiv.org/abs/2304.13250v1,"Recent work has shown that prompting language models with code-likerepresentations of natural language leads to performance improvements onstructured reasoning tasks. However, such tasks comprise only a small subset ofall natural language tasks. In our work, we seek to answer whether or notcode-prompting is the preferred way of interacting with language models ingeneral. We compare code and text prompts across three popular GPT models(davinci, code-davinci-002, and text-davinci-002) on a broader selection oftasks (e.g., QA, sentiment, summarization) and find that with few exceptions,code prompts do not consistently outperform text prompts. Furthermore, we showthat the style of code prompt has a large effect on performance for some butnot all tasks and that fine-tuning on text instructions leads to betterrelative performance of code prompts.",Li Zhang,2023/4/26,2023/4/26
2311.08364v1,Plum: Prompt Learning using Metaheuristic,http://arxiv.org/abs/2311.08364v1,"Since the emergence of large language models, prompt learning has become apopular method for optimizing and customizing these models. Special prompts,such as Chain-of-Thought, have even revealed previously unknown reasoningcapabilities within these models. However, the progress of discoveringeffective prompts has been slow, driving a desire for general promptoptimization methods. Unfortunately, few existing prompt learning methodssatisfy the criteria of being truly ""general"", i.e., automatic, discrete,black-box, gradient-free, and interpretable all at once. In this paper, weintroduce metaheuristics, a branch of discrete non-convex optimization methodswith over 100 options, as a promising approach to prompt learning. Within ourparadigm, we test six typical methods: hill climbing, simulated annealing,genetic algorithms with/without crossover, tabu search, and harmony search,demonstrating their effectiveness in black-box prompt learning andChain-of-Thought prompt tuning. Furthermore, we show that these methods can beused to discover more human-understandable prompts that were previouslyunknown, opening the door to a cornucopia of possibilities in promptoptimization. We release all the codes in\url{https://github.com/research4pan/Plum}.",Rui Pan,2023/11/14,2023/11/14
2306.06656v1,VPUFormer: Visual Prompt Unified Transformer for Interactive Image Segmentation,http://arxiv.org/abs/2306.06656v1,"The integration of diverse visual prompts like clicks, scribbles, and boxesin interactive image segmentation could significantly facilitate userinteraction as well as improve interaction efficiency. Most existing studiesfocus on a single type of visual prompt by simply concatenating prompts andimages as input for segmentation prediction, which suffers from low-efficiencyprompt representation and weak interaction issues. This paper proposes a simpleyet effective Visual Prompt Unified Transformer (VPUFormer), which introduces aconcise unified prompt representation with deeper interaction to boost thesegmentation performance. Specifically, we design a Prompt-unified Encoder(PuE) by using Gaussian mapping to generate a unified one-dimensional vectorfor click, box, and scribble prompts, which well captures users' intentions aswell as provides a denser representation of user prompts. In addition, wepresent a Prompt-to-Pixel Contrastive Loss (P2CL) that leverages user feedbackto gradually refine candidate semantic features, aiming to bring image semanticfeatures closer to the features that are similar to the user prompt, whilepushing away those image semantic features that are dissimilar to the userprompt, thereby correcting results that deviate from expectations. On thisbasis, our approach injects prompt representations as queries into Dual-crossMerging Attention (DMA) blocks to perform a deeper interaction between imageand query inputs. A comprehensive variety of experiments on seven challengingdatasets demonstrates that the proposed VPUFormer with PuE, DMA, and P2CLachieves consistent improvements, yielding state-of-the-art segmentationperformance. Our code will be made publicly available athttps://github.com/XuZhang1211/VPUFormer.",Xu Zhang,2023/6/11,2023/6/11
2205.14865v3,Prompt-aligned Gradient for Prompt Tuning,http://arxiv.org/abs/2205.14865v3,"Thanks to the large pre-trained vision-language models (VLMs) like CLIP, wecan craft a zero-shot classifier by ""prompt"", e.g., the confidence score of animage being ""[CLASS]"" can be obtained by using the VLM provided similaritymeasure between the image and the prompt sentence ""a photo of a [CLASS]"".Therefore, prompt shows a great potential for fast adaptation of VLMs todownstream tasks if we fine-tune the prompt-based similarity measure. However,we find a common failure that improper fine-tuning may not only undermine theprompt's inherent prediction for the task-related classes, but also for otherclasses in the VLM vocabulary. Existing methods still address this problem byusing traditional anti-overfitting techniques such as early stopping and dataaugmentation, which lack a principled solution specific to prompt. We presentPrompt-aligned Gradient, dubbed ProGrad, to prevent prompt tuning fromforgetting the the general knowledge learned from VLMs. In particular, ProGradonly updates the prompt whose gradient is aligned (or non-conflicting) to the""general direction"", which is represented as the gradient of the KL loss of thepre-defined prompt prediction. Extensive experiments demonstrate the strongerfew-shot generalization ability of ProGrad over state-of-the-art prompt tuningmethods. Codes are available at https://github.com/BeierZhu/Prompt-align.",Beier Zhu,2022/5/30,2024/1/10
2209.12711v1,Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts,http://arxiv.org/abs/2209.12711v1,"Previous work has shown that there exists a scaling law between the size ofLanguage Models (LMs) and their zero-shot performance on different downstreamNLP tasks. In this work, we show that this phenomenon does not hold whenevaluating large LMs on tasks with negated prompts, but instead shows aninverse scaling law. We evaluate 9 different tasks with negated prompts on (1)pretrained LMs (OPT & GPT-3) of varying sizes (125M - 175B), (2) LMs furtherpretrained to generalize to novel prompts (InstructGPT), (3) LMs provided withfew-shot examples, and (4) LMs fine-tuned specifically on negated prompts; allLM types perform worse on negated prompts as they scale and show a hugeperformance gap between the human performance when comparing the average scoreon both original and negated prompts. By highlighting a critical limitation ofexisting LMs and methods, we urge the community to develop new approaches ofdeveloping LMs that actually follow the given instructions. We provide the codeand the datasets to explore negated prompts athttps://github.com/joeljang/negated-prompts-for-llms",Joel Jang,2022/9/26,2022/9/26
2401.10759v1,Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models,http://arxiv.org/abs/2401.10759v1,"Large Language Models (LLMs) have upended decades of pedagogy in computingeducation. Students previously learned to code through \textit{writing} manysmall problems with less emphasis on code reading and comprehension. Recentresearch has shown that free code generation tools powered by LLMs can solveintroductory programming problems presented in natural language with ease. Inthis paper, we propose a new way to teach programming with Prompt Problems.Students receive a problem visually, indicating how input should be transformedto output, and must translate that to a prompt for an LLM to decipher. Theproblem is considered correct when the code that is generated by the studentprompt can pass all test cases. In this paper we present the design of thistool, discuss student interactions with it as they learn, and provide insightsinto this new class of programming problems as well as the design tools thatintegrate LLMs.",James Prather,2024/1/19,2024/1/19
2305.04091v3,Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,http://arxiv.org/abs/2305.04091v3,"Large language models (LLMs) have recently been shown to deliver impressiveperformance in various NLP tasks. To tackle multi-step reasoning tasks,few-shot chain-of-thought (CoT) prompting includes a few manually craftedstep-by-step reasoning demonstrations which enable LLMs to explicitly generatereasoning steps and improve their reasoning task accuracy. To eliminate themanual effort, Zero-shot-CoT concatenates the target problem statement with""Let's think step by step"" as an input prompt to LLMs. Despite the success ofZero-shot-CoT, it still suffers from three pitfalls: calculation errors,missing-step errors, and semantic misunderstanding errors. To address themissing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists oftwo components: first, devising a plan to divide the entire task into smallersubtasks, and then carrying out the subtasks according to the plan. To addressthe calculation errors and improve the quality of generated reasoning steps, weextend PS prompting with more detailed instructions and derive PS+ prompting.We evaluate our proposed prompting strategy on ten datasets across threereasoning problems. The experimental results over GPT-3 show that our proposedzero-shot prompting consistently outperforms Zero-shot-CoT across all datasetsby a large margin, is comparable to or exceeds Zero-shot-Program-of-ThoughtPrompting, and has comparable performance with 8-shot CoT prompting on the mathreasoning problem. The code can be found athttps://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.",Lei Wang,2023/5/6,2023/5/26
2311.15500v2,Function-constrained Program Synthesis,http://arxiv.org/abs/2311.15500v2,"This work introduces (1) a technique that allows large language models (LLMs)to leverage user-provided code when solving programming tasks and (2) a methodto iteratively generate modular sub-functions that can aid future codegeneration attempts when the initial code generated by the LLM is inadequate.Generating computer programs in general-purpose programming languages likePython poses a challenge for LLMs when instructed to use code provided in theprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate codecompletions in real-time by drawing on all code available in a developmentenvironment. However, restricting code-specific LLMs to use only in-contextcode is not straightforward, as the model is not explicitly instructed to usethe user-provided code and users cannot highlight precisely which snippets ofcode the model should incorporate into its context. Moreover, current systemslack effective recovery methods, forcing users to iteratively re-prompt themodel with modified prompts until a sufficient solution is reached. Our methoddiffers from traditional LLM-powered code-generation by constrainingcode-generation to an explicit function set and enabling recovery from failedattempts through automatically generated sub-functions. When the LLM cannotproduce working code, we generate modular sub-functions to aid subsequentattempts at generating functional code. A by-product of our method is a libraryof reusable sub-functions that can solve related tasks, imitating a softwareteam where efficiency scales with experience. We also introduce a new""half-shot"" evaluation paradigm that provides tighter estimates of LLMs' codingabilities compared to traditional zero-shot evaluation. Our proposed evaluationmethod encourages models to output solutions in a structured format, decreasingsyntax errors that can be mistaken for poor coding ability.",Patrick Hajali,2023/11/27,2023/12/4
2310.08699v2,CoLadder: Supporting Programmers with Hierarchical Code Generation in Multi-Level Abstraction,http://arxiv.org/abs/2310.08699v2,"Programmers increasingly rely on Large Language Models (LLMs) for codegeneration. However, misalignment between programmers' goals and generated codecomplicates the code evaluation process and demands frequent switching betweenprompt authoring and code evaluation. Yet, current LLM-driven code assistantslack sufficient scaffolding to help programmers format intentions from theiroverarching goals, a crucial step before translating these intentions intonatural language prompts. To address this gap, we adopted an iterative designprocess to gain insights into programmers' strategies when using LLMs forprogramming. Building on our findings, we created CoLadder, a system thatsupports programmers by facilitating hierarchical task decomposition, directcode segment manipulation, and result evaluation during prompt authoring. Auser study with 12 experienced programmers showed that CoLadder is effective inhelping programmers externalize their problem-solving intentions flexibly,improving their ability to evaluate and modify code across various abstractionlevels, from goal to final code implementation.",Ryan Yen,2023/10/12,2023/12/26
2302.04012v2,CodeLMSec Benchmark: Systematically Evaluating and Finding Security Vulnerabilities in Black-Box Code Language Models,http://arxiv.org/abs/2302.04012v2,"Large language models (LLMs) for automatic code generation have achievedbreakthroughs in several programming tasks. Their advances in competition-levelprogramming problems have made them an essential pillar of AI-assisted pairprogramming, and tools such as GitHub Copilot have emerged as part of the dailyprogramming workflow used by millions of developers. The training data forthese models is usually collected from the Internet (e.g., from open-sourcerepositories) and is likely to contain faults and security vulnerabilities.This unsanitized training data can cause the language models to learn thesevulnerabilities and propagate them during the code generation procedure. Whilethese models have been extensively assessed for their ability to producefunctionally correct programs, there remains a lack of comprehensiveinvestigations and benchmarks addressing the security aspects of these models.  In this work, we propose a method to systematically study the security issuesof code language models to assess their susceptibility to generating vulnerablecode. To this end, we introduce the first approach to automatically findgenerated code that contains vulnerabilities in black-box code generationmodels. To achieve this, we present an approach to approximate inversion of theblack-box code generation models based on few-shot prompting. We evaluate theeffectiveness of our approach by examining code language models in generatinghigh-risk security weaknesses. Furthermore, we establish a collection ofdiverse non-secure prompts for various vulnerability scenarios using ourmethod. This dataset forms a benchmark for evaluating and comparing thesecurity weaknesses in code language models.",Hossein Hajipour,2023/2/8,2023/10/23
2307.10348v1,Code Detection for Hardware Acceleration Using Large Language Models,http://arxiv.org/abs/2307.10348v1,"Large language models (LLMs) have been massively applied to many tasks, oftensurpassing state-of-the-art approaches. While their effectiveness in codegeneration has been extensively studied (e.g., AlphaCode), their potential forcode detection remains unexplored.  This work presents the first analysis of code detection using LLMs. Our studyexamines essential kernels, including matrix multiplication, convolution, andfast-fourier transform, implemented in C/C++. We propose both a preliminary,naive prompt and a novel prompting strategy for code detection.  Results reveal that conventional prompting achieves great precision but pooraccuracy (68.8%, 22.3%, and 79.2% for GEMM, convolution, and FFT, respectively)due to a high number of false positives. Our novel prompting strategysubstantially reduces false positives, resulting in excellent overall accuracy(91.1%, 97.9%, and 99.7%, respectively). These results pose a considerablechallenge to existing state-of-the-art code detection methods.",Pablo Antonio Martnez,2023/7/19,2023/7/19
2211.11720v3,Multitask Vision-Language Prompt Tuning,http://arxiv.org/abs/2211.11720v3,"Prompt Tuning, conditioning on task-specific learned prompt vectors, hasemerged as a data-efficient and parameter-efficient method for adapting largepretrained vision-language models to multiple downstream tasks. However,existing approaches usually consider learning prompt vectors for each taskindependently from scratch, thereby failing to exploit the rich shareableknowledge across different vision-language tasks. In this paper, we proposemultitask vision-language prompt tuning (MVLPT), which incorporates cross-taskknowledge into prompt tuning for vision-language models. Specifically, (i) wedemonstrate the effectiveness of learning a single transferable prompt frommultiple source tasks to initialize the prompt for each target task; (ii) weshow many target tasks can benefit each other from sharing prompt vectors andthus can be jointly learned via multitask prompt tuning. We benchmark theproposed MVLPT using three representative prompt tuning methods, namely textprompt tuning, visual prompt tuning, and the unified vision-language prompttuning. Results in 20 vision tasks demonstrate that the proposed approachoutperforms all single-task baseline prompt tuning methods, setting the newstate-of-the-art on the few-shot ELEVATER benchmarks and cross-taskgeneralization benchmarks. To understand where the cross-task knowledge is mosteffective, we also conduct a large-scale study on task transferability with 20vision tasks in 400 combinations for each prompt tuning method. It shows thatthe most performant MVLPT for each prompt tuning method prefers different taskcombinations and many tasks can benefit each other, depending on their visualsimilarity and label similarity. Code is available athttps://github.com/sIncerass/MVLPT.",Sheng Shen,2022/11/21,2022/12/5
2206.07585v2,"NatGen: Generative pre-training by ""Naturalizing"" source code",http://arxiv.org/abs/2206.07585v2,"Pre-trained Generative Language models (e.g. PLBART, CodeT5, SPT-Code) forsource code yielded strong results on several tasks in the past few years,including code generation and translation. These models have adopted varyingpre-training objectives to learn statistics of code construction from verylarge-scale corpora in a self-supervised fashion; the success of pre-trainedmodels largely hinges on these pre-training objectives. This paper proposes anew pre-training objective, ""Naturalizing"" of source code, exploiting code'sbimodal, dual-channel (formal & natural channels) nature. Unlike naturallanguage, code's bimodal, dual-channel nature allows us to generatesemantically equivalent code at scale. We introduce six classes of semanticpreserving transformations to introduce un-natural forms of code, and thenforce our model to produce more natural original programs written bydevelopers. Learning to generate equivalent, but more natural code, at scale,over large corpora of open-source code, without explicit manual supervision,helps the model learn to both ingest & generate code. We fine-tune our model inthree generative Software Engineering tasks: code generation, code translation,and code refinement with limited human-curated labeled data and achievestate-of-the-art performance rivaling CodeT5. We show that our pre-trainedmodel is especially competitive at zero-shot and few-shot learning, and betterat learning code properties (e.g., syntax, data flow).",Saikat Chakraborty,2022/6/15,2022/7/5
2102.06360v3,Fine-grained Pseudo-code Generation Method via Code Feature Extraction and Transformer,http://arxiv.org/abs/2102.06360v3,"Pseudo-code written by natural language is helpful for novice developers'program comprehension. However, writing such pseudo-code is time-consuming andlaborious. Motivated by the research advancements of sequence-to-sequencelearning and code semantic learning, we propose a novel deep pseudo-codegeneration method DeepPseudo via code feature extraction and Transformer. Inparticular, DeepPseudo utilizes a Transformer encoder to perform encoding forsource code and then use a code feature extractor to learn the knowledge oflocal features. Finally, it uses a pseudo-code generator to perform decoding,which can generate the corresponding pseudo-code. We choose two corpora (i.e.,Django and SPoC) from real-world large-scale projects as our empiricalsubjects. We first compare DeepPseudo with seven state-of-the-art baselinesfrom pseudo-code generation and neural machine translation domains in terms offour performance measures. Results show the competitiveness of DeepPseudo.Moreover, we also analyze the rationality of the component settings inDeepPseudo.",Guang Yang,2021/2/12,2021/9/21
2206.05239v2,StructCoder: Structure-Aware Transformer for Code Generation,http://arxiv.org/abs/2206.05239v2,"There has been a recent surge of interest in automating software engineeringtasks using deep learning. This paper addresses the problem of code generationwhere the goal is to generate target code given source code in a differentlanguage or a natural language description. Most of the state-of-the-art deeplearning models for code generation use training strategies primarily designedfor natural language. However, understanding and generating code requires amore rigorous comprehension of the code syntax and semantics. With thismotivation, we develop an encoder-decoder Transformer model where both theencoder and decoder are explicitly trained to recognize the syntax and dataflow in the source and target codes, respectively. We not only make the encoderstructure-aware by leveraging the source code's syntax tree and data flowgraph, but we also support the decoder in preserving the syntax and data flowof the target code by introducing two novel auxiliary tasks: AST (AbstractSyntax Tree) paths prediction and data flow prediction. To the best of ourknowledge, this is the first work to introduce a structure-aware Transformerdecoder that models both syntax and data flow to enhance the quality ofgenerated code. The proposed StructCoder model achieves state-of-the-artperformance on code translation and text-to-code generation tasks in theCodeXGLUE benchmark, and improves over baselines of similar size on the APPScode generation benchmark. Our code is publicly available athttps://github.com/reddy-lab-code-research/StructCoder/.",Sindhu Tipirneni,2022/6/10,2023/5/31
1907.08615v1,Logical Segmentation of Source Code,http://arxiv.org/abs/1907.08615v1,"Many software analysis methods have come to rely on machine learningapproaches. Code segmentation - the process of decomposing source code intomeaningful blocks - can augment these methods by featurizing code, reducingnoise, and limiting the problem space. Traditionally, code segmentation hasbeen done using syntactic cues; current approaches do not intentionally capturelogical content. We develop a novel deep learning approach to generate logicalcode segments regardless of the language or syntactic correctness of the code.Due to the lack of logically segmented source code, we introduce a unique dataset construction technique to approximate ground truth for logically segmentedcode. Logical code segmentation can improve tasks such as automaticallycommenting code, detecting software vulnerabilities, repairing bugs, labelingcode functionality, and synthesizing new code.",Jacob Dormuth,2019/7/18,2019/7/18
1010.2354v1,Predicting Coding Effort in Projects Containing XML Code,http://arxiv.org/abs/1010.2354v1,"This paper studies the problem of predicting the coding effort for asubsequent year of development by analysing metrics extracted from projectrepositories, with an emphasis on projects containing XML code. The studyconsiders thirteen open source projects and applies machine learning algorithmsto generate models to predict one-year coding effort, measured in terms oflines of code added, modified and deleted. Both organisational and code metricsassociated to revisions are taken into account. The results show that codingeffort is highly determined by the expertise of developers while source codemetrics have little effect on improving the accuracy of estimations of codingeffort. The study also shows that models trained on one project are unreliableat estimating effort in other projects.",Siim Karus,2010/10/12,2010/10/12
2303.01056v1,Deep Learning Based Code Generation Methods: A Literature Review,http://arxiv.org/abs/2303.01056v1,"Code Generation aims at generating relevant code fragments according to givennatural language descriptions. In the process of software development, thereexist a large number of repetitive and low-tech code writing tasks, so codegeneration has received a lot of attention among academia and industry forassisting developers in coding. In fact, it has also been one of the keyconcerns in the field of software engineering to make machines understandusers' requirements and write programs on their own. The recent development ofdeep learning techniques especially pre-training models make the codegeneration task achieve promising performance. In this paper, we systematicallyreview the current work on deep learning-based code generation and classify thecurrent deep learning-based code generation methods into three categories:methods based on code features, methods incorporated with retrieval, andmethods incorporated with post-processing. The first category refers to themethods that use deep learning algorithms for code generation based on codefeatures, and the second and third categories of methods improve theperformance of the methods in the first category. In this paper, the existingresearch results of each category of methods are systematically reviewed,summarized and commented. The paper then summarizes and analyzes the corpus andthe popular evaluation metrics used in the existing code generation work.Finally, the paper summarizes the overall literature review and provides aprospect on future research directions worthy of attention.",Zezhou Yang,2023/3/2,2023/3/2
1904.00720v1,CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning,http://arxiv.org/abs/1904.00720v1,"To accelerate software development, much research has been performed to helppeople understand and reuse the huge amount of available code resources. Twoimportant tasks have been widely studied: code retrieval, which aims toretrieve code snippets relevant to a given natural language query from a codebase, and code annotation, where the goal is to annotate a code snippet with anatural language description. Despite their advancement in recent years, thetwo tasks are mostly explored separately. In this work, we investigate a novelperspective of Code annotation for Code retrieval (hence called `CoaCor'),where a code annotation model is trained to generate a natural languageannotation that can represent the semantic meaning of a given code snippet andcan be leveraged by a code retrieval model to better distinguish relevant codesnippets from others. To this end, we propose an effective framework based onreinforcement learning, which explicitly encourages the code annotation modelto generate annotations that can be used for the retrieval task. Throughextensive experiments, we show that code annotations generated by our frameworkare much more detailed and more useful for code retrieval, and they can furtherimprove the performance of existing code retrieval models significantly.",Ziyu Yao,2019/3/13,2019/3/13
2305.05383v1,Code Execution with Pre-trained Language Models,http://arxiv.org/abs/2305.05383v1,"Code execution is a fundamental aspect of programming language semantics thatreflects the exact behavior of the code. However, most pre-trained models forcode intelligence ignore the execution trace and only rely on source code andsyntactic structures. In this paper, we investigate how well pre-trained modelscan understand and perform code execution. We develop a mutation-based dataaugmentation technique to create a large-scale and realistic Python dataset andtask for code execution, which challenges existing models such as Codex. Wethen present CodeExecutor, a Transformer model that leverages code executionpre-training and curriculum learning to enhance its semantic comprehension. Weevaluate CodeExecutor on code execution and show its promising performance andlimitations. We also demonstrate its potential benefits for code intelligencetasks such as zero-shot code-to-code search and text-to-code generation. Ouranalysis provides insights into the learning and generalization abilities ofpre-trained models for code execution.",Chenxiao Liu,2023/5/8,2023/5/8
2302.03924v1,CCRep: Learning Code Change Representations via Pre-Trained Code Model and Query Back,http://arxiv.org/abs/2302.03924v1,"Representing code changes as numeric feature vectors, i.e., code changerepresentations, is usually an essential step to automate many softwareengineering tasks related to code changes, e.g., commit message generation andjust-in-time defect prediction. Intuitively, the quality of code changerepresentations is crucial for the effectiveness of automated approaches. Priorwork on code changes usually designs and evaluates code change representationapproaches for a specific task, and little work has investigated code changeencoders that can be used and jointly trained on various tasks. To fill thisgap, this work proposes a novel Code Change Representation learning approachnamed CCRep, which can learn to encode code changes as feature vectors fordiverse downstream tasks. Specifically, CCRep regards a code change as thecombination of its before-change and after-change code, leverages a pre-trainedcode model to obtain high-quality contextual embeddings of code, and uses anovel mechanism named query back to extract and encode the changed codefragments and make them explicitly interact with the whole code change. Toevaluate CCRep and demonstrate its applicability to diverse code-change-relatedtasks, we apply it to three tasks: commit message generation, patch correctnessassessment, and just-in-time defect prediction. Experimental results show thatCCRep outperforms the state-of-the-art techniques on each task.",Zhongxin Liu,2023/2/8,2023/2/8
2204.06894v1,To What Extent do Deep Learning-based Code Recommenders Generate Predictions by Cloning Code from the Training Set?,http://arxiv.org/abs/2204.06894v1,"Deep Learning (DL) models have been widely used to support code completion.These models, once properly trained, can take as input an incomplete codecomponent (e.g., an incomplete function) and predict the missing tokens tofinalize it. GitHub Copilot is an example of code recommender built by traininga DL model on millions of open source repositories: The source code of theserepositories acts as training data, allowing the model to learn ""how toprogram"". The usage of such a code is usually regulated by Free and Open SourceSoftware (FOSS) licenses, that establish under which conditions the licensedcode can be redistributed or modified. As of Today, it is unclear whether thecode generated by DL models trained on open source code should be considered as""new"" or as ""derivative"" work, with possible implications on licenseinfringements. In this work, we run a large-scale study investigating theextent to which DL models tend to clone code from their training set whenrecommending code completions. Such an exploratory study can help in assessingthe magnitude of the potential licensing issues mentioned before: If thesemodels tend to generate new code that is unseen in the training set, thenlicensing issues are unlikely to occur. Otherwise, a revision of these licensesurges to regulate how the code generated by these models should be treated whenused, for example, in a commercial setting. Highlights from our results showthat ~$10% to ~0.1% of the predictions generated by a state-of-the-art DL-basedcode completion tool are Type-1 clones of instances in the training set,depending on the size of the predicted code. Long predictions are unlikely tobe cloned.",Matteo Ciniselli,2022/4/14,2022/4/14
2401.10314v1,LangProp: A code optimization framework using Language Models applied to driving,http://arxiv.org/abs/2401.10314v1,"LangProp is a framework for iteratively optimizing code generated by largelanguage models (LLMs) in a supervised/reinforcement learning setting. WhileLLMs can generate sensible solutions zero-shot, the solutions are oftensub-optimal. Especially for code generation tasks, it is likely that theinitial code will fail on certain edge cases. LangProp automatically evaluatesthe code performance on a dataset of input-output pairs, as well as catches anyexceptions, and feeds the results back to the LLM in the training loop, so thatthe LLM can iteratively improve the code it generates. By adopting a metric-and data-driven training paradigm for this code optimization procedure, onecould easily adapt findings from traditional machine learning techniques suchas imitation learning, DAgger, and reinforcement learning. We demonstrate thefirst proof of concept of automated code optimization for autonomous driving inCARLA, showing that LangProp can generate interpretable and transparent drivingpolicies that can be verified and improved in a metric- and data-driven way.Our code will be open-sourced and is available athttps://github.com/shuishida/LangProp.",Shu Ishida,2024/1/18,2024/1/18
1807.00801v1,Deepcode: Feedback Codes via Deep Learning,http://arxiv.org/abs/1807.00801v1,"The design of codes for communicating reliably over a statistically welldefined channel is an important endeavor involving deep mathematical researchand wide-ranging practical applications. In this work, we present the firstfamily of codes obtained via deep learning, which significantly beatsstate-of-the-art codes designed over several decades of research. Thecommunication channel under consideration is the Gaussian noise channel withfeedback, whose study was initiated by Shannon; feedback is known theoreticallyto improve reliability of communication, but no practical codes that do so haveever been successfully constructed.  We break this logjam by integrating information theoretic insightsharmoniously with recurrent-neural-network based encoders and decoders tocreate novel codes that outperform known codes by 3 orders of magnitude inreliability. We also demonstrate several desirable properties of the codes: (a)generalization to larger block lengths, (b) composability with known codes, (c)adaptation to practical constraints. This result also has broader ramificationsfor coding theory: even when the channel has a clear mathematical model, deeplearning methodologies, when combined with channel-specificinformation-theoretic insights, can potentially beat state-of-the-art codesconstructed over decades of mathematical research.",Hyeji Kim,2018/7/2,2018/7/2
2007.06934v3,CoreGen: Contextualized Code Representation Learning for Commit Message Generation,http://arxiv.org/abs/2007.06934v3,"Automatic generation of high-quality commit messages for code commits cansubstantially facilitate software developers' works and coordination. However,the semantic gap between source code and natural language poses a majorchallenge for the task. Several studies have been proposed to alleviate thechallenge but none explicitly involves code contextual information duringcommit message generation. Specifically, existing research adopts staticembedding for code tokens, which maps a token to the same vector regardless ofits context. In this paper, we propose a novel Contextualized coderepresentation learning strategy for commit message Generation (CoreGen).CoreGen first learns contextualized code representations which exploit thecontextual information behind code commit sequences. The learnedrepresentations of code commits built upon Transformer are then fine-tuned fordownstream commit message generation. Experiments on the benchmark datasetdemonstrate the superior effectiveness of our model over the baseline modelswith at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we alsohighlight the future opportunities in training contextualized coderepresentations on larger code corpus as a solution to low-resource tasks andadapting the contextualized code representation framework to other code-to-textgeneration tasks.",Lun Yiu Nie,2020/7/14,2021/6/21
2107.07987v1,Deep Learning to Ternary Hash Codes by Continuation,http://arxiv.org/abs/2107.07987v1,"Recently, it has been observed that {0,1,-1}-ternary codes which are simplygenerated from deep features by hard thresholding, tend to outperform{-1,1}-binary codes in image retrieval. To obtain better ternary codes, we forthe first time propose to jointly learn the features with the codes byappending a smoothed function to the networks. During training, the functioncould evolve into a non-smoothed ternary function by a continuation method. Themethod circumvents the difficulty of directly training discrete functions andreduces the quantization errors of ternary codes. Experiments show that thegenerated codes indeed could achieve higher retrieval accuracy.",Mingrui Chen,2021/7/16,2021/7/16
2105.08645v4,CoTexT: Multi-task Learning with Code-Text Transformer,http://arxiv.org/abs/2105.08645v4,"We present CoTexT, a pre-trained, transformer-based encoder-decoder modelthat learns the representative context between natural language (NL) andprogramming language (PL). Using self-supervision, CoTexT is pre-trained onlarge programming language corpora to learn a general understanding of languageand code. CoTexT supports downstream NL-PL tasks such as codesummarizing/documentation, code generation, defect detection, and codedebugging. We train CoTexT on different combinations of available PL corpusincluding both ""bimodal"" and ""unimodal"" data. Here, bimodal data is thecombination of text and corresponding code snippets, whereas unimodal data ismerely code snippets. We first evaluate CoTexT with multi-task learning: weperform Code Summarization on 6 different programming languages and CodeRefinement on both small and medium size featured in the CodeXGLUE dataset. Wefurther conduct extensive experiments to investigate CoTexT on other taskswithin the CodeXGlue dataset, including Code Generation and Defect Detection.We consistently achieve SOTA results in these tasks, demonstrating theversatility of our models.",Long Phan,2021/5/18,2021/6/21
2105.09630v1,Enriching Query Semantics for Code Search with Reinforcement Learning,http://arxiv.org/abs/2105.09630v1,"Code search is a common practice for developers during softwareimplementation. The challenges of accurate code search mainly lie in theknowledge gap between source code and natural language (i.e., queries). Due tothe limited code-query pairs and large code-description pairs available, theprior studies based on deep learning techniques focus on learning the semanticmatching relation between source code and corresponding description texts forthe task, and hypothesize that the semantic gap between descriptions and userqueries is marginal. In this work, we found that the code search models trainedon code-description pairs may not perform well on user queries, which indicatesthe semantic distance between queries and code descriptions. To mitigate thesemantic distance for more effective code search, we propose QueCos, aQuery-enriched Code search model. QueCos learns to generate semantic enrichedqueries to capture the key semantics of given queries with reinforcementlearning (RL). With RL, the code search performance is considered as a rewardfor producing accurate semantic enriched queries. The enriched queries arefinally employed for code search. Experiments on the benchmark datasets showthat QueCos can significantly outperform the state-of-the-art code searchmodels.",Chaozheng Wang,2021/5/20,2021/5/20
2301.09043v3,CodeScore: Evaluating Code Generation by Learning Code Execution,http://arxiv.org/abs/2301.09043v3,"A proper code evaluation metric (CEM) profoundly impacts the evolution ofcode generation, which is an important research field in NLP and softwareengineering. Prevailing match-based CEMs (e.g., BLEU, Accuracy, and CodeBLEU)suffer from two significant drawbacks. 1. They primarily measure the surfacedifferences between codes without considering their functional equivalence.However, functional equivalence is pivotal in evaluating the effectiveness ofcode generation, as different codes can perform identical operations. 2. Theyare predominantly designed for the Ref-only input format. However, codeevaluation necessitates versatility in input formats. Aside from Ref-only,there are NL-only and Ref\&NL formats, which existing match-based CEMs cannoteffectively accommodate. In this paper, we propose CodeScore, a large languagemodel (LLM)-based CEM, which estimates the functional correctness of generatedcode on three input types. To acquire CodeScore, we present UniCE, a unifiedcode generation learning framework, for LLMs to learn code execution (i.e.,learning PassRatio and Executability of generated code) with unified input.Extensive experimental results on multiple code evaluation datasets demonstratethat CodeScore absolutely improves up to 58.87% correlation with functionalcorrectness compared to other CEMs, achieves state-of-the-art performance, andeffectively handles three input formats.",Yihong Dong,2023/1/22,2023/12/1
2010.09803v2,Adversarial Training for Code Retrieval with Question-Description Relevance Regularization,http://arxiv.org/abs/2010.09803v2,"Code retrieval is a key task aiming to match natural and programminglanguages. In this work, we propose adversarial learning for code retrieval,that is regularized by question-description relevance. First, we adapt a simpleadversarial learning technique to generate difficult code snippets given theinput question, which can help the learning of code retrieval that facesbi-modal and data-scarce challenges. Second, we propose to leveragequestion-description relevance to regularize adversarial learning, such that agenerated code snippet should contribute more to the code retrieval trainingloss, only if its paired natural language description is predicted to be lessrelevant to the user given question. Experiments on large-scale code retrievaldatasets of two programming languages show that our adversarial learning methodis able to improve the performance of state-of-the-art models. Moreover, usingan additional duplicate question prediction model to regularize adversariallearning further improves the performance, and this is more effective thanusing the duplicated questions in strong multi-task learning baselines",Jie Zhao,2020/10/19,2020/11/10
2304.02690v1,Hierarchical B-frame Video Coding Using Two-Layer CANF without Motion Coding,http://arxiv.org/abs/2304.02690v1,"Typical video compression systems consist of two main modules: motion codingand residual coding. This general architecture is adopted by classical codingschemes (such as international standards H.265 and H.266) and deeplearning-based coding schemes. We propose a novel B-frame coding architecturebased on two-layer Conditional Augmented Normalization Flows (CANF). It has thestriking feature of not transmitting any motion information. Our proposed ideaof video compression without motion coding offers a new direction for learnedvideo coding. Our base layer is a low-resolution image compressor that replacesthe full-resolution motion compressor. The low-resolution coded image is mergedwith the warped high-resolution images to generate a high-quality image as aconditioning signal for the enhancement-layer image coding in full resolution.One advantage of this architecture is significantly reduced computationalcomplexity due to eliminating the motion information compressor. In addition,we adopt a skip-mode coding technique to reduce the transmitted latent samples.The rate-distortion performance of our scheme is slightly lower than that ofthe state-of-the-art learned B-frame coding scheme, B-CANF, but outperformsother learned B-frame coding schemes. However, compared to B-CANF, our schemesaves 45% of multiply-accumulate operations (MACs) for encoding and 27% of MACsfor decoding. The code is available at https://nycu-clab.github.io.",David Alexandre,2023/4/5,2023/4/5
2305.11718v1,Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization,http://arxiv.org/abs/2305.11718v1,"Existing vector quantization (VQ) based autoregressive models follow atwo-stage generation paradigm that first learns a codebook to encode images asdiscrete codes, and then completes generation based on the learned codebook.However, they encode fixed-size image regions into fixed-length codes andignore their naturally different information densities, which results ininsufficiency in important regions and redundancy in unimportant ones, andfinally degrades the generation quality and speed. Moreover, the fixed-lengthcoding leads to an unnatural raster-scan autoregressive generation. To addressthe problem, we propose a novel two-stage framework: (1) Dynamic-QuantizationVAE (DQ-VAE) which encodes image regions into variable-length codes based ontheir information densities for an accurate and compact code representation.(2) DQ-Transformer which thereby generates images autoregressively fromcoarse-grained (smooth regions with fewer codes) to fine-grained (detailsregions with more codes) by modeling the position and content of codes in eachgranularity alternately, through a novel stacked-transformer architecture andshared-content, non-shared position input layers designs. Comprehensiveexperiments on various generation tasks validate our superiorities in botheffectiveness and efficiency. Code will be released athttps://github.com/CrossmodalGroup/DynamicVectorQuantization.",Mengqi Huang,2023/5/19,2023/5/19
2004.03538v1,On Decoding of Generalized Concatenated Codes and Matrix-Product Codes,http://arxiv.org/abs/2004.03538v1,"Generalized concatenated codes were introduced in the 1970s by Zinoviev.There are many types of codes in the literature that are known by other namesthat can be viewed as generalized concatenated codes. Examples includematrix-product codes, multilevel codes and generalized cascade codes. Decodingalgorithms for generalized concatenated codes were developed during the 1970sand 1980s. However, their use does not appear to be as widespread as it should,especially for codes that are known by other names but can be viewed asgeneralized concatenated codes.  In this paper we review the decoding algorithms for concatenated codes,generalized concatenated codes and matrix-product codes, and clarify theconnection between matrix-product codes and generalized concatenated codes. Wepresent a small improvement to the decoding algorithm for concatenated codes.We also extend the decoding algorithms from errors-only decoders toerror-and-erasure decoders. Furthermore, we improve the upper bound on thecomputational complexity of the decoding algorithm in the case ofmatrix-product codes where the generator matrix for the inner code isnon-singular by columns.",Ferdinand Blomqvist,2020/4/7,2020/4/7
2008.03708v1,New Constructions of MDS Twisted Reed-Solomon Codes and LCD MDS Codes,http://arxiv.org/abs/2008.03708v1,"Maximum distance separable (MDS) codes are optimal where the minimum distancecannot be improved for a given length and code size. Twisted Reed-Solomon codesover finite fields were introduced in 2017, which are generalization ofReed-Solomon codes. Twisted Reed-Solomon codes can be applied in cryptographywhich prefer the codes with large minimum distance. MDS codes can beconstructed from twisted Reed-Solomon codes, and most of them are notequivalent to Reed-Solomon codes. In this paper, we first generalize twistedReed-Solomon codes to generalized twisted Reed-Solomon codes, then we give somenew explicit constructions of MDS (generalized) twisted Reed-Solomon codes. Insome cases, our constructions can get MDS codes with the length longer than theconstructions of previous works. Linear complementary dual (LCD) codes arelinear codes that intersect with their duals trivially. LCD codes can beapplied in cryptography. This application of LCD codes renewed the interest inthe construction of LCD codes having a large minimum distance. We also providenew constructions of LCD MDS codes from generalized twisted Reed-Solomon codes.",Hongwei Liu,2020/8/9,2020/8/9
cs/0609006v2,New Quasi-Cyclic Codes from Simplex Codes,http://arxiv.org/abs/cs/0609006v2,"As a generalization of cyclic codes, quasi-cyclic (QC) codes contain manygood linear codes. But quasi-cyclic codes studied so far are mainly limited toone generator (1-generator) QC codes. In this correspondence, 2-generator and3-generator QC codes are studied, and many good, new QC codes are constructedfrom simplex codes. Some new binary QC codes or related codes, that improve thebounds on maximum minimum distance for binary linear codes are constructed.They are 5-generator QC [93, 17, 34] and [254, 23, 102] codes, and related [96,17, 36], [256, 23, 104] codes.",Eric Zhi Chen,2006/9/2,2006/11/20
math/0604603v1,Skew-cyclic codes,http://arxiv.org/abs/math/0604603v1,"We generalize the notion of cyclic codes by using generator polynomials in(non commutative) skew polynomial rings. Since skew polynomial rings are leftand right euclidean, the obtained codes share most properties of cyclic codes.Since there are much more skew-cyclic codes, this new class of codes allows tosystematically search for codes with good properties. We give many examples ofcodes which improve the previously best known linear codes.",Delphine Boucher,2006/4/27,2006/4/27
0905.0428v1,Generalized Concatenation for Quantum Codes,http://arxiv.org/abs/0905.0428v1,"We show how good quantum error-correcting codes can be constructed usinggeneralized concatenation. The inner codes are quantum codes, the outer codescan be linear or nonlinear classical codes. Many new good codes are found,including both stabilizer codes as well as so-called nonadditive codes.",Markus Grassl,2009/5/4,2009/5/4
1002.3629v1,Generalized Adaptive Network Coded Cooperation (GANCC): A Unified Framework for Network Coding and Channel Coding,http://arxiv.org/abs/1002.3629v1,"This paper considers distributed coding for multi-source single-sink datacollection wireless networks. A unified framework for network coding andchannel coding, termed ""generalized adaptive network coded cooperation""(GANCC), is proposed. Key ingredients of GANCC include: matching code graphswith the dynamic network graphs on-the-fly, and integrating channel coding withnetwork coding through circulant low-density parity-check codes. Several codeconstructing methods and several families of sparse-graph codes are proposed,and information theoretical analysis is performed. It is shown that GANCC issimple to operate, adaptive in real time, distributed in nature, and capable ofproviding remarkable coding gains even with a very limited number ofcooperating users.",Xingkai Bao,2010/2/18,2010/2/18
1911.06384v1,Entanglement-assisted Quantum Codes from Cyclic Codes,http://arxiv.org/abs/1911.06384v1,"Entanglement-assisted quantum (QUENTA) codes are a subclass of quantumerror-correcting codes which use entanglement as a resource. These codes canprovide error correction capability higher than the codes derived from thetraditional stabilizer formalism. In this paper, it is shown a general methodto construct QUENTA codes from cyclic codes. Afterwards, the method is appliedto Reed-Solomon codes, BCH codes, and general cyclic codes. We use theEuclidean and Hermitian construction of QUENTA codes. Two families of QUENTAcodes are maximal distance separable (MDS), and one is almost MDS or almostnear MDS. The comparison of the codes in this paper is mostly based on thequantum Singleton bound.",Francisco Revson F. Pereira,2019/11/14,2019/11/14
2312.05772v2,"Context-Aware Code Generation Framework for Code Repositories: Local, Global, and Third-Party Library Awareness",http://arxiv.org/abs/2312.05772v2,"Code generation tools are essential to help developers in the softwaredevelopment process. Existing tools often disconnect with the working context,i.e., the code repository, causing the generated code to be not similar tohuman developers. In this paper, we propose a novel code generation framework,dubbed \textbf{$A^3$}-CodGen, to harness information within the code repositoryto generate code with fewer logical errors, code redundancy, andlibrary-related compatibility issues. We identify three categories ofrepresentative information for the code repository: local-aware informationfrom current code file, global-aware information from other code files, andthird-party-library information. Results demonstrate that by adopting the\textbf{$A^3$}-CodGen framework, we successfully extract, fuse, and feed coderepository information into the LLM, generating more accurate, efficient, andhighly reusable code. The effectiveness of our framework is further underscoredby generating code with a higher reuse rate, compared to human developers. Thisresearch contributes significantly to the field of code generation, providingdevelopers with a more powerful tool to address the evolving demands insoftware development in practice.",Dianshu Liao,2023/12/10,2023/12/18
2208.14613v2,How Readable is Model-generated Code? Examining Readability and Visual Inspection of GitHub Copilot,http://arxiv.org/abs/2208.14613v2,"Background: Recent advancements in large language models have motivated thepractical use of such models in code generation and program synthesis. However,little is known about the effects of such tools on code readability and visualattention in practice.  Objective: In this paper, we focus on GitHub Copilot to address the issues ofreadability and visual inspection of model generated code. Readability and lowcomplexity are vital aspects of good source code, and visual inspection ofgenerated code is important in light of automation bias.  Method: Through a human experiment (n=21) we compare model generated code tocode written completely by human programmers. We use a combination of staticcode analysis and human annotators to assess code readability, and we use eyetracking to assess the visual inspection of code.  Results: Our results suggest that model generated code is comparable incomplexity and readability to code written by human pair programmers. At thesame time, eye tracking data suggests, to a statistically significant level,that programmers direct less visual attention to model generated code.  Conclusion: Our findings highlight that reading code is more important thanever, and programmers should beware of complacency and automation bias withmodel generated code.",Naser Al Madi,2022/8/31,2022/9/1
2009.06298v1,MDS or NMDS self-dual codes from twisted generalized Reed-Solomon codes,http://arxiv.org/abs/2009.06298v1,"Self-dual maximum distance separable codes (self-dual MDS codes) andself-dual near MDS codes are very important in coding theory and practice.Thus, it is interesting to construct self-dual MDS or self-dual near MDS codes.In this paper, we not only give check matrices of dual codes of twistedgeneralized Reed-Solomon codes (TGRS codes) but also present the efficient andnecessary condition of self-dual TGRS codes. Moreover, we construct severalclasses of self-dual MDS or self-dual near MDS codes from TGRS codes.",Daitao Huang,2020/9/14,2020/9/14
2009.07743v1,Twisted Reed-Solomon Codes With One-dimensional Hull,http://arxiv.org/abs/2009.07743v1,"The hull of a linear code is defined to be the intersection of the code andits dual. When the size of the hull is small, it has been proved that somealgorithms for checking permutation equivalence of two linear codes andcomputing the automorphism group of a linear code are very effective ingeneral. Maximum distance separable (MDS) codes are codes meeting the Singletonbound. Twisted Reed-Solomon codes is a generalization of Reed-Solomon codes,which is also a nice construction for MDS codes. In this short letter, weobtain some twisted Reed-Solomon MDS codes with one-dimensional hull. Moreover,these codes are not monomially equivalent to Reed-Solomon codes.",Yansheng Wu,2020/9/16,2020/9/16
2204.11960v1,The equivalence of GRS codes and EGRS codes,http://arxiv.org/abs/2204.11960v1,"Generalized Reed-Solomon and extended generalized Reed-Solomon (abbreviationto GRS and EGRS) codes are the most well-known family of MDS codes with wideapplications in coding theory and practice. Let $\mathbb{F}_q$ be the $q$elements finite field, where $q$ is the power of a prime. For a linear code$\mathcal{C}$ over $\mathbb{F}_q$ with length $2\le n\le q$, we prove that$\mathcal{C}$ is a GRS code if and only if $\mathcal{C}$ is a EGRS code.",Canze Zhu,2022/4/25,2022/4/25
2112.06325v1,Multivariate Goppa codes,http://arxiv.org/abs/2112.06325v1,"In this paper, we introduce multivariate Goppa codes, which contain as aspecial case the well-known, classical Goppa codes. We provide a parity checkmatrix for a multivariate Goppa code in terms of a tensor product ofgeneralized Reed-Solomon codes. We prove that multivariate Goppa codes aresubfield subcodes of augmented Cartesian codes. By showing how this new familyof codes relates to tensor products of generalized Reed-Solomon codes andaugmented codes, we obtain information about the parameters, subcodes, duals,and hulls of multivariate Goppa codes. We see that in certain cases, the hullsof multivariate Goppa codes (resp., tensor product of generalized Reed-Solomoncodes), are also multivariate Goppa codes (resp. tensor product of generalizedReed-Solomon codes). We utilize the multivariate Goppa codes to obtainentanglement-assisted quantum error-correcting codes and to build families oflong LCD, self-dual, or self-orthogonal codes.",Hiram H. Lpez,2021/12/12,2021/12/12
1810.11826v1,$m$-adic residue codes over $\mathbb{F}_q[v]/(v^s-v)$,http://arxiv.org/abs/1810.11826v1,"Due to their rich algebraic structure, cyclic codes have a great deal ofsignificance amongst linear codes. Duadic codes are the generalization of thequadratic residue codes, a special case of cyclic codes. The $m$-adic residuecodes are the generalization of the duadic codes. The aim of this paper is tostudy the structure of the $m$-adic residue codes over the quotient ring$\mathbb{F}_{q}[v]/(v^s-v).$ We determine the idempotent generators of the$m$-adic residue codes over $\mathbb{F}_{q}[v]/(v^s-v)$. We obtain someparameters of optimal $m$-adic residue codes over $\mathbb{F}_{q}[v]/(v^s-v),$with respect to Griesmer bound for rings.",Ferhat Kuruz,2018/10/28,2018/10/28
2307.06595v1,Integer sequences that are generalized weights of a linear code,http://arxiv.org/abs/2307.06595v1,"Which integer sequences are sequences of generalized weights of a linearcode? In this paper, we answer this question for linear block codes,rank-metric codes, and more generally for sum-rank metric codes. We do so underan existence assumption for MDS and MSRD codes. We also prove that the sameinteger sequences appear as sequences of greedy weights of linear block codes,rank-metric codes, and sum-rank metric codes. Finally, we characterize theinteger sequences which appear as sequences of relative generalized weights(respectively, relative greedy weights) of linear block codes.",Elisa Gorla,2023/7/13,2023/7/13
1606.07161v1,New MDS Euclidean and Hermitian self-dual codes over finite fields,http://arxiv.org/abs/1606.07161v1,"In this paper, we construct MDS Euclidean self-dual codes which are extendedcyclic duadic codes.  And we obtain many new MDS Euclidean self-dual codes. We also construct MDSHermitian self-dual codes from generalized Reed-Solomon codes and constacycliccodes. And we give some results on Hermitian self-dual codes, which are theextended cyclic duadic codes.",Hongxi Tong,2016/6/23,2016/6/23
2108.10316v1,A Generalization of the ASR Search Algorithm to 2-Generator Quasi-Twisted Codes,http://arxiv.org/abs/2108.10316v1,"One of the main goals of coding theory is to construct codes with bestpossible parameters and properties. A special class of codes calledquasi-twisted (QT) codes is well-known to produce codes with good parameters.Most of the work on QT codes has been over the 1-generator case. In this work,we focus on 2-generator QT codes and generalize the ASR algorithm that has beenvery effective to produce new linear codes from 1-generator QT codes. Moreover,we also generalize a recent algorithm to test equivalence of cyclic codes toconstacyclic codes. This algorithm makes the ASR search even more effective. Asa result of implementing our algorithm, we have found 103 QT codes that are newamong the class of QT codes. Additionally, most of these codes possess thefollowing additional properties: a) they have the same parameters as best knownlinear codes, and b) many of the have additional desired properties such asbeing LCD and dual-containing. Further, we have also found a binary 2-generatorQT code that is new (record breaking) among all binary linear codes and itsextension yields another record breaking binary linear code.",Dev Akre,2021/8/20,2021/8/20
1208.4907v1,On the Fourier Transform Approach to Quantum Error Control,http://arxiv.org/abs/1208.4907v1,"Quantum codes are subspaces of the state space of a quantum system that areused to protect quantum information. Some common classes of quantum codes arestabilizer (or additive) codes, non-stabilizer (or non-additive) codes obtainedfrom stabilizer codes, and Clifford codes. These are analyzed in a frameworkusing the Fourier transform on finite groups, the finite group in questionbeing a subgroup of the quantum error group considered. All the classes ofcodes that can be obtained in this framework are explored, including codes moregeneral than Clifford codes. The error detection properties of one of thesemore general classes (""direct sums of translates of Clifford codes"") arecharacterized. Examples codes are constructed, and computer code search resultspresented and analysed.",Hari Dilip Kumar,2012/8/24,2012/8/24
2204.11955v1,The non-GRS properties for the twisted generalized Reed-Solomon code and its extended code,http://arxiv.org/abs/2204.11955v1,"In 2017, Beelen et al. firstly introduced twisted generalized Reed-Solomon(in short, TGRS) codes, and constructed a large subclass of MDS TGRS codes.Later, they proved that TGRS code is non-GRS when the code rate is less thanone half. In this letter, basing on the dual code of the TGRS code or theextended TGRS code, by using the Schur product, we prove that almost all ofTGRS codes and extended TGRS codes are non-GRS when the code rate more than onehalf.",Canze Zhu,2022/4/25,2022/4/25
2308.04838v1,No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT,http://arxiv.org/abs/2308.04838v1,"Large language models (LLMs) have demonstrated impressive capabilities acrossvarious natural language processing (NLP) tasks, such as machine translation,question answering, summarization, and so on. Additionally, LLMs are alsohighly valuable in supporting software engineering tasks, particularly in thefield of code generation. Automatic code generation is a process ofautomatically generating source code or executable code based on givenspecifications or requirements, improving developer productivity. In thisstudy, we perform a systematic empirical assessment of code generation usingChatGPT, a recent and popular LLM. Our evaluation encompasses a comprehensiveanalysis of code snippets generated by ChatGPT, focusing on three criticalaspects: correctness, understandability, and security. We also specificallyinvestigate ChatGPT's ability to engage in multi-round process (i.e., ChatGPT'sdialog ability) of facilitating code generation. By delving into the generatedcode and examining the experimental results, this work provides valuableinsights into the performance of ChatGPT in tackling code generation tasks.Overall, our findings uncover potential issues and limitations that arise inthe ChatGPT-based code generation and lay the groundwork for improving AI andLLM-based code generation techniques.",Zhijie Liu,2023/8/9,2023/8/9
1111.0228v1,Classification of extremal and $s$-extremal binary self-dual codes of length 38,http://arxiv.org/abs/1111.0228v1,"In this paper we classify all extremal and $s$-extremal binary self-dualcodes of length 38. There are exactly 2744 extremal $[38,19,8]$ self-dualcodes, two $s$-extremal $[38,19,6]$ codes, and 1730 $s$-extremal $[38,19,8]$codes. We obtain our results from the use of a recursive algorithm used in therecent classification of all extremal self-dual codes of length 36, and from ageneralization of this recursive algorithm for the shadow. The classificationof $s$-extremal $[38,19,6]$ codes permits to achieve the classification of all$s$-extremal codes with d=6.",Carlos Aguilar-Melchor,2011/11/1,2011/11/1
1205.5062v1,The Classification of Complementary Information Set Codes of Lengths 14 and 16,http://arxiv.org/abs/1205.5062v1,"In the paper ""A new class of codes for Boolean masking of cryptographiccomputations,"" Carlet, Gaborit, Kim, and Sol\'{e} defined a new class of rateone-half binary codes called \emph{complementary information set} (or CIS)codes. The authors then classified all CIS codes of length less than or equalto 12. CIS codes have relations to classical Coding Theory as they are ageneralization of self-dual codes. As stated in the paper, CIS codes also haveimportant practical applications as they may improve the cost of maskingcryptographic algorithms against side channel attacks. In this paper, we give acomplete classification result for length 14 CIS codes using an equivalencerelation on $GL(n,\FF_2)$. We also give a new classification for all binary$[16,8,3]$ and $[16,8,4]$ codes. We then complete the classification for length16 CIS codes and give additional classifications for optimal CIS codes oflengths 20 and 26.",Finley Freibert,2012/5/22,2012/5/22
1907.04372v3,A Geometric Approach to Rank Metric Codes and a Classification of Constant Weight Codes,http://arxiv.org/abs/1907.04372v3,"In this work we develop a geometric approach to the study of rank metriccodes. Using this method, we introduce a simpler definition for generalizedrank weight of linear codes. We give a complete classification of constant rankweight code and we give their generalized rank weights.",Tovohery Hajatiana Randrianarisoa,2019/7/9,2020/1/22
1909.13154v1,Generalized Zero-shot ICD Coding,http://arxiv.org/abs/1909.13154v1,"The International Classification of Diseases (ICD) is a list ofclassification codes for the diagnoses. Automatic ICD coding is in high demandas the manual coding can be labor-intensive and error-prone. It is amulti-label text classification task with extremely long-tailed labeldistribution, making it difficult to perform fine-grained classification onboth frequent and zero-shot codes at the same time. In this paper, we propose alatent feature generation framework for generalized zero-shot ICD coding, wherewe aim to improve the prediction on codes that have no labeled data withoutcompromising the performance on seen codes. Our framework generates pseudofeatures conditioned on the ICD code descriptions and exploits the ICD codehierarchical structure. To guarantee the semantic consistency between thegenerated features and real features, we reconstruct the keywords in the inputdocuments that are related to the conditioned ICD codes. To the best of ourknowledge, this works represents the first one that proposes an adversarialgenerative model for the generalized zero-shot learning on multi-label textclassification. Extensive experiments demonstrate the effectiveness of ourapproach. On the public MIMIC-III dataset, our methods improve the F1 scorefrom nearly 0 to 20.91% for the zero-shot codes, and increase the AUC score by3% (absolute improvement) from previous state of the art. We also show that theframework improves the performance on few-shot codes.",Congzheng Song,2019/9/28,2019/9/28
2306.00005v1,A Two-Stage Decoder for Efficient ICD Coding,http://arxiv.org/abs/2306.00005v1,"Clinical notes in healthcare facilities are tagged with the InternationalClassification of Diseases (ICD) code; a list of classification codes formedical diagnoses and procedures. ICD coding is a challenging multilabel textclassification problem due to noisy clinical document inputs and long-tailedlabel distribution. Recent automated ICD coding efforts improve performance byencoding medical notes and codes with additional data and knowledge bases.However, most of them do not reflect how human coders generate the code: first,the coders select general code categories and then look for specificsubcategories that are relevant to a patient's condition. Inspired by this, wepropose a two-stage decoding mechanism to predict ICD codes. Our model uses thehierarchical properties of the codes to split the prediction into two steps: Atfirst, we predict the parent code and then predict the child code based on theprevious prediction. Experiments on the public MIMIC-III data set show that ourmodel performs well in single-model settings without external data orknowledge.",Thanh-Tung Nguyen,2023/5/27,2023/5/27
2208.04087v1,Self-Dual Convolutional Codes,http://arxiv.org/abs/2208.04087v1,This paper investigates the concept of self-dual convolutional code. Wederive the basic properties of this interesting class of codes and we show howsome of the techniques to construct self-dual linear block codes generalize toself-dual convolutional codes. As for self-dual linear block codes we are ableto give a complete classification for some small parameters.,Sebastian Heri,2022/8/8,2022/8/8
0902.3883v3,Directed Graph Representation of Half-Rate Additive Codes over GF(4),http://arxiv.org/abs/0902.3883v3,"We show that (n,2^n) additive codes over GF(4) can be represented as directedgraphs. This generalizes earlier results on self-dual additive codes overGF(4), which correspond to undirected graphs. Graph representation reduces thecomplexity of code classification, and enables us to classify additive (n,2^n)codes over GF(4) of length up to 7. From this we also derive classifications ofisodual and formally self-dual codes. We introduce new constructions ofcirculant and bordered circulant directed graph codes, and show that thesecodes will always be isodual. A computer search of all such codes of length upto 26 reveals that these constructions produce many codes of high minimumdistance. In particular, we find new near-extremal formally self-dual codes oflength 11 and 13, and isodual codes of length 24, 25, and 26 with betterminimum distance than the best known self-dual codes.",Lars Eirik Danielsen,2009/2/23,2009/12/15
2207.06076v1,Journal of Economic Literature codes classification system (JEL),http://arxiv.org/abs/2207.06076v1,"The Journal of Economic Literature codes classification system (JEL)published by the American Economic Association (AEA) is the de facto standardclassification system for research literature in economics. The JELclassification system is used to classify articles, dissertations, books, bookreviews, and working papers in EconLit, a database maintained by the AEA. Overtime, it has evolved and extended to a system with over 850 subclasses. Thispaper reviews the history and development of the JEL classification system,describes the current version, and provides a selective overview of its usesand applications in research. The JEL codes classification system has beenadopted by several publishers, and their instructions are reviewed. There areinteresting avenues for future research as the JEL classification system hasbeen surprisingly little used in existing bibliometric and scientometricresearch as well as in library classification systems.",Jussi T. S. Heikkila,2022/7/13,2022/7/13
1112.1238v1,Cyclic Orbit Codes,http://arxiv.org/abs/1112.1238v1,"In network coding a constant dimension code consists of a set ofk-dimensional subspaces of F_q^n. Orbit codes are constant dimension codeswhich are defined as orbits of a subgroup of the general linear group, actingon the set of all subspaces of F_q^n. If the acting group is cyclic, thecorresponding orbit codes are called cyclic orbit codes. In this paper we givea classification of cyclic orbit codes and propose a decoding procedure for aparticular subclass of cyclic orbit codes.",Anna-Lena Trautmann,2011/12/6,2011/12/6
1507.01728v1,Equidistant subspace codes,http://arxiv.org/abs/1507.01728v1,"In this paper we study equidistant subspace codes, i.e. subspace codes withthe property that each two distinct codewords have the same distance. Weprovide an almost complete classification of such codes under the assumptionthat the cardinality of the ground field is large enough. More precisely, weprove that for most values of the parameters, an equidistant code of maximumcardinality is either a sunflower or the orthogonal of a sunflower. We alsostudy equidistant codes with extremal parameters, and establish generalproperties of equidistant codes that are not sunflowers. Finally, we propose asystematic construction of equidistant codes based on our previous constructionof partial spread codes, and provide an efficient decoding algorithm.",Elisa Gorla,2015/7/7,2015/7/7
1603.05850v1,N-ary Error Correcting Coding Scheme,http://arxiv.org/abs/1603.05850v1,"The coding matrix design plays a fundamental role in the predictionperformance of the error correcting output codes (ECOC)-based multi-class task.{In many-class classification problems, e.g., fine-grained categorization, itis difficult to distinguish subtle between-class differences under existingcoding schemes due to a limited choices of coding values.} In this paper, weinvestigate whether one can relax existing binary and ternary code design to$N$-ary code design to achieve better classification performance. {Inparticular, we present a novel $N$-ary coding scheme that decomposes theoriginal multi-class problem into simpler multi-class subproblems, which issimilar to applying a divide-and-conquer method.} The two main advantages ofsuch a coding scheme are as follows: (i) the ability to construct morediscriminative codes and (ii) the flexibility for the user to select the best$N$ for ECOC-based classification. We show empirically that the optimal $N$(based on classification performance) lies in $[3, 10]$ with some trade-off incomputational cost. Moreover, we provide theoretical insights on the dependencyof the generalization error bound of an $N$-ary ECOC on the average baseclassifier generalization error and the minimum distance between any two codesconstructed. Extensive experimental results on benchmark multi-class datasetsshow that the proposed coding scheme achieves superior prediction performanceover the state-of-the-art coding methods.",Joey Tianyi Zhou,2016/3/18,2016/3/18
2311.06575v1,Sparse Attention-Based Neural Networks for Code Classification,http://arxiv.org/abs/2311.06575v1,"Categorizing source codes accurately and efficiently is a challenging problemin real-world programming education platform management. In recent years,model-based approaches utilizing abstract syntax trees (ASTs) have been widelyapplied to code classification tasks. We introduce an approach named the SparseAttention-based neural network for Code Classification (SACC) in this paper.The approach involves two main steps: In the first step, source code undergoessyntax parsing and preprocessing. The generated abstract syntax tree is splitinto sequences of subtrees and then encoded using a recursive neural network toobtain a high-dimensional representation. This step simultaneously considersboth the logical structure and lexical level information contained within thecode. In the second step, the encoded sequences of subtrees are fed into aTransformer model that incorporates sparse attention mechanisms for the purposeof classification. This method efficiently reduces the computational cost ofthe self-attention mechanisms, thus improving the training speed whilepreserving effectiveness. Our work introduces a carefully designed sparseattention pattern that is specifically designed to meet the unique needs ofcode classification tasks. This design helps reduce the influence of redundantinformation and enhances the overall performance of the model. Finally, we alsodeal with problems in previous related research, which include issues likeincomplete classification labels and a small dataset size. We annotated theCodeNet dataset with algorithm-related labeling categories, which contains asignificantly large amount of data. Extensive comparative experimental resultsdemonstrate the effectiveness and efficiency of SACC for the codeclassification tasks.",Ziyang Xiang,2023/11/11,2023/11/11
1107.2059v1,One dimensional Convolutional Goppa Codes over the projective line,http://arxiv.org/abs/1107.2059v1,We give a general method to construct MDS one-dimensional convolutionalcodes. Our method generalizes previous constructions of H. Gluesing-Luerssenand B. Langfeld. Moreover we give a classification of one-dimensionalConvolutional Goppa Codes and propose a characterization of MDS codes of thistype.,J. A. Domnguez Prez,2011/7/11,2011/7/11
2306.14397v2,Discriminating Human-authored from ChatGPT-Generated Code Via Discernable Feature Analysis,http://arxiv.org/abs/2306.14397v2,"The ubiquitous adoption of Large Language Generation Models (LLMs) inprogramming has underscored the importance of differentiating betweenhuman-written code and code generated by intelligent models. This paperspecifically aims to distinguish code generated by ChatGPT from that authoredby humans. Our investigation reveals disparities in programming style,technical level, and readability between these two sources. Consequently, wedevelop a discriminative feature set for differentiation and evaluate itsefficacy through ablation experiments. Additionally, we devise a datasetcleansing technique, which employs temporal and spatial segmentation, tomitigate the dearth of datasets and to secure high-caliber, uncontaminateddatasets. To further enrich data resources, we employ ""code transformation,""""feature transformation,"" and ""feature customization"" techniques, generating anextensive dataset comprising 10,000 lines of ChatGPT-generated code. Thesalient contributions of our research include: proposing a discriminativefeature set yielding high accuracy in differentiating ChatGPT-generated codefrom human-authored code in binary classification tasks; devising methods forgenerating extensive ChatGPT-generated codes; and introducing a datasetcleansing strategy that extracts immaculate, high-grade code datasets fromopen-source repositories, thus achieving exceptional accuracy in codeauthorship attribution tasks.",Li Ke,2023/6/26,2023/7/4
2112.02569v3,"Optimal quaternary $(r,)$-Locally Recoverable Codes: Their Structures and Complete Classification",http://arxiv.org/abs/2112.02569v3,"Aiming to recover the data from several concurrent node failures, linear$r$-LRC codes with locality $r$ were extended into $(r, \delta)$-LRC codes withlocality $(r, \delta)$ which can enable the local recovery of a failed node incase of more than one node failure. Optimal LRC codes are those whoseparameters achieve the generalized Singleton bound with equality. In thepresent paper, we are interested in studying optimal LRC codes over smallfields and, more precisely, over $\mathbb{F}_4$. We shall adopt an approach byinvestigating optimal quaternary $(r,\delta)$-LRC codes through theirparity-check matrices.  Our study includes determining the structural properties of optimal$(r,\delta)$-LRC codes, their constructions, and their complete classificationover $\F_4$ by browsing all possible parameters. We emphasize that the precisestructure of optimal quaternary $(r,\delta)$-LRC codes and their classificationare obtained via the parity-check matrix approach use proofs-techniquesdifferent from those used recently for optimal binary and ternary$(r,\delta)$-LRC codes obtained by Hao et al. in [IEEE Trans. Inf. Theory,2020, 66(12): 7465-7474].",Li Xu,2021/12/5,2022/2/21
2001.01047v1,Adapting Deep Learning for Sentiment Classification of Code-Switched Informal Short Text,http://arxiv.org/abs/2001.01047v1,"Nowadays, an abundance of short text is being generated that uses nonstandardwriting styles influenced by regional languages. Such informal andcode-switched content are under-resourced in terms of labeled datasets andlanguage models even for popular tasks like sentiment classification. In thiswork, we (1) present a labeled dataset called MultiSenti for sentimentclassification of code-switched informal short text, (2) explore thefeasibility of adapting resources from a resource-rich language for an informalone, and (3) propose a deep learning-based model for sentiment classificationof code-switched informal short text. We aim to achieve this without anylexical normalization, language translation, or code-switching indication. Theperformance of the proposed models is compared with three existing multilingualsentiment classification models. The results show that the proposed modelperforms better in general and adapting character-based embeddings yieldequivalent performance while being computationally more efficient than trainingword-based domain-specific embeddings.",Muhammad Haroon Shakeel,2020/1/4,2020/1/4
2211.13813v2,Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt,http://arxiv.org/abs/2211.13813v2,"Automatic International Classification of Diseases (ICD) coding aims toassign multiple ICD codes to a medical note with an average of 3,000+ tokens.This task is challenging due to the high-dimensional space of multi-labelassignment (155,000+ ICD code candidates) and the long-tail challenge - ManyICD codes are infrequently assigned yet infrequent ICD codes are importantclinically. This study addresses the long-tail challenge by transforming thismulti-label classification task into an autoregressive generation task.Specifically, we first introduce a novel pretraining objective to generate freetext diagnoses and procedure using the SOAP structure, the medical logicphysicians use for note documentation. Second, instead of directly predictingthe high dimensional space of ICD codes, our model generates the lowerdimension of text descriptions, which then infer ICD codes. Third, we designeda novel prompt template for multi-label classification. We evaluate ourGeneration with Prompt model with the benchmark of all code assignment(MIMIC-III-full) and few shot ICD code assignment evaluation benchmark(MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs witha marco F1 30.2, which substantially outperforms the previous MIMIC-III-fullSOTA model (marco F1 4.3) and the model specifically designed for few/zero shotsetting (marco F1 18.7). Finally, we design a novel ensemble learner, a crossattention reranker with prompts, to integrate previous SOTA and our bestfew-shot coding predictions. Experiments on MIMIC-III-full show that ourensemble learner substantially improves both macro and micro F1, from 10.4 to14.6 and from 58.2 to 59.1, respectively.",Zhichao Yang,2022/11/24,2022/11/29
1707.00847v1,A Complete Classification of Partial-MDS (Maximally Recoverable) Codes with One Global Parity,http://arxiv.org/abs/1707.00847v1,"Partial-MDS (PMDS) codes are a family of locally repairable codes, mainlyused for distributed storage. They are defined to be able to correct anypattern of $s$ additional erasures, after a given number of erasures perlocality group have occurred. This makes them also maximally recoverable (MR)codes, another class of locally repairable codes. It is known that MR codes ingeneral, and PMDS codes in particular, exist for any set of parameters, if thefield size is large enough. Moreover, some explicit constructions of PMDS codesare known, mostly (but not always) with a strong restriction on the number oferasures that can be corrected per locality group. In this paper we generalizethe notion of PMDS codes to allow locality groups of different sizes. We give ageneral construction of such PMDS codes with $s=1$ global parity, i.e., oneadditional erasure can be corrected. Furthermore, we show that all PMDS codesfor the given parameters are of this form, i.e., we give a classification ofthese codes. This implies a necessary and sufficient condition on theunderlying field size for the existence of these codes (assuming that the MDSconjecture is true). For some parameter sets our generalized construction givesrise to PMDS codes with a smaller field size than any other known construction.",Anna-Lena Horlemann-Trautmann,2017/7/4,2017/7/4
1907.10863v1,A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques,http://arxiv.org/abs/1907.10863v1,"As an integral part of source code files, code comments help improve programreadability and comprehension. However, developers sometimes do not comment ontheir program code adequately due to the incurred extra efforts, lack ofrelevant knowledge, unawareness of the importance of code commenting or someother factors. As a result, code comments can be inadequate, absent or evenmismatched with source code, which affects the understanding, reusing and themaintenance of software. To solve these problems of code comments, researchershave been concerned with generating code comments automatically. In this work,we aim at conducting a survey of automatic code commenting researches. First,we generally analyze the challenges and research framework of automaticgeneration of program comments. Second, we present the classification ofrepresentative algorithms, the design principles, strengths and weaknesses ofeach category of algorithms. Meanwhile, we also provide an overview of thequality assessment of the generated comments. Finally, we summarize some futuredirections for advancing the techniques of automatic generation of codecomments and the quality assessment of comments.",Xiaotao Song,2019/7/25,2019/7/25
2003.03238v2,TranS^3: A Transformer-based Framework for Unifying Code Summarization and Code Search,http://arxiv.org/abs/2003.03238v2,"Code summarization and code search have been widely adopted insofwaredevelopmentandmaintenance. However, fewstudieshave explored the efcacyof unifying them. In this paper, we propose TranS^3 , a transformer-basedframework to integrate code summarization with code search. Specifcally, forcode summarization,TranS^3 enables an actor-critic network, where in the actornetwork, we encode the collected code snippets via transformer- andtree-transformer-based encoder and decode the given code snippet to generateits comment. Meanwhile, we iteratively tune the actor network via the feedbackfrom the critic network for enhancing the quality of the generated comments.Furthermore, we import the generated comments to code search for enhancing itsaccuracy. To evaluatetheefectivenessof TranS^3 , we conduct a set ofexperimental studies and case studies where the experimental results suggestthat TranS^3 can signifcantly outperform multiple state-of-the-art approachesin both code summarization and code search and the study results furtherstrengthen the efcacy of TranS^3 from the developers' points of view.",Wenhua Wang,2020/3/6,2020/3/9
2209.08978v1,MMF3: Neural Code Summarization Based on Multi-Modal Fine-Grained Feature Fusion,http://arxiv.org/abs/2209.08978v1,"Background: Code summarization automatically generates the correspondingnatural language descriptions according to the input code. Comprehensiveness ofcode representation is critical to code summarization task. However, mostexisting approaches typically use coarse-grained fusion methods to integratemulti-modal features. They generally represent different modalities of a pieceof code, such as an Abstract Syntax Tree (AST) and a token sequence, as twoembeddings and then fuse the two ones at the AST/code levels. Such a coarseintegration makes it difficult to learn the correlations between fine-grainedcode elements across modalities effectively. Aims: This study intends toimprove the model's prediction performance for high-quality code summarizationby accurately aligning and fully fusing semantic and syntactic structureinformation of source code at node/token levels. Method: This paper proposes aMulti-Modal Fine-grained Feature Fusion approach (MMF3) for neural codesummarization. We introduce a novel fine-grained fusion method, which allowsfine-grained fusion of multiple code modalities at the token and node levels.Specifically, we use this method to fuse information from both token and ASTmodalities and apply the fused features to code summarization. Results: Weconduct experiments on one Java and one Python datasets, and evaluate generatedsummaries using four metrics. The results show that: 1) the performance of ourmodel outperforms the current state-of-the-art models, and 2) the ablationexperiments show that our proposed fine-grained fusion method can effectivelyimprove the accuracy of generated summaries. Conclusion: MMF3 can mine therelationships between crossmodal elements and perform accurate fine-grainedelement-level alignment fusion accordingly. As a result, more clues can beprovided to improve the accuracy of the generated code summaries.",Zheng Ma,2022/9/19,2022/9/19
2012.04281v1,CTRLsum: Towards Generic Controllable Text Summarization,http://arxiv.org/abs/2012.04281v1,"Current summarization systems yield generic summaries that are disconnectedfrom users' preferences and expectations. To address this limitation, wepresent CTRLsum, a novel framework for controllable summarization. Our approachenables users to control multiple aspects of generated summaries by interactingwith the summarization system through textual input in the form of a set ofkeywords or descriptive prompts. Using a single unified model, CTRLsum is ableto achieve a broad scope of summary manipulation at inference time withoutrequiring additional human annotations or pre-defining a set of control aspectsduring training. We quantitatively demonstrate the effectiveness of ourapproach on three domains of summarization datasets and five control aspects:1) entity-centric and 2) length-controllable summarization, 3) contributionsummarization on scientific papers, 4) invention purpose summarization onpatent filings, and 5) question-guided summarization on news articles in areading comprehension setting. Moreover, when used in a standard, uncontrolledsummarization setting, CTRLsum achieves state-of-the-art results on theCNN/DailyMail dataset. Code and model checkpoints are available athttps://github.com/salesforce/ctrl-sum",Junxian He,2020/12/8,2020/12/8
2002.10198v2,Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning,http://arxiv.org/abs/2002.10198v2,"Code summarization generates brief natural language description given asource code snippet, while code retrieval fetches relevant source code given anatural language query. Since both tasks aim to model the association betweennatural language and programming language, recent studies have combined thesetwo tasks to improve their performance. However, researchers have yet been ableto effectively leverage the intrinsic connection between the two tasks as theytrain these tasks in a separate or pipeline manner, which means theirperformance can not be well balanced. In this paper, we propose a novelend-to-end model for the two tasks by introducing an additional code generationtask. More specifically, we explicitly exploit the probabilistic correlationbetween code summarization and code generation with dual learning, and utilizethe two encoders for code summarization and code generation to train the coderetrieval task via multi-task learning. We have carried out extensiveexperiments on an existing dataset of SQL and Python, and results show that ourmodel can significantly improve the results of the code retrieval task overthe-state-of-art models, as well as achieve competitive performance in terms ofBLEU score for the code summarization task.",Wei Ye,2020/2/24,2020/2/25
2207.05579v2,Are We Building on the Rock? On the Importance of Data Preprocessing for Code Summarization,http://arxiv.org/abs/2207.05579v2,"Code summarization, the task of generating useful comments given the code,has long been of interest. Most of the existing code summarization models aretrained and validated on widely-used code comment benchmark datasets. However,little is known about the quality of the benchmark datasets built fromreal-world projects. Are the benchmark datasets as good as expected? To bridgethe gap, we conduct a systematic research to assess and improve the quality offour benchmark datasets widely used for code summarization tasks. First, wepropose an automated code-comment cleaning tool that can accurately detectnoisy data caused by inappropriate data preprocessing operations from existingbenchmark datasets. Then, we apply the tool to further assess the data qualityof the four benchmark datasets, based on the detected noises. Finally, weconduct comparative experiments to investigate the impact of noisy data on theperformance of code summarization models. The results show that these datapreprocessing noises widely exist in all four benchmark datasets, and removingthese noisy data leads to a significant improvement on the performance of codesummarization. We believe that the findings and insights will enable a betterunderstanding of data quality in code summarization tasks, and pave the way forrelevant research and practice.",Lin Shi,2022/7/12,2022/10/16
2107.01933v1,CoCoSum: Contextual Code Summarization with Multi-Relational Graph Neural Network,http://arxiv.org/abs/2107.01933v1,"Source code summaries are short natural language descriptions of codesnippets that help developers better understand and maintain source code. Therehas been a surge of work on automatic code summarization to reduce the burdenof writing summaries manually. However, most contemporary approaches mainlyleverage the information within the boundary of the method being summarized(i.e., local context), and ignore the broader context that could assist withcode summarization. This paper explores two global contexts, namely intra-classand inter-class contexts, and proposes the model CoCoSUM: Contextual CodeSummarization with Multi-Relational Graph Neural Networks. CoCoSUM firstincorporates class names as the intra-class context to generate the classsemantic embeddings. Then, relevant Unified Modeling Language (UML) classdiagrams are extracted as inter-class context and are encoded into the classrelational embeddings using a novel Multi-Relational Graph Neural Network(MRGNN). Class semantic embeddings and class relational embeddings, togetherwith the outputs from code token encoder and AST encoder, are passed to adecoder armed with a two-level attention mechanism to generate high-quality,context-aware code summaries. We conduct extensive experiments to evaluate ourapproach and compare it with other automatic code summarization models. Theexperimental results show that CoCoSUM is effective and outperformsstate-of-the-art methods. Our source code and experimental data are availablein the supplementary materials and will be made publicly available.",Yanlin Wang,2021/7/5,2021/7/5
2203.09707v2,M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source Code Summarization,http://arxiv.org/abs/2203.09707v2,"Source code summarization aims to generate natural language descriptions ofcode snippets. Many existing studies learn the syntactic and semantic knowledgeof code snippets from their token sequences and Abstract Syntax Trees (ASTs).They use the learned code representations as input to code summarizationmodels, which can accordingly generate summaries describing source code.Traditional models traverse ASTs as sequences or split ASTs into paths asinput. However, the former loses the structural properties of ASTs, and thelatter destroys the overall structure of ASTs. Therefore, comprehensivelycapturing the structural features of ASTs in learning code representations forsource code summarization remains a challenging problem to be solved. In thispaper, we propose M2TS, a Multi-scale Multi-modal approach based on Transformerfor source code Summarization. M2TS uses a multi-scale AST feature extractionmethod, which can extract the structures of ASTs more completely and accuratelyat multiple local and global levels. To complement missing semantic informationin ASTs, we also obtain code token features, and further combine them with theextracted AST features using a cross modality fusion method that not only fusesthe syntactic and contextual semantic information of source code, but alsohighlights the key features of each modality. We conduct experiments on twoJava and one Python datasets, and the experimental results demonstrate thatM2TS outperforms current state-of-the-art methods. We release our code athttps://github.com/TranSMS/M2TS.",Yuexiu Gao,2022/3/18,2022/3/27
1909.04352v2,Automatic Code Summarization: A Systematic Literature Review,http://arxiv.org/abs/1909.04352v2,"Background: During software maintenance and development, the comprehension ofprogram code is key to success. High-quality comments can help us betterunderstand programs, but they're often missing or outmoded in today's programs.Automatic code summarization is proposed to solve these problems. During thelast decade, huge progress has been made in this field, but there is a lack ofan up-to-date survey. Aims: We studied publications concerning codesummarization in the field of program comprehension to investigatestate-of-the-art approaches. By reading and analyzing relevant articles, we aimat obtaining a comprehensive understanding of the current status of automaticcode summarization. Method: In this paper, we performed a systematic literaturereview over the automatic source code summarization field. Furthermore, wesynthesized the obtained data and investigated different approaches. Results:We successfully collected and analyzed 41 selected studies from the differentresearch communities. We exhaustively investigated and described the dataextraction techniques, description generation methods, evaluation methods andrelevant artifacts of those works. Conclusions: Our systematic review providesan overview of the state of the art, and we also discuss further researchdirections. By fully elaborating current approaches in the field, our worksheds light on future research directions of program comprehension and commentgeneration.",Yuxiang Zhu,2019/9/10,2019/10/13
2305.05280v2,VCSUM: A Versatile Chinese Meeting Summarization Dataset,http://arxiv.org/abs/2305.05280v2,"Compared to news and chat summarization, the development of meetingsummarization is hugely decelerated by the limited data. To this end, weintroduce a versatile Chinese meeting summarization dataset, dubbed VCSum,consisting of 239 real-life meetings, with a total duration of over 230 hours.We claim our dataset is versatile because we provide the annotations of topicsegmentation, headlines, segmentation summaries, overall meeting summaries, andsalient sentences for each meeting transcript. As such, the dataset can adaptto various summarization tasks or methods, including segmentation-basedsummarization, multi-granularity summarization and retrieval-then-generatesummarization. Our analysis confirms the effectiveness and robustness of VCSum.We also provide a set of benchmark models regarding different downstreamsummarization tasks on VCSum to facilitate further research. The dataset andcode will be released at https://github.com/hahahawu/VCSum.",Han Wu,2023/5/9,2023/5/15
2309.02326v1,Revisiting File Context for Source Code Summarization,http://arxiv.org/abs/2309.02326v1,"Source code summarization is the task of writing natural languagedescriptions of source code. A typical use case is generating short summariesof subroutines for use in API documentation. The heart of almost all currentresearch into code summarization is the encoder-decoder neural architecture,and the encoder input is almost always a single subroutine or other short codesnippet. The problem with this setup is that the information needed to describethe code is often not present in the code itself -- that information oftenresides in other nearby code. In this paper, we revisit the idea of ``filecontext'' for code summarization. File context is the idea of encoding selectinformation from other subroutines in the same file. We propose a novelmodification of the Transformer architecture that is purpose-built to encodefile context and demonstrate its improvement over several baselines. We findthat file context helps on a subset of challenging examples where traditionalapproaches struggle.",Aakash Bansal,2023/9/5,2023/9/5
2103.11448v2,Exploiting Method Names to Improve Code Summarization: A Deliberation Multi-Task Learning Approach,http://arxiv.org/abs/2103.11448v2,"Code summaries are brief natural language descriptions of source code pieces.The main purpose of code summarization is to assist developers in understandingcode and to reduce documentation workload. In this paper, we design a novelmulti-task learning (MTL) approach for code summarization through mining therelationship between method code summaries and method names. More specifically,since a method's name can be considered as a shorter version of its codesummary, we first introduce the tasks of generation and informativenessprediction of method names as two auxiliary training objectives for codesummarization. A novel two-pass deliberation mechanism is then incorporatedinto our MTL architecture to generate more consistent intermediate states fedinto a summary decoder, especially when informative method names do not exist.To evaluate our deliberation MTL approach, we carried out a large-scaleexperiment on two existing datasets for Java and Python. The experiment resultsshow that our technique can be easily applied to many state-of-the-art neuralmodels for code summarization and improve their performance. Meanwhile, ourapproach shows significant superiority when generating summaries for methodswith non-informative names.",Rui Xie,2021/3/21,2021/3/30
2305.09773v1,Towards Modeling Human Attention from Eye Movements for Neural Source Code Summarization,http://arxiv.org/abs/2305.09773v1,"Neural source code summarization is the task of generating natural languagedescriptions of source code behavior using neural networks. A fundamentalcomponent of most neural models is an attention mechanism. The attentionmechanism learns to connect features in source code to specific words to usewhen generating natural language descriptions. Humans also pay attention tosome features in code more than others. This human attention reflectsexperience and high-level cognition well beyond the capability of any currentneural model. In this paper, we use data from published eye-trackingexperiments to create a model of this human attention. The model predicts whichwords in source code are the most important for code summarization. Next, weaugment a baseline neural code summarization approach using our model of humanattention. We observe an improvement in prediction performance of the augmentedapproach in line with other bio-inspired neural models.",Aakash Bansal,2023/5/16,2023/5/16
2209.10492v2,Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees,http://arxiv.org/abs/2209.10492v2,"Current abstractive summarization models either suffer from a lack of clearinterpretability or provide incomplete rationales by only highlighting parts ofthe source document. To this end, we propose the Summarization Program (SP), aninterpretable modular framework consisting of an (ordered) list of binarytrees, each encoding the step-by-step generative process of an abstractivesummary sentence from the source document. A Summarization Program contains oneroot node per summary sentence, and a distinct tree connects each summarysentence (root node) to the document sentences (leaf nodes) from which it isderived, with the connecting nodes containing intermediate generated sentences.Edges represent different modular operations involved in summarization such assentence fusion, compression, and paraphrasing. We first propose an efficientbest-first search method over neural modules, SP-Search that identifies SPs forhuman summaries by directly optimizing for ROUGE scores. Next, using theseprograms as automatic supervision, we propose seq2seq models that generateSummarization Programs, which are then executed to obtain final summaries. Wedemonstrate that SP-Search effectively represents the generative process behindhuman summaries using modules that are typically faithful to their intendedbehavior. We also conduct a simulation study to show that SummarizationPrograms improve the interpretability of summarization models by allowinghumans to better simulate model reasoning. Summarization Programs constitute apromising step toward interpretable and modular abstractive summarization, acomplex task previously addressed primarily through blackbox end-to-end neuralsystems. Supporting code available athttps://github.com/swarnaHub/SummarizationPrograms",Swarnadeep Saha,2022/9/21,2023/2/2
2010.05139v2,CDEvalSumm: An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems,http://arxiv.org/abs/2010.05139v2,"Neural network-based models augmented with unsupervised pre-trained knowledgehave achieved impressive performance on text summarization. However, mostexisting evaluation methods are limited to an in-domain setting, wheresummarizers are trained and evaluated on the same dataset. We argue that thisapproach can narrow our understanding of the generalization ability fordifferent summarization systems. In this paper, we perform an in-depth analysisof characteristics of different datasets and investigate the performance ofdifferent summarization models under a cross-dataset setting, in which asummarizer trained on one corpus will be evaluated on a range of out-of-domaincorpora. A comprehensive study of 11 representative summarization systems on 5datasets from different domains reveals the effect of model architectures andgeneration ways (i.e. abstractive and extractive) on model generalizationability. Further, experimental results shed light on the limitations ofexisting summarizers. Brief introduction and supplementary code can be found inhttps://github.com/zide05/CDEvalSumm.",Yiran Chen,2020/10/11,2020/10/22
2009.02731v8,Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations,http://arxiv.org/abs/2009.02731v8,"We propose Corder, a self-supervised contrastive learning framework forsource code model. Corder is designed to alleviate the need of labeled data forcode retrieval and code summarization tasks. The pre-trained model of Cordercan be used in two ways: (1) it can produce vector representation of code whichcan be applied to code retrieval tasks that do not have labeled data; (2) itcan be used in a fine-tuning process for tasks that might still require labeldata such as code summarization. The key innovation is that we train the sourcecode model by asking it to recognize similar and dissimilar code snippetsthrough a contrastive learning objective. To do so, we use a set ofsemantic-preserving transformation operators to generate code snippets that aresyntactically diverse but semantically equivalent. Through extensiveexperiments, we have shown that the code models pretrained by Cordersubstantially outperform the other baselines for code-to-code retrieval,text-to-code retrieval, and code-to-text summarization tasks.",Nghi D. Q. Bui,2020/9/6,2021/5/23
2308.03109v3,Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code,http://arxiv.org/abs/2308.03109v3,"Code translation aims to convert source code from one programming language(PL) to another. Given the promising abilities of large language models (LLMs)in code synthesis, researchers are exploring their potential to automate codetranslation. The prerequisite for advancing the state of LLM-based codetranslation is to understand their promises and limitations over existingtechniques. To that end, we present a large-scale empirical study toinvestigate the ability of general LLMs and code LLMs for code translationacross pairs of different languages, including C, C++, Go, Java, and Python.Our study, which involves the translation of 1,700 code samples from threebenchmarks and two real-world projects, reveals that LLMs are yet to bereliably used to automate code translation -- with correct translations rangingfrom 2.1% to 47.3% for the studied LLMs. Further manual investigation ofunsuccessful translations identifies 15 categories of translation bugs. We alsocompare LLM-based code translation with traditional non-LLM-based approaches.Our analysis shows that these two classes of techniques have their ownstrengths and weaknesses. Finally, insights from our study suggest thatproviding more context to LLMs during translation can help them produce betterresults. To that end, we propose a prompt-crafting approach based on thesymptoms of erroneous translations; this improves the performance of LLM-basedcode translation by 5.5% on average. Our study is the first of its kind, interms of scale and breadth, that provides insights into the current limitationsof LLMs in code translation and opportunities for improving them. Our dataset-- consisting of 1,700 code samples in five PLs with 10K+ tests, 43K+translated code, 1,748 manually labeled bugs, and 1,365 bug-fix pairs -- canhelp drive research in this area.",Rangeet Pan,2023/8/6,2024/1/16
2205.11707v1,A Complex Java Code Generator for ACL2 Based on a Shallow Embedding of ACL2 in Java,http://arxiv.org/abs/2205.11707v1,"This paper describes a code generator that translates ACL2 constructs tocorresponding Java constructs, according to a shallow embedding of ACL2 inJava. Starting from purely functional ACL2 code, the generated Java codeexhibits imperative and object-oriented features like destructive updates,loops, and overloading. The overall translation from ACL2 to Java is fairlyelaborate, consisting of several ACL2-to-ACL2 pre-translation steps, anACL2-to-Java proper translation step, and several Java-to-Java post-translationsteps. Experiments suggest that the generated Java code is not much slower thanthe ACL2 code. The code generator can also recognize, and translate to Java,ACL2 representations of certain Java constructs, forerunning a code generationapproach based on a shallow embedding of Java in ACL2 (i.e. going the otherway). This code generator builds upon, and significantly extends, a simple Javacode generator for ACL2 based on a deep embedding of ACL2 in Java.",Alessandro Coglio,2022/5/24,2022/5/24
2012.07581v2,Quality Estimation & Interpretability for Code Translation,http://arxiv.org/abs/2012.07581v2,"Recently, the automated translation of source code from one programminglanguage to another by using automatic approaches inspired by Neural MachineTranslation (NMT) methods for natural languages has come under study. However,such approaches suffer from the same problem as previous NMT approaches onnatural languages, viz. the lack of an ability to estimate and evaluate thequality of the translations; and consequently ascribe some measure ofinterpretability to the model's choices. In this paper, we attempt to estimatethe quality of source code translations built on top of the TransCoder model.We consider the code translation task as an analog of machine translation (MT)for natural languages, with some added caveats. We present our main motivationfrom a user study built around code translation; and present a technique thatcorrelates the confidences generated by that model to lint errors in thetranslated code. We conclude with some observations on these correlations, andsome ideas for future work.",Mayank Agarwal,2020/12/4,2021/4/26
2311.00317v1,Data Augmentation for Code Translation with Comparable Corpora and Multiple References,http://arxiv.org/abs/2311.00317v1,"One major challenge of translating code between programming languages is thatparallel training data is often limited. To overcome this challenge, we presenttwo data augmentation techniques, one that builds comparable corpora (i.e.,code pairs with similar functionality), and another that augments existingparallel data with multiple reference translations. Specifically, we build andanalyze multiple types of comparable corpora, including programs generated fromnatural language documentation using a code generation model. Furthermore, toreduce overfitting to a single reference translation, we automatically generateadditional translation references for available parallel data and filter thetranslations by unit tests, which increases variation in target translations.Experiments show that our data augmentation techniques significantly improveCodeT5 for translation between Java, Python, and C++ by an average of 7.5%Computational Accuracy (CA@1), which verifies the correctness of translationsby execution. The code is available at https://github.com/Veronicium/CMTrans.",Yiqing Xie,2023/11/1,2023/11/1
2312.00912v1,Quick Back-Translation for Unsupervised Machine Translation,http://arxiv.org/abs/2312.00912v1,"The field of unsupervised machine translation has seen significantadvancement from the marriage of the Transformer and the back-translationalgorithm. The Transformer is a powerful generative model, and back-translationleverages Transformer's high-quality translations for iterativeself-improvement. However, the Transformer is encumbered by the run-time ofautoregressive inference during back-translation, and back-translation islimited by a lack of synthetic data efficiency. We propose a two-for-oneimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBTre-purposes the encoder as a generative model, and uses encoder-generatedsequences to train the decoder in conjunction with the original autoregressiveback-translation step, improving data throughput and utilization. Experimentson various WMT benchmarks demonstrate that a relatively small number ofrefining steps of QBT improve current unsupervised machine translation models,and that QBT dramatically outperforms standard back-translation only method interms of training efficiency for comparable translation qualities.",Benjamin Brimacombe,2023/12/1,2023/12/1
2207.03578v5,Code Translation with Compiler Representations,http://arxiv.org/abs/2207.03578v5,"In this paper, we leverage low-level compiler intermediate representations(IR) to improve code translation. Traditional transpilers rely on syntacticinformation and handcrafted rules, which limits their applicability andproduces unnatural-looking code. Applying neural machine translation (NMT)approaches to code has successfully broadened the set of programs on which onecan get a natural-looking translation. However, they treat the code assequences of text tokens, and still do not differentiate well enough betweensimilar pieces of code which have different semantics in different languages.The consequence is low quality translation, reducing the practicality of NMT,and stressing the need for an approach significantly increasing its accuracy.Here we propose to augment code translation with IRs, specifically LLVM IR,with results on the C++, Java, Rust, and Go languages. Our method improves uponthe state of the art for unsupervised code translation, increasing the numberof correct translations by 11% on average, and up to 79% for the Java -> Rustpair with greedy decoding. We extend previous test sets for code translation,by adding hundreds of Go and Rust functions. Additionally, we train models withhigh performance on the problem of IR decompilation, generating programmingsource code from IR, and study using IRs as intermediary pivot for translation.",Marc Szafraniec,2022/6/30,2023/4/24
2105.04846v1,Can You Traducir This? Machine Translation for Code-Switched Input,http://arxiv.org/abs/2105.04846v1,"Code-Switching (CSW) is a common phenomenon that occurs in multilingualgeographic or social contexts, which raises challenging problems for naturallanguage processing tools. We focus here on Machine Translation (MT) of CSWtexts, where we aim to simultaneously disentangle and translate the two mixedlanguages. Due to the lack of actual translated CSW data, we generateartificial training data from regular parallel texts. Experiments show thistraining strategy yields MT systems that surpass multilingual systems forcode-switched texts. These results are confirmed in an alternative task aimedat providing contextual translations for a L2 writing assistant.",Jitao Xu,2021/5/11,2021/5/11
2309.12813v1,Automatically Testing Functional Properties of Code Translation Models,http://arxiv.org/abs/2309.12813v1,"Large language models are becoming increasingly practical for translatingcode across programming languages, a process known as $transpiling$. Eventhough automated transpilation significantly boosts developer productivity, akey concern is whether the generated code is correct. Existing work initiallyused manually crafted test suites to test the translations of a small corpus ofprograms; these test suites were later automated. In contrast, we devise thefirst approach for automated, functional, property-based testing of codetranslation models. Our general, user-provided specifications about thetranspiled code capture a range of properties, from purely syntactic to purelysemantic ones. As shown by our experiments, this approach is very effective indetecting property violations in popular code translation models, andtherefore, in evaluating model quality with respect to given properties. Wealso go a step further and explore the usage scenario where a user simply aimsto obtain a correct translation of some code with respect to certain propertieswithout necessarily being concerned about the overall quality of the model. Tothis purpose, we develop the first property-guided search procedure for codetranslation models, where a model is repeatedly queried with slightly differentparameters to produce alternative and potentially more correct translations.Our results show that this search procedure helps to obtain significantlybetter code translations.",Hasan Ferit Eniser,2023/9/7,2023/9/7
1808.04525v1,Discrete Structural Planning for Neural Machine Translation,http://arxiv.org/abs/1808.04525v1,"Structural planning is important for producing long sentences, which is amissing part in current language generation models. In this work, we add aplanning phase in neural machine translation to control the coarse structure ofoutput sentences. The model first generates some planner codes, then predictsreal output words conditioned on them. The codes are learned to capture thecoarse structure of the target sentence. In order to obtain the codes, wedesign an end-to-end neural network with a discretization bottleneck, whichpredicts the simplified part-of-speech tags of target sentences. Experimentsshow that the translation performance are generally improved by planning ahead.We also find that translations with different structures can be obtained bymanipulating the planner codes.",Raphael Shu,2018/8/14,2018/8/14
2309.05044v1,The Effect of Alignment Objectives on Code-Switching Translation,http://arxiv.org/abs/2309.05044v1,"One of the things that need to change when it comes to machine translation isthe models' ability to translate code-switching content, especially with therise of social media and user-generated content. In this paper, we areproposing a way of training a single machine translation model that is able totranslate monolingual sentences from one language to another, along withtranslating code-switched sentences to either language. This model can beconsidered a bilingual model in the human sense. For better use of paralleldata, we generated synthetic code-switched (CSW) data along with an alignmentloss on the encoder to align representations across languages. Using the WMT14English-French (En-Fr) dataset, the trained model strongly outperformsbidirectional baselines on code-switched translation while maintaining qualityfor non-code-switched (monolingual) data.",Mohamed Anwar,2023/9/10,2023/9/10
2305.13504v1,Neural Machine Translation for Code Generation,http://arxiv.org/abs/2305.13504v1,"Neural machine translation (NMT) methods developed for natural languageprocessing have been shown to be highly successful in automating translationfrom one natural language to another. Recently, these NMT methods have beenadapted to the generation of program code. In NMT for code generation, the taskis to generate output source code that satisfies constraints expressed in theinput. In the literature, a variety of different input scenarios have beenexplored, including generating code based on natural language description,lower-level representations such as binary or assembly (neural decompilation),partial representations of source code (code completion and repair), and sourcecode in another language (code translation). In this paper we survey the NMTfor code generation literature, cataloging the variety of methods that havebeen explored according to input and output representations, modelarchitectures, optimization techniques used, data sets, and evaluation methods.We discuss the limitations of existing methods and future research directions",Dharma KC,2023/5/22,2023/5/22
1610.00845v1,Isometrically Self-dual Cyclic Codes,http://arxiv.org/abs/1610.00845v1,"General isometries of cyclic codes, including multipliers and translations,are introduced; and isometrically self-dual cyclic codes are defined. In termsof Type-I duadic splittings given by multipliers and translations, a necessaryand sufficient condition for the existence of isometrically self-dual cycliccodes is obtained. A program to construct isometrically self-dual cyclic codesis provided, and illustrated by several examples. In particular, a class ofisometrically self-dual MDS cyclic codes, which are alternant codes from aclass of generalized Reed-Solomon codes, is presented.",Yun Fan,2016/10/4,2016/10/4
1810.04991v2,SingleGAN: Image-to-Image Translation by a Single-Generator Network using Multiple Generative Adversarial Learning,http://arxiv.org/abs/1810.04991v2,"Image translation is a burgeoning field in computer vision where the goal isto learn the mapping between an input image and an output image. However, mostrecent methods require multiple generators for modeling different domainmappings, which are inefficient and ineffective on some multi-domain imagetranslation tasks. In this paper, we propose a novel method, SingleGAN, toperform multi-domain image-to-image translations with a single generator. Weintroduce the domain code to explicitly control the different generative tasksand integrate multiple optimization goals to ensure the translation.Experimental results on several unpaired datasets show superior performance ofour model in translation between two domains. Besides, we explore variants ofSingleGAN for different tasks, including one-to-many domain translation,many-to-many domain translation and one-to-one domain translation withmultimodality. The extended experiments show the universality and extensibilityof our model.",Xiaoming Yu,2018/10/11,2020/4/17
2002.04578v1,A sufficient condition for penalized polynomial regression to be invariant to translations of the predictor variables,http://arxiv.org/abs/2002.04578v1,"Whereas translating the coding of predictor variables does not change the fitof a polynomial least squares regression, penalized polynomial regressions arepotentially affected. A result on which terms can be penalized to maintain theinvariance to translations of the coding has earlier been published. Ageneralization of a corresponding proposition, which requires a more precisemathematical framework, is presented in this short note.",J W R Martini,2020/2/11,2020/2/11
2309.08207v1,MetaOCaml Theory and Implementation,http://arxiv.org/abs/2309.08207v1,"Quasi-quotation (or, code templates) has long been used as a convenient toolfor code generation, commonly implemented as a pre-processing/translation intocode-generation combinators. The original MetaOCaml was also based on suchtranslation, done post type checking. BER MetaOCaml employs a significantlydifferent, efficient (especially in version N114) translation integrated withtype-checking, in the least intrusive way. This paper presents the integratedefficient translation for the first time.",Oleg Kiselyov,2023/9/15,2023/9/15
2205.11116v2,Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages,http://arxiv.org/abs/2205.11116v2,"Back-translation is widely known for its effectiveness in neural machinetranslation when there is little to no parallel data. In this approach, asource-to-target model is coupled with a target-to-source model trained inparallel. The target-to-source model generates noisy sources, while thesource-to-target model is trained to reconstruct the targets and vice versa.Recent developments of multilingual pre-trained sequence-to-sequence models forprogramming languages have been very effective for a broad spectrum ofdownstream software engineering tasks. Hence, training them to buildprogramming language translation systems via back-translation is compelling.However, these models cannot be further trained via back-translation since theylearn to output sequences in the same language as the inputs duringpre-training. As an alternative, we propose performing back-translation viacode summarization and generation. In code summarization, a model learns togenerate natural language (NL) summaries given code snippets. In codegeneration, the model learns to do the opposite. Therefore, target-to-sourcegeneration in back-translation can be viewed as a target-to-NL-to-sourcegeneration. We show that our proposed approach performs competitively withstate-of-the-art methods. We have made the code publicly available.",Wasi Uddin Ahmad,2022/5/23,2023/2/11
2101.06400v1,ComQA:Compositional Question Answering via Hierarchical Graph Neural Networks,http://arxiv.org/abs/2101.06400v1,"With the development of deep learning techniques and large scale datasets,the question answering (QA) systems have been quickly improved, providing moreaccurate and satisfying answers. However, current QA systems either focus onthe sentence-level answer, i.e., answer selection, or phrase-level answer,i.e., machine reading comprehension. How to produce compositional answers hasnot been throughout investigated. In compositional question answering, thesystems should assemble several supporting evidence from the document togenerate the final answer, which is more difficult than sentence-level orphrase-level QA. In this paper, we present a large-scale compositional questionanswering dataset containing more than 120k human-labeled questions. The answerin this dataset is composed of discontiguous sentences in the correspondingdocument. To tackle the ComQA problem, we proposed a hierarchical graph neuralnetworks, which represents the document from the low-level word to thehigh-level sentence. We also devise a question selection and node selectiontask for pre-training. Our proposed model achieves a significant improvementover previous machine reading comprehension methods and pre-training methods.Codes and dataset can be found at \url{https://github.com/benywon/ComQA}.",Bingning Wang,2021/1/16,2021/1/16
2210.16495v1,Two is Better than Many? Binary Classification as an Effective Approach to Multi-Choice Question Answering,http://arxiv.org/abs/2210.16495v1,"We propose a simple refactoring of multi-choice question answering (MCQA)tasks as a series of binary classifications. The MCQA task is generallyperformed by scoring each (question, answer) pair normalized over all thepairs, and then selecting the answer from the pair that yield the highestscore. For n answer choices, this is equivalent to an n-class classificationsetup where only one class (true answer) is correct. We instead show thatclassifying (question, true answer) as positive instances and (question, falseanswer) as negative instances is significantly more effective across variousmodels and datasets. We show the efficacy of our proposed approach in differenttasks -- abductive reasoning, commonsense question answering, science questionanswering, and sentence completion. Our DeBERTa binary classification modelreaches the top or close to the top performance on public leaderboards forthese tasks. The source code of the proposed approach is available athttps://github.com/declare-lab/TEAM.",Deepanway Ghosal,2022/10/29,2022/10/29
2311.09050v1,Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts,http://arxiv.org/abs/2311.09050v1,"Zero-shot Visual Question Answering (VQA) is a prominent vision-language taskthat examines both the visual and textual understanding capability of systemsin the absence of training data. Recently, by converting the images intocaptions, information across multi-modalities is bridged and Large LanguageModels (LLMs) can apply their strong zero-shot generalization capability tounseen questions. To design ideal prompts for solving VQA via LLMs, severalstudies have explored different strategies to select or generatequestion-answer pairs as the exemplar prompts, which guide LLMs to answer thecurrent questions effectively. However, they totally ignore the role ofquestion prompts. The original questions in VQA tasks usually encounterellipses and ambiguity which require intermediate reasoning. To this end, wepresent Reasoning Question Prompts for VQA tasks, which can further activatethe potential of LLMs in zero-shot scenarios. Specifically, for each question,we first generate self-contained questions as reasoning question prompts via anunsupervised question edition module considering sentence fluency, semanticintegrity and syntactic invariance. Each reasoning question prompt clearlyindicates the intent of the original question. This results in a set ofcandidate answers. Then, the candidate answers associated with their confidencescores acting as answer heuristics are fed into LLMs and produce the finalanswer. We evaluate reasoning question prompts on three VQA challenges,experimental results demonstrate that they can significantly improve theresults of LLMs on zero-shot setting and outperform existing state-of-the-artzero-shot methods on three out of four data sets. Our source code is publiclyreleased at \url{https://github.com/ECNU-DASE-NLP/RQP}.",Yunshi Lan,2023/11/15,2023/11/15
2308.09363v1,Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models,http://arxiv.org/abs/2308.09363v1,"Video Question Answering (VideoQA) is a challenging task that entails complexmulti-modal reasoning. In contrast to multiple-choice VideoQA which aims topredict the answer given several options, the goal of open-ended VideoQA is toanswer questions without restricting candidate answers. However, the majorityof previous VideoQA models formulate open-ended VideoQA as a classificationtask to classify the video-question pairs into a fixed answer set, i.e.,closed-vocabulary, which contains only frequent answers (e.g., top-1000answers). This leads the model to be biased toward only frequent answers andfail to generalize on out-of-vocabulary answers. We hence propose a newbenchmark, Open-vocabulary Video Question Answering (OVQA), to measure thegeneralizability of VideoQA models by considering rare and unseen answers. Inaddition, in order to improve the model's generalization power, we introduce anovel GNN-based soft verbalizer that enhances the prediction on rare and unseenanswers by aggregating the information from their similar words. Forevaluation, we introduce new baselines by modifying the existing(closed-vocabulary) open-ended VideoQA models and improve their performances byfurther taking into account rare and unseen answers. Our ablation studies andqualitative analyses demonstrate that our GNN-based soft verbalizer furtherimproves the model performance, especially on rare and unseen answers. We hopethat our benchmark OVQA can serve as a guide for evaluating thegeneralizability of VideoQA models and inspire future research. Code isavailable at https://github.com/mlvlab/OVQA.",Dohwan Ko,2023/8/18,2023/8/18
1809.01997v2,Dual Ask-Answer Network for Machine Reading Comprehension,http://arxiv.org/abs/1809.01997v2,"There are three modalities in the reading comprehension setting: question,answer and context. The task of question answering or question generation aimsto infer an answer or a question when given the counterpart based on context.We present a novel two-way neural sequence transduction model that connectsthree modalities, allowing it to learn two tasks simultaneously and mutuallybenefit one another. During training, the model receivesquestion-context-answer triplets as input and captures the cross-modalinteraction via a hierarchical attention process. Unlike previous jointlearning paradigms that leverage the duality of question generation andquestion answering at data level, we solve such dual tasks at the architecturelevel by mirroring the network structure and partially sharing components atdifferent layers. This enables the knowledge to be transferred from one task toanother, helping the model to find a general representation for each modality.The evaluation on four public datasets shows that our dual-learning modeloutperforms the mono-learning counterpart as well as the state-of-the-art jointmodels on both question answering and question generation tasks.",Han Xiao,2018/9/6,2018/9/10
1908.04364v2,AmazonQA: A Review-Based Question Answering Task,http://arxiv.org/abs/1908.04364v2,"Every day, thousands of customers post questions on Amazon product pages.After some time, if they are fortunate, a knowledgeable customer might answertheir question. Observing that many questions can be answered based upon theavailable product reviews, we propose the task of review-based QA. Given acorpus of reviews and a question, the QA system synthesizes an answer. To thisend, we introduce a new dataset and propose a method that combines informationretrieval techniques for selecting relevant reviews (given a question) and""reading comprehension"" models for synthesizing an answer (given a question andreview). Our dataset consists of 923k questions, 3.6M answers and 14M reviewsacross 156k products. Building on the well-known Amazon dataset, we collectadditional annotations, marking each question as either answerable orunanswerable based on the available reviews. A deployed system could firstclassify a question as answerable and then attempt to generate an answer.Notably, unlike many popular QA datasets, here, the questions, passages, andanswers are all extracted from real human interactions. We evaluate numerousmodels for answer generation and propose strong baselines, demonstrating thechallenging nature of this new task.",Mansi Gupta,2019/8/12,2019/8/20
2104.07535v2,Sequence tagging for biomedical extractive question answering,http://arxiv.org/abs/2104.07535v2,"Current studies in extractive question answering (EQA) have modeled thesingle-span extraction setting, where a single answer span is a label topredict for a given question-passage pair. This setting is natural for generaldomain EQA as the majority of the questions in the general domain can beanswered with a single span. Following general domain EQA models, currentbiomedical EQA (BioEQA) models utilize the single-span extraction setting withpost-processing steps. In this article, we investigate the questiondistribution across the general and biomedical domains and discover biomedicalquestions are more likely to require list-type answers (multiple answers) thanfactoid-type answers (single answer). This necessitates the models capable ofproducing multiple answers for a question. Based on this preliminary study, wepropose a sequence tagging approach for BioEQA, which is a multi-spanextraction setting. Our approach directly tackles questions with a variablenumber of phrases as their answer and can learn to decide the number of answersfor a question from training data. Our experimental results on the BioASQ 7band 8b list-type questions outperformed the best-performing existing modelswithout requiring post-processing steps. Source codes and resources are freelyavailable for download at https://github.com/dmis-lab/SeqTagQA",Wonjin Yoon,2021/4/15,2022/7/7
2011.13137v2,Answering Ambiguous Questions through Generative Evidence Fusion and Round-Trip Prediction,http://arxiv.org/abs/2011.13137v2,"In open-domain question answering, questions are highly likely to beambiguous because users may not know the scope of relevant topics whenformulating them. Therefore, a system needs to find possible interpretations ofthe question, and predict one or multiple plausible answers. When multipleplausible answers are found, the system should rewrite the question for eachanswer to resolve the ambiguity. In this paper, we present a model thataggregates and combines evidence from multiple passages to adaptively predict asingle answer or a set of question-answer pairs for ambiguous questions. Inaddition, we propose a novel round-trip prediction approach to iterativelygenerate additional interpretations that our model fails to find in the firstpass, and then verify and filter out the incorrect question-answer pairs toarrive at the final disambiguated output. Our model, named Refuel, achieves anew state-of-the-art performance on the AmbigQA dataset, and shows competitiveperformance on NQ-Open and TriviaQA. The proposed round-trip prediction is amodel-agnostic general approach for answering ambiguous open-domain questions,which improves our Refuel as well as several baseline models. We release sourcecode for our models and experiments athttps://github.com/amzn/refuel-open-domain-qa.",Yifan Gao,2020/11/26,2021/5/30
2005.11665v1,A Question Type Driven and Copy Loss Enhanced Frameworkfor Answer-Agnostic Neural Question Generation,http://arxiv.org/abs/2005.11665v1,"The answer-agnostic question generation is a significant and challengingtask, which aims to automatically generate questions for a given sentence butwithout an answer. In this paper, we propose two new strategies to deal withthis task: question type prediction and copy loss mechanism. The question typemodule is to predict the types of questions that should be asked, which allowsour model to generate multiple types of questions for the same source sentence.The new copy loss enhances the original copy mechanism to make sure that everyimportant word in the source sentence has been copied when generatingquestions. Our integrated model outperforms the state-of-the-art approach inanswer-agnostic question generation, achieving a BLEU-4 score of 13.9 on SQuAD.Human evaluation further validates the high quality of our generated questions.We will make our code public available for further research.",Xiuyu Wu,2020/5/24,2020/5/24
2111.06476v4,Automated question generation and question answering from Turkish texts,http://arxiv.org/abs/2111.06476v4,"While exam-style questions are a fundamental educational tool serving avariety of purposes, manual construction of questions is a complex process thatrequires training, experience and resources. Automatic question generation (QG)techniques can be utilized to satisfy the need for a continuous supply of newquestions by streamlining their generation. However, compared to automaticquestion answering (QA), QG is a more challenging task. In this work, wefine-tune a multilingual T5 (mT5) transformer in a multi-task setting for QA,QG and answer extraction tasks using Turkish QA datasets. To the best of ourknowledge, this is the first academic work that performs automated text-to-textquestion generation from Turkish texts. Experimental evaluations show that theproposed multi-task setting achieves state-of-the-art Turkish questionanswering and question generation performance on TQuADv1, TQuADv2 datasets andXQuAD Turkish split. The source code and the pre-trained models are availableat https://github.com/obss/turkish-question-generation.",Fatih Cagatay Akyon,2021/11/11,2022/4/7
2205.05019v2,Learning to Answer Visual Questions from Web Videos,http://arxiv.org/abs/2205.05019v2,"Recent methods for visual question answering rely on large-scale annotateddatasets. Manual annotation of questions and answers for videos, however, istedious, expensive and prevents scalability. In this work, we propose to avoidmanual annotation and generate a large-scale training dataset for videoquestion answering making use of automatic cross-modal supervision. We leveragea question generation transformer trained on text data and use it to generatequestion-answer pairs from transcribed video narrations. Given narrated videos,we then automatically generate the HowToVQA69M dataset with 69Mvideo-question-answer triplets. To handle the open vocabulary of diverseanswers in this dataset, we propose a training procedure based on a contrastiveloss between a video-question multi-modal transformer and an answertransformer. We introduce the zero-shot VideoQA task and the VideoQA featureprobe evaluation setting and show excellent results, in particular for rareanswers. Furthermore, our method achieves competitive results on MSRVTT-QA,ActivityNet-QA, MSVD-QA and How2QA datasets. We also show that our VideoQAdataset generation approach generalizes to another source of web video and textdata. We use our method to generate the WebVidVQA3M dataset from the WebViddataset, i.e., videos with alt-text annotations, and show its benefits fortraining VideoQA models. Finally, for a detailed evaluation we introduce iVQA,a new VideoQA dataset with reduced language bias and high-quality manualannotations. Code, datasets and trained models are available athttps://antoyang.github.io/just-ask.html",Antoine Yang,2022/5/10,2022/5/11
2310.13512v2,Improving Question Generation with Multi-level Content Planning,http://arxiv.org/abs/2310.13512v2,"This paper addresses the problem of generating questions from a given contextand an answer, specifically focusing on questions that require multi-hopreasoning across an extended context. Previous studies have suggested that keyphrase selection is essential for question generation (QG), yet it is stillchallenging to connect such disjointed phrases into meaningful questions,particularly for long context. To mitigate this issue, we propose MultiFactor,a novel QG framework based on multi-level content planning. Specifically,MultiFactor includes two components: FA-model, which simultaneously selects keyphrases and generates full answers, and Q-model which takes the generated fullanswer as an additional input to generate questions. Here, full answergeneration is introduced to connect the short answer with the selected keyphrases, thus forming an answer-aware summary to facilitate QG. Both FA-modeland Q-model are formalized as simple-yet-effective Phrase-EnhancedTransformers, our joint model for phrase selection and text generation.Experimental results show that our method outperforms strong baselines on twopopular QG datasets. Our code is available athttps://github.com/zeaver/MultiFactor.",Zehua Xia,2023/10/20,2023/10/23
2304.01647v1,SC-ML: Self-supervised Counterfactual Metric Learning for Debiased Visual Question Answering,http://arxiv.org/abs/2304.01647v1,"Visual question answering (VQA) is a critical multimodal task in which anagent must answer questions according to the visual cue. Unfortunately,language bias is a common problem in VQA, which refers to the model generatinganswers only by associating with the questions while ignoring the visualcontent, resulting in biased results. We tackle the language bias problem byproposing a self-supervised counterfactual metric learning (SC-ML) method tofocus the image features better. SC-ML can adaptively select thequestion-relevant visual features to answer the question, reducing the negativeinfluence of question-irrelevant visual features on inferring answers. Inaddition, question-irrelevant visual features can be seamlessly incorporatedinto counterfactual training schemes to further boost robustness. Extensiveexperiments have proved the effectiveness of our method with improved resultson the VQA-CP dataset. Our code will be made publicly available.",Xinyao Shu,2023/4/4,2023/4/4
2012.00451v3,Just Ask: Learning to Answer Questions from Millions of Narrated Videos,http://arxiv.org/abs/2012.00451v3,"Recent methods for visual question answering rely on large-scale annotateddatasets. Manual annotation of questions and answers for videos, however, istedious, expensive and prevents scalability. In this work, we propose to avoidmanual annotation and generate a large-scale training dataset for videoquestion answering making use of automatic cross-modal supervision. We leveragea question generation transformer trained on text data and use it to generatequestion-answer pairs from transcribed video narrations. Given narrated videos,we then automatically generate the HowToVQA69M dataset with 69Mvideo-question-answer triplets. To handle the open vocabulary of diverseanswers in this dataset, we propose a training procedure based on a contrastiveloss between a video-question multi-modal transformer and an answertransformer. We introduce the zero-shot VideoQA task and show excellentresults, in particular for rare answers. Furthermore, we demonstrate our methodto significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduceiVQA, a new VideoQA dataset with reduced language biases and high-qualityredundant manual annotations. Our code, datasets and trained models areavailable at https://antoyang.github.io/just-ask.html.",Antoine Yang,2020/12/1,2021/8/12
2011.01102v1,Exploring Question-Specific Rewards for Generating Deep Questions,http://arxiv.org/abs/2011.01102v1,"Recent question generation (QG) approaches often utilize thesequence-to-sequence framework (Seq2Seq) to optimize the log-likelihood ofground-truth questions using teacher forcing. However, this training objectiveis inconsistent with actual question quality, which is often reflected bycertain global properties such as whether the question can be answered by thedocument. As such, we directly optimize for QG-specific objectives viareinforcement learning to improve question quality. We design three differentrewards that target to improve the fluency, relevance, and answerability ofgenerated questions. We conduct both automatic and human evaluations inaddition to a thorough analysis to explore the effect of each QG-specificreward. We find that optimizing question-specific rewards generally leads tobetter performance in automatic evaluation metrics. However, only the rewardsthat correlate well with human judgement (e.g., relevance) lead to realimprovement in question quality. Optimizing for the others, especiallyanswerability, introduces incorrect bias to the model, resulting in poorquestion quality. Our code is publicly available athttps://github.com/YuxiXie/RL-for-Question-Generation.",Yuxi Xie,2020/11/2,2020/11/2
2110.08175v2,MixQG: Neural Question Generation with Mixed Answer Types,http://arxiv.org/abs/2110.08175v2,"Asking good questions is an essential ability for both human and machineintelligence. However, existing neural question generation approaches mainlyfocus on the short factoid type of answers. In this paper, we propose a neuralquestion generator, MixQG, to bridge this gap. We combine 9 question answeringdatasets with diverse answer types, including yes/no, multiple-choice,extractive, and abstractive answers, to train a single generative model. Weshow with empirical results that our model outperforms existing work in bothseen and unseen domains and can generate questions with different cognitivelevels when conditioned on different answer types. Our code is released andwell-integrated with the Huggingface library to facilitate various downstreamapplications.",Lidiya Murakhovs'ka,2021/10/15,2022/5/31
2306.00435v1,How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension,http://arxiv.org/abs/2306.00435v1,"The multi-answer phenomenon, where a question may have multiple answersscattered in the document, can be well handled by humans but is challengingenough for machine reading comprehension (MRC) systems. Despite recent progressin multi-answer MRC, there lacks a systematic analysis of how this phenomenonarises and how to better address it. In this work, we design a taxonomy tocategorize commonly-seen multi-answer MRC instances, with which we inspectthree multi-answer datasets and analyze where the multi-answer challenge comesfrom. We further analyze how well different paradigms of current multi-answerMRC models deal with different types of multi-answer instances. We find thatsome paradigms capture well the key information in the questions while othersbetter model the relationship between questions and contexts. We thus explorestrategies to make the best of the strengths of different paradigms.Experiments show that generation models can be a promising platform toincorporate different paradigms. Our annotations and code are released forfurther research.",Chen Zhang,2023/6/1,2023/6/1
2312.00937v1,Zero-Shot Video Question Answering with Procedural Programs,http://arxiv.org/abs/2312.00937v1,"We propose to answer zero-shot questions about videos by generating shortprocedural programs that derive a final answer from solving a sequence ofvisual subtasks. We present Procedural Video Querying (ProViQ), which uses alarge language model to generate such programs from an input question and anAPI of visual modules in the prompt, then executes them to obtain the output.Recent similar procedural approaches have proven successful for image questionanswering, but videos remain challenging: we provide ProViQ with modulesintended for video understanding, allowing it to generalize to a wide varietyof videos. This code generation framework additionally enables ProViQ toperform other video tasks in addition to question answering, such asmulti-object tracking or basic video editing. ProViQ achieves state-of-the-artresults on a diverse range of benchmarks, with improvements of up to 25% onshort, long, open-ended, and multimodal video question-answering datasets. Ourproject page is at https://rccchoudhury.github.io/proviq2023.",Rohan Choudhury,2023/12/1,2023/12/1
2111.08171v1,Solving Linear Algebra by Program Synthesis,http://arxiv.org/abs/2111.08171v1,"We solve MIT's Linear Algebra 18.06 course and Columbia University'sComputational Linear Algebra COMS3251 courses with perfect accuracy byinteractive program synthesis. This surprisingly strong result is achieved byturning the course questions into programming tasks and then running theprograms to produce the correct answers. We use OpenAI Codex with zero-shotlearning, without providing any examples in the prompts, to synthesize codefrom questions. We quantify the difference between the original question textand the transformed question text that yields a correct answer. Since allCOMS3251 questions are not available online the model is not overfitting. We gobeyond just generating code for questions with numerical answers byinteractively generating code that also results visually pleasing plots asoutput. Finally, we automatically generate new questions given a few samplequestions which may be used as new course content. This work is a significantstep forward in solving quantitative math problems and opens the door forsolving many university level STEM courses by machine.",Iddo Drori,2021/11/16,2021/11/16
2107.06483v1,From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text,http://arxiv.org/abs/2107.06483v1,"Generating code-switched text is a problem of growing interest, especiallygiven the scarcity of corpora containing large volumes of real code-switchedtext. In this work, we adapt a state-of-the-art neural machine translationmodel to generate Hindi-English code-switched sentences starting frommonolingual Hindi sentences. We outline a carefully designed curriculum ofpretraining steps, including the use of synthetic code-switched text, thatenable the model to generate high-quality code-switched text. Using textgenerated from our model as data augmentation, we show significant reductionsin perplexity on a language modeling task, compared to using text from othergenerative models of CS text. We also show improvements using our text for adownstream code-switched natural language inference task. Our generated text isfurther subjected to a rigorous evaluation using a human evaluation study and arange of objective metrics, where we show performance comparable (and sometimeseven superior) to code-switched text obtained via crowd workers who are nativeHindi speakers.",Ishan Tarunesh,2021/7/14,2021/7/14
2309.02915v1,Persona-aware Generative Model for Code-mixed Language,http://arxiv.org/abs/2309.02915v1,"Code-mixing and script-mixing are prevalent across online social networks andmultilingual societies. However, a user's preference toward code-mixing dependson the socioeconomic status, demographics of the user, and the local context,which existing generative models mostly ignore while generating code-mixedtexts. In this work, we make a pioneering attempt to develop a persona-awaregenerative model to generate texts resembling real-life code-mixed texts ofindividuals. We propose a Persona-aware Generative Model for Code-mixedGeneration, PARADOX, a novel Transformer-based encoder-decoder model thatencodes an utterance conditioned on a user's persona and generates code-mixedtexts without monolingual reference data. We propose an alignment module thatre-calibrates the generated sequence to resemble real-life code-mixed texts.PARADOX generates code-mixed texts that are semantically more meaningful andlinguistically more valid. To evaluate the personification capabilities ofPARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CMKS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% betterperplexity and 32% better semantic coherence than the non-persona-basedcounterparts.",Ayan Sengupta,2023/9/6,2023/9/6
2112.06327v1,Improving Code-switching Language Modeling with Artificially Generated Texts using Cycle-consistent Adversarial Networks,http://arxiv.org/abs/2112.06327v1,"This paper presents our latest effort on improving Code-switching languagemodels that suffer from data scarcity. We investigate methods to augmentCode-switching training text data by artificially generating them. Concretely,we propose a cycle-consistent adversarial networks based framework to transfermonolingual text into Code-switching text, considering Code-switching as aspeaking style. Our experimental results on the SEAME corpus show thatutilising artificially generated Code-switching text data improves consistentlythe language model as well as the automatic speech recognition performance.",Chia-Yu Li,2021/12/12,2021/12/12
2206.07988v1,PreCogIIITH at HinglishEval : Leveraging Code-Mixing Metrics & Language Model Embeddings To Estimate Code-Mix Quality,http://arxiv.org/abs/2206.07988v1,"Code-Mixing is a phenomenon of mixing two or more languages in a speech eventand is prevalent in multilingual societies. Given the low-resource nature ofCode-Mixing, machine generation of code-mixed text is a prevalent approach fordata augmentation. However, evaluating the quality of such machine generatedcode-mixed text is an open problem. In our submission to HinglishEval, ashared-task collocated with INLG2022, we attempt to build models factors thatimpact the quality of synthetically generated code-mix text by predictingratings for code-mix quality.",Prashant Kodali,2022/6/16,2022/6/16
1904.07293v2,Latent Code and Text-based Generative Adversarial Networks for Soft-text Generation,http://arxiv.org/abs/1904.07293v2,"Text generation with generative adversarial networks (GANs) can be dividedinto the text-based and code-based categories according to the type of signalsused for discrimination. In this work, we introduce a novel text-based approachcalled Soft-GAN to effectively exploit GAN setup for text generation. Wedemonstrate how autoencoders (AEs) can be used for providing a continuousrepresentation of sentences, which we will refer to as soft-text. This softrepresentation will be used in GAN discrimination to synthesize similarsoft-texts. We also propose hybrid latent code and text-based GAN (LATEXT-GAN)approaches with one or more discriminators, in which a combination of thelatent code and the soft-text is used for GAN discriminations. We perform anumber of subjective and objective experiments on two well-known datasets (SNLIand Image COCO) to validate our techniques. We discuss the results usingseveral evaluation metrics and show that the proposed techniques outperform thetraditional GAN-based text-generation methods.",Md. Akmal Haidar,2019/4/15,2019/4/23
1906.08972v1,A Deep Generative Model for Code-Switched Text,http://arxiv.org/abs/1906.08972v1,"Code-switching, the interleaving of two or more languages within a sentenceor discourse is pervasive in multilingual societies. Accurate language modelsfor code-switched text are critical for NLP tasks. State-of-the-artdata-intensive neural language models are difficult to train well from scarcelanguage-labeled code-switched text. A potential solution is to use deepgenerative models to synthesize large volumes of realistic code-switched text.Although generative adversarial networks and variational autoencoders cansynthesize plausible monolingual text from continuous latent space, they cannotadequately address code-switched text, owing to their informal style andcomplex interplay between the constituent languages. We introduce VACS, a novelvariational autoencoder architecture specifically tailored to code-switchingphenomena. VACS encodes to and decodes from a two-level hierarchicalrepresentation, which models syntactic contextual signals in the lower level,and language switching signals in the upper layer. Sampling representationsfrom the prior and decoding them produced well-formed, diverse code-switchedsentences. Extensive experiments show that using synthetic code-switched textwith natural monolingual data results in significant (33.06%) drop inperplexity.",Bidisha Samanta,2019/6/21,2019/6/21
2003.00674v1,Style Example-Guided Text Generation using Generative Adversarial Transformers,http://arxiv.org/abs/2003.00674v1,"We introduce a language generative model framework for generating a styledparagraph based on a context sentence and a style reference example. Theframework consists of a style encoder and a texts decoder. The style encoderextracts a style code from the reference example, and the text decodergenerates texts based on the style code and the context. We propose a novelobjective function to train our framework. We also investigate differentnetwork design choices. We conduct extensive experimental validation withcomparison to strong baselines to validate the effectiveness of the proposedframework using a newly collected dataset with diverse text styles. Both codeand dataset will be released upon publication.",Kuo-Hao Zeng,2020/3/2,2020/3/2
2206.08680v1,BITS Pilani at HinglishEval: Quality Evaluation for Code-Mixed Hinglish Text Using Transformers,http://arxiv.org/abs/2206.08680v1,"Code-Mixed text data consists of sentences having words or phrases from morethan one language. Most multi-lingual communities worldwide communicate usingmultiple languages, with English usually one of them. Hinglish is a Code-Mixedtext composed of Hindi and English but written in Roman script. This paper aimsto determine the factors influencing the quality of Code-Mixed text datagenerated by the system. For the HinglishEval task, the proposed model usesmulti-lingual BERT to find the similarity between synthetically generated andhuman-generated sentences to predict the quality of synthetically generatedHinglish sentences.",Shaz Furniturewala,2022/6/17,2022/6/17
1903.11380v1,Binary LCD Codes from $\mathbb{Z}_2\mathbb{Z}_2[u]$,http://arxiv.org/abs/1903.11380v1,"Linear complementary dual (LCD) codes over finite fields are linear codessatisfying $C\cap C^{\perp}=\{0\}$. We generalize the LCD codes over finitefields to $\mathbb{Z}_2\mathbb{Z}_2[u]$-LCD codes over the ring$\mathbf{Z}_2\times(\mathbf{Z}_2+u\mathbf{Z}_2)$. Under suitable conditions,$\mathbb{Z}_2\mathbb{Z}_2[u]$-linear codes that are$\mathbb{Z}_2\mathbb{Z}_2[u]$-LCD codes are characterized. We then prove thatthe binary image of a $\mathbb{Z}_2\mathbb{Z}_2[u]$-LCD code is a binary LCDcode. Finally, by means of these conditions, we construct new binary LCD codesusing $\mathbb{Z}_2\mathbb{Z}_2[u]$-LCD codes, most of which have betterparameters than current binary LCD codes available.",Hu Peng,2019/3/26,2019/3/26
1302.4510v1,An Approach Of Substitution Method Based On ASCII Codes In Encryption Technique,http://arxiv.org/abs/1302.4510v1,"In poly alphabetic substitution the plain texts letters are enciphereddifferently according to their position. The name poly alphabetic suggests thatthere are more than one key so we have used two keys combination instead ofjust one, in order to produce the cipher text. We can also use three or morekeys to make the enciphering process more complicated. In this paper haveproduced ASCII Codes of the plain text and then we have reversed it saidreverse ASCII Codes and then we have generated two keys K1 is generated byaddition of reverse ASCII Codes and K2 is generated by addition of ASCII Codes.Then these K1 and K2 Keys are alternatively applied on Reverse ASCII codes inorder to produce cipher text. On the Destination hand Deciphering is used toproduce the plain text again. Our technique generates random cipher text forthe same plain text and this is the major advantage of our technique.",Avinash Sharma,2013/2/19,2013/2/19
2311.10401v1,LLM-based Control Code Generation using Image Recognition,http://arxiv.org/abs/2311.10401v1,"LLM-based code generation could save significant manual efforts in industrialautomation, where control engineers manually produce control logic forsophisticated production processes. Previous attempts in control logic codegeneration lacked methods to interpret schematic drawings from processengineers. Recent LLMs now combine image recognition, trained domain knowledge,and coding skills. We propose a novel LLM-based code generation method thatgenerates IEC 61131-3 Structure Text control logic source code fromPiping-and-Instrumentation Diagrams (P&IDs) using image recognition. We haveevaluated the method in three case study with industrial P&IDs and providefirst evidence on the feasibility of such a code generation besides experienceson image recognition glitches.",Heiko Koziolek,2023/11/17,2023/11/17
1911.12260v2,Infinite Families of Quantum-Classical Hybrid Codes,http://arxiv.org/abs/1911.12260v2,"Hybrid codes simultaneously encode both quantum and classical informationinto physical qubits. We give several general results about hybrid codes, mostnotably that the quantum codes comprising a genuine hybrid code must be impureand that hybrid codes can always detect more errors than comparable quantumcodes. We also introduce the weight enumerators for general hybrid codes, whichwe then use to derive linear programming bounds. Finally, inspired by theconstruction of some families of nonadditive codes, we construct severalinfinite families of genuine hybrid codes with minimum distance two and three.",Andrew Nemec,2019/11/26,2020/9/9
2006.08339v1,Graph-Stega: Semantic Controllable Steganographic Text Generation Guided by Knowledge Graph,http://arxiv.org/abs/2006.08339v1,"Most of the existing text generative steganographic methods are based oncoding the conditional probability distribution of each word during thegeneration process, and then selecting specific words according to the secretinformation, so as to achieve information hiding. Such methods have theirlimitations which may bring potential security risks. Firstly, with theincrease of embedding rate, these models will choose words with lowerconditional probability, which will reduce the quality of the generatedsteganographic texts; secondly, they can not control the semantic expression ofthe final generated steganographic text. This paper proposes a new textgenerative steganography method which is quietly different from the existingmodels. We use a Knowledge Graph (KG) to guide the generation of steganographicsentences. On the one hand, we hide the secret information by coding the pathin the knowledge graph, but not the conditional probability of each generatedword; on the other hand, we can control the semantic expression of thegenerated steganographic text to a certain extent. The experimental resultsshow that the proposed model can guarantee both the quality of the generatedtext and its semantic expression, which is a supplement and improvement to thecurrent text generation steganography.",Zhongliang Yang,2020/6/2,2020/6/2
2108.01861v1,Quality Evaluation of the Low-Resource Synthetically Generated Code-Mixed Hinglish Text,http://arxiv.org/abs/2108.01861v1,"In this shared task, we seek the participating teams to investigate thefactors influencing the quality of the code-mixed text generation systems. Wesynthetically generate code-mixed Hinglish sentences using two distinctapproaches and employ human annotators to rate the generation quality. Wepropose two subtasks, quality rating prediction and annotators' disagreementprediction of the synthetic Hinglish dataset. The proposed subtasks will putforward the reasoning and explanation of the factors influencing the qualityand human perception of the code-mixed text.",Vivek Srivastava,2021/8/4,2021/8/4
2306.09671v1,The Optimality of AIFV Codes in the Class of $2$-bit Delay Decodable Codes,http://arxiv.org/abs/2306.09671v1,"AIFV (almost instantaneous fixed-to-variable length) codes are noiselesssource codes that can attain a shorter average codeword length than Huffmancodes by allowing a time-variant encoder with two code tables and a decodingdelay of at most 2 bits. First, we consider a general class of noiseless sourcecodes, called k-bit delay decodable codes, in which one allows a finite numberof code tables and a decoding delay of at most k bits for k >= 0. Then we provethat AIFV codes achieve the optimal average codeword length in the 2-bit delaydecodable codes class.",Kengo Hashimoto,2023/6/16,2023/6/16
2107.03760v1,HinGE: A Dataset for Generation and Evaluation of Code-Mixed Hinglish Text,http://arxiv.org/abs/2107.03760v1,"Text generation is a highly active area of research in the computationallinguistic community. The evaluation of the generated text is a challengingtask and multiple theories and metrics have been proposed over the years.Unfortunately, text generation and evaluation are relatively understudied dueto the scarcity of high-quality resources in code-mixed languages where thewords and phrases from multiple languages are mixed in a single utterance oftext and speech. To address this challenge, we present a corpus (HinGE) for awidely popular code-mixed language Hinglish (code-mixing of Hindi and Englishlanguages). HinGE has Hinglish sentences generated by humans as well as tworule-based algorithms corresponding to the parallel Hindi-English sentences. Inaddition, we demonstrate the inefficacy of widely-used evaluation metrics onthe code-mixed data. The HinGE dataset will facilitate the progress of naturallanguage generation research in code-mixed languages.",Vivek Srivastava,2021/7/8,2021/7/8
1501.01327v1,Cyclic codes over $\mathbb{Z}_4+u\mathbb{Z}_4$,http://arxiv.org/abs/1501.01327v1,"In this paper, we have studied cyclic codes over the ring$R=\mathbb{Z}_4+u\mathbb{Z}_4$, $u^2=0$. We have considered cyclic codes of oddlengths. A sufficient condition for a cyclic code over $R$ to be a$\mathbb{Z}_4$-free module is presented. We have provided the general form ofthe generators of a cyclic code over $R$ and determined a formula for the ranksof such codes. In this paper we have mainly focused on principally generatedcyclic codes of odd length over $R$. We have determined a necessary conditionand a sufficient condition for cyclic codes of odd lengths over $R$ to be$R$-free.",Rama Krishna Bandi,2015/1/6,2015/1/6
2310.16343v1,A Comprehensive Evaluation of Constrained Text Generation for Large Language Models,http://arxiv.org/abs/2310.16343v1,"Advancements in natural language generation (NLG) and large language models(LLMs) have led to proficient text generation in various tasks. However,integrating intricate constraints into neural text generation, due to LLMs'opacity, remains challenging. This study investigates constrained textgeneration for LLMs, where predefined constraints are applied during LLM'sgeneration process. Our research examines multiple LLMs, including ChatGPT andGPT-4, categorizing constraints into lexical, structural, and relation-basedtypes. We also present various benchmarks to facilitate fair evaluation. Thestudy addresses some key research questions, including the extent of LLMs'compliance with constraints. Results illuminate LLMs' capacity and deficiencyto incorporate constraints and provide insights for future developments inconstrained text generation. Codes and datasets will be released uponacceptance.",Xiang Chen,2023/10/25,2023/10/25
2206.06888v1,CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation,http://arxiv.org/abs/2206.06888v1,"Code generation is a longstanding challenge, aiming to generate a codesnippet based on a natural language description. Usually, expensive text-codepaired data is essential for training a code generation model. Recently, thanksto the success of pre-training techniques, large language models are trained onlarge-scale unlabelled code corpora and perform well in code generation. Inthis paper, we investigate how to leverage an unlabelled code corpus to train amodel for library-oriented code generation. Since it is a common practice forprogrammers to reuse third-party libraries, in which case the text-code paireddata are harder to obtain due to the huge number of libraries. We observe thatlibrary-oriented code snippets are more likely to share similar code sketches.Hence, we present CERT with two steps: a sketcher generates the sketch, then agenerator fills the details in the sketch. Both the sketcher and the generatorare continually pre-trained upon a base model using unlabelled data.Furthermore, we craft two benchmarks named PandasEval and NumpyEval to evaluatelibrary-oriented code generation. Experimental results demonstrate theimpressive performance of CERT. For example, it surpasses the base model by anabsolute 15.67% improvement in terms of pass@1 on PandasEval. Our work isavailable at https://github.com/microsoft/PyCodeGPT.",Daoguang Zan,2022/6/14,2022/6/14
2302.00923v4,Multimodal Chain-of-Thought Reasoning in Language Models,http://arxiv.org/abs/2302.00923v4,"Large language models (LLMs) have shown impressive performance on complexreasoning by leveraging chain-of-thought (CoT) prompting to generateintermediate reasoning chains as the rationale to infer the answer. However,existing CoT studies have focused on the language modality. We proposeMultimodal-CoT that incorporates language (text) and vision (images) modalitiesinto a two-stage framework that separates rationale generation and answerinference. In this way, answer inference can leverage better generatedrationales that are based on multimodal information. With Multimodal-CoT, ourmodel under 1 billion parameters outperforms the previous state-of-the-art LLM(GPT-3.5) by 16 percentage points (75.17%->91.68% accuracy) on the ScienceQAbenchmark and even surpasses human performance. Code is publicly availableavailable at https://github.com/amazon-science/mm-cot.",Zhuosheng Zhang,2023/2/2,2023/2/17
2305.03453v4,T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering,http://arxiv.org/abs/2305.03453v4,"Large Language Models (LLMs) have recently demonstrated exceptionalperformance in various Natural Language Processing (NLP) tasks. They have alsoshown the ability to perform chain-of-thought (CoT) reasoning to solve complexproblems. Recent studies have explored CoT reasoning in complex multimodalscenarios, such as the science question answering task, by fine-tuningmultimodal models with high-quality human-annotated CoT rationales. However,collecting high-quality COT rationales is usually time-consuming and costly.Besides, the annotated rationales are hardly accurate due to the externalessential information missed. To address these issues, we propose a novelmethod termed T-SciQ that aims at teaching science question answering with LLMsignals. The T-SciQ approach generates high-quality CoT rationales as teachingsignals and is advanced to train much smaller models to perform CoT reasoningin complex modalities. Additionally, we introduce a novel data mixing strategyto produce more effective teaching data samples for simple and complex sciencequestion answer problems. Extensive experimental results show that our T-SciQmethod achieves a new state-of-the-art performance on the ScienceQA benchmark,with an accuracy of 96.18%. Moreover, our approach outperforms the mostpowerful fine-tuned baseline by 4.5%. The code is publicly available athttps://github.com/T-SciQ/T-SciQ.",Lei Wang,2023/5/5,2023/12/18
2212.10509v2,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,http://arxiv.org/abs/2212.10509v2,"Prompting-based large language models (LLMs) are surprisingly powerful atgenerating natural language reasoning steps or Chains-of-Thoughts (CoT) formulti-step question answering (QA). They struggle, however, when the necessaryknowledge is either unavailable to the LLM or not up-to-date within itsparameters. While using the question to retrieve relevant text from an externalknowledge source helps LLMs, we observe that this one-step retrieve-and-readapproach is insufficient for multi-step QA. Here, \textit{what to retrieve}depends on \textit{what has already been derived}, which in turn may depend on\textit{what was previously retrieved}. To address this, we propose IRCoT, anew approach for multi-step QA that interleaves retrieval with steps(sentences) in a CoT, guiding the retrieval with CoT and in turn usingretrieved results to improve CoT. Using IRCoT with GPT3 substantially improvesretrieval (up to 21 points) as well as downstream QA (up to 15 points) on fourdatasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similarsubstantial gains in out-of-distribution (OOD) settings as well as with muchsmaller models such as Flan-T5-large without additional training. IRCoT reducesmodel hallucination, resulting in factually more accurate CoT reasoning. Code,data, and prompts are available at \url{https://github.com/stonybrooknlp/ircot}",Harsh Trivedi,2022/12/20,2023/6/23
2311.14024v1,Creating and Benchmarking a Synthetic Dataset for Cloud Optical Thickness Estimation,http://arxiv.org/abs/2311.14024v1,"Cloud formations often obscure optical satellite-based monitoring of theEarth's surface, thus limiting Earth observation (EO) activities such as landcover mapping, ocean color analysis, and cropland monitoring. The integrationof machine learning (ML) methods within the remote sensing domain hassignificantly improved performance on a wide range of EO tasks, including clouddetection and filtering, but there is still much room for improvement. A keybottleneck is that ML methods typically depend on large amounts of annotateddata for training, which is often difficult to come by in EO contexts. This isespecially true for the task of cloud optical thickness (COT) estimation. Areliable estimation of COT enables more fine-grained and application-dependentcontrol compared to using pre-specified cloud categories, as is commonly donein practice. To alleviate the COT data scarcity problem, in this work wepropose a novel synthetic dataset for COT estimation, where top-of-atmosphereradiances have been simulated for 12 of the spectral bands of theMulti-Spectral Instrument (MSI) sensor onboard Sentinel-2 platforms. These datapoints have been simulated under consideration of different cloud types, COTs,and ground surface and atmospheric profiles. Extensive experimentation oftraining several ML models to predict COT from the measured reflectivity of thespectral bands demonstrates the usefulness of our proposed dataset.Generalization to real data is also demonstrated on two satellite imagedatasets -- one that is publicly available, and one which we have collected andannotated. The synthetic data, the newly collected real dataset, code andmodels have been made publicly available athttps://github.com/aleksispi/ml-cloud-opt-thick.",Aleksis Pirinen,2023/11/23,2023/11/23
2310.01714v2,Large Language Models as Analogical Reasoners,http://arxiv.org/abs/2310.01714v2,"Chain-of-thought (CoT) prompting for language models demonstrates impressiveperformance across reasoning tasks, but typically needs labeled exemplars ofthe reasoning process. In this work, we introduce a new prompting approach,Analogical Prompting, designed to automatically guide the reasoning process oflarge language models. Inspired by analogical reasoning, a cognitive process inwhich humans draw from relevant past experiences to tackle new problems, ourapproach prompts language models to self-generate relevant exemplars orknowledge in the context, before proceeding to solve the given problem. Thismethod presents several advantages: it obviates the need for labeling orretrieving exemplars, offering generality and convenience; it can also tailorthe generated exemplars and knowledge to each problem, offering adaptability.Experimental results show that our approach outperforms 0-shot CoT and manualfew-shot CoT in a variety of reasoning tasks, including math problem solving inGSM8K and MATH, code generation in Codeforces, and other reasoning tasks inBIG-Bench.",Michihiro Yasunaga,2023/10/3,2023/10/7
2303.09014v1,ART: Automatic multi-step reasoning and tool-use for large language models,http://arxiv.org/abs/2303.09014v1,"Large language models (LLMs) can perform complex reasoning in few- andzero-shot settings by generating intermediate chain of thought (CoT) reasoningsteps. Further, each reasoning step can rely on external tools to supportcomputation beyond the core LLM capabilities (e.g. search/running code). Priorwork on CoT prompting and tool use typically requires hand-craftingtask-specific demonstrations and carefully scripted interleaving of modelgenerations with tool use. We introduce Automatic Reasoning and Tool-use (ART),a framework that uses frozen LLMs to automatically generate intermediatereasoning steps as a program. Given a new task to solve, ART selectsdemonstrations of multi-step reasoning and tool use from a task library. Attest time, ART seamlessly pauses generation whenever external tools are called,and integrates their output before resuming generation. ART achieves asubstantial improvement over few-shot prompting and automatic CoT on unseentasks in the BigBench and MMLU benchmarks, and matches performance ofhand-crafted CoT prompts on a majority of these tasks. ART is also extensible,and makes it easy for humans to improve performance by correcting errors intask-specific programs or incorporating new tools, which we demonstrate bydrastically improving performance on select tasks with minimal humanintervention.",Bhargavi Paranjape,2023/3/16,2023/3/16
2212.10071v2,Large Language Models Are Reasoning Teachers,http://arxiv.org/abs/2212.10071v2,"Recent works have shown that chain-of-thought (CoT) prompting can elicitlanguage models to solve complex reasoning tasks, step-by-step. However,prompt-based CoT methods are dependent on very large models such as GPT-3 175Bwhich are prohibitive to deploy at scale. In this paper, we use these largemodels as reasoning teachers to enable complex reasoning in smaller models andreduce model size requirements by several orders of magnitude. We proposeFine-tune-CoT, a method that generates reasoning samples from very largeteacher models to fine-tune smaller models. We evaluate our method on a widerange of public models and complex tasks. We find that Fine-tune-CoT enablessubstantial reasoning capability in small models, far outperformingprompt-based baselines and even the teacher model in many tasks. Additionally,we extend our method by leveraging the teacher model's ability to generatemultiple distinct rationales for each original sample. Enriching thefine-tuning data with such diverse reasoning results in a substantialperformance boost across datasets, even for very small models. We conductablations and sample studies to understand the emergence of reasoningcapabilities of student models. Our code implementation and data are availableat https://github.com/itsnamgyu/reasoning-teacher.",Namgyu Ho,2022/12/20,2023/6/13
2312.04474v2,Chain of Code: Reasoning with a Language Model-Augmented Code Emulator,http://arxiv.org/abs/2312.04474v2,"Code provides a general syntactic structure to build complex programs andperform precise computations when paired with a code interpreter - wehypothesize that language models (LMs) can leverage code-writing to improveChain of Thought reasoning not only for logic and arithmetic tasks, but alsofor semantic ones (and in particular, those that are a mix of both). Forexample, consider prompting an LM to write code that counts the number of timesit detects sarcasm in an essay: the LM may struggle to write an implementationfor ""detect_sarcasm(string)"" that can be executed by the interpreter (handlingthe edge cases would be insurmountable). However, LMs may still produce a validsolution if they not only write code, but also selectively ""emulate"" theinterpreter by generating the expected output of ""detect_sarcasm(string)"" andother lines of code that cannot be executed. In this work, we propose Chain ofCode (CoC), a simple yet surprisingly effective extension that improves LMcode-driven reasoning. The key idea is to encourage LMs to format semanticsub-tasks in a program as flexible pseudocode that the interpreter canexplicitly catch undefined behaviors and hand off to simulate with an LM (as an""LMulator""). Experiments demonstrate that Chain of Code outperforms Chain ofThought and other baselines across a variety of benchmarks; on BIG-Bench Hard,Chain of Code achieves 84%, a gain of 12% over Chain of Thought. CoC scaleswell with large and small models alike, and broadens the scope of reasoningquestions that LMs can correctly answer by ""thinking in code"". Project webpage:https://chain-of-code.github.io.",Chengshu Li,2023/12/7,2023/12/8
2305.16744v3,Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought,http://arxiv.org/abs/2305.16744v3,"Language instructions and demonstrations are two natural ways for users toteach robots personalized tasks. Recent progress in Large Language Models(LLMs) has shown impressive performance in translating language instructionsinto code for robotic tasks. However, translating demonstrations into task codecontinues to be a challenge due to the length and complexity of bothdemonstrations and code, making learning a direct mapping intractable. Thispaper presents Demo2Code, a novel framework that generates robot task code fromdemonstrations via an extended chain-of-thought and defines a common latentspecification to connect the two. Our framework employs a robust two-stageprocess: (1) a recursive summarization technique that condenses demonstrationsinto concise specifications, and (2) a code synthesis approach that expandseach function recursively from the generated specifications. We conductextensive evaluation on various robot task benchmarks, including a novel gamebenchmark Robotouille, designed to simulate diverse cooking tasks in a kitchenenvironment. The project's website is available athttps://portal-cornell.github.io/demo2code/",Huaxiaoyue Wang,2023/5/26,2023/11/2
2310.14628v2,"Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts",http://arxiv.org/abs/2310.14628v2,"As large language models (LLMs) have shown effectiveness with differentprompting methods, such as Chain of Thought, Program of Thought, we find thatthese methods have formed a great complementarity to each other on mathreasoning tasks. In this work, we propose XoT, an integrated problem solvingframework by prompting LLMs with diverse reasoning thoughts. For each question,XoT always begins with selecting the most suitable method then executes eachmethod iteratively. Within each iteration, XoT actively checks the validity ofthe generated answer and incorporates the feedback from external executors,allowing it to dynamically switch among different prompting methods. Throughextensive experiments on 10 popular math reasoning datasets, we demonstrate theeffectiveness of our proposed approach and thoroughly analyze the strengths ofeach module. Moreover, empirical results suggest that our framework isorthogonal to recent work that makes improvements on single reasoning methodsand can further generalise to logical reasoning domain. By allowing methodswitching, XoT provides a fresh perspective on the collaborative integration ofdiverse reasoning thoughts in a unified framework. The code is available athttps://github.com/tengxiaoliu/XoT.",Tengxiao Liu,2023/10/23,2023/12/27
2310.10698v2,Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation,http://arxiv.org/abs/2310.10698v2,"Large language models (LLMs) have showcased remarkable prowess in codegeneration. However, automated code generation is still challenging since itrequires a high-level semantic mapping between natural language requirementsand codes. Most existing LLMs-based approaches for code generation rely ondecoder-only causal language models often treate codes merely as plain texttokens, i.e., feeding the requirements as a prompt input, and outputing code asflat sequence of tokens, potentially missing the rich semantic featuresinherent in source code. To bridge this gap, this paper proposes the ""SemanticChain-of-Thought"" approach to intruduce semantic information of code, namedSeCoT. Our motivation is that the semantic information of the source code (\egdata flow and control flow) describes more precise program execution behavior,intention and function. By guiding LLM consider and integrate semanticinformation, we can achieve a more granular understanding and representation ofcode, enhancing code generation accuracy. Meanwhile, while traditionaltechniques leveraging such semantic information require complex static ordynamic code analysis to obtain features such as data flow and control flow,SeCoT demonstrates that this process can be fully automated via the intrinsiccapabilities of LLMs (i.e., in-context learning), while being generalizable andapplicable to challenging domains. While SeCoT can be applied with differentLLMs, this paper focuses on the powerful GPT-style models: ChatGPT(close-sourcemodel) and WizardCoder(open-source model). The experimental study on threepopular DL benchmarks (i.e., HumanEval, HumanEval-ET and MBPP) shows that SeCoTcan achieves state-of-the-art performance, greatly improving the potential forlarge models and code generation.",Yingwei Ma,2023/10/16,2023/10/22
quant-ph/0005008v1,Nonbinary Quantum Stabilizer Codes,http://arxiv.org/abs/quant-ph/0005008v1,We define and show how to construct nonbinary quantum stabilizer codes. Ourapproach is based on nonbinary error bases. It generalizes the relationshipbetween selforthogonal codes over $GF_{4}$ and binary quantum codes to onebetween selforthogonal codes over $GF_{q^2}$ and $q$-ary quantum codes for anyprime power $q$.,Alexei Ashikhmin,2000/5/1,2000/5/1
1212.5802v1,Generalized AG codes as evaluation codes,http://arxiv.org/abs/1212.5802v1,We extend the construction of GAG codes to the case of evaluation codes. Weestimate the minimum distance of these extended evaluation codes and wedescribe the connection to the one-point GAG codes.,Marco Calderini,2012/12/23,2012/12/23
2312.17055v1,Improving In-context Learning via Bidirectional Alignment,http://arxiv.org/abs/2312.17055v1,"Large language models (LLMs) have shown impressive few-shot generalization onmany tasks via in-context learning (ICL). Despite their success in showing suchemergent abilities, the scale and complexity of larger models also lead tounprecedentedly high computational demands and deployment challenges. Inreaction, researchers explore transferring the powerful capabilities of largermodels to more efficient and compact models by typically aligning the output ofsmaller models with that of larger models. Existing methods either trainsmaller models on the generated outputs of larger models or to imitate theirtoken-level probability distributions. However, these distillation methods paylittle to no attention to the input part, which also plays a crucial role inICL. Based on the finding that the performance of ICL is highly sensitive tothe selection of demonstration examples, we propose Bidirectional Alignment(BiAlign) to fully leverage the models' preferences for ICL examples to improvethe ICL abilities of smaller models. Specifically, we introduce the alignmentof input preferences between smaller and larger models by incorporating a novelranking loss, in addition to aligning the token-level output distribution. Withextensive experiments and analysis, we demonstrate that BiAlign canconsistently outperform existing baselines on a variety of tasks includinglanguage understanding, reasoning, and coding.",Chengwei Qin,2023/12/28,2023/12/28
2306.04637v2,Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection,http://arxiv.org/abs/2306.04637v2,"Neural sequence models based on the transformer architecture havedemonstrated remarkable \emph{in-context learning} (ICL) abilities, where theycan perform new tasks when prompted with training and test examples, withoutany parameter update to the model. This work first provides a comprehensivestatistical theory for transformers to perform ICL. Concretely, we show thattransformers can implement a broad class of standard machine learningalgorithms in context, such as least squares, ridge regression, Lasso, learninggeneralized linear models, and gradient descent on two-layer neural networks,with near-optimal predictive power on various in-context data distributions.Using an efficient implementation of in-context gradient descent as theunderlying mechanism, our transformer constructions admit mild size bounds, andcan be learned with polynomially many pretraining sequences.  Building on these ``base'' ICL algorithms, intriguingly, we show thattransformers can implement more complex ICL procedures involving\emph{in-context algorithm selection}, akin to what a statistician can do inreal life -- A \emph{single} transformer can adaptively select different baseICL algorithms -- or even perform qualitatively different tasks -- on differentinput sequences, without any explicit prompting of the right algorithm or task.We both establish this in theory by explicit constructions, and also observethis phenomenon experimentally. In theory, we construct two general mechanismsfor algorithm selection with concrete examples: pre-ICL testing, and post-ICLvalidation. As an example, we use the post-ICL validation mechanism toconstruct a transformer that can perform nearly Bayes-optimal ICL on achallenging task -- noisy linear models with mixed noise levels.Experimentally, we demonstrate the strong in-context algorithm selectioncapabilities of standard transformer architectures.",Yu Bai,2023/6/7,2023/7/6
2309.14681v3,Are Human-generated Demonstrations Necessary for In-context Learning?,http://arxiv.org/abs/2309.14681v3,"Despite the promising few-shot ability of large language models (LLMs), thestandard paradigm of In-context Learning (ICL) suffers the disadvantages ofsusceptibility to selected demonstrations and the intricacy to generate thesedemonstrations. In this paper, we raise the fundamental question that whetherhuman-generated demonstrations are necessary for ICL. To answer this question,we propose self-contemplation prompting strategy (SEC), a paradigm free fromhuman-crafted demonstrations. The key point of SEC is that, instead of usinghand-crafted examples as demonstrations in ICL, SEC asks LLMs to first createdemonstrations on their own, based on which the final output is generated. SECis a flexible framework and can be adapted to both the vanilla ICL and thechain-of-thought (CoT), but with greater ease: as the manual-generation processof both examples and rationale can be saved. Extensive experiments inarithmetic reasoning, commonsense reasoning, multi-task language understanding,and code generation benchmarks, show that SEC, which does not requirehand-crafted demonstrations, significantly outperforms the zero-shot learningstrategy, and achieves comparable results to ICL with hand-crafteddemonstrations. This demonstrates that, for many tasks, contemporary LLMspossess a sufficient level of competence to exclusively depend on their owncapacity for decision making, removing the need for external training data.Code is available at https://github.com/ruili33/SEC.",Rui Li,2023/9/26,2023/11/26
2312.03276v2,An inverter-chain link implementation of quantum teleportation and superdense coding,http://arxiv.org/abs/2312.03276v2,"A new perspective in terms of inverter-chain link (ICL) diagrams of quantumentanglement faithfully captures the fundamental concept of quantumteleportation and superdense coding. The ICL may be considered a series of{\sigma}_{x} Pauli-matrix operations, where a physical/geometric representationprovides the mysterious link raised by EPR. Here, we employ discrete phasespace and ICL analyses of quantum entanglement as a resource for quantumteleportation and superdense coding. We underscore the quantum superpositionprinciple and Hadamard transformation under a local single-qubit operation. Onthe fundamental question posed by EPR, our result seems to lend support to thegeometric nature of quantum entanglement. In concluding remarks, we discussvery briefly a bold conjecture in physics aiming to unify general relativitywith quantum mechanics, namely, ER=EPR.",Felix A. Buot,2023/12/6,2023/12/12
2311.09519v1,Leveraging Code to Improve In-context Learning for Semantic Parsing,http://arxiv.org/abs/2311.09519v1,"In-context learning (ICL) is an appealing approach for semantic parsing dueto its few-shot nature and improved generalization. However, learning to parseto rare domain-specific languages (DSLs) from just a few demonstrations ischallenging, limiting the performance of even the most capable LLMs. In thiswork, we improve the effectiveness of ICL for semantic parsing by (1) usinggeneral-purpose programming languages such as Python instead of DSLs, and (2)augmenting prompts with a structured domain description that includes, e.g.,the available classes and functions. We show that both these changessignificantly improve accuracy across three popular datasets. Combined, theylead to dramatic improvements (e.g. 7.9% to 66.5% on SMCalFlow compositionalsplit), nearly closing the performance gap between easier i.i.d.\ and hardercompositional splits when used with a strong model, and reducing the need for alarge number of demonstrations. We find that the resemblance of the targetparse language to general-purpose code is a more important factor than thelanguage's popularity in pre-training corpora. Our findings provide an improvedmethodology for building semantic parsers in the modern context of ICL withLLMs.",Ben Bogin,2023/11/16,2023/11/16
2401.12087v1,Revisiting Demonstration Selection Strategies in In-Context Learning,http://arxiv.org/abs/2401.12087v1,"Large language models (LLMs) have shown an impressive ability to perform awide range of tasks using in-context learning (ICL), where a few examples areused to describe a task to the model. However, the performance of ICL variessignificantly with the choice of demonstrations, and it is still unclear whythis happens or what factors will influence its choice. In this work, we firstrevisit the factors contributing to this variance from both data and modelaspects, and find that the choice of demonstration is both data- andmodel-dependent. We further proposed a data- and model-dependent demonstrationselection method, \textbf{TopK + ConE}, based on the assumption that\textit{the performance of a demonstration positively correlates with itscontribution to the model's understanding of the test samples}, resulting in asimple and effective recipe for ICL. Empirically, our method yields consistentimprovements in both language understanding and generation tasks with differentmodel scales. Further analyses confirm that, besides the generality andstability under different circumstances, our method provides a unifiedexplanation for the effectiveness of previous methods. Code will be released.",Keqin Peng,2024/1/22,2024/1/22
2401.12406v1,Enhancing In-context Learning via Linear Probe Calibration,http://arxiv.org/abs/2401.12406v1,"In-context learning (ICL) is a new paradigm for natural language processingthat utilizes Generative Pre-trained Transformer (GPT)-like models. Thisapproach uses prompts that include in-context demonstrations to generate thecorresponding output for a new query input. However, applying ICL in real casesdoes not scale with the number of samples, and lacks robustness to differentprompt templates and demonstration permutations. In this paper, we first showthat GPT-like models using ICL result in unreliable predictions based on a newmetric based on Shannon entropy. Then, to solve this problem, we propose a newtechnique called the Linear Probe Calibration (LinC), a method that calibratesthe model's output probabilities, resulting in reliable predictions andimproved performance, while requiring only minimal additional samples (as fewas five labeled data samples). LinC significantly enhances the ICL testperformance of GPT models on various benchmark datasets, with an averageimprovement of up to 21%, and up to a 50% improvement in some cases, andsignificantly boosts the performance of PEFT methods, especially in the lowresource regime. Moreover, LinC achieves lower expected calibration error, andis highly robust to varying label proportions, prompt templates, anddemonstration permutations. Our code is available at\url{https://github.com/mominabbass/LinC}.",Momin Abbas,2024/1/22,2024/1/22
2305.14802v2,Estimating Large Language Model Capabilities without Labeled Test Data,http://arxiv.org/abs/2305.14802v2,"Large Language Models (LLMs) have the impressive ability to performin-context learning (ICL) from only a few examples, but the success of ICLvaries widely from task to task. Thus, it is important to quickly determinewhether ICL is applicable to a new task, but directly evaluating ICL accuracycan be expensive in situations where test data is expensive to annotate -- theexact situations where ICL is most appealing. In this paper, we propose thetask of ICL accuracy estimation, in which we predict the accuracy of an LLMwhen doing in-context learning on a new task given only unlabeled test data forthat task. To perform ICL accuracy estimation, we propose a method that trainsa meta-model using LLM confidence scores as features. We compare our method toseveral strong accuracy estimation baselines on a new benchmark that covers 4LLMs and 3 task collections. The meta-model improves over all baselines across8 out of 12 settings and achieves the same estimation performance as directlyevaluating on 40 collected labeled test examples per task. At the same time, noexisting approach provides an accurate and reliable ICL accuracy estimation inevery setting, highlighting the need for better ways to measure the uncertaintyof LLM predictions.",Harvey Yiyun Fu,2023/5/24,2023/10/26
2302.05698v3,Compositional Exemplars for In-context Learning,http://arxiv.org/abs/2302.05698v3,"Large pretrained language models (LMs) have shown impressive In-ContextLearning (ICL) ability, where the model learns to do an unseen task via aprompt consisting of input-output examples as the demonstration, without anyparameter updates. The performance of ICL is highly dominated by the quality ofthe selected in-context examples. However, previous selection methods aremostly based on simple heuristics, leading to sub-optimal performance. In thiswork, we formulate in-context example selection as a subset selection problem.We propose CEIL (Compositional Exemplars for In-context Learning), which isinstantiated by Determinantal Point Processes (DPPs) to model the interactionbetween the given input and in-context examples, and optimized through acarefully-designed contrastive learning objective to obtain preference fromLMs. We validate CEIL on 12 classification and generation datasets from 7distinct NLP tasks, including sentiment analysis, paraphrase detection, naturallanguage inference, commonsense reasoning, open-domain question answering, codegeneration, and semantic parsing. Extensive experiments demonstrate not onlythe state-of-the-art performance but also the transferability andcompositionality of CEIL, shedding new light on effective and efficientin-context learning. Our code is released athttps://github.com/HKUNLP/icl-ceil.",Jiacheng Ye,2023/2/11,2023/6/20
2305.15035v2,Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations,http://arxiv.org/abs/2305.15035v2,"Large language models (LLMs) have exhibited striking in-context learning(ICL) ability to adapt to target tasks with a few input-output demonstrations.For better ICL, different methods are proposed to select representativedemonstrations from existing training corpora. However, such settings are notaligned with real-world practices, as end-users usually query LMs withoutaccess to demonstration pools. In this work, we introduce Self-ICL -- a simpleframework which bootstraps LMs' intrinsic capabilities to perform zero-shotICL. Given a test input, Self-ICL first prompts the model to generatepseudo-inputs. Next, the model predicts pseudo-labels for the pseudo-inputs viazero-shot prompting. Finally, we perform ICL for the test input with thepseudo-input-label pairs as demonstrations. Evaluation on 23 BIG-Bench Hardtasks shows Self-ICL outperforms zero-shot baselines on both average accuracyand head-to-head comparison. Moreover, with zero-shot chain-of-thought,Self-ICL achieves results comparable to using real demonstrations.Additionally, we conduct a range of analyses to validate Self-ICL'seffectiveness and provide insights for its behaviors under different settings.",Wei-Lin Chen,2023/5/24,2023/10/23
astro-ph/0605603v1,The Formation and Evolution of Intracluster Light,http://arxiv.org/abs/astro-ph/0605603v1,"Using N-body simulations, we have modeled the production and evolution ofdiffuse, low surface brightness intracluster light (ICL) in three simulatedgalaxy clusters. Using an observational definition of ICL to be luminosity at asurface brightness mu_V>26.5 mag/sq.arcsec, we have found that the fraction ofcluster luminosity contained in ICL generally increases as clusters evolve,although there are large deviations from this trend over short timescales,including sustained periods of decreasing ICL luminosity. Most ICL luminosityincreases come in short, discrete events which are highly correlated with groupaccretion events within the cluster. In evolved clusters we find that ~10-15%of the clusters' luminosity is at ICL surface brightness. The morphologicalstructure of the ICL changes with time, evolving from a complex of filamentsand small-scale, relatively high surface brightness features early in acluster's history, to a more diffuse and amorphous cluster-scale ICL envelopeat later times. Finally, we also see a correlation between the evolution of ICLat different surface brightnesses, including a time delay between the evolutionof faint and extremely faint surface brightness features which is traced to thediffering dynamical timescales in the group and cluster environment.",Craig S. Rudick,2006/5/23,2006/5/23
2212.10007v2,CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context,http://arxiv.org/abs/2212.10007v2,"While pre-trained language models (LM) for code have achieved great successin code completion, they generate code conditioned only on the contents withinthe file, i.e., in-file context, but ignore the rich semantics in other fileswithin the same project, i.e., cross-file context, a critical source ofinformation that is especially useful in modern modular software development.Such overlooking constrains code language models' capacity in code completion,leading to unexpected behaviors such as generating hallucinated class memberfunctions or function calls with unexpected arguments. In this work, we developa cross-file context finder tool, CCFINDER, that effectively locates andretrieves the most relevant cross-file context. We propose CoCoMIC, a frameworkthat incorporates cross-file context to learn the in-file and cross-filecontext jointly on top of pretrained code LMs. CoCoMIC successfully improvesthe existing code LM with a 33.94% relative increase in exact match and a28.69% relative increase in identifier matching for code completion when thecross-file context is provided.",Yangruibo Ding,2022/12/20,2023/5/24
2305.09137v1,Pre-Training to Learn in Context,http://arxiv.org/abs/2305.09137v1,"In-context learning, where pre-trained language models learn to perform tasksfrom task examples and instructions in their contexts, has attracted muchattention in the NLP community. However, the ability of in-context learning isnot fully exploited because language models are not explicitly trained to learnin context. To this end, we propose PICL (Pre-training for In-ContextLearning), a framework to enhance the language models' in-context learningability by pre-training the model on a large collection of ""intrinsic tasks"" inthe general plain-text corpus using the simple language modeling objective.PICL encourages the model to infer and perform tasks by conditioning on thecontexts while maintaining task generalization of pre-trained models. Weevaluate the in-context learning performance of the model trained with PICL onseven widely-used text classification datasets and the Super-NaturalInstrctionsbenchmark, which contains 100+ NLP tasks formulated to text generation. Ourexperiments show that PICL is more effective and task-generalizable than arange of baselines, outperforming larger language models with nearly 4xparameters. The code is publicly available at https://github.com/thu-coai/PICL.",Yuxian Gu,2023/5/16,2023/5/16
1910.02216v2,JuICe: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation,http://arxiv.org/abs/1910.02216v2,"Interactive programming with interleaved code snippet cells and naturallanguage markdown is recently gaining popularity in the form of Jupyternotebooks, which accelerate prototyping and collaboration. To study codegeneration conditioned on a long context history, we present JuICe, a corpus of1.5 million examples with a curated test set of 3.7K instances based on onlineprogramming assignments. Compared with existing contextual code generationdatasets, JuICe provides refined human-curated data, open-domain code, and anorder of magnitude more training data. Using JuICe, we train models for twotasks: (1) generation of the API call sequence in a code cell, and (2) fullcode cell generation, both conditioned on the NL-Code history up to aparticular code cell. Experiments using current baseline code generation modelsshow that both context and distant supervision aid in generation, and that thedataset is challenging for current systems.",Rajas Agashe,2019/10/5,2019/10/9
2311.09635v1,Evaluating In-Context Learning of Libraries for Code Generation,http://arxiv.org/abs/2311.09635v1,"Contemporary Large Language Models (LLMs) exhibit a high degree of codegeneration and comprehension capability. A particularly promising area is theirability to interpret code modules from unfamiliar libraries for solvinguser-instructed tasks. Recent work has shown that large proprietary LLMs canlearn novel library usage in-context from demonstrations. These results raiseseveral open questions: whether demonstrations of library usage is required,whether smaller (and more open) models also possess such capabilities, etc. Inthis work, we take a broader approach by systematically evaluating a diversearray of LLMs across three scenarios reflecting varying levels of domainspecialization to understand their abilities and limitations in generating codebased on libraries defined in-context. Our results show that even smalleropen-source LLMs like Llama-2 and StarCoder demonstrate an adept understandingof novel code libraries based on specification presented in-context. Ourfindings further reveal that LLMs exhibit a surprisingly high proficiency inlearning novel library modules even when provided with just natural languagedescriptions or raw code implementations of the functions, which are oftencheaper to obtain than demonstrations. Overall, our results pave the way forharnessing LLMs in more adaptable and dynamic coding environments.",Arkil Patel,2023/11/16,2023/11/16
2302.05527v2,CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code,http://arxiv.org/abs/2302.05527v2,"Since the rise of neural natural-language-to-code models (NL->Code) that cangenerate long expressions and statements rather than a single next-token, oneof the major problems has been reliably evaluating their generated output. Inthis paper, we propose CodeBERTScore: an evaluation metric for code generation,which builds on BERTScore (Zhang et al., 2020). Instead of encoding only thegenerated tokens as in BERTScore, CodeBERTScore also encodes the naturallanguage input preceding the generated code, thus modeling the consistencybetween the generated code and its given natural language context as well. Weperform an extensive evaluation of CodeBERTScore across four programminglanguages. We find that CodeBERTScore achieves a higher correlation with humanpreference and with functional correctness than all existing metrics. That is,generated code that receives a higher score by CodeBERTScore is more likely tobe preferred by humans, as well as to function correctly when executed. Werelease five language-specific pretrained models to use with our publiclyavailable code. Our language-specific models have been downloaded more than1,000,000 times from the Huggingface Hub. Our code and data are available athttps://github.com/neulab/code-bert-score",Shuyan Zhou,2023/2/10,2023/10/31
1909.03147v1,Self Learning from Large Scale Code Corpus to Infer Structure of Method Invocations,http://arxiv.org/abs/1909.03147v1,"Automatically generating code from a textual description of method invocationconfronts challenges. There were two current research directions for thisproblem. One direction focuses on considering a textual description of methodinvocations as a separate Natural Language query and do not consider thesurrounding context of the code. Another direction takes advantage of apractical large scale code corpus for providing a Machine Translation model togenerate code. However, this direction got very low accuracy. In this work, wetried to improve these drawbacks by proposing MethodInfoToCode, an approachthat embeds context information and optimizes the ability of learning oforiginal Phrase-based Statistical Machine Translation (PBMT) in NLP to inferimplementation of method invocation given method name and other contextinformation. We conduct an expression prediction models learned from 2.86million method invocations from the practical data of high qualities corpus onGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,and Xstream. By the evaluation, we show that if the developers only write themethod name of a method invocation in a body of a method, MethodInfoToCode canpredict the generated expression correctly at 73% in F1 score.",Hung Phan,2019/9/6,2019/9/6
2003.11696v2,CAZSL: Zero-Shot Regression for Pushing Models by Generalizing Through Context,http://arxiv.org/abs/2003.11696v2,"Learning accurate models of the physical world is required for a lot ofrobotic manipulation tasks. However, during manipulation, robots are expectedto interact with unknown workpieces so that building predictive models whichcan generalize over a number of these objects is highly desirable. In thispaper, we study the problem of designing deep learning agents which cangeneralize their models of the physical world by building context-awarelearning models. The purpose of these agents is to quickly adapt and/orgeneralize their notion of physics of interaction in the real world based oncertain features about the interacting objects that provide different contextsto the predictive models. With this motivation, we present context-aware zeroshot learning (CAZSL, pronounced as casual) models, an approach utilizing aSiamese network architecture, embedding space masking and regularization basedon context variables which allows us to learn a model that can generalize todifferent parameters or features of the interacting objects. We test ourproposed learning algorithm on the recently released Omnipush datatset thatallows testing of meta-learning capabilities using low-dimensional data. Codesfor CAZSL are available at https://www.merl.com/research/license/CAZSL.",Wenyu Zhang,2020/3/26,2020/11/1
2305.12461v1,Towards Tracing Code Provenance with Code Watermarking,http://arxiv.org/abs/2305.12461v1,"Recent advances in large language models have raised wide concern ingenerating abundant plausible source code without scrutiny, and thus tracingthe provenance of code emerges as a critical issue. To solve the issue, wepropose CodeMark, a watermarking system that hides bit strings into variablesrespecting the natural and operational semantics of the code. For naturalness,we novelly introduce a contextual watermarking scheme to generate watermarkedvariables more coherent in the context atop graph neural networks. Eachvariable is treated as a node on the graph and the node feature gathersneighborhood (context) information through learning. Watermarks embedded intothe features are thus reflected not only by the variables but also by the localcontexts. We further introduce a pre-trained model on source code as a teacherto guide more natural variable generation. Throughout the embedding, theoperational semantics are preserved as only variable names are altered. Beyondguaranteeing code-specific properties, CodeMark is superior in watermarkingaccuracy, capacity, and efficiency due to a more diversified pattern generated.Experimental results show CodeMark outperforms the SOTA watermarking systemswith a better balance of the watermarking requirements.",Wei Li,2023/5/21,2023/5/21
2106.01501v1,Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins,http://arxiv.org/abs/2106.01501v1,"Structured data, or data that adheres to a pre-defined schema, can sufferfrom fragmented context: information describing a single entity can bescattered across multiple datasets or tables tailored for specific businessneeds, with no explicit linking keys (e.g., primary key-foreign keyrelationships or heuristic functions). Context enrichment, or rebuildingfragmented context, using keyless joins is an implicit or explicit step inmachine learning (ML) pipelines over structured data sources. This process istedious, domain-specific, and lacks support in now-prevalent no-code ML systemsthat let users create ML pipelines using just input data and high-levelconfiguration files. In response, we propose Ember, a system that abstracts andautomates keyless joins to generalize context enrichment. Our key insight isthat Ember can enable a general keyless join operator by constructing an indexpopulated with task-specific embeddings. Ember learns these embeddings byleveraging Transformer-based representation learning techniques. We describeour core architectural principles and operators when developing Ember, andempirically demonstrate that Ember allows users to develop no-code pipelinesfor five domains, including search, recommendation and question answering, andcan exceed alternatives by up to 39% recall, with as little as a single lineconfiguration change.",Sahaana Suri,2021/6/2,2021/6/2
2303.14542v1,Combining Contexts from Multiple Sources for Documentation-Specific Code Example Generation,http://arxiv.org/abs/2303.14542v1,"Code example is a crucial part of good documentation. It helps the developersto understand the documentation easily and use the corresponding code unit(e.g., method) properly. However, many official documentation still lacks(good) code example and it is one of the common documentation issues as foundby several studies. Hence in this paper, we consider automatic code examplegeneration for documentation, a direction less explored by the existingresearch. We employ Codex, a GPT-3 based model, pre-trained on both natural andprogramming languages to generate code examples from source code anddocumentation given as input. Our preliminary investigation on 40 scikit-learnmethods reveals that this approach is able to generate good code examples where72.5% code examples were executed without error (passability) and 82.5%properly dealt with the target method and documentation (relevance). We alsofind that incorporation of error logs (produced by the compiler while executinga failed code example) in the input further improves the passability from 72.5%to 87.5%. Thus, our investigation sets the base of documentation-specific codeexample generation and warrants in-depth future studies.",Junaed Younus Khan,2023/3/25,2023/3/25
2208.01066v3,What Can Transformers Learn In-Context? A Case Study of Simple Function Classes,http://arxiv.org/abs/2208.01066v3,"In-context learning refers to the ability of a model to condition on a promptsequence consisting of in-context examples (input-output pairs corresponding tosome task) along with a new query input, and generate the corresponding output.Crucially, in-context learning happens only at inference time without anyparameter updates to the model. While large language models such as GPT-3exhibit some ability to perform in-context learning, it is unclear what therelationship is between tasks on which this succeeds and what is present in thetraining data. To make progress towards understanding in-context learning, weconsider the well-defined problem of training a model to in-context learn afunction class (e.g., linear functions): that is, given data derived from somefunctions in the class, can we train a model to in-context learn ""most""functions from this class? We show empirically that standard Transformers canbe trained from scratch to perform in-context learning of linear functions --that is, the trained model is able to learn unseen linear functions fromin-context examples with performance comparable to the optimal least squaresestimator. In fact, in-context learning is possible even under two forms ofdistribution shift: (i) between the training data of the model andinference-time prompts, and (ii) between the in-context examples and the queryinput during inference. We also show that we can train Transformers toin-context learn more complex function classes -- namely sparse linearfunctions, two-layer neural networks, and decision trees -- with performancethat matches or exceeds task-specific learning algorithms. Our code and modelsare available at https://github.com/dtsip/in-context-learning .",Shivam Garg,2022/8/1,2023/8/11
1906.07108v1,Coupling Retrieval and Meta-Learning for Context-Dependent Semantic Parsing,http://arxiv.org/abs/1906.07108v1,"In this paper, we present an approach to incorporate retrieved datapoints assupporting evidence for context-dependent semantic parsing, such as generatingsource code conditioned on the class environment. Our approach naturallycombines a retrieval model and a meta-learner, where the former learns to findsimilar datapoints from the training data, and the latter considers retrieveddatapoints as a pseudo task for fast adaptation. Specifically, our retriever isa context-aware encoder-decoder model with a latent variable which takescontext environment into consideration, and our meta-learner learns to utilizeretrieved datapoints in a model-agnostic meta-learning paradigm for fastadaptation. We conduct experiments on CONCODE and CSQA datasets, where thecontext refers to class environment in JAVA codes and conversational history,respectively. We use sequence-to-action model as the base semantic parser,which performs the state-of-the-art accuracy on both datasets. Results showthat both the context-aware retriever and the meta-learning strategy improveaccuracy, and our approach performs better than retrieve-and-edit baselines.",Daya Guo,2019/6/17,2019/6/17
2005.04661v1,Learning Context-Based Non-local Entropy Modeling for Image Compression,http://arxiv.org/abs/2005.04661v1,"The entropy of the codes usually serves as the rate loss in the recentlearned lossy image compression methods. Precise estimation of theprobabilistic distribution of the codes plays a vital role in the performance.However, existing deep learning based entropy modeling methods generally assumethe latent codes are statistically independent or depend on some sideinformation or local context, which fails to take the global similarity withinthe context into account and thus hinder the accurate entropy estimation. Toaddress this issue, we propose a non-local operation for context modeling byemploying the global similarity within the context. Specifically, we firstintroduce the proxy similarity functions and spatial masks to handle themissing reference problem in context modeling. Then, we combine the local andthe global context via a non-local attention block and employ it in maskedconvolutional networks for entropy modeling. The entropy model is furtheradopted as the rate loss in a joint rate-distortion optimization to guide thetraining of the analysis transform and the synthesis transform network intransforming coding framework. Considering that the width of the transforms isessential in training low distortion models, we finally produce a U-Net blockin the transforms to increase the width with manageable memory consumption andtime complexity. Experiments on Kodak and Tecnick datasets demonstrate thesuperiority of the proposed context-based non-local attention block in entropymodeling and the U-Net block in low distortion compression against the existingimage compression standards and recent deep image compression models.",Mu Li,2020/5/10,2020/5/10
2306.03438v2,Large Language Models of Code Fail at Completing Code with Potential Bugs,http://arxiv.org/abs/2306.03438v2,"Large language models of code (Code-LLMs) have recently brought tremendousadvances to code completion, a fundamental feature of programming assistanceand code intelligence. However, most existing works ignore the possiblepresence of bugs in the code context for generation, which are inevitable insoftware development. Therefore, we introduce and study the buggy-codecompletion problem, inspired by the realistic scenario of real-time codesuggestion where the code context contains potential bugs -- anti-patterns thatcan become bugs in the completed program. To systematically study the task, weintroduce two datasets: one with synthetic bugs derived from semantics-alteringoperator changes (buggy-HumanEval) and one with realistic bugs derived fromuser submissions to coding problems (buggy-FixEval). We find that the presenceof potential bugs significantly degrades the generation performance of thehigh-performing Code-LLMs. For instance, the passing rates of CODEGEN-2B-MONOon test cases of buggy-HumanEval drop more than 50% given a single potentialbug in the context. Finally, we investigate several post-hoc methods formitigating the adverse effect of potential bugs and find that there remains asignificant gap in post-mitigation performance.",Tuan Dinh,2023/6/6,2023/12/1
2007.11671v2,DeepClone: Modeling Clones to Generate Code Predictions,http://arxiv.org/abs/2007.11671v2,"Programmers often reuse code from source code repositories to reduce thedevelopment effort. Code clones are candidates for reuse in exploratory orrapid development, as they represent often repeated functionality in softwaresystems. To facilitate code clone reuse, we propose DeepClone, a novel approachutilizing a deep learning algorithm for modeling code clones to predict thenext set of tokens (possibly a complete clone method body) based on the codewritten so far. The predicted tokens require minimal customization to fit thecontext. DeepClone applies natural language processing techniques to learn froma large code corpus, and generates code tokens using the model learned. We havequantitatively evaluated our solution to assess (1) our model's quality and itsaccuracy in token prediction, and (2) its performance and effectiveness inclone method prediction. We also discuss various application scenarios for ourapproach.",Muhammad Hammad,2020/7/22,2020/12/5
2310.07289v1,Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators,http://arxiv.org/abs/2310.07289v1,"Large language models (LLMs) outperform information retrieval techniques fordownstream knowledge-intensive tasks when being prompted to generate worldknowledge. However, community concerns abound regarding the factuality andpotential implications of using this uncensored knowledge. In light of this, weintroduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed tosystematically and automatically evaluate generated knowledge from siximportant perspectives -- Factuality, Relevance, Coherence, Informativeness,Helpfulness and Validity. We conduct an extensive empirical analysis of thegenerated knowledge from three different types of LLMs on two widely studiedknowledge-intensive tasks, i.e., open-domain question answering andknowledge-grounded dialogue. Surprisingly, our study reveals that thefactuality of generated knowledge, even if lower, does not significantly hinderdownstream tasks. Instead, the relevance and coherence of the outputs are moreimportant than small factual mistakes. Further, we show how to use CONNER toimprove knowledge-intensive tasks by designing two strategies: PromptEngineering and Knowledge Selection. Our evaluation code and LLM-generatedknowledge with human annotations will be released to facilitate futureresearch.",Liang Chen,2023/10/11,2023/10/11
2304.01508v3,EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,http://arxiv.org/abs/2304.01508v3,"Skin lesion recognition using deep learning has made remarkable progress, andthere is an increasing need for deploying these systems in real-worldscenarios. However, recent research has revealed that deep neural networks forskin lesion recognition may overly depend on disease-irrelevant image artifacts(i.e., dark corners, dense hairs), leading to poor generalization in unseenenvironments. To address this issue, we propose a novel domain generalizationmethod called EPVT, which involves embedding prompts into the visiontransformer to collaboratively learn knowledge from diverse domains.Concretely, EPVT leverages a set of domain prompts, each of which plays as adomain expert, to capture domain-specific knowledge; and a shared prompt forgeneral knowledge over the entire dataset. To facilitate knowledge sharing andthe interaction of different prompts, we introduce a domain prompt generatorthat enables low-rank multiplicative updates between domain prompts and theshared prompt. A domain mixup strategy is additionally devised to reduce theco-occurring artifacts in each domain, which allows for more flexible decisionmargins and mitigates the issue of incorrectly assigned domain labels.Experiments on four out-of-distribution datasets and six different biased ISICdatasets demonstrate the superior generalization ability of EPVT in skin lesionrecognition across various environments. Code is avaliable athttps://github.com/SiyuanYan1/EPVT.",Siyuan Yan,2023/4/4,2023/6/27
2110.08387v3,Generated Knowledge Prompting for Commonsense Reasoning,http://arxiv.org/abs/2110.08387v3,"It remains an open question whether incorporating external knowledge benefitscommonsense reasoning while maintaining the flexibility of pretrained sequencemodels. To investigate this question, we develop generated knowledge prompting,which consists of generating knowledge from a language model, then providingthe knowledge as additional input when answering a question. Our method doesnot require task-specific supervision for knowledge integration, or access to astructured knowledge base, yet it improves performance of large-scale,state-of-the-art models on four commonsense reasoning tasks, achievingstate-of-the-art results on numerical commonsense (NumerSense), generalcommonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks.Generated knowledge prompting highlights large-scale language models asflexible sources of external knowledge for improving commonsense reasoning. Ourcode is available at https://github.com/liujch1998/GKP",Jiacheng Liu,2021/10/15,2022/9/28
2305.11790v3,Prompting with Pseudo-Code Instructions,http://arxiv.org/abs/2305.11790v3,"Prompting with natural language instructions has recently emerged as apopular method of harnessing the capabilities of large language models. Giventhe inherent ambiguity present in natural language, it is intuitive to considerthe possible advantages of prompting with less ambiguous prompt styles, such asthe use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helpsimprove the performance of pre-trained language models. We manually create adataset of pseudo-code prompts for 132 different tasks spanning classification,QA and generative language tasks, sourced from the Super-NaturalInstructionsdataset. Using these prompts along with their counterparts in natural language,we study their performance on two LLM families - BLOOM and CodeGen. Ourexperiments show that using pseudo-code instructions leads to better results,with an average increase (absolute) of 7-16 points in F1 scores forclassification tasks and an improvement (relative) of 12-38% in aggregateROUGE-L scores across all tasks. We include detailed ablation studies whichindicate that code comments, docstrings, and the structural clues encoded inpseudo-code all contribute towards the improvement in performance.  To the best of our knowledge our work is the first to demonstrate howpseudo-code prompts can be helpful in improving the performance of pre-trainedLMs.",Mayank Mishra,2023/5/19,2023/10/19
2307.06948v2,Self-regulating Prompts: Foundational Model Adaptation without Forgetting,http://arxiv.org/abs/2307.06948v2,"Prompt learning has emerged as an efficient alternative for fine-tuningfoundational models, such as CLIP, for various downstream tasks. Conventionallytrained using the task-specific objective, i.e., cross-entropy loss, promptstend to overfit downstream data distributions and find it challenging tocapture task-agnostic general features from the frozen CLIP. This leads to theloss of the model's original generalization capability. To address this issue,our work introduces a self-regularization framework for prompting calledPromptSRC (Prompting with Self-regulating Constraints). PromptSRC guides theprompts to optimize for both task-specific and task-agnostic generalrepresentations using a three-pronged approach by: (a) regulating promptedrepresentations via mutual agreement maximization with the frozen model, (b)regulating with self-ensemble of prompts over the training trajectory to encodetheir complementary strengths, and (c) regulating with textual diversity tomitigate sample diversity imbalance with the visual branch. To the best of ourknowledge, this is the first regularization framework for prompt learning thatavoids overfitting by jointly attending to pre-trained model features, thetraining trajectory during prompting, and the textual diversity. PromptSRCexplicitly steers the prompts to learn a representation space that maximizesperformance on downstream tasks without compromising CLIP generalization. Weperform extensive experiments on 4 benchmarks where PromptSRC overall performsfavorably well compared to the existing methods. Our code and pre-trainedmodels are publicly available at: https://github.com/muzairkhattak/PromptSRC.",Muhammad Uzair Khattak,2023/7/13,2023/8/24
2210.03629v3,ReAct: Synergizing Reasoning and Acting in Language Models,http://arxiv.org/abs/2210.03629v3,"While large language models (LLMs) have demonstrated impressive capabilitiesacross tasks in language understanding and interactive decision making, theirabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.action plan generation) have primarily been studied as separate topics. In thispaper, we explore the use of LLMs to generate both reasoning traces andtask-specific actions in an interleaved manner, allowing for greater synergybetween the two: reasoning traces help the model induce, track, and updateaction plans as well as handle exceptions, while actions allow it to interfacewith external sources, such as knowledge bases or environments, to gatheradditional information. We apply our approach, named ReAct, to a diverse set oflanguage and decision making tasks and demonstrate its effectiveness overstate-of-the-art baselines, as well as improved human interpretability andtrustworthiness over methods without reasoning or acting components.Concretely, on question answering (HotpotQA) and fact verification (Fever),ReAct overcomes issues of hallucination and error propagation prevalent inchain-of-thought reasoning by interacting with a simple Wikipedia API, andgenerates human-like task-solving trajectories that are more interpretable thanbaselines without reasoning traces. On two interactive decision makingbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation andreinforcement learning methods by an absolute success rate of 34% and 10%respectively, while being prompted with only one or two in-context examples.Project site with code: https://react-lm.github.io",Shunyu Yao,2022/10/6,2023/3/10
2310.04406v2,Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models,http://arxiv.org/abs/2310.04406v2,"While large language models (LLMs) have demonstrated impressive performanceon a range of decision-making tasks, they rely on simple acting processes andfall short of broad deployment as autonomous agents. We introduce LATS(Language Agent Tree Search), a general framework that synergizes thecapabilities of LLMs in planning, acting, and reasoning. Drawing inspirationfrom Monte Carlo tree search in model-based reinforcement learning, LATSemploys LLMs as agents, value functions, and optimizers, repurposing theirlatent strengths for enhanced decision-making. What is crucial in this methodis the use of an environment for external feedback, which offers a moredeliberate and adaptive problem-solving mechanism that moves beyond thelimitations of existing techniques. Our experimental evaluation across diversedomains, such as programming, HotPotQA, and WebShop, illustrates theapplicability of LATS for both reasoning and acting. In particular, LATSachieves 94.4% for programming on HumanEval with GPT-4 and an average score of75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectivenessand generality of our method.",Andy Zhou,2023/10/6,2023/12/5
2401.01529v1,Glance and Focus: Memory Prompting for Multi-Event Video Question Answering,http://arxiv.org/abs/2401.01529v1,"Video Question Answering (VideoQA) has emerged as a vital tool to evaluateagents' ability to understand human daily behaviors. Despite the recent successof large vision language models in many multi-modal tasks, complex situationreasoning over videos involving multiple human-object interaction events stillremains challenging. In contrast, humans can easily tackle it by using a seriesof episode memories as anchors to quickly locate question-related key momentsfor reasoning. To mimic this effective reasoning strategy, we propose theGlance-Focus model. One simple way is to apply an action detection model topredict a set of actions as key memories. However, these actions within aclosed set vocabulary are hard to generalize to various video domains. Insteadof that, we train an Encoder-Decoder to generate a set of dynamic eventmemories at the glancing stage. Apart from using supervised bipartite matchingto obtain the event memories, we further design an unsupervised memorygeneration method to get rid of dependence on event annotations. Next, at thefocusing stage, these event memories act as a bridge to establish thecorrelation between the questions with high-level event concepts and low-levellengthy video content. Given the question, the model first focuses on thegenerated key event memory, then focuses on the most relevant moment forreasoning through our designed multi-level cross-attention mechanism. Weconduct extensive experiments on four Multi-Event VideoQA benchmarks includingSTAR, EgoTaskQA, AGQA, and NExT-QA. Our proposed model achievesstate-of-the-art results, surpassing current large models in variouschallenging reasoning tasks. The code and models are available athttps://github.com/ByZ0e/Glance-Focus.",Ziyi Bai,2024/1/3,2024/1/3
2312.11444v2,An In-depth Look at Gemini's Language Abilities,http://arxiv.org/abs/2312.11444v2,"The recently released Google Gemini class of models are the first tocomprehensively report results that rival the OpenAI GPT series across a widevariety of tasks. In this paper, we do an in-depth exploration of Gemini'slanguage abilities, making two contributions. First, we provide a third-party,objective comparison of the abilities of the OpenAI GPT and Google Geminimodels with reproducible code and fully transparent results. Second, we take acloser look at the results, identifying areas where one of the two modelclasses excels. We perform this analysis over 10 datasets testing a variety oflanguage abilities, including reasoning, answering knowledge-based questions,solving math problems, translating between languages, generating code, andacting as instruction-following agents. From this analysis, we find that GeminiPro achieves accuracy that is close but slightly inferior to the correspondingGPT 3.5 Turbo on all tasks that we benchmarked. We further provide explanationsfor some of this under-performance, including failures in mathematicalreasoning with many digits, sensitivity to multiple-choice answer ordering,aggressive content filtering, and others. We also identify areas where Geminidemonstrates comparably high performance, including generation into non-Englishlanguages, and handling longer and more complex reasoning chains. Code and datafor reproduction can be found at https://github.com/neulab/gemini-benchmark",Syeda Nahida Akter,2023/12/18,2023/12/24
1605.03222v1,Action Recognition in Video Using Sparse Coding and Relative Features,http://arxiv.org/abs/1605.03222v1,"This work presents an approach to category-based action recognition in videousing sparse coding techniques. The proposed approach includes two maincontributions: i) A new method to handle intra-class variations by decomposingeach video into a reduced set of representative atomic action acts orkey-sequences, and ii) A new video descriptor, ITRA: Inter-Temporal RelationalAct Descriptor, that exploits the power of comparative reasoning to capturerelative similarity relations among key-sequences. In terms of the method toobtain key-sequences, we introduce a loss function that, for each video, leadsto the identification of a sparse set of representative key-frames capturingboth, relevant particularities arising in the input video, as well as relevantgeneralities arising in the complete class collection. In terms of the methodto obtain the ITRA descriptor, we introduce a novel scheme to quantify relativeintra and inter-class similarities among local temporal patterns arising in thevideos. The resulting ITRA descriptor demonstrates to be highly effective todiscriminate among action categories. As a result, the proposed approachreaches remarkable action recognition performance on several popular benchmarkdatasets, outperforming alternative state-of-the-art techniques by a largemargin.",Anali Alfaro,2016/5/10,2016/5/10
2302.09646v2,A Planning-Based Explainable Collaborative Dialogue System,http://arxiv.org/abs/2302.09646v2,"Eva is a multimodal conversational system that helps users to accomplishtheir domain goals through collaborative dialogue. The system does this byinferring users' intentions and plans to achieve those goals, detects whetherobstacles are present, finds plans to overcome them or to achieve higher-levelgoals, and plans its actions, including speech acts,to help users accomplishthose goals. In doing so, the system maintains and reasons with its ownbeliefs, goals and intentions, and explicitly reasons about those of its user.Belief reasoning is accomplished with a modal Horn-clause meta-interpreter. Theplanning and reasoning subsystems obey the principles of persistent goals andintentions, including the formation and decomposition of intentions to performcomplex actions, as well as the conditions under which they can be given up. Invirtue of its planning process, the system treats its speech acts just like itsother actions -- physical acts affect physical states, digital acts affectdigital states, and speech acts affect mental and social states. This generalapproach enables Eva to plan a variety of speech acts including requests,informs, questions, confirmations, recommendations, offers, acceptances,greetings, and emotive expressions. Each of these has a formally specifiedsemantics which is used during the planning and reasoning processes. Because itcan keep track of different users' mental states, it can engage in multi-partydialogues. Importantly, Eva can explain its utterances because it has created aplan standing behind each of them. Finally, Eva employs multimodal input andoutput, driving an avatar that can perceive and employ facial and headmovements along with emotive speech acts.",Philip R. Cohen,2023/2/19,2023/3/2
1707.03938v2,Representation Learning for Grounded Spatial Reasoning,http://arxiv.org/abs/1707.03938v2,"The interpretation of spatial references is highly contextual, requiringjoint inference over both language and the environment. We consider the task ofspatial reasoning in a simulated environment, where an agent can act andreceive rewards. The proposed model learns a representation of the worldsteered by instruction text. This design allows for precise alignment of localneighborhoods with corresponding verbalizations, while also handling globalreferences in the instructions. We train our model with reinforcement learningusing a variant of generalized value iteration. The model outperformsstate-of-the-art approaches on several metrics, yielding a 45% reduction ingoal localization error.",Michael Janner,2017/7/13,2017/11/11
2309.16298v2,At Which Training Stage Does Code Data Help LLMs Reasoning?,http://arxiv.org/abs/2309.16298v2,"Large Language Models (LLMs) have exhibited remarkable reasoning capabilitiesand become the foundation of language technologies. Inspired by the greatsuccess of code data in training LLMs, we naturally wonder at which trainingstage introducing code data can really help LLMs reasoning. To this end, thispaper systematically explores the impact of code data on LLMs at differentstages. Concretely, we introduce the code data at the pre-training stage,instruction-tuning stage, and both of them, respectively. Then, the reasoningcapability of LLMs is comprehensively and fairly evaluated via six reasoningtasks in five domains. We critically analyze the experimental results andprovide conclusions with insights. First, pre-training LLMs with the mixture ofcode and text can significantly enhance LLMs' general reasoning capabilityalmost without negative transfer on other tasks. Besides, at theinstruction-tuning stage, code data endows LLMs the task-specific reasoningcapability. Moreover, the dynamic mixing strategy of code and text data assistsLLMs to learn reasoning capability step-by-step during training. These insightsdeepen the understanding of LLMs regarding reasoning ability for theirapplication, such as scientific question answering, legal support, etc. Thesource code and model parameters are released at thelink:~\url{https://github.com/yingweima2022/CodeLLM}.",Yingwei Ma,2023/9/28,2023/9/30
1009.2902v1,Informal Control code logic,http://arxiv.org/abs/1009.2902v1,"General definitions as well as rules of reasoning regarding control codeproduction, distribution, deployment, and usage are described. The role oftesting, trust, confidence and risk analysis is considered. A rationale forcontrol code testing is sought and found for the case of safety criticalembedded control code.",Jan A. Bergstra,2010/9/15,2010/9/15
2210.04191v2,CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models,http://arxiv.org/abs/2210.04191v2,"We motivate and introduce CHARD: Clinical Health-Aware Reasoning acrossDimensions, to investigate the capability of text generation models to act asimplicit clinical knowledge bases and generate free-flow textual explanationsabout various health-related conditions across several dimensions. We collectand present an associated dataset, CHARDat, consisting of explanations about 52health conditions across three clinical dimensions. We conduct extensiveexperiments using BART and T5 along with data augmentation, and performautomatic, human, and qualitative analyses. We show that while our models canperform decently, CHARD is very challenging with strong potential for furtherexploration.",Steven Y. Feng,2022/10/9,2023/2/13
2010.02830v1,PRover: Proof Generation for Interpretable Reasoning over Rules,http://arxiv.org/abs/2010.02830v1,"Recent work by Clark et al. (2020) shows that transformers can act as 'softtheorem provers' by answering questions over explicitly provided knowledge innatural language. In our work, we take a step closer to emulating formaltheorem provers, by proposing PROVER, an interpretable transformer-based modelthat jointly answers binary questions over rule-bases and generates thecorresponding proofs. Our model learns to predict nodes and edges correspondingto proof graphs in an efficient constrained training paradigm. Duringinference, a valid proof, satisfying a set of global constraints is generated.We conduct experiments on synthetic, hand-authored, and human-paraphrasedrule-bases to show promising results for QA and proof generation, with stronggeneralization performance. First, PROVER generates proofs with an accuracy of87%, while retaining or improving performance on the QA task, compared toRuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trainedon questions requiring lower depths of reasoning, it generalizes significantlybetter to higher depths (up to 15% improvement). Third, PROVER obtains nearperfect QA accuracy of 98% using only 40% of the training data. However,generating proofs for questions requiring higher depths of reasoning becomeschallenging, and the accuracy drops to 65% for 'depth 5', indicatingsignificant scope for future work. Our code and models are publicly availableat https://github.com/swarnaHub/PRover",Swarnadeep Saha,2020/10/6,2020/10/6
2302.11520v4,Guiding Large Language Models via Directional Stimulus Prompting,http://arxiv.org/abs/2302.11520v4,"We introduce Directional Stimulus Prompting, a novel framework for guidingblack-box large language models (LLMs) toward specific desired outputs. Insteadof directly adjusting LLMs, our method employs a small tunable policy model(e.g., T5) to generate an auxiliary directional stimulus prompt for each inputinstance. These directional stimulus prompts act as nuanced, instance-specifichints and clues to guide LLMs in generating desired outcomes, such as includingspecific keywords in the generated summary. Our approach sidesteps thechallenges of direct LLM tuning by optimizing the policy model to exploredirectional stimulus prompts that align LLMs with desired behaviors. The policymodel can be optimized through 1) supervised fine-tuning using labeled data and2) reinforcement learning from offline or online rewards based on the LLM'soutput. We assess our method across summarization, dialogue responsegeneration, and chain-of-thought reasoning tasks. Our experiments demonstratethat the framework consistently improves LLMs' (e.g., ChatGPT, Codex,InstructGPT) performance on these supervised tasks using minimal labeled data.Notably, using just 80 dialogues on the MultiWOZ dataset, our approach enhancesChatGPT's performance by an impressive 41.4%, matching or surpassing some fullysupervised start-of-the-art models. Additionally, the instance-specificchain-of-thought prompt generated by our approach improves InstructGPT'sreasoning accuracy compared to human-crafted or automatically generatedprompts. The code and data are publicly available at\url{https://github.com/Leezekun/Directional-Stimulus-Prompting}.",Zekun Li,2023/2/22,2023/10/9
1502.05838v1,Automated Reasoning for Robot Ethics,http://arxiv.org/abs/1502.05838v1,"Deontic logic is a very well researched branch of mathematical logic andphilosophy. Various kinds of deontic logics are considered for differentapplication domains like argumentation theory, legal reasoning, and acts inmulti-agent systems. In this paper, we show how standard deontic logic can beused to model ethical codes for multi-agent systems. Furthermore we show howHyper, a high performance theorem prover, can be used to prove properties ofthese ethical codes.",Ulrich Furbach,2015/2/20,2015/2/20
2303.06573v2,Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search,http://arxiv.org/abs/2303.06573v2,"Precisely understanding users' contextual search intent has been an importantchallenge for conversational search. As conversational search sessions are muchmore diverse and long-tailed, existing methods trained on limited data stillshow unsatisfactory effectiveness and robustness to handle real conversationalsearch scenarios. Recently, large language models (LLMs) have demonstratedamazing capabilities for text generation and conversation understanding. Inthis work, we present a simple yet effective prompting framework, calledLLM4CS, to leverage LLMs as a text-based search intent interpreter to helpconversational search. Under this framework, we explore three prompting methodsto generate multiple query rewrites and hypothetical responses, and propose toaggregate them into an integrated representation that can robustly representthe user's real contextual search intent. Extensive automatic evaluations andhuman evaluations on three widely used conversational search benchmarks,including CAsT-19, CAsT-20, and CAsT-21, demonstrate the remarkable performanceof our simple LLM4CS framework compared with existing methods and even usinghuman rewrites. Our findings provide important evidence to better understandand leverage LLMs for conversational search.",Kelong Mao,2023/3/12,2023/10/19
2205.01308v1,Contrastive Learning for Prompt-Based Few-Shot Language Learners,http://arxiv.org/abs/2205.01308v1,"The impressive performance of GPT-3 using natural language prompts andin-context learning has inspired work on better fine-tuning of moderately-sizedmodels under this paradigm. Following this line of work, we present acontrastive learning framework that clusters inputs from the same class forbetter generality of models trained with only limited examples. Specifically,we propose a supervised contrastive framework that clusters inputs from thesame class under different augmented ""views"" and repel the ones from differentclasses. We create different ""views"" of an example by appending it withdifferent language prompts and contextual demonstrations. Combining acontrastive loss with the standard masked language modeling (MLM) loss inprompt-based few-shot learners, the experimental results show that our methodcan improve over the state-of-the-art methods in a diverse set of 15 languagetasks. Our framework makes minimal assumptions on the task or the base model,and can be applied to many recent methods with little modification. The codewill be made available at: https://github.com/yiren-jian/LM-SupCon.",Yiren Jian,2022/5/3,2022/5/3
2206.09363v1,Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning,http://arxiv.org/abs/2206.09363v1,"Conversational recommender systems (CRS) aim to proactively elicit userpreference and recommend high-quality items through natural languageconversations. Typically, a CRS consists of a recommendation module to predictpreferred items for users and a conversation module to generate appropriateresponses. To develop an effective CRS, it is essential to seamlessly integratethe two modules. Existing works either design semantic alignment strategies, orshare knowledge resources and representations between the two modules. However,these approaches still rely on different architectures or techniques to developthe two modules, making it difficult for effective module integration.  To address this problem, we propose a unified CRS model named UniCRS based onknowledge-enhanced prompt learning. Our approach unifies the recommendation andconversation subtasks into the prompt learning paradigm, and utilizesknowledge-enhanced prompts based on a fixed pre-trained language model (PLM) tofulfill both subtasks in a unified approach. In the prompt design, we includefused knowledge representations, task-specific soft tokens, and the dialoguecontext, which can provide sufficient contextual information to adapt the PLMfor the CRS task. Besides, for the recommendation subtask, we also incorporatethe generated response template as an important part of the prompt, to enhancethe information interaction between the two subtasks. Extensive experiments ontwo public CRS datasets have demonstrated the effectiveness of our approach.",Xiaolei Wang,2022/6/19,2022/6/19
2310.16164v1,"Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities",http://arxiv.org/abs/2310.16164v1,"Large Language Models (LLMs) are being increasingly employed in data sciencefor tasks like data preprocessing and analytics. However, data scientistsencounter substantial obstacles when conversing with LLM-powered chatbots andacting on their suggestions and answers. We conducted a mixed-methods study,including contextual observations, semi-structured interviews (n=14), and asurvey (n=114), to identify these challenges. Our findings highlight key issuesfaced by data scientists, including contextual data retrieval, formulatingprompts for complex tasks, adapting generated code to local environments, andrefining prompts iteratively. Based on these insights, we propose actionabledesign recommendations, such as data brushing to support context selection, andinquisitive feedback loops to improve communications with AI-based assistantsin data-science tools.",Bhavya Chopra,2023/10/24,2023/10/24
2307.11278v1,Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering,http://arxiv.org/abs/2307.11278v1,"Open-domain question answering (QA) tasks usually require the retrieval ofrelevant information from a large corpus to generate accurate answers. Wepropose a novel approach called Generator-Retriever-Generator (GRG) thatcombines document retrieval techniques with a large language model (LLM), byfirst prompting the model to generate contextual documents based on a givenquestion. In parallel, a dual-encoder network retrieves documents that arerelevant to the question from an external corpus. The generated and retrieveddocuments are then passed to the second LLM, which generates the final answer.By combining document retrieval and LLM generation, our approach addresses thechallenges of open-domain QA, such as generating informative and contextuallyrelevant answers. GRG outperforms the state-of-the-art generate-then-read andretrieve-then-read pipelines (GENREAD and RFiD) improving their performance atleast by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.We provide code, datasets, and checkpoints\footnote{\url{https://github.com/abdoelsayed2016/GRG}}",Abdelrahman Abdallah,2023/7/21,2023/7/21
2209.10063v3,Generate rather than Retrieve: Large Language Models are Strong Context Generators,http://arxiv.org/abs/2209.10063v3,"Knowledge-intensive tasks, such as open-domain question answering (QA),require access to a large amount of world or domain knowledge. A commonapproach for knowledge-intensive tasks is to employ a retrieve-then-readpipeline that first retrieves a handful of relevant contextual documents froman external corpus such as Wikipedia and then predicts an answer conditioned onthe retrieved documents. In this paper, we present a novel perspective forsolving knowledge-intensive tasks by replacing document retrievers with largelanguage model generators. We call our method generate-then-read (GenRead),which first prompts a large language model to generate contextutal documentsbased on a given question, and then reads the generated documents to producethe final answer. Furthermore, we propose a novel clustering-based promptingmethod that selects distinct prompts, resulting in the generated documents thatcover different perspectives, leading to better recall over acceptable answers.We conduct extensive experiments on three different knowledge-intensive tasks,including open-domain QA, fact checking, and dialogue system. Notably, GenReadachieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantlyoutperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0and +3.9, without retrieving any documents from any external knowledge source.Lastly, we demonstrate the model performance can be further improved bycombining retrieval and generation. Our code and generated documents can befound at https://github.com/wyu97/GenRead.",Wenhao Yu,2022/9/21,2023/1/25
2208.08340v4,Dual Modality Prompt Tuning for Vision-Language Pre-Trained Model,http://arxiv.org/abs/2208.08340v4,"With the emergence of large pre-trained vison-language model like CLIP,transferable representations can be adapted to a wide range of downstream tasksvia prompt tuning. Prompt tuning tries to probe the beneficial information fordownstream tasks from the general knowledge stored in the pre-trained model. Arecently proposed method named Context Optimization (CoOp) introduces a set oflearnable vectors as text prompt from the language side. However, tuning thetext prompt alone can only adjust the synthesized ""classifier"", while thecomputed visual features of the image encoder can not be affected , thusleading to sub-optimal solutions. In this paper, we propose a novelDual-modality Prompt Tuning (DPT) paradigm through learning text and visualprompts simultaneously. To make the final image feature concentrate more on thetarget visual concept, a Class-Aware Visual Prompt Tuning (CAVPT) scheme isfurther proposed in our DPT, where the class-aware visual prompt is generateddynamically by performing the cross attention between text prompts features andimage patch token embeddings to encode both the downstream task-relatedinformation and visual instance information. Extensive experimental results on11 datasets demonstrate the effectiveness and generalization ability of theproposed method. Our code is available in https://github.com/fanrena/DPT.",Yinghui Xing,2022/8/17,2023/7/7
2401.10588v1,DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval,http://arxiv.org/abs/2401.10588v1,"Text-video retrieval is a critical multi-modal task to find the most relevantvideo for a text query. Although pretrained models like CLIP have demonstratedimpressive potential in this area, the rising cost of fully finetuning thesemodels due to increasing model size continues to pose a problem. To addressthis challenge, prompt tuning has emerged as an alternative. However, existingworks still face two problems when adapting pretrained image-text models todownstream video-text tasks: (1) The visual encoder could only encodeframe-level features and failed to extract global-level general videoinformation. (2) Equipping the visual and text encoder with separated promptsfailed to mitigate the visual-text modality gap. To this end, we propose DGL, across-modal Dynamic prompt tuning method with Global-Local video attention. Incontrast to previous prompt tuning methods, we employ the shared latent spaceto generate local-level text and frame prompts that encourage inter-modalinteraction. Furthermore, we propose modeling video in a global-local attentionmechanism to capture global video information from the perspective of prompttuning. Extensive experiments reveal that when only 0.67% parameters are tuned,our cross-modal prompt tuning strategy DGL outperforms or is comparable tofully finetuning methods on MSR-VTT, VATEX, LSMDC, and ActivityNet datasets.Code will be available at https://github.com/knightyxp/DGL",Xiangpeng Yang,2024/1/19,2024/1/19
2306.05718v3,Learning Domain-Aware Detection Head with Prompt Tuning,http://arxiv.org/abs/2306.05718v3,"Domain adaptive object detection (DAOD) aims to generalize detectors trainedon an annotated source domain to an unlabelled target domain. However, existingmethods focus on reducing the domain bias of the detection backbone byinferring a discriminative visual encoder, while ignoring the domain bias inthe detection head. Inspired by the high generalization of vision-languagemodels (VLMs), applying a VLM as the robust detection backbone following adomain-aware detection head is a reasonable way to learn the discriminativedetector for each domain, rather than reducing the domain bias in traditionalmethods. To achieve the above issue, we thus propose a novel DAOD frameworknamed Domain-Aware detection head with Prompt tuning (DA-Pro), which appliesthe learnable domain-adaptive prompt to generate the dynamic detection head foreach domain. Formally, the domain-adaptive prompt consists of thedomain-invariant tokens, domain-specific tokens, and the domain-related textualdescription along with the class label. Furthermore, two constraints betweenthe source and target domains are applied to ensure that the domain-adaptiveprompt can capture the domains-shared and domain-specific knowledge. A promptensemble strategy is also proposed to reduce the effect of prompt disturbance.Comprehensive experiments over multiple cross-domain adaptation tasksdemonstrate that using the domain-adaptive prompt can produce an effectivelydomain-related detection head for boosting domain-adaptive object detection.Our code is available at https://github.com/Therock90421/DA-Pro.",Haochen Li,2023/6/9,2023/10/10
2309.15664v1,Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing,http://arxiv.org/abs/2309.15664v1,"Large-scale text-to-image generative models have been a ground-breakingdevelopment in generative AI, with diffusion models showing their astoundingability to synthesize convincing images following an input text prompt. Thegoal of image editing research is to give users control over the generatedimages by modifying the text prompt. Current image editing techniques aresusceptible to unintended modifications of regions outside the targeted area,such as on the background or on distractor objects which have some semantic orvisual relationship with the targeted object. According to our experimentalfindings, inaccurate cross-attention maps are at the root of this problem.Based on this observation, we propose Dynamic Prompt Learning (DPL) to forcecross-attention maps to focus on correct noun words in the text prompt. Byupdating the dynamic tokens for nouns in the textual input with the proposedleakage repairment losses, we achieve fine-grained image editing overparticular objects while preventing undesired changes to other image regions.Our method DPL, based on the publicly available Stable Diffusion, isextensively evaluated on a wide range of images, and consistently obtainssuperior results both quantitatively (CLIP score, Structure-Dist) andqualitatively (on user-evaluation). We show improved prompt editing results forWord-Swap, Prompt Refinement, and Attention Re-weighting, especially forcomplex multi-object scenes.",Kai Wang,2023/9/27,2023/9/27
2304.07221v2,Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models,http://arxiv.org/abs/2304.07221v2,"Pre-trained point cloud models have found extensive applications in 3Dunderstanding tasks like object classification and part segmentation. However,the prevailing strategy of full fine-tuning in downstream tasks leads to largeper-task storage overhead for model parameters, which limits the efficiencywhen applying large-scale pre-trained models. Inspired by the recent success ofvisual prompt tuning (VPT), this paper attempts to explore prompt tuning onpre-trained point cloud models, to pursue an elegant balance betweenperformance and parameter efficiency. We find while instance-agnostic staticprompting, e.g. VPT, shows some efficacy in downstream transfer, it isvulnerable to the distribution diversity caused by various types of noises inreal-world point cloud data. To conquer this limitation, we propose a novelInstance-aware Dynamic Prompt Tuning (IDPT) strategy for pre-trained pointcloud models. The essence of IDPT is to develop a dynamic prompt generationmodule to perceive semantic prior features of each point cloud instance andgenerate adaptive prompt tokens to enhance the model's robustness. Notably,extensive experiments demonstrate that IDPT outperforms full fine-tuning inmost tasks with a mere 7% of the trainable parameters, providing a promisingsolution to parameter-efficient learning for pre-trained point cloud models.Code is available at \url{https://github.com/zyh16143998882/ICCV23-IDPT}.",Yaohua Zha,2023/4/14,2023/7/25
2310.02473v1,Prompting-based Efficient Temporal Domain Generalization,http://arxiv.org/abs/2310.02473v1,"Machine learning traditionally assumes that training and testing data aredistributed independently and identically. However, in many real-worldsettings, the data distribution can shift over time, leading to poorgeneralization of trained models in future time periods. Our paper presents anovel prompting-based approach to temporal domain generalization that isparameter-efficient, time-efficient, and does not require access to the targetdomain data (i.e., unseen future time periods) during training. Our methodadapts a target pre-trained model to temporal drift by learning global prompts,domain-specific prompts, and drift-aware prompts that capture underlyingtemporal dynamics. It is compatible across diverse tasks, such asclassification, regression, and time series forecasting, and sets a newstate-of-the-art benchmark in temporal domain generalization. The coderepository will be publicly shared.",Sepidehsadat Hosseini,2023/10/3,2023/10/3
2311.13445v1,Transfer Attacks and Defenses for Large Language Models on Coding Tasks,http://arxiv.org/abs/2311.13445v1,"Modern large language models (LLMs), such as ChatGPT, have demonstratedimpressive capabilities for coding tasks including writing and reasoning aboutcode. They improve upon previous neural network models of code, such ascode2seq or seq2seq, that already demonstrated competitive results whenperforming tasks such as code summarization and identifying codevulnerabilities. However, these previous code models were shown vulnerable toadversarial examples, i.e. small syntactic perturbations that do not change theprogram's semantics, such as the inclusion of ""dead code"" through falseconditions or the addition of inconsequential print statements, designed to""fool"" the models. LLMs can also be vulnerable to the same adversarialperturbations but a detailed study on this concern has been lacking so far. Inthis paper we aim to investigate the effect of adversarial perturbations oncoding tasks with LLMs. In particular, we study the transferability ofadversarial examples, generated through white-box attacks on smaller codemodels, to LLMs. Furthermore, to make the LLMs more robust against suchadversaries without incurring the cost of retraining, we propose prompt-baseddefenses that involve modifying the prompt to include additional informationsuch as examples of adversarially perturbed code and explicit instructions forreversing adversarial perturbations. Our experiments show that adversarialexamples obtained with a smaller code model are indeed transferable, weakeningthe LLMs' performance. The proposed defenses show promise in improving themodel's resilience, paving the way to more robust defensive solutions for LLMsin code-related applications.",Chi Zhang,2023/11/22,2023/11/22
2212.10556v2,Unleashing the Power of Visual Prompting At the Pixel Level,http://arxiv.org/abs/2212.10556v2,"This paper presents a simple and effective visual prompting method foradapting pre-trained models to downstream recognition tasks. Our methodincludes two key designs. First, rather than directly adding together theprompt and the image, we treat the prompt as an extra and independent learnablecomponent. We show that the strategy of reconciling the prompt and the imagematters, and find that warping the prompt around a properly shrinked imageempirically works the best. Second, we re-introduce two ""old tricks"" commonlyused in building transferable adversarial examples, i.e., input diversity andgradient normalization, into visual prompting. These techniques improveoptimization and enable the prompt to generalize better. We provide extensiveexperimental results to demonstrate the effectiveness of our method. Using aCLIP model, our prompting method sets a new record of 82.8% average accuracyacross 12 popular classification datasets, substantially surpassing the priorart by +5.6%. It is worth noting that this prompting performance alreadyoutperforms linear probing by +2.1% and can even match fully fine-tuning incertain datasets. In addition, our prompting method shows competitiveperformance across different data scales and against distribution shifts. Thecode is publicly available at https://github.com/UCSC-VLAA/EVP.",Junyang Wu,2022/12/20,2023/3/29
2302.12252v2,Boosting Adversarial Transferability using Dynamic Cues,http://arxiv.org/abs/2302.12252v2,"The transferability of adversarial perturbations between image models hasbeen extensively studied. In this case, an attack is generated from a knownsurrogate \eg, the ImageNet trained model, and transferred to change thedecision of an unknown (black-box) model trained on an image dataset. However,attacks generated from image models do not capture the dynamic nature of amoving object or a changing scene due to a lack of temporal cues within imagemodels. This leads to reduced transferability of adversarial attacks fromrepresentation-enriched \emph{image} models such as Supervised VisionTransformers (ViTs), Self-supervised ViTs (\eg, DINO), and Vision-languagemodels (\eg, CLIP) to black-box \emph{video} models. In this work, we inducedynamic cues within the image models without sacrificing their originalperformance on images. To this end, we optimize \emph{temporal prompts} throughfrozen image models to capture motion dynamics. Our temporal prompts are theresult of a learnable transformation that allows optimizing for temporalgradients during an adversarial attack to fool the motion dynamics.Specifically, we introduce spatial (image) and temporal (video) cues within thesame source model through task-specific prompts. Attacking such promptsmaximizes the adversarial transferability from image-to-video andimage-to-image models using the attacks designed for image models. Our attackresults indicate that the attacker does not need specialized architectures,\eg, divided space-time attention, 3D convolutions, or multi-view convolutionnetworks for different data modalities. Image models are effective surrogatesto optimize an adversarial attack to fool black-box models in a changingenvironment over time. Code is available at https://bit.ly/3Xd9gRQ",Muzammal Naseer,2023/2/23,2023/4/4
2311.01011v1,Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game,http://arxiv.org/abs/2311.01011v1,"While Large Language Models (LLMs) are increasingly being used in real-worldapplications, they remain vulnerable to prompt injection attacks: maliciousthird party prompts that subvert the intent of the system designer. To helpresearchers study this problem, we present a dataset of over 126,000 promptinjection attacks and 46,000 prompt-based ""defenses"" against prompt injection,all created by players of an online game called Tensor Trust. To the best ofour knowledge, this is currently the largest dataset of human-generatedadversarial examples for instruction-following LLMs. The attacks in our datasethave a lot of easily interpretable stucture, and shed light on the weaknessesof LLMs. We also use the dataset to create a benchmark for resistance to twotypes of prompt injection, which we refer to as prompt extraction and prompthijacking. Our benchmark results show that many models are vulnerable to theattack strategies in the Tensor Trust dataset. Furthermore, we show that someattack strategies from the dataset generalize to deployed LLM-basedapplications, even though they have a very different set of constraints to thegame. We release all data and source code at https://tensortrust.ai/paper",Sam Toyer,2023/11/2,2023/11/2
2310.04451v1,AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,http://arxiv.org/abs/2310.04451v1,"The aligned Large Language Models (LLMs) are powerful language understandingand decision-making tools that are created through extensive alignment withhuman feedback. However, these large models remain susceptible to jailbreakattacks, where adversaries manipulate prompts to elicit malicious outputs thatshould not be given by aligned LLMs. Investigating jailbreak prompts can leadus to delve into the limitations of LLMs and further guide us to secure them.Unfortunately, existing jailbreak techniques suffer from either (1) scalabilityissues, where attacks heavily rely on manual crafting of prompts, or (2)stealthiness problems, as attacks depend on token-based algorithms to generateprompts that are often semantically meaningless, making them susceptible todetection through basic perplexity testing. In light of these challenges, weintend to answer this question: Can we develop an approach that canautomatically generate stealthy jailbreak prompts? In this paper, we introduceAutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN canautomatically generate stealthy jailbreak prompts by the carefully designedhierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDANnot only automates the process while preserving semantic meaningfulness, butalso demonstrates superior attack strength in cross-model transferability, andcross-sample universality compared with the baseline. Moreover, we also compareAutoDAN with perplexity-based defense methods and show that AutoDAN can bypassthem effectively.",Xiaogeng Liu,2023/10/3,2023/10/3
2210.17238v1,Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task,http://arxiv.org/abs/2210.17238v1,"In retrieval-based dialogue systems, a response selection model acts as aranker to select the most appropriate response among several candidates.However, such selection models tend to rely on context-response contentsimilarity, which makes models vulnerable to adversarial responses that aresemantically similar but not relevant to the dialogue context. Recent studieshave shown that leveraging these adversarial responses as negative trainingsamples is useful for improving the discriminating power of the selectionmodel. Nevertheless, collecting human-written adversarial responses isexpensive, and existing synthesizing methods often have limited scalability. Toovercome these limitations, this paper proposes a simple but efficient methodfor generating adversarial negative responses leveraging a large-scale languagemodel. Experimental results on dialogue selection tasks show that our methodoutperforms other methods of synthesizing adversarial negative responses. Theseresults suggest that our method can be an effective alternative to humanannotators in generating adversarial responses. Our dataset and generation codeis available at https://github.com/leenw23/generating-negatives-by-gpt3.",Nyoungwoo Lee,2022/10/31,2022/10/31
2310.02107v2,Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance,http://arxiv.org/abs/2310.02107v2,"Enabling large language models (LLMs) to perform tasks in zero-shot has beenan appealing goal owing to its labor-saving (i.e., requiring no task-specificannotations); as such, zero-shot prompting approaches also enjoy better taskgeneralizability. To improve LLMs' zero-shot performance, prior work hasfocused on devising more effective task instructions (e.g., ``let's think stepby step'' ). However, we argue that, in order for an LLM to solve themcorrectly in zero-shot, individual test instances need more carefully designedand customized instructions. To this end, we propose PRoMPTd, an approach thatrewrites the task prompt for each individual test input to be more specific,unambiguous, and complete, so as to provide better guidance to the task LLM. Weevaluated PRoMPTd on eight datasets covering tasks including arithmetics,logical reasoning, and code generation, using GPT-4 as the task LLM. Notably,PRoMPTd achieves an absolute improvement of around 10% on the complex MATHdataset and 5% on the code generation task on HumanEval, outperformingconventional zero-shot methods. In addition, we also showed that the rewrittenprompt can provide better interpretability of how the LLM resolves each testinstance, which can potentially be leveraged as a defense mechanism againstadversarial prompting. The source code and dataset can be obtained fromhttps://github.com/salokr/PRoMPTd",Saurabh Srivastava,2023/10/3,2023/10/5
2306.11400v1,MuDPT: Multi-modal Deep-symphysis Prompt Tuning for Large Pre-trained Vision-Language Models,http://arxiv.org/abs/2306.11400v1,"Prompt tuning, like CoOp, has recently shown promising vision recognizing andtransfer learning ability on various downstream tasks with the emergence oflarge pre-trained vision-language models like CLIP. However, we identify thatexisting uni-modal prompt tuning approaches may result in sub-optimalperformance since this uni-modal design breaks the original alignment oftextual and visual representations in the pre-trained model. Inspired by thenature of pre-trained vision-language models, we aim to achieve completeness inprompt tuning and propose a novel approach called Multi-modal Deep-symphysisPrompt Tuning, dubbed as MuDPT, which extends independent multi-modal prompttuning by additionally learning a model-agnostic transformative network toallow deep hierarchical bi-directional prompt fusion. We evaluate theeffectiveness of MuDPT on few-shot vision recognition and out-of-domaingeneralization tasks. Compared with the state-of-the-art methods, MuDPTachieves better recognition and generalization ability with an apparent marginthanks to synergistic alignment of textual and visual representations. Our codeis available at: https://github.com/Mechrev0/MuDPT.",Yongzhu Miao,2023/6/20,2023/6/20
2201.08531v3,Black-box Prompt Learning for Pre-trained Language Models,http://arxiv.org/abs/2201.08531v3,"The increasing scale of general-purpose Pre-trained Language Models (PLMs)necessitates the study of more efficient adaptation across different downstreamtasks. In this paper, we establish a Black-box Discrete Prompt Learning (BDPL)to resonate with pragmatic interactions between the cloud infrastructure andedge devices. Particularly, instead of fine-tuning the model in the cloud, weadapt PLMs by prompt learning, which efficiently optimizes only a fewparameters of the discrete prompts. Moreover, we consider the scenario that wedo not have access to the parameters and gradients of the pre-trained models,except for its outputs given inputs. This black-box setting secures the cloudinfrastructure from potential attack and misuse to cause a single-pointfailure, which is preferable to the white-box counterpart by currentinfrastructures. Under this black-box constraint, we apply a variance-reducedpolicy gradient algorithm to estimate the gradients of parameters in thecategorical distribution of each discrete prompt. In light of our method, theuser devices can efficiently tune their tasks by querying the PLMs bounded by arange of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that theproposed algorithm achieves significant improvement on eight benchmarks in acloud-device collaboration manner. Finally, we conduct in-depth case studies tocomprehensively analyze our method in terms of various data sizes, promptlengths, training budgets, optimization objectives, prompt transferability, andexplanations of the learned prompts. Our code will be available athttps://github.com/shizhediao/Black-Box-Prompt-Learning.",Shizhe Diao,2022/1/21,2023/2/23
2305.17903v3,Deeply Coupled Cross-Modal Prompt Learning,http://arxiv.org/abs/2305.17903v3,"Recent advancements in multimodal foundation models (e.g., CLIP) haveexcelled in zero-shot generalization. Prompt tuning involved in the knowledgetransfer from foundation models to downstream tasks has gained significantattention recently. Existing prompt-tuning methods in cross-modal learning,however, either solely focus on language branch, or learn vision-languageinteraction in a shallow mechanism. In this context, we propose a Deeplycoupled Cross-modal Prompt learning (DCP) method based on CLIP. DCP flexiblyaccommodates the interplay between vision and language with a Cross-ModalPrompt Attention (CMPA) mechanism, which enables the mutual exchange ofrespective representation through a well-connected multi-head attention moduleprogressively and strongly. We then conduct comprehensive few-shot learningexperiments on 11 image classification datasets and analyze the robustness todomain shift as well. Thorough experimental analysis evidently demonstrates thesuperb few-shot generalization and compelling domain adaption capacity of awell-executed DCP. The code can be found at https://github.com/GingL/CMPA.",Xuejing Liu,2023/5/29,2023/12/6
2310.07730v2,Domain-Controlled Prompt Learning,http://arxiv.org/abs/2310.07730v2,"Large pre-trained vision-language models, such as CLIP, have shown remarkablegeneralization capabilities across various tasks when appropriate text promptsare provided. However, adapting these models to specific domains, like remotesensing images (RSIs), medical images, etc, remains unexplored and challenging.Existing prompt learning methods often lack domain-awareness or domain-transfermechanisms, leading to suboptimal performance due to the misinterpretation ofspecific images in natural image patterns. To tackle this dilemma, we proposeda \textbf{Domain-Controlled Prompt Learning} for the specific domains.Specifically, the large-scale specific domain foundation model (LSDM) is firstintroduced to provide essential specific domain knowledge. Using lightweightneural networks, we transfer this knowledge into domain biases, which controlboth the visual and language branches to obtain domain-adaptive prompts in adirectly incorporating manner. Simultaneously, to overcome the existingoverfitting challenge, we propose a novel noisy-adding strategy, without extratrainable parameters, to help the model escape the suboptimal solution in aglobal domain oscillation manner. Experimental results show our method achievesstate-of-the-art performance in specific domain image recognition datasets. Ourcode is available at https://github.com/caoql98/DCPL.",Qinglong Cao,2023/9/30,2023/12/12
2003.05325v1,Meta-learning curiosity algorithms,http://arxiv.org/abs/2003.05325v1,"We hypothesize that curiosity is a mechanism found by evolution thatencourages meaningful exploration early in an agent's life in order to exposeit to experiences that enable it to obtain high rewards over the course of itslifetime. We formulate the problem of generating curious behavior as one ofmeta-learning: an outer loop will search over a space of curiosity mechanismsthat dynamically adapt the agent's reward signal, and an inner loop willperform standard reinforcement learning using the adapted reward signal.However, current meta-RL methods based on transferring neural network weightshave only generalized between very similar tasks. To broaden thegeneralization, we instead propose to meta-learn algorithms: pieces of codesimilar to those designed by humans in ML papers. Our rich language of programscombines neural networks with other building blocks such as buffers,nearest-neighbor modules and custom loss functions. We demonstrate theeffectiveness of the approach empirically, finding two novel curiosityalgorithms that perform on par or better than human-designed publishedcuriosity algorithms in domains as disparate as grid navigation with imageinputs, acrobot, lunar lander, ant and hopper.",Ferran Alet,2020/3/11,2020/3/11
2106.09017v1,Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation,http://arxiv.org/abs/2106.09017v1,"Multi-task learning (MTL) aims to improve the generalization of severalrelated tasks by learning them jointly. As a comparison, in addition to thejoint training scheme, modern meta-learning allows unseen tasks with limitedlabels during the test phase, in the hope of fast adaptation over them. Despitethe subtle difference between MTL and meta-learning in the problem formulation,both learning paradigms share the same insight that the shared structurebetween existing training tasks could lead to better generalization andadaptation. In this paper, we take one important step further to understand theclose connection between these two learning paradigms, through both theoreticalanalysis and empirical investigation. Theoretically, we first demonstrate thatMTL shares the same optimization formulation with a class of gradient-basedmeta-learning (GBML) algorithms. We then prove that for over-parameterizedneural networks with sufficient depth, the learned predictive functions of MTLand GBML are close. In particular, this result implies that the predictionsgiven by these two models are similar over the same unseen task. Empirically,we corroborate our theoretical findings by showing that, with properimplementation, MTL is competitive against state-of-the-art GBML algorithms ona set of few-shot image classification benchmarks. Since existing GBMLalgorithms often involve costly second-order bi-level optimization, ourfirst-order MTL method is an order of magnitude faster on large-scale datasetssuch as mini-ImageNet. We believe this work could help bridge the gap betweenthese two learning paradigms, and provide a computationally efficientalternative to GBML that also supports fast task adaptation.",Haoxiang Wang,2021/6/16,2021/6/16
2303.13495v1,ReVersion: Diffusion-Based Relation Inversion from Images,http://arxiv.org/abs/2303.13495v1,"Diffusion models gain increasing popularity for their generativecapabilities. Recently, there have been surging needs to generate customizedimages by inverting diffusion models from exemplar images. However, existinginversion methods mainly focus on capturing object appearances. How to invertobject relations, another important pillar in the visual world, remainsunexplored. In this work, we propose ReVersion for the Relation Inversion task,which aims to learn a specific relation (represented as ""relation prompt"") fromexemplar images. Specifically, we learn a relation prompt from a frozenpre-trained text-to-image diffusion model. The learned relation prompt can thenbe applied to generate relation-specific images with new objects, backgrounds,and styles. Our key insight is the ""preposition prior"" - real-world relationprompts can be sparsely activated upon a set of basis prepositional words.Specifically, we propose a novel relation-steering contrastive learning schemeto impose two critical properties of the relation prompt: 1) The relationprompt should capture the interaction between objects, enforced by thepreposition prior. 2) The relation prompt should be disentangled away fromobject appearances. We further devise relation-focal importance sampling toemphasize high-level interactions over low-level appearances (e.g., texture,color). To comprehensively evaluate this new task, we contribute ReVersionBenchmark, which provides various exemplar images with diverse relations.Extensive experiments validate the superiority of our approach over existingmethods across a wide range of visual relations.",Ziqi Huang,2023/3/23,2023/3/23
2205.04980v2,ALLSH: Active Learning Guided by Local Sensitivity and Hardness,http://arxiv.org/abs/2205.04980v2,"Active learning, which effectively collects informative unlabeled data forannotation, reduces the demand for labeled data. In this work, we propose toretrieve unlabeled samples with a local sensitivity and hardness-awareacquisition function. The proposed method generates data copies through localperturbations and selects data points whose predictive likelihoods diverge themost from their copies. We further empower our acquisition function byinjecting the select-worst case perturbation. Our method achieves consistentgains over the commonly used active learning strategies in variousclassification tasks. Furthermore, we observe consistent improvements over thebaselines on the study of prompt selection in prompt-based few-shot learning.These experiments demonstrate that our acquisition guided by local sensitivityand hardness can be effective and beneficial for many NLP tasks.",Shujian Zhang,2022/5/10,2022/9/23
2309.14049v1,How Novices Use LLM-Based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment,http://arxiv.org/abs/2309.14049v1,"As Large Language Models (LLMs) gain in popularity, it is important tounderstand how novice programmers use them. We present a thematic analysis of33 learners, aged 10-17, independently learning Python through 45code-authoring tasks using Codex, an LLM-based code generator. We exploreseveral questions related to how learners used these code generators andprovide an analysis of the properties of the written prompts and the generatedcode. Specifically, we explore (A) the context in which learners use Codex, (B)what learners are asking from Codex, (C) properties of their prompts in termsof relation to task description, language, and clarity, and prompt craftingpatterns, (D) the correctness, complexity, and accuracy of the AI-generatedcode, and (E) how learners utilize AI-generated code in terms of placement,verification, and manual modifications. Furthermore, our analysis reveals fourdistinct coding approaches when writing code with an AI code generator: AISingle Prompt, where learners prompted Codex once to generate the entiresolution to a task; AI Step-by-Step, where learners divided the problem intoparts and used Codex to generate each part; Hybrid, where learners wrote someof the code themselves and used Codex to generate others; and Manual coding,where learners wrote the code themselves. The AI Single Prompt approachresulted in the highest correctness scores on code-authoring tasks, but thelowest correctness scores on subsequent code-modification tasks duringtraining. Our results provide initial insight into how novice learners use AIcode generators and the challenges and opportunities associated withintegrating them into self-paced learning environments. We conclude withvarious signs of over-reliance and self-regulation, as well as opportunitiesfor curriculum and tool development.",Majeed Kazemitabaar,2023/9/25,2023/9/25
2202.05531v2,Cyclical Curriculum Learning,http://arxiv.org/abs/2202.05531v2,"Artificial neural networks (ANN) are inspired by human learning. However,unlike human education, classical ANN does not use a curriculum. CurriculumLearning (CL) refers to the process of ANN training in which examples are usedin a meaningful order. When using CL, training begins with a subset of thedataset and new samples are added throughout the training, or training beginswith the entire dataset and the number of samples used is reduced. With thesechanges in training dataset size, better results can be obtained withcurriculum, anti-curriculum, or random-curriculum methods than the vanillamethod. However, a generally efficient CL method for various architectures anddata sets is not found. In this paper, we propose cyclical curriculum learning(CCL), in which the data size used during training changes cyclically ratherthan simply increasing or decreasing. Instead of using only the vanilla methodor only the curriculum method, using both methods cyclically like in CCLprovides more successful results. We tested the method on 18 different datasets and 15 architectures in image and text classification tasks and obtainedmore successful results than no-CL and existing CL methods. We also have showntheoretically that it is less erroneous to apply CL and vanilla cyclicallyinstead of using only CL or only vanilla method. The code of CyclicalCurriculum is available athttps://github.com/CyclicalCurriculum/Cyclical-Curriculum.",H. Toprak Kesgin,2022/2/11,2022/3/15
2208.02301v1,HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding,http://arxiv.org/abs/2208.02301v1,"There are several opportunities for automation in healthcare that can improveclinician throughput. One such example is assistive tools to document diagnosiscodes when clinicians write notes. We study the automation of medical codeprediction using curriculum learning, which is a training strategy for machinelearning models that gradually increases the hardness of the learning tasksfrom easy to difficult. One of the challenges in curriculum learning is thedesign of curricula -- i.e., in the sequential design of tasks that graduallyincrease in difficulty. We propose Hierarchical Curriculum Learning (HiCu), analgorithm that uses graph structure in the space of outputs to design curriculafor multi-label classification. We create curricula for multi-labelclassification models that predict ICD diagnosis and procedure codes fromnatural language descriptions of patients. By leveraging the hierarchy of ICDcodes, which groups diagnosis codes based on various organ systems in the humanbody, we find that our proposed curricula improve the generalization of neuralnetwork-based predictive models across recurrent, convolutional, andtransformer-based architectures. Our code is available athttps://github.com/wren93/HiCu-ICD.",Weiming Ren,2022/8/3,2022/8/3
2108.07183v2,Improving Self-supervised Learning with Hardness-aware Dynamic Curriculum Learning: An Application to Digital Pathology,http://arxiv.org/abs/2108.07183v2,"Self-supervised learning (SSL) has recently shown tremendous potential tolearn generic visual representations useful for many image analysis tasks.Despite their notable success, the existing SSL methods fail to generalize todownstream tasks when the number of labeled training instances is small or ifthe domain shift between the transfer domains is significant. In this paper, weattempt to improve self-supervised pretrained representations through the lensof curriculum learning by proposing a hardness-aware dynamic curriculumlearning (HaDCL) approach. To improve the robustness and generalizability ofSSL, we dynamically leverage progressive harder examples via easy-to-hard andhard-to-very-hard samples during mini-batch downstream fine-tuning. We discoverthat by progressive stage-wise curriculum learning, the pretrainedrepresentations are significantly enhanced and adaptable to both in-domain andout-of-domain distribution data.  We performed extensive validation on three histology benchmark datasets onboth patch-wise and slide-level classification problems. Our curriculum basedfine-tuning yields a significant improvement over standard fine-tuning, with aminimum improvement in area-under-the-curve (AUC) score of 1.7% and 2.2% onin-domain and out-of-domain distribution data, respectively. Further, weempirically show that our approach is more generic and adaptable to any SSLmethods and does not impose any additional overhead complexity. Besides, wealso outline the role of patch-based versus slide-based curriculum learning inhistopathology to provide practical insights into the success of curriculumbased fine-tuning of SSL methods. Code is released athttps://github.com/srinidhiPY/ICCV-CDPATH2021-ID-8",Chetan L Srinidhi,2021/8/16,2021/10/5
2310.08549v1,Cross-Episodic Curriculum for Transformer Agents,http://arxiv.org/abs/2310.08549v1,"We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost thelearning efficiency and generalization of Transformer agents. Central to CEC isthe placement of cross-episodic experiences into a Transformer's context, whichforms the basis of a curriculum. By sequentially structuring online learningtrials and mixed-quality demonstrations, CEC constructs curricula thatencapsulate learning progression and proficiency increase across episodes. Suchsynergy combined with the potent pattern recognition capabilities ofTransformer models delivers a powerful cross-episodic attention mechanism. Theeffectiveness of CEC is demonstrated under two representative scenarios: oneinvolving multi-task reinforcement learning with discrete control, such as inDeepMind Lab, where the curriculum captures the learning progression in bothindividual and progressively complex settings; and the other involvingimitation learning with mixed-quality data for continuous control, as seen inRoboMimic, where the curriculum captures the improvement in demonstrators'expertise. In all instances, policies resulting from CEC exhibit superiorperformance and strong generalization. Code is open-sourced athttps://cec-agent.github.io/ to facilitate research on Transformer agentlearning.",Lucy Xiaoyang Shi,2023/10/12,2023/10/12
2310.12931v1,Eureka: Human-Level Reward Design via Coding Large Language Models,http://arxiv.org/abs/2310.12931v1,"Large Language Models (LLMs) have excelled as high-level semantic plannersfor sequential decision-making tasks. However, harnessing them to learn complexlow-level manipulation tasks, such as dexterous pen spinning, remains an openproblem. We bridge this fundamental gap and present Eureka, a human-levelreward design algorithm powered by LLMs. Eureka exploits the remarkablezero-shot generation, code-writing, and in-context improvement capabilities ofstate-of-the-art LLMs, such as GPT-4, to perform evolutionary optimization overreward code. The resulting rewards can then be used to acquire complex skillsvia reinforcement learning. Without any task-specific prompting or pre-definedreward templates, Eureka generates reward functions that outperform experthuman-engineered rewards. In a diverse suite of 29 open-source RL environmentsthat include 10 distinct robot morphologies, Eureka outperforms human expertson 83% of the tasks, leading to an average normalized improvement of 52%. Thegenerality of Eureka also enables a new gradient-free in-context learningapproach to reinforcement learning from human feedback (RLHF), readilyincorporating human inputs to improve the quality and the safety of thegenerated rewards without model updating. Finally, using Eureka rewards in acurriculum learning setting, we demonstrate for the first time, a simulatedShadow Hand capable of performing pen spinning tricks, adeptly manipulating apen in circles at rapid speed.",Yecheng Jason Ma,2023/10/19,2023/10/19
2305.16291v2,Voyager: An Open-Ended Embodied Agent with Large Language Models,http://arxiv.org/abs/2305.16291v2,"We introduce Voyager, the first LLM-powered embodied lifelong learning agentin Minecraft that continuously explores the world, acquires diverse skills, andmakes novel discoveries without human intervention. Voyager consists of threekey components: 1) an automatic curriculum that maximizes exploration, 2) anever-growing skill library of executable code for storing and retrievingcomplex behaviors, and 3) a new iterative prompting mechanism that incorporatesenvironment feedback, execution errors, and self-verification for programimprovement. Voyager interacts with GPT-4 via blackbox queries, which bypassesthe need for model parameter fine-tuning. The skills developed by Voyager aretemporally extended, interpretable, and compositional, which compounds theagent's abilities rapidly and alleviates catastrophic forgetting. Empirically,Voyager shows strong in-context lifelong learning capability and exhibitsexceptional proficiency in playing Minecraft. It obtains 3.3x more uniqueitems, travels 2.3x longer distances, and unlocks key tech tree milestones upto 15.3x faster than prior SOTA. Voyager is able to utilize the learned skilllibrary in a new Minecraft world to solve novel tasks from scratch, while othertechniques struggle to generalize. We open-source our full codebase and promptsat https://voyager.minedojo.org/.",Guanzhi Wang,2023/5/25,2023/10/19
2211.09703v3,EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones,http://arxiv.org/abs/2211.09703v3,"The superior performance of modern deep networks usually comes with a costlytraining procedure. This paper presents a new curriculum learning approach forthe efficient training of visual backbones (e.g., vision Transformers). Ourwork is inspired by the inherent learning dynamics of deep networks: weexperimentally show that at an earlier training stage, the model mainly learnsto recognize some 'easier-to-learn' discriminative patterns within eachexample, e.g., the lower-frequency components of images and the originalinformation before data augmentation. Driven by this phenomenon, we propose acurriculum where the model always leverages all the training data at eachepoch, while the curriculum starts with only exposing the 'easier-to-learn'patterns of each example, and introduces gradually more difficult patterns. Toimplement this idea, we 1) introduce a cropping operation in the Fourierspectrum of the inputs, which enables the model to learn from only thelower-frequency components efficiently, 2) demonstrate that exposing thefeatures of original images amounts to adopting weaker data augmentation, and3) integrate 1) and 2) and design a curriculum learning schedule with agreedy-search algorithm. The resulting approach, EfficientTrain, is simple,general, yet surprisingly effective. As an off-the-shelf method, it reduces thewall-time training cost of a wide variety of popular models (e.g., ResNet,ConvNeXt, DeiT, PVT, Swin, and CSWin) by >1.5x on ImageNet-1K/22K withoutsacrificing accuracy. It is also effective for self-supervised learning (e.g.,MAE). Code is available at https://github.com/LeapLabTHU/EfficientTrain.",Yulin Wang,2022/11/17,2023/8/16
2302.13025v1,Autonomous Exploration and Mapping for Mobile Robots via Cumulative Curriculum Reinforcement Learning,http://arxiv.org/abs/2302.13025v1,"Deep reinforcement learning (DRL) has been widely applied in autonomousexploration and mapping tasks, but often struggles with the challenges ofsampling efficiency, poor adaptability to unknown map sizes, and slowsimulation speed. To speed up convergence, we combine curriculum learning (CL)with DRL, and first propose a Cumulative Curriculum Reinforcement Learning(CCRL) training framework to alleviate the issue of catastrophic forgettingfaced by general CL. Besides, we present a novel state representation, whichconsiders a local egocentric map and a global exploration map resized to thefixed dimension, so as to flexibly adapt to environments with various sizes andshapes. Additionally, for facilitating the fast training of DRL models, wedevelop a lightweight grid-based simulator, which can substantially acceleratesimulation compared to popular robot simulation platforms such as Gazebo. Basedon the customized simulator, comprehensive experiments have been conducted, andthe results show that the CCRL framework not only mitigates the catastrophicforgetting problem, but also improves the sample efficiency and generalizationof DRL models, compared to general CL as well as without a curriculum. Our codeis available at https://github.com/BeamanLi/CCRL_Exploration.",Zhi Li,2023/2/25,2023/2/25
2308.16572v2,CL-MAE: Curriculum-Learned Masked Autoencoders,http://arxiv.org/abs/2308.16572v2,"Masked image modeling has been demonstrated as a powerful pretext task forgenerating robust representations that can be effectively generalized acrossmultiple downstream tasks. Typically, this approach involves randomly maskingpatches (tokens) in input images, with the masking strategy remaining unchangedduring training. In this paper, we propose a curriculum learning approach thatupdates the masking strategy to continually increase the complexity of theself-supervised reconstruction task. We conjecture that, by graduallyincreasing the task complexity, the model can learn more sophisticated andtransferable representations. To facilitate this, we introduce a novellearnable masking module that possesses the capability to generate masks ofdifferent complexities, and integrate the proposed module into maskedautoencoders (MAE). Our module is jointly trained with the MAE, while adjustingits behavior during training, transitioning from a partner to the MAE(optimizing the same reconstruction loss) to an adversary (optimizing theopposite loss), while passing through a neutral state. The transition betweenthese behaviors is smooth, being regulated by a factor that is multiplied withthe reconstruction loss of the masking module. The resulting training proceduregenerates an easy-to-hard curriculum. We train our Curriculum-Learned MaskedAutoencoder (CL-MAE) on ImageNet and show that it exhibits superiorrepresentation learning capabilities compared to MAE. The empirical results onfive downstream tasks confirm our conjecture, demonstrating that curriculumlearning can be successfully used to self-supervise masked autoencoders. Werelease our code at https://github.com/ristea/cl-mae.",Neelu Madan,2023/8/31,2023/10/25
2212.05590v2,PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Novel Category Discovery,http://arxiv.org/abs/2212.05590v2,"Although existing semi-supervised learning models achieve remarkable successin learning with unannotated in-distribution data, they mostly fail to learn onunlabeled data sampled from novel semantic classes due to their closed-setassumption. In this work, we target a pragmatic but under-explored GeneralizedNovel Category Discovery (GNCD) setting. The GNCD setting aims to categorizeunlabeled training data coming from known and novel classes by leveraging theinformation of partially labeled known classes. We propose a two-stageContrastive Affinity Learning method with auxiliary visual Prompts, dubbedPromptCAL, to address this challenging problem. Our approach discovers reliablepairwise sample affinities to learn better semantic clustering of both knownand novel classes for the class token and visual prompts. First, we propose adiscriminative prompt regularization loss to reinforce semanticdiscriminativeness of prompt-adapted pre-trained vision transformer for refinedaffinity relationships.Besides, we propose contrastive affinity learning tocalibrate semantic representations based on our iterative semi-supervisedaffinity graph generation method for semantically-enhanced supervision.Extensive experimental evaluation demonstrates that our PromptCAL method ismore effective in discovering novel classes even with limited annotations andsurpasses the current state-of-the-art on generic and fine-grained benchmarks(e.g., with nearly 11% gain on CUB-200, and 9% on ImageNet-100) on overallaccuracy. Our code is available at https://github.com/sheng-eatamath/PromptCAL.",Sheng Zhang,2022/12/11,2023/3/26
2310.18308v1,Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models,http://arxiv.org/abs/2310.18308v1,"Generalist robot manipulators need to learn a wide variety of manipulationskills across diverse environments. Current robot training pipelines rely onhumans to provide kinesthetic demonstrations or to program simulationenvironments and to code up reward functions for reinforcement learning. Suchhuman involvement is an important bottleneck towards scaling up robot learningacross diverse tasks and environments. We propose Generation to Simulation(Gen2Sim), a method for scaling up robot skill learning in simulation byautomating generation of 3D assets, task descriptions, task decompositions andreward functions using large pre-trained generative models of language andvision. We generate 3D assets for simulation by lifting open-world 2Dobject-centric images to 3D using image diffusion models and querying LLMs todetermine plausible physics parameters. Given URDF files of generated andhuman-developed assets, we chain-of-thought prompt LLMs to map these torelevant task descriptions, temporal decompositions, and corresponding pythonreward functions for reinforcement learning. We show Gen2Sim succeeds inlearning policies for diverse long horizon tasks, where reinforcement learningwith non temporally decomposed reward functions fails. Gen2Sim provides aviable path for scaling up reinforcement learning for robot manipulators insimulation, both by diversifying and expanding task and environmentdevelopment, and by facilitating the discovery of reinforcement-learnedbehaviors through temporal task decomposition in RL. Our work contributeshundreds of simulated assets, tasks and demonstrations, taking a step towardsfully autonomous robotic manipulation skill acquisition in simulation.",Pushkal Katara,2023/10/27,2023/10/27
2311.02847v2,Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs,http://arxiv.org/abs/2311.02847v2,"Generalizable articulated object manipulation is essential for home-assistantrobots. Recent efforts focus on imitation learning from demonstrations orreinforcement learning in simulation, however, due to the prohibitive costs ofreal-world data collection and precise object simulation, it still remainschallenging for these works to achieve broad adaptability across diversearticulated objects. Recently, many works have tried to utilize the strongin-context learning ability of Large Language Models (LLMs) to achievegeneralizable robotic manipulation, but most of these researches focus onhigh-level task planning, sidelining low-level robotic control. In this work,building on the idea that the kinematic structure of the object determines howwe can manipulate it, we propose a kinematic-aware prompting framework thatprompts LLMs with kinematic knowledge of objects to generate low-level motiontrajectory waypoints, supporting various object manipulation. To effectivelyprompt LLMs with the kinematic structure of different objects, we design aunified kinematic knowledge parser, which represents various articulatedobjects as a unified textual description containing kinematic joints andcontact location. Building upon this unified description, a kinematic-awareplanner model is proposed to generate precise 3D manipulation waypoints via adesigned kinematic-aware chain-of-thoughts prompting method. Our evaluationspanned 48 instances across 16 distinct categories, revealing that ourframework not only outperforms traditional methods on 8 seen categories butalso shows a powerful zero-shot capability for 8 unseen articulated objectcategories. Moreover, the real-world experiments on 7 different objectcategories prove our framework's adaptability in practical scenarios. Code isreleased at\href{https://github.com/GeWu-Lab/LLM_articulated_object_manipulation/tree/main}{here}.",Wenke Xia,2023/11/6,2023/11/8
1311.2308v1,"Elastic proton-proton scattering from ISR to LHC energies, focusing on the dip region",http://arxiv.org/abs/1311.2308v1,"The differential cross-section of elastic proton-proton collisions is studiedat ISR and LHC energies, utilizing a quark-diquark model, that generalizesearlier models of Bialas and Bzdak, and, in addition, a model of Glauber andVelasco. These studies suggest that the increase of the total pp cross-sectionis mainly due to an increase of the separation of the quark and the diquarkwith increasing energies. Within the investigated class of models, two simpleand model-independent phenomenological relations were found, that connect thetotal pp scattering cross-section to the effective quark, diquark size andtheir average separation, on one hand, and to the position of the dip of thedifferential cross-section, on the other hand. The latter t(dip) sigma(tot) ~const relation can be used to predict t(dip), the position of the dip ofelastic pp scattering for future colliding energies, and for other reactions,where sigma(tot) is either known or can be reliably estimated.",T. Csorgo,2013/11/10,2013/11/10
2305.14072v1,When the Music Stops: Tip-of-the-Tongue Retrieval for Music,http://arxiv.org/abs/2305.14072v1,"We present a study of Tip-of-the-tongue (ToT) retrieval for music, where asearcher is trying to find an existing music entity, but is unable to succeedas they cannot accurately recall important identifying information. ToTinformation needs are characterized by complexity, verbosity, uncertainty, andpossible false memories. We make four contributions. (1) We collect a dataset -$ToT_{Music}$ - of 2,278 information needs and ground truth answers. (2) Weintroduce a schema for these information needs and show that they often involvemultiple modalities encompassing several Music IR subtasks such as lyricsearch, audio-based search, audio fingerprinting, and text search. (3) Weunderscore the difficulty of this task by benchmarking a standard textretrieval approach on this dataset. (4) We investigate the efficacy of queryreformulations generated by a large language model (LLM), and show that theyare not as effective as simply employing the entire information need as a query- leaving several open questions for future research.",Samarth Bhargav,2023/5/23,2023/5/23
2309.07694v1,Tree of Uncertain Thoughts Reasoning for Large Language Models,http://arxiv.org/abs/2309.07694v1,"While the recently introduced Tree of Thoughts (ToT) has heraldedadvancements in allowing Large Language Models (LLMs) to reason throughforesight and backtracking for global decision-making, it has overlooked theinherent local uncertainties in intermediate decision points or ""thoughts"".These local uncertainties, intrinsic to LLMs given their potential for diverseresponses, remain a significant concern in the reasoning process. Addressingthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - areasoning framework tailored for LLMs. Our TouT effectively leverages MonteCarlo Dropout to quantify uncertainty scores associated with LLMs' diverselocal responses at these intermediate steps. By marrying this local uncertaintyquantification with global search algorithms, TouT enhances the model'sprecision in response generation. We substantiate our approach with rigorousexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.The empirical evidence underscores TouT's superiority over both ToT andchain-of-thought prompting methods.",Shentong Mo,2023/9/14,2023/9/14
2401.05787v1,Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning,http://arxiv.org/abs/2401.05787v1,"While chain-of-thought (CoT) prompting has revolutionized how LLMs performreasoning tasks, its current methods and variations (e.g, Self-consistency,ReACT, Reflexion, Tree-of-Thoughts (ToT), Cumulative Reasoning (CR)) sufferfrom limitations like slowness, limited context grounding, hallucination andinconsistent outputs. To overcome these challenges, we introduce Evidence toGenerate (E2G), a novel single-agent, two-step prompting framework. Instead ofunverified reasoning claims, this innovative approach leverages the power of""evidence for decision making"" by first focusing exclusively on the thoughtsequences (the series of intermediate steps) explicitly mentioned in thecontext which then serve as extracted evidence, guiding the LLM's outputgeneration process with greater precision and efficiency. This simple yetpowerful approach unlocks the true potential of chain-of-thought likeprompting, paving the way for faster, more reliable, and more contextuallyaware reasoning in LLMs. \tool achieves remarkable results robustly across awide range of knowledge-intensive reasoning and generation tasks, surpassingbaseline approaches with state-of-the-art LLMs. For example, (i) on LogiQAbenchmark using GPT-4 as backbone model, \tool achieves a new state-of-theAccuracy of 53.8% exceeding CoT by 18%, ToT by 11%, CR by 9% (ii) a variant ofE2G with PaLM2 outperforms the variable-shot performance of Gemini Ultra by 0.9F1 points, reaching an F1 score of 83.3 on a subset of DROP.",Md Rizwan Parvez,2024/1/11,2024/1/11
2002.02666v3,Cohomology ring of manifold arrangements,http://arxiv.org/abs/2002.02666v3,"We study the cohomology ring of the complement $\mathcal{M}(\mathcal{A})$ ofa manifold arrangement $\mathcal{A}$ in a smooth manifold $M$ without boundary.We first give the concept of monoidal cosheaf on a locally geometric poset$\mathfrak{L}$, and then define the generalized Orlik--Solomon algebra$A^*(\mathfrak{L}, \mathcal{C})$ over a commutative ring with unit, which isbuilt by the classical Orlik--Solomon algebra and a monoidal cosheaf$\mathcal{C}$ as coefficients. Furthermore, we construct a monoidal cosheaf$\hat{\mathcal{C}}(\mathcal{A})$ associated with $\mathcal{A}$, so that thegeneralized Orlik--Solomon algebra $A^*(\mathfrak{L},\hat{\mathcal{C}}(\mathcal{A}))$ becomes a double complex with suitablemultiplication structure and the associated total complex$Tot(A^*(\mathfrak{L}, \hat{\mathcal{C}}(\mathcal{A})))$ is a differentialalgebra. Our main result is that $H^*(Tot(A^*(\mathfrak{L},\hat{\mathcal{C}}(\mathcal{A}))))$ is isomorphic to$H^*(\mathcal{M}(\mathcal{A}))$ as algebras. Our argument is of topologicalwith the use of a spectral sequence induced by a geometric filtrationassociated with $\mathcal{A}$. In particular, we also discuss the mixed Hodgecomplex structure on our model if $M$ and all elements in $\mathcal{A}$ arecomplex smooth varieties, and show that it induces the canonical mixed Hodgestructure of $\mathcal{M}(\mathcal{A})$. As an application, we calculate thecohomology of chromatic configuration spaces, which agrees with many knownresults in some special cases. In addition, some explicit formulas with respectto Poincar\'e polynomial and chromatic polynomial are also given.",Junda Chen,2020/2/7,2021/9/7
2110.08085v1,Prediction of Lung CT Scores of Systemic Sclerosis by Cascaded Regression Neural Networks,http://arxiv.org/abs/2110.08085v1,"Visually scoring lung involvement in systemic sclerosis from CT scans playsan important role in monitoring progression, but its labor intensivenesshinders practical application. We proposed, therefore, an automatic scoringframework that consists of two cascaded deep regression neural networks. Thefirst (3D) network aims to predict the craniocaudal position of fiveanatomically defined scoring levels on the 3D CT scans. The second (2D) networkreceives the resulting 2D axial slices and predicts the scores. We used 227 3DCT scans to train and validate the first network, and the resulting 1135 axialslices were used in the second network. Two experts scored independently asubset of data to obtain intra- and interobserver variabilities and the groundtruth for all data was obtained in consensus. To alleviate the unbalance intraining labels in the second network, we introduced a sampling technique andto increase the diversity of the training samples synthetic data was generated,mimicking ground glass and reticulation patterns. The 4-fold cross validationshowed that our proposed network achieved an average MAE of 5.90, 4.66 and4.49, weighted kappa of 0.66, 0.58 and 0.65 for total score (TOT), ground glass(GG) and reticular pattern (RET), respectively. Our network performed slightlyworse than the best experts on TOT and GG prediction but it has competitiveperformance on RET prediction and has the potential to be an objectivealternative for the visual scoring of SSc in CT thorax studies.",Jingnan Jia,2021/10/15,2021/10/15
2308.09687v3,Graph of Thoughts: Solving Elaborate Problems with Large Language Models,http://arxiv.org/abs/2308.09687v3,"We introduce Graph of Thoughts (GoT): a framework that advances promptingcapabilities in large language models (LLMs) beyond those offered by paradigmssuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primaryadvantage of GoT is the ability to model the information generated by an LLM asan arbitrary graph, where units of information (""LLM thoughts"") are vertices,and edges correspond to dependencies between these vertices. This approachenables combining arbitrary LLM thoughts into synergistic outcomes, distillingthe essence of whole networks of thoughts, or enhancing thoughts using feedbackloops. We illustrate that GoT offers advantages over state of the art ondifferent tasks, for example increasing the quality of sorting by 62% over ToT,while simultaneously reducing costs by >31%. We ensure that GoT is extensiblewith new thought transformations and thus can be used to spearhead newprompting schemes. This work brings the LLM reasoning closer to human thinkingor brain mechanisms such as recurrence, both of which form complex networks.",Maciej Besta,2023/8/18,2023/11/24
2010.12757v2,Adding Chit-Chat to Enhance Task-Oriented Dialogues,http://arxiv.org/abs/2010.12757v2,"Existing dialogue corpora and models are typically designed under twodisjoint motives: while task-oriented systems focus on achieving functionalgoals (e.g., booking hotels), open-domain chatbots aim at making sociallyengaging conversations. In this work, we propose to integrate both types ofsystems by Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR), withthe goal of making virtual assistant conversations more engaging andinteractive. Specifically, we propose a Human <-> AI collaborative datacollection approach for generating diverse chit-chat responses to augmenttask-oriented dialogues with minimal annotation effort. We then present our newchit-chat-based annotations to 23.8K dialogues from two popular task-orienteddatasets (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate theiradvantage over the originals via human evaluation. Lastly, we propose three newmodels for adding chit-chat to task-oriented dialogues, explicitly trained topredict user goals and to generate contextually relevant chit-chat responses.Automatic and human evaluations show that, compared with the state-of-the-arttask-oriented baseline, our models can code-switch between task and chit-chatto be more engaging, interesting, knowledgeable, and humanlike, whilemaintaining competitive task performance.",Kai Sun,2020/10/24,2021/5/1
2109.00668v1,Towards Making the Most of Dialogue Characteristics for Neural Chat Translation,http://arxiv.org/abs/2109.00668v1,"Neural Chat Translation (NCT) aims to translate conversational text betweenspeakers of different languages. Despite the promising performance ofsentence-level and context-aware neural machine translation models, there stillremain limitations in current NCT models because the inherent dialoguecharacteristics of chat, such as dialogue coherence and speaker personality,are neglected. In this paper, we propose to promote the chat translation byintroducing the modeling of dialogue characteristics into the NCT model. Tothis end, we design four auxiliary tasks including monolingual responsegeneration, cross-lingual response generation, next utterance discrimination,and speaker identification. Together with the main chat translation task, weoptimize the NCT model through the training objectives of all these tasks. Bythis means, the NCT model can be enhanced by capturing the inherent dialoguecharacteristics, thus generating more coherent and speaker-relevanttranslations. Comprehensive experiments on four language directions(English-German and English-Chinese) verify the effectiveness and superiorityof the proposed approach.",Yunlong Liang,2021/9/2,2021/9/2
2310.07301v1,Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions,http://arxiv.org/abs/2310.07301v1,"Impressive progress has been made on chat models based on Large LanguageModels (LLMs) recently; however, there is a noticeable lag in multi-turnconversations between open-source chat models (e.g., Alpaca and Vicuna) and theleading chat models (e.g., ChatGPT and GPT-4). Through a series of analyses, weattribute the lag to the lack of enough high-quality multi-turninstruction-tuning data. The available instruction-tuning data for thecommunity are either single-turn conversations or multi-turn ones with certainissues, such as non-human-like instructions, less detailed responses, or raretopic shifts. In this paper, we address these challenges by introducing Parrot,a highly scalable solution designed to automatically generate high-qualityinstruction-tuning data, which are then used to enhance the effectiveness ofchat models in multi-turn conversations. Specifically, we start by training theParrot-Ask model, which is designed to emulate real users in generatinginstructions. We then utilize Parrot-Ask to engage in multi-turn conversationswith ChatGPT across a diverse range of topics, resulting in a collection of 40Khigh-quality multi-turn dialogues (Parrot-40K). These data are subsequentlyemployed to train a chat model that we have named Parrot-Chat. We demonstratethat the dialogues gathered from Parrot-Ask markedly outperform existingmulti-turn instruction-following datasets in critical metrics, including topicdiversity, number of turns, and resemblance to human conversation. With only40K training examples, Parrot-Chat achieves strong performance against other13B open-source models across a range of instruction-following benchmarks, andparticularly excels in evaluations of multi-turn capabilities. We make allcodes, datasets, and two versions of the Parrot-Ask model based on LLaMA2-13Band KuaiYii-13B available at https://github.com/kwai/KwaiYii/Parrot.",Yuchong Sun,2023/10/11,2023/10/11
2304.00592v1,PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue Model,http://arxiv.org/abs/2304.00592v1,"In the research of end-to-end dialogue systems, using real-world knowledge togenerate natural, fluent, and human-like utterances with correct answers iscrucial. However, domain-specific conversational dialogue systems may beincoherent and introduce erroneous external information to answer questions dueto the out-of-vocabulary issue or the wrong knowledge from the parameters ofthe neural network. In this work, we propose PK-Chat, a Pointer network guidedKnowledge-driven generative dialogue model, incorporating a unified pretrainedlanguage model and a pointer network over knowledge graphs. The words generatedby PK-Chat in the dialogue are derived from the prediction of word lists andthe direct prediction of the external knowledge graph knowledge. Moreover,based on the PK-Chat, a dialogue system is built for academic scenarios in thecase of geosciences. Finally, an academic dialogue benchmark is constructed toevaluate the quality of dialogue systems in academic scenarios and the sourcecode is available online.",Cheng Deng,2023/4/2,2023/4/2
2004.05388v1,You Impress Me: Dialogue Generation via Mutual Persona Perception,http://arxiv.org/abs/2004.05388v1,"Despite the continuing efforts to improve the engagingness and consistency ofchit-chat dialogue systems, the majority of current work simply focus onmimicking human-like responses, leaving understudied the aspects of modelingunderstanding between interlocutors. The research in cognitive science,instead, suggests that understanding is an essential signal for a high-qualitychit-chat conversation. Motivated by this, we propose P^2 Bot, atransmitter-receiver based framework with the aim of explicitly modelingunderstanding. Specifically, P^2 Bot incorporates mutual persona perception toenhance the quality of personalized dialogue generation. Experiments on a largepublic dataset, Persona-Chat, demonstrate the effectiveness of our approach,with a considerable boost over the state-of-the-art baselines across bothautomatic metrics and human evaluations.",Qian Liu,2020/4/11,2020/4/11
2205.05589v1,KETOD: Knowledge-Enriched Task-Oriented Dialogue,http://arxiv.org/abs/2205.05589v1,"Existing studies in dialogue system research mostly treat task-orienteddialogue and chit-chat as separate domains. Towards building a human-likeassistant that can converse naturally and seamlessly with users, it isimportant to build a dialogue system that conducts both types of conversationseffectively. In this work, we investigate how task-oriented dialogue andknowledge-grounded chit-chat can be effectively integrated into a single model.To this end, we create a new dataset, KETOD (Knowledge-Enriched Task-OrientedDialogue), where we naturally enrich task-oriented dialogues with chit-chatbased on relevant entity knowledge. We also propose two new models,SimpleToDPlus and Combiner, for the proposed task. Experimental results on bothautomatic and human evaluations show that the proposed methods cansignificantly improve the performance in knowledge-enriched response generationwhile maintaining a competitive task-oriented dialog performance. We believeour new dataset will be a valuable resource for future studies. Our dataset andcode are publicly available at \url{https://github.com/facebookresearch/ketod}.",Zhiyu Chen,2022/5/11,2022/5/11
2305.06223v1,ComputeGPT: A computational chat model for numerical problems,http://arxiv.org/abs/2305.06223v1,"Language models are not accurate in numerical problems. Their architecturedoes not allow for anything less than a probabilistic next word. This paperintroduces ComputeGPT: an approach of creating a chat model able to answercomputational problems through running on-demand code. ComputeGPT converts eachquestion to relevant code, runs the code, and returns the computed answer aspart of the chat. We combine this approach with a local browser-based Pythoninterpretation and fine-tuned prompts in order to achieve state-of-the-artefficiency on numerical problems and provide a suitable front-end and safeenvironment for the code to be executed in.",Ryan Hardesty Lewis,2023/5/8,2023/5/8
2304.11093v1,Hi Sheldon! Creating Deep Personalized Characters from TV Shows,http://arxiv.org/abs/2304.11093v1,"Imagine an interesting multimodal interactive scenario that you can see,hear, and chat with an AI-generated digital character, who is capable ofbehaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearanceto personality. Towards this fantastic multimodal chatting scenario, we proposea novel task, named Deep Personalized Character Creation (DPCC): creatingmultimodal chat personalized characters from multimodal data such as TV shows.Specifically, given a single- or multi-modality input (text, audio, video), thegoal of DPCC is to generate a multi-modality (text, audio, video) response,which should be well-matched the personality of a specific character such asSheldon, and of high quality as well. To support this novel task, we furthercollect a character centric multimodal dialogue dataset, named DeepPersonalized Character Dataset (DPCD), from TV shows. DPCD containscharacter-specific multimodal dialogue data of ~10k utterances and ~6 hours ofaudio/video per character, which is around 10 times larger compared to existingrelated datasets.On DPCD, we present a baseline method for the DPCC task andcreate 5 Deep personalized digital Characters (DeepCharacters) from Big Bang TVShows. We conduct both subjective and objective experiments to evaluate themultimodal response from DeepCharacters in terms of characterization andquality. The results demonstrates that, on our collected DPCD dataset, theproposed baseline can create personalized digital characters for generatingmultimodal response.Our collected DPCD dataset, the code of data collection andour baseline will be published soon.",Meidai Xuanyuan,2023/4/9,2023/4/9
2304.14657v1,Knowledge Enhanced Model for Live Video Comment Generation,http://arxiv.org/abs/2304.14657v1,"Live video commenting is popular on video media platforms, as it can create achatting atmosphere and provide supplementary information for users whilewatching videos. Automatically generating live video comments can improve userexperience and enable human-like generation for bot chatting. Existing worksmostly focus on short video datasets while ignoring other important video typessuch as long videos like movies. In this work, we collect a new Movie LiveComments (MovieLC) dataset to support research on live video comment generationfor long videos. We also propose a knowledge enhanced generation model inspiredby the divergent and informative nature of live video comments. Our modeladopts a pre-training encoder-decoder framework and incorporates externalknowledge. Extensive experiments show that both objective metrics and humanevaluation demonstrate the effectiveness of our proposed model. The MovieLCdataset and our code will be released.",Jieting Chen,2023/4/28,2023/4/28
2308.16149v2,Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models,http://arxiv.org/abs/2308.16149v2,"We introduce Jais and Jais-chat, new state-of-the-art Arabic-centricfoundation and instruction-tuned open generative large language models (LLMs).The models are based on the GPT-3 decoder-only architecture and are pretrainedon a mixture of Arabic and English texts, including source code in variousprogramming languages. With 13 billion parameters, they demonstrate betterknowledge and reasoning capabilities in Arabic than any existing open Arabicand multilingual models by a sizable margin, based on extensive evaluation.Moreover, the models are competitive in English compared to English-centricopen models of similar size, despite being trained on much less English data.We provide a detailed description of the training, the tuning, the safetyalignment, and the evaluation of the models. We release two open versions ofthe model -- the foundation Jais model, and an instruction-tuned Jais-chatvariant -- with the aim of promoting research on Arabic LLMs. Available athttps://huggingface.co/inception-mbzuai/jais-13b-chat",Neha Sengupta,2023/8/30,2023/9/29
1912.09589v1,Smart Home Appliances: Chat with Your Fridge,http://arxiv.org/abs/1912.09589v1,"Current home appliances are capable to execute a limited number of voicecommands such as turning devices on or off, adjusting music volume or lightconditions. Recent progress in machine reasoning gives an opportunity todevelop new types of conversational user interfaces for home appliances. Inthis paper, we apply state-of-the-art visual reasoning model and demonstratethat it is feasible to ask a smart fridge about its contents and variousproperties of the food with close-to-natural conversation experience. Ourvisual reasoning model answers user questions about existence, count, categoryand freshness of each product by analyzing photos made by the image sensorinside the smart fridge. Users may chat with their fridge using off-the-shelfphone messenger while being away from home, for example, when shopping in thesupermarket. We generate a visually realistic synthetic dataset to trainmachine learning reasoning model that achieves 95% answer accuracy on testdata. We present the results of initial user tests and discuss how we modifydistribution of generated questions for model training based onhuman-in-the-loop guidance. We open source code for the whole system includingdataset generation, reasoning model and demonstration scripts.",Denis Gudovskiy,2019/12/19,2019/12/19
2306.04328v1,IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for multilayer summarization of clinical conversations?,http://arxiv.org/abs/2306.04328v1,"Clinical conversation summarization has become an important application ofNatural language Processing. In this work, we intend to analyze summarizationmodel ensembling approaches, that can be utilized to improve the overallaccuracy of the generated medical report called chart note. The work startswith a single summarization model creating the baseline. Then leads to anensemble of summarization models trained on a separate section of the chartnote. This leads to the final approach of passing the generated results toanother summarization model in a multi-layer/stage fashion for better coherencyof the generated text. Our results indicate that although an ensemble of modelsspecialized in each section produces better results, the multi-layer/stageapproach does not improve accuracy. The code for the above paper is availableat https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git",Dhananjay Srivastava,2023/6/7,2023/6/7
2312.12299v1,Instruct-SCTG: Guiding Sequential Controlled Text Generation through Instructions,http://arxiv.org/abs/2312.12299v1,"Instruction-tuned large language models have shown remarkable performance inaligning generated text with user intentions across various tasks. However,maintaining human-like discourse structure in the generated text remains achallenging research question. In this paper, we propose Instruct-SCTG, aflexible and effective sequential framework that harnesses instruction-tunedlanguage models to generate structurally coherent text in both fine-tuned andzero-shot setups. Our framework generates articles in a section-by-sectionmanner, aligned with the desired human structure using natural languageinstructions. Furthermore, we introduce a new automatic metric that measuresdiscourse divergence in a fuzzy manner. Extensive experiments on three datasetsfrom representative domains of news and recipes demonstrate thestate-of-the-art performance of our framework in imposing discourse structureduring text generation, as verified by both automatic and human evaluation. Ourcode will be available on Github.",Yinhong Liu,2023/12/19,2023/12/19
2309.17102v1,Guiding Instruction-based Image Editing via Multimodal Large Language Models,http://arxiv.org/abs/2309.17102v1,"Instruction-based image editing improves the controllability and flexibilityof image manipulation via natural commands without elaborate descriptions orregional masks. However, human instructions are sometimes too brief for currentmethods to capture and follow. Multimodal large language models (MLLMs) showpromising capabilities in cross-modal understanding and visual-aware responsegeneration via LMs. We investigate how MLLMs facilitate edit instructions andpresent MLLM-Guided Image Editing (MGIE). MGIE learns to derive expressiveinstructions and provides explicit guidance. The editing model jointly capturesthis visual imagination and performs manipulation through end-to-end training.We evaluate various aspects of Photoshop-style modification, global photooptimization, and local editing. Extensive experimental results demonstratethat expressive instructions are crucial to instruction-based image editing,and our MGIE can lead to a notable improvement in automatic metrics and humanevaluation while maintaining competitive inference efficiency.",Tsu-Jui Fu,2023/9/29,2023/9/29
2310.08511v1,HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science,http://arxiv.org/abs/2310.08511v1,"We propose an instruction-based process for trustworthy data curation inmaterials science (MatSci-Instruct), which we then apply to finetune aLLaMa-based language model targeted for materials science (HoneyBee).MatSci-Instruct helps alleviate the scarcity of relevant, high-qualitymaterials science textual data available in the open literature, and HoneyBeeis the first billion-parameter language model specialized to materials science.In MatSci-Instruct we improve the trustworthiness of generated data byprompting multiple commercially available large language models for generationwith an Instructor module (e.g. Chat-GPT) and verification from an independentVerifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset ofmultiple tasks and measure the quality of our dataset along multipledimensions, including accuracy against known facts, relevance to materialsscience, as well as completeness and reasonableness of the data. Moreover, weiteratively generate more targeted instructions and instruction-data in afinetuning-evaluation-feedback loop leading to progressively better performancefor our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmarkshows HoneyBee's outperformance of existing language models on materialsscience tasks and iterative improvement in successive stages ofinstruction-data refinement. We study the quality of HoneyBee's languagemodeling through automatic evaluation and analyze case studies to furtherunderstand the model's capabilities and limitations. Our code and relevantdatasets are publicly available at\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee}.",Yu Song,2023/10/12,2023/10/12
1303.5762v1,Object-oriented approach to Rapid Custom Instruction design,http://arxiv.org/abs/1303.5762v1,"Due to continuous evolution of Systems-on-Chip (SoC), the complexity of theirdesign and development has augmented exponentially. To deal with theever-growing complexity of such embedded systems, we introduce, in this paper,an object-oriented approach to rapid SoC design using auto-generation ofhardware custom instructions to simplify and accelerate the SoC design process.In our approach, a Data Flow Graph (DFG) is adopted as a representation of thearithmetic operation to convert it to a custom instruction. Then VHDL code willbe automatically generated. The input C code is automatically updated forcalling the new hardware components. To prove the effectiveness of the proposedapproach, a Java source code framework named Automatic Custom Architecturegenerator (ACAgen) is developed. Experimental results on 3D sample applicationvalidate our approach and demonstrate how the proposed framework facilitatesand accelerates the SoC design process at low costs.",Emna Kallel,2013/3/21,2013/3/21
2308.02992v1,Binary Code Similarity Detection,http://arxiv.org/abs/2308.02992v1,"Binary code similarity detection is to detect the similarity of code atbinary (assembly) level without source code. Existing works have theirlimitations when dealing with mutated binary code generated by differentcompiling options. In this paper, we propose a novel approach to addressingthis problem. By inspecting the binary code, we found that generally, within afunction, some instructions aim to calculate (prepare) values for otherinstructions. The latter instructions are defined by us as key instructions.Currently, we define four categories of key instructions: calling subfunctions,comparing instruction, returning instruction, and memory-store instruction.Thus if we symbolically execute similar binary codes, symbolic values at thesekey instructions are expected to be similar. As such, we implement a prototypetool, which has three steps. First, it symbolically executes binary code;Second, it extracts symbolic values at defined key instructions into a graph;Last, it compares the symbolic graph similarity. In our implementation, we alsoaddress some problems, including path explosion and loop handling.",Zian Liu,2023/8/6,2023/8/6
2306.05425v1,MIMIC-IT: Multi-Modal In-Context Instruction Tuning,http://arxiv.org/abs/2306.05425v1,"High-quality instructions and responses are essential for the zero-shotperformance of large language models on interactive natural language tasks. Forinteractive vision-language tasks involving intricate visual scenes, a largequantity of diverse and creative instruction-response pairs should beimperative to tune vision-language models (VLMs). Nevertheless, the currentavailability of vision-language instruction-response pairs in terms ofquantity, diversity, and creativity remains limited, posing challenges to thegeneralization of interactive VLMs. Here we present MultI-Modal In-ContextInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodalinstruction-response pairs, with 2.2 million unique instructions derived fromimages and videos. Each pair is accompanied by multi-modal in-contextinformation, forming conversational contexts aimed at empowering VLMs inperception, reasoning, and planning. The instruction-response collectionprocess, dubbed as Syphus, is scaled using an automatic annotation pipelinethat combines human expertise with GPT's capabilities. Using the MIMIC-ITdataset, we train a large VLM named Otter. Based on extensive evaluationsconducted on vision-language benchmarks, it has been observed that Otterdemonstrates remarkable proficiency in multi-modal perception, reasoning, andin-context learning. Human evaluation reveals it effectively aligns with theuser's intentions. We release the MIMIC-IT dataset, instruction-responsecollection pipeline, benchmarks, and the Otter model.",Bo Li,2023/6/8,2023/6/8
2308.12067v2,InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4,http://arxiv.org/abs/2308.12067v2,"Multimodal large language models are typically trained in two stages: firstpre-training on image-text pairs, and then fine-tuning using supervisedvision-language instruction data. Recent studies have shown that large languagemodels can achieve satisfactory results even with a limited amount ofhigh-quality instruction-following data. In this paper, we introduceInstructionGPT-4, which is fine-tuned on a small dataset comprising only 200examples, amounting to approximately 6\% of the instruction-following data usedin the alignment dataset for MiniGPT-4. To achieve this, we first proposeseveral metrics to access the quality of multimodal instruction data. Based onthese metrics, we present an effective and trainable data selector toautomatically identify and filter low-quality vision-language data. Byemploying this method, InstructionGPT-4 outperforms the original MiniGPT-4 onvarious evaluations. Overall, our findings demonstrate that less buthigh-quality instruction tuning data is efficient in enabling multimodal largelanguage models to generate better output. Our code is available athttps://github.com/waltonfuture/InstructionGPT-4.",Lai Wei,2023/8/23,2023/10/11
2004.13873v1,Automated Physics-Derived Code Generation for Sensor Fusion and State Estimation,http://arxiv.org/abs/2004.13873v1,"We present a new method for automatically generating the implementation ofstate-estimation algorithms from a machine-readable specification of thephysics of a sensing system and physics of its signals and signal constraints.We implement the new state-estimator code generation method as a backend for aphysics specification language and we apply the backend to generate complete Ccode implementations of state estimators for both linear systems (Kalmanfilters) and non-linear systems (extended Kalman filters). The state estimatorcode generation from physics specification is completely automated and requiresno manual intervention. The generated filters can incorporate an AutomaticDifferentiation technique which combines function evaluation anddifferentiation in a single process. Using the description of physical systemof a range of complexities, we generate extended Kalman filters, which weevaluate in terms of prediction accuracy using simulation traces. The resultsshow that our automatically-generated sensor fusion and state estimationimplementations provide state estimation within the same error bound as thehuman-written hand-optimized counterparts. We additionally quantify the codesize and dynamic instruction count requirements of the generated stateestimator implementations on the RISC-V architecture. The results show that oursynthesized state estimation implementation employing Automatic Differentiationleads to an average improvement in the dynamic instruction count of thegenerated Kalman filter of 7%-16% compared to the standard differentiationtechnique. This is improvement comes at the limited cost of an average 4.5%increase in the code size of the generated filters.",Orestis Kaparounakis,2020/4/28,2020/4/28
2306.10968v2,BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models,http://arxiv.org/abs/2306.10968v2,"Large language models (LLMs) have demonstrated remarkable prowess in languageunderstanding and generation. Advancing from foundation LLMs toinstructionfollowing LLMs, instruction tuning plays a vital role in aligningLLMs to human preferences. However, the existing LLMs are usually focused onEnglish, leading to inferior performance in non-English languages. In order toimprove the performance for non-English languages, it is necessary to collectlanguage-specific training data for foundation LLMs and constructlanguage-specific instructions for instruction tuning, both of which are heavyloads. To minimize human workload, we propose to transfer the capabilities oflanguage generation and instruction following from English to other languagesthrough an interactive translation task. We have developed BayLing, aninstruction-following LLM by utilizing LLaMA as the foundation LLM andautomatically constructing interactive translation instructions for instructingtuning. Extensive assessments demonstrate that BayLing achieves comparableperformance to GPT-3.5-turbo, despite utilizing a considerably smallerparameter size of only 13 billion. Experimental results on translation tasksshow that BayLing achieves 95% of single-turn translation capability comparedto GPT-4 with automatic evaluation and 96% of interactive translationcapability compared to GPT-3.5-turbo with human evaluation. To estimate theperformance on general tasks, we created a multi-turn instruction test setcalled BayLing-80. The experimental results on BayLing-80 indicate that BayLingachieves 89% of performance compared to GPT-3.5-turbo. BayLing alsodemonstrates outstanding performance on knowledge assessment of Chinese GaoKaoand English SAT, second only to GPT-3.5-turbo among a multitude ofinstruction-following LLMs. Demo, homepage, code and models of BayLing areavailable.",Shaolei Zhang,2023/6/19,2023/6/21
2007.08095v2,"Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis",http://arxiv.org/abs/2007.08095v2,"The use of deep learning techniques has achieved significant progress forprogram synthesis from input-output examples. However, when the programsemantics become more complex, it still remains a challenge to synthesizeprograms that are consistent with the specification. In this work, we proposeSED, a neural program generation framework that incorporates synthesis,execution, and debugging stages. Instead of purely relying on the neuralprogram synthesizer to generate the final program, SED first produces initialprograms using the neural program synthesizer component, then utilizes a neuralprogram debugger to iteratively repair the generated programs. The integrationof the debugger component enables SED to modify the programs based on theexecution results and specification, which resembles the coding process ofhuman programmers. On Karel, a challenging input-output program synthesisbenchmark, SED reduces the error rate of the neural program synthesizer itselfby a considerable margin, and outperforms the standard beam search fordecoding.",Kavi Gupta,2020/7/16,2020/10/22
2209.05948v2,Don't Complete It! Preventing Unhelpful Code Completion for Productive and Sustainable Neural Code Completion Systems,http://arxiv.org/abs/2209.05948v2,"Currently, large pre-trained language models are widely applied in neuralcode completion systems. Though large code models significantly outperformtheir smaller counterparts, around 70% displayed code completions from Copilotare not accepted by developers. Being reviewed but not accepted, their help todeveloper productivity is considerably limited. Even worse, considering thehigh cost of the large code models, it is a huge waste of computing resourcesand energy. To fill this significant gap, we first investigate the prompts ofunhelpful code completions, and empirically find four observable patterns thatcause such prompts, all of which are inherent, namely, they can hardly beaddressed by improving the accuracy of the model. This demonstrates thefeasibility of identifying such prompts based on the prompts themselves.Motivated by this finding, we propose an early-rejection mechanism to turn downlow-return prompts by foretelling the code completion qualities without sendingthem to the code completion system. Furthermore, we propose a lightweightTransformer-based estimator to demonstrate the feasibility of the mechanism.The experimental results show that the proposed estimator helps save 23.3% ofcomputational cost measured in floating-point operations for the codecompletion systems, and 80.2% of rejected prompts lead to unhelpful completion",Zhensu Sun,2022/9/13,2023/2/1
2401.01701v2,De-Hallucinator: Iterative Grounding for LLM-Based Code Completion,http://arxiv.org/abs/2401.01701v2,"Large languages models (LLMs) trained on datasets of publicly availablesource code have established a new state-of-the-art in code completion.However, these models are mostly unaware of the code that already exists withina specific project, preventing the models from making good use of existingAPIs. Instead, LLMs often invent, or ""hallucinate"", non-existent APIs orproduce variants of already existing code. Although the API information isavailable to IDEs, the input size limit of LLMs prevents code completiontechniques from including all relevant context into the prompt. This paperpresents De-Hallucinator, an LLM-based code completion technique that groundsthe predictions of a model through a novel combination of retrieving suitableAPI references and iteratively querying the model with increasingly suitablecontext information in the prompt. The approach exploits the observation thatLLMs often predict code that resembles the desired completion, but that failsto correctly refer to already existing APIs. De-Hallucinator automaticallyidentifies project-specific API references related to the code prefix and tothe model's initial predictions and adds these references into the prompt. Ourevaluation applies the approach to the task of predicting API usages inopen-source Python projects. We show that De-Hallucinator consistently improvesthe predicted code across four state-of-the-art LLMs compared to querying themodel only with the code before the cursor. In particular, the approachimproves the edit distance of the predicted code by 23-51% and the recall ofcorrectly predicted API usages by 24-61% relative to the baseline.",Aryaz Eghbali,2024/1/3,2024/1/8
2312.10101v1,A Review of Repository Level Prompting for LLMs,http://arxiv.org/abs/2312.10101v1,"As coding challenges become more complex, recent advancements in LargeLanguage Models (LLMs) have led to notable successes, such as achieving a94.6\% solve rate on the HumanEval benchmark. Concurrently, there is anincreasing commercial push for repository-level inline code completion tools,such as GitHub Copilot and Tab Nine, aimed at enhancing developer productivity.This paper delves into the transition from individual coding problems torepository-scale solutions, presenting a thorough review of the currentliterature on effective LLM prompting for code generation at the repositorylevel. We examine approaches that will work with black-box LLMs such that theywill be useful and applicable to commercial use cases, and their applicabilityin interpreting code at a repository scale. We juxtapose the Repository-LevelPrompt Generation technique with RepoCoder, an iterative retrieval andgeneration method, to highlight the trade-offs inherent in each approach and toestablish best practices for their application in cutting-edge codingbenchmarks. The interplay between iterative refinement of prompts and thedevelopment of advanced retrieval systems forms the core of our discussion,offering a pathway to significantly improve LLM performance in code generationtasks. Insights from this study not only guide the application of these methodsbut also chart a course for future research to integrate such techniques intobroader software engineering contexts.",Douglas Schonholtz,2023/12/15,2023/12/15
2311.01490v2,The Behavior of Large Language Models When Prompted to Generate Code Explanations,http://arxiv.org/abs/2311.01490v2,"This paper systematically investigates the generation of code explanations byLarge Language Models (LLMs) for code examples commonly encountered inintroductory programming courses. Our findings reveal significant variations inthe nature of code explanations produced by LLMs, influenced by factors such asthe wording of the prompt, the specific code examples under consideration, theprogramming language involved, the temperature parameter, and the version ofthe LLM. However, a consistent pattern emerges for Java and Python, whereexplanations exhibit a Flesch-Kincaid readability level of approximately 7-8grade and a consistent lexical density, indicating the proportion of meaningfulwords relative to the total explanation size. Additionally, the generatedexplanations consistently achieve high scores for correctness, but lower scoreson three other metrics: completeness, conciseness, and specificity.",Priti Oli,2023/11/2,2023/11/9
2311.07806v1,Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts,http://arxiv.org/abs/2311.07806v1,"Interactive segmentation model leverages prompts from users to produce robustsegmentation. This advancement is facilitated by prompt engineering, whereinteractive prompts serve as strong priors during test-time. However, this isan inherently subjective and hard-to-reproduce process. The variability in userexpertise and inherently ambiguous boundaries in medical images can lead toinconsistent prompt selections, potentially affecting segmentation accuracy.This issue has not yet been extensively explored for medical imaging. In thispaper, we assess the test-time variability for interactive medical imagesegmentation with diverse point prompts. For a given target region, the pointis classified into three sub-regions: boundary, margin, and center. Our goal isto identify a straightforward and efficient approach for optimal promptselection during test-time based on three considerations: (1) benefits ofadditional prompts, (2) effects of prompt placement, and (3) strategies foroptimal prompt selection. We conduct extensive experiments on the publicMedical Segmentation Decathlon dataset for challenging colon tumor segmentationtask. We suggest an optimal strategy for prompt selection during test-time,supported by comprehensive results. The code is publicly available athttps://github.com/MedICL-VU/variability",Hao Li,2023/11/13,2023/11/13
2312.17611v1,P2M2-Net: Part-Aware Prompt-Guided Multimodal Point Cloud Completion,http://arxiv.org/abs/2312.17611v1,"Inferring missing regions from severely occluded point clouds is highlychallenging. Especially for 3D shapes with rich geometry and structure details,inherent ambiguities of the unknown parts are existing. Existing approacheseither learn a one-to-one mapping in a supervised manner or train a generativemodel to synthesize the missing points for the completion of 3D point cloudshapes. These methods, however, lack the controllability for the completionprocess and the results are either deterministic or exhibiting uncontrolleddiversity. Inspired by the prompt-driven data generation and editing, wepropose a novel prompt-guided point cloud completion framework, coinedP2M2-Net, to enable more controllable and more diverse shape completion. Givenan input partial point cloud and a text prompt describing the part-awareinformation such as semantics and structure of the missing region, ourTransformer-based completion network can efficiently fuse the multimodalfeatures and generate diverse results following the prompt guidance. We trainthe P2M2-Net on a new large-scale PartNet-Prompt dataset and conduct extensiveexperiments on two challenging shape completion benchmarks. Quantitative andqualitative results show the efficacy of incorporating prompts for morecontrollable part-aware point cloud completion and generation. Code and dataare available at https://github.com/JLU-ICL/P2M2-Net.",Linlian Jiang,2023/12/29,2023/12/29
2312.16244v2,Modality-missing RGBT Tracking via Invertible Prompt Learning and A High-quality Data Simulation Method,http://arxiv.org/abs/2312.16244v2,"Current RGBT tracking researches mainly focus on the modality-completescenarios, overlooking the modality-missing challenge in real-world scenes. Inthis work, we comprehensively investigate the impact of modality-missingchallenge in RGBT tracking and propose a novel invertible prompt learningapproach, which integrates the content-preserving prompts into a well-trainedtracking model to adapt to various modality-missing scenarios, formodality-missing RGBT tracking. In particular, given one modality-missingscenario, we propose to utilize the available modality to generate the promptof the missing modality to adapt to RGBT tracking model. However, thecross-modality gap between available and missing modalities usually causessemantic distortion and information loss in prompt generation. To handle thisissue, we propose the invertible prompt learning scheme by incorporating thefull reconstruction of the input available modality from the prompt in promptgeneration model. Considering that there lacks a modality-missing RGBT trackingdataset and many modality-missing scenarios are difficult to capture, we designa high-quality data simulation method based on hierarchical combination schemesto generate real-world modality-missing data. Extensive experiments on threemodality-missing datasets show that our method achieves significant performanceimprovements compared with state-of-the-art methods. We will release the codeand simulation dataset.",Andong Lu,2023/12/25,2024/1/22
2312.01837v1,Prompting Disentangled Embeddings for Knowledge Graph Completion with Pre-trained Language Model,http://arxiv.org/abs/2312.01837v1,"Both graph structures and textual information play a critical role inKnowledge Graph Completion (KGC). With the success of Pre-trained LanguageModels (PLMs) such as BERT, they have been applied for text encoding for KGC.However, the current methods mostly prefer to fine-tune PLMs, leading to hugetraining costs and limited scalability to larger PLMs. In contrast, we proposeto utilize prompts and perform KGC on a frozen PLM with only the promptstrained. Accordingly, we propose a new KGC method named PDKGC with two prompts-- a hard task prompt which is to adapt the KGC task to the PLM pre-trainingtask of token prediction, and a disentangled structure prompt which learnsdisentangled graph representation so as to enable the PLM to combine morerelevant structure knowledge with the text information. With the two prompts,PDKGC builds a textual predictor and a structural predictor, respectively, andtheir combination leads to more comprehensive entity prediction. Solidevaluation on two widely used KGC datasets has shown that PDKGC oftenoutperforms the baselines including the state-of-the-art, and its componentsare all effective. Our codes and data are available athttps://github.com/genggengcss/PDKGC.",Yuxia Geng,2023/12/4,2023/12/4
2310.06839v1,LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression,http://arxiv.org/abs/2310.06839v1,"In long context scenarios, large language models (LLMs) face three mainchallenges: higher computational/financial cost, longer latency, and inferiorperformance. Some studies reveal that the performance of LLMs depends on boththe density and the position of the key information (question relevant) in theinput prompt. Inspired by these findings, we propose LongLLMLingua for promptcompression towards improving LLMs' perception of the key information tosimultaneously address the three challenges. We conduct evaluation on a widerange of long context scenarios including single-/multi-document QA, few-shotlearning, summarization, synthetic tasks, and code completion. The experimentalresults show that LongLLMLingua compressed prompt can derive higher performancewith much less cost. The latency of the end-to-end system is also reduced. Forexample, on NaturalQuestions benchmark, LongLLMLingua gains a performance boostof up to 17.1% over the original prompt with ~4x fewer tokens as input toGPT-3.5-Turbo. It can derive cost savings of \$28.5 and \$27.4 per 1,000samples from the LongBench and ZeroScrolls benchmark, respectively.Additionally, when compressing prompts of ~10k tokens at a compression rate of2x-10x, LongLLMLingua can speed up the end-to-end latency by 1.4x-3.8x. Ourcode is available at https://aka.ms/LLMLingua.",Huiqiang Jiang,2023/10/10,2023/10/10
2312.14091v2,HD-Painter: High-Resolution and Prompt-Faithful Text-Guided Image Inpainting with Diffusion Models,http://arxiv.org/abs/2312.14091v2,"Recent progress in text-guided image inpainting, based on the unprecedentedsuccess of text-to-image diffusion models, has led to exceptionally realisticand visually plausible results. However, there is still significant potentialfor improvement in current text-to-image inpainting models, particularly inbetter aligning the inpainted area with user prompts and performinghigh-resolution inpainting. Therefore, in this paper we introduce HD-Painter, acompletely training-free approach that accurately follows to prompts andcoherently scales to high-resolution image inpainting. To this end, we designthe Prompt-Aware Introverted Attention (PAIntA) layer enhancing self-attentionscores by prompt information and resulting in better text alignmentgenerations. To further improve the prompt coherence we introduce theReweighting Attention Score Guidance (RASG) mechanism seamlessly integrating apost-hoc sampling strategy into general form of DDIM to preventout-of-distribution latent shifts. Moreover, HD-Painter allows extension tolarger scales by introducing a specialized super-resolution techniquecustomized for inpainting, enabling the completion of missing regions in imagesof up to 2K resolution. Our experiments demonstrate that HD-Painter surpassesexisting state-of-the-art approaches qualitatively and quantitatively,achieving an impressive generation accuracy improvement of 61.4% vs 51.9%. Wewill make the codes publicly available at:https://github.com/Picsart-AI-Research/HD-Painter",Hayk Manukyan,2023/12/21,2023/12/25
2209.07753v4,Code as Policies: Language Model Programs for Embodied Control,http://arxiv.org/abs/2209.07753v4,"Large language models (LLMs) trained on code completion have been shown to becapable of synthesizing simple Python programs from docstrings [1]. We findthat these code-writing LLMs can be re-purposed to write robot policy code,given natural language commands. Specifically, policy code can expressfunctions or feedback loops that process perception outputs (e.g.,from objectdetectors [2], [3]) and parameterize control primitive APIs. When provided asinput several example language commands (formatted as comments) followed bycorresponding policy code (via few-shot prompting), LLMs can take in newcommands and autonomously re-compose API calls to generate new policy coderespectively. By chaining classic logic structures and referencing third-partylibraries (e.g., NumPy, Shapely) to perform arithmetic, LLMs used in this waycan write robot policies that (i) exhibit spatial-geometric reasoning, (ii)generalize to new instructions, and (iii) prescribe precise values (e.g.,velocities) to ambiguous descriptions (""faster"") depending on context (i.e.,behavioral commonsense). This paper presents code as policies: a robot-centricformulation of language model generated programs (LMPs) that can representreactive policies (e.g., impedance controllers), as well as waypoint-basedpolicies (vision-based pick and place, trajectory-based control), demonstratedacross multiple real robot platforms. Central to our approach is promptinghierarchical code-gen (recursively defining undefined functions), which canwrite more complex code and also improves state-of-the-art to solve 39.8% ofproblems on the HumanEval [1] benchmark. Code and videos are available athttps://code-as-policies.github.io",Jacky Liang,2022/9/16,2023/5/25
2212.06094v3,Prompting Is Programming: A Query Language for Large Language Models,http://arxiv.org/abs/2212.06094v3,"Large language models have demonstrated outstanding performance on a widerange of tasks such as question answering and code generation. On a high level,given an input, a language model can be used to automatically complete thesequence in a statistically-likely way. Based on this, users prompt thesemodels with language instructions or examples, to implement a variety ofdownstream tasks. Advanced prompting methods can even imply interaction betweenthe language model, a user, and external tools such as calculators. However, toobtain state-of-the-art performance or adapt language models for specifictasks, complex task- and model-specific programs have to be implemented, whichmay still require ad-hoc interaction.  Based on this, we present the novel idea of Language Model Programming (LMP).LMP generalizes language model prompting from pure text prompts to an intuitivecombination of text prompting and scripting. Additionally, LMP allowsconstraints to be specified over the language model output. This enables easyadaption to many tasks while abstracting language model internals and providinghigh-level semantics.  To enable LMP, we implement LMQL(short for Language Model Query Language),which leverages the constraints and control flow from an LMP prompt to generatean efficient inference procedure that minimizes the number of expensive callsto the underlying language model.  We show that LMQL can capture a wide range of state-of-the-art promptingmethods in an intuitive way, especially facilitating interactive flows that arechallenging to implement with existing high-level APIs. Our evaluation showsthat we retain or increase the accuracy on several downstream tasks, while alsosignificantly reducing the required amount of computation or cost in the caseof pay-to-use APIs (26-85% cost savings).",Luca Beurer-Kellner,2022/12/12,2023/5/30
2311.11183v2,Deploying and Evaluating LLMs to Program Service Mobile Robots,http://arxiv.org/abs/2311.11183v2,"Recent advancements in large language models (LLMs) have spurred interest inusing them for generating robot programs from natural language, with promisinginitial results. We investigate the use of LLMs to generate programs forservice mobile robots leveraging mobility, perception, and human interactionskills, and where accurate sequencing and ordering of actions is crucial forsuccess. We contribute CodeBotler, an open-source robot-agnostic tool toprogram service mobile robots from natural language, and RoboEval, a benchmarkfor evaluating LLMs' capabilities of generating programs to complete servicerobot tasks. CodeBotler performs program generation via few-shot prompting ofLLMs with an embedded domain-specific language (eDSL) in Python, and leveragesskill abstractions to deploy generated programs on any general-purpose mobilerobot. RoboEval evaluates the correctness of generated programs by checkingexecution traces starting with multiple initial states, and checking whetherthe traces satisfy temporal logic properties that encode correctness for eachtask. RoboEval also includes multiple prompts per task to test for therobustness of program generation. We evaluate several popular state-of-the-artLLMs with the RoboEval benchmark, and perform a thorough analysis of the modesof failures, resulting in a taxonomy that highlights common pitfalls of LLMs atgenerating robot programs. We release our code and benchmark athttps://amrl.cs.utexas.edu/codebotler/.",Zichao Hu,2023/11/18,2023/12/12
2303.13528v1,Many bioinformatics programming tasks can be automated with ChatGPT,http://arxiv.org/abs/2303.13528v1,"Computer programming is a fundamental tool for life scientists, allowing themto carry out many essential research tasks. However, despite a variety ofeducational efforts, learning to write code can be a challenging endeavor forboth researchers and students in life science disciplines. Recent advances inartificial intelligence have made it possible to translate human-languageprompts to functional code, raising questions about whether these technologiescan aid (or replace) life scientists' efforts to write code. Using 184programming exercises from an introductory-bioinformatics course, we evaluatedthe extent to which one such model -- OpenAI's ChatGPT -- can successfullycomplete basic- to moderate-level programming tasks. On its first attempt,ChatGPT solved 139 (75.5%) of the exercises. For the remaining exercises, weprovided natural-language feedback to the model, prompting it to try differentapproaches. Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of theexercises. These findings have important implications for life-sciencesresearch and education. For many programming tasks, researchers no longer needto write code from scratch. Instead, machine-learning models may produce usablesolutions. Instructors may need to adapt their pedagogical approaches andassessment techniques to account for these new capabilities that are availableto the general public.",Stephen R. Piccolo,2023/3/7,2023/3/7
2108.09293v3,Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions,http://arxiv.org/abs/2108.09293v3,"There is burgeoning interest in designing AI-based systems to assist humansin designing computing systems, including tools that automatically generatecomputer code. The most notable of these comes in the form of the firstself-described `AI pair programmer', GitHub Copilot, a language model trainedover open-source GitHub code. However, code often contains bugs - and so, giventhe vast quantity of unvetted code that Copilot has processed, it is certainthat the language model will have learned from exploitable, buggy code. Thisraises concerns on the security of Copilot's code contributions. In this work,we systematically investigate the prevalence and conditions that can causeGitHub Copilot to recommend insecure code. To perform this analysis we promptCopilot to generate code in scenarios relevant to high-risk CWEs (e.g. thosefrom MITRE's ""Top 25"" list). We explore Copilot's performance on three distinctcode generation axes -- examining how it performs given diversity ofweaknesses, diversity of prompts, and diversity of domains. In total, weproduce 89 different scenarios for Copilot to complete, producing 1,689programs. Of these, we found approximately 40% to be vulnerable.",Hammond Pearce,2021/8/20,2021/12/16
2304.13172v1,Generating Procedural Materials from Text or Image Prompts,http://arxiv.org/abs/2304.13172v1,"Node graph systems are used ubiquitously for material design in computergraphics. They allow the use of visual programming to achieve desired effectswithout writing code. As high-level design tools they provide convenience andflexibility, but mastering the creation of node graphs usually requiresprofessional training. We propose an algorithm capable of generating multiplenode graphs from different types of prompts, significantly lowering the bar forusers to explore a specific design space. Previous work was limited tounconditional generation of random node graphs, making the generation of anenvisioned material challenging. We propose a multi-modal node graph generationneural architecture for high-quality procedural material synthesis which can beconditioned on different inputs (text or image prompts), using a CLIP-basedencoder. We also create a substantially augmented material graph dataset, keyto improving the generation quality. Finally, we generate high-quality graphsamples using a regularized sampling process and improve the matching qualityby differentiable optimization for top-ranked samples. We compare our methodsto CLIP-based database search baselines (which are themselves novel) andachieve superior or similar performance without requiring massive data storage.We further show that our model can produce a set of material graphsunconditionally, conditioned on images, text prompts or partial graphs, servingas a tool for automatic visual programming completion.",Yiwei Hu,2023/4/25,2023/4/25
2303.13824v1,$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference,http://arxiv.org/abs/2303.13824v1,"In-Context Learning (ICL), which formulates target tasks as prompt completionconditioned on in-context demonstrations, has become the prevailing utilizationof LLMs. In this paper, we first disclose an actual predicament for thistypical usage that it can not scale up with training data due to context lengthrestriction. Besides, existing works have shown that ICL also suffers fromvarious biases and requires delicate calibration treatment. To address bothchallenges, we advocate a simple and effective solution, $k$NN Prompting, whichfirst queries LLM with training data for distributed representations, thenpredicts test instances by simply referring to nearest neighbors. We conductcomprehensive experiments to demonstrate its two-fold superiority: 1)Calibration-Free: $k$NN Prompting does not directly align LLM outputdistribution with task-specific label space, instead leverages suchdistribution to align test and training instances. It significantly outperformsstate-of-the-art calibration-based methods under comparable few-shot scenario.2) Beyond-Context: $k$NN Prompting can further scale up effectively with asmany training data as are available, continually bringing substantialimprovements. The scaling trend holds across 10 orders of magnitude rangingfrom 2 shots to 1024 shots as well as different LLMs scales ranging from 0.8Bto 30B. It successfully bridges data scaling into model scaling, and brings newpotentials for the gradient-free paradigm of LLM deployment. Code is publiclyavailable.",Benfeng Xu,2023/3/24,2023/3/24
2208.08289v3,CCTEST: Testing and Repairing Code Completion Systems,http://arxiv.org/abs/2208.08289v3,"Code completion, a highly valuable topic in the software development domain,has been increasingly promoted for use by recent advances in large languagemodels (LLMs). To date, visible LLM-based code completion frameworks such asGitHub Copilot and GPT are trained using deep learning over vast quantities ofunstructured text and open source code. As the paramount component and thecornerstone in daily programming tasks, code completion has largely boostedprofessionals' efficiency in building real-world software systems. In contrastto this flourishing market, we find that code completion systems often outputsuspicious results, and to date, an automated testing and enhancement frameworkfor code completion systems is not available. This research proposes CCTEST, aframework to test and repair code completion systems in blackbox settings.CCTEST features a set of novel mutation strategies, namely programstructure-correlated (PSC) mutations, to generate mutated code completioninputs. Then, it detects inconsistent outputs, representing possibly erroneouscases, from all the completed code cases. Moreover, CCTEST repairs the codecompletion outputs by selecting the output that mostly reflects the ""average""appearance of all output cases, as the final output of the code completionsystems. We detected a total of 33,540 inputs (with a true positive rate of86%) that can trigger erroneous cases from eight popular LLM-based codecompletion systems. With repairing, we show that the accuracy of codecompletion systems is notably increased by 40% and 67% with respect to BLEUscore and Levenshtein edit similarity.",Zongjie Li,2022/8/17,2023/5/8
2311.00177v1,Students' Perspective on AI Code Completion: Benefits and Challenges,http://arxiv.org/abs/2311.00177v1,"AI Code Completion (e.g., GitHub's Copilot, Amazon CodeWhisperer) hasrevolutionized the way in which computer science students interact withprogramming languages. However, these tools are not available for free publicuse, preventing us from conducting our research. In addition, AI codecompletion has been studied from developers' perspective, not students'perspective who represent the future generation of our digital world. In thisarticle, we investigated the benefits, challenges, and expectations of AI codecompletion from students' perspectives and introduced AutoAurora, an AI codecompletion tool integrated into the Visual Studio Code Extension as a researchinstrument. Through an interview study with ten participants, we found that AIcode completion enhanced students' productivity and efficiency by providingcorrect syntax suggestions, offering alternative solutions, and functioning asa coding tutor. However, the over-reliance on AI code completion may lead to asurface-level understanding of programming concepts, diminishingproblem-solving skills and restricting creativity. In the future, AI codecompletion must be explainable to facilitate the learning of coding concepts.",Wannita Takerngsaksiri,2023/10/31,2023/10/31
2203.07722v1,ReACC: A Retrieval-Augmented Code Completion Framework,http://arxiv.org/abs/2203.07722v1,"Code completion, which aims to predict the following code token(s) accordingto the code context, can improve the productivity of software development.Recent work has proved that statistical language modeling with transformers cangreatly improve the performance in the code completion task via learning fromlarge-scale source code datasets. However, current approaches focus only oncode context within the file or project, i.e. internal context. Our distinctionis utilizing ""external"" context, inspired by human behaviors of copying fromthe related code snippets when writing code. Specifically, we propose aretrieval-augmented code completion framework, leveraging both lexical copyingand referring to code with similar semantics by retrieval. We adopt astage-wise training approach that combines a source code retriever and anauto-regressive language model for programming language. We evaluate ourapproach in the code completion task in Python and Java programming languages,achieving a state-of-the-art performance on CodeXGLUE benchmark.",Shuai Lu,2022/3/15,2022/3/15
2103.09499v1,Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs,http://arxiv.org/abs/2103.09499v1,"Code completion has become an essential component of integrated developmentenvironments. Contemporary code completion methods rely on the abstract syntaxtree (AST) to generate syntactically correct code. However, they cannot fullycapture the sequential and repetitive patterns of writing code and thestructural information of the AST. To alleviate these problems, we propose anew code completion approach named CCAG, which models the flattened sequence ofa partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Blockto capture different dependencies in the AST graph for representation learningin code completion. The sub-tasks of code completion are optimized viamulti-task learning in CCAG, and the task balance is automatically achievedusing uncertainty without the need to tune task weights. The experimentalresults show that CCAG has superior performance than state-of-the-artapproaches and it is able to provide intelligent code completion.",Yanlin Wang,2021/3/17,2021/3/17
1711.09573v2,Code Completion with Neural Attention and Pointer Networks,http://arxiv.org/abs/1711.09573v2,"Intelligent code completion has become an essential research task toaccelerate modern software development. To facilitate effective code completionfor dynamically-typed programming languages, we apply neural language models bylearning from large codebases, and develop a tailored attention mechanism forcode completion. However, standard neural language models even with attentionmechanism cannot correctly predict the out-of-vocabulary (OoV) words thatrestrict the code completion performance. In this paper, inspired by theprevalence of locally repeated terms in program source code, and the recentlyproposed pointer copy mechanism, we propose a pointer mixture network forbetter predicting OoV words in code completion. Based on the context, thepointer mixture network learns to either generate a within-vocabulary wordthrough an RNN component, or regenerate an OoV word from local context througha pointer component. Experiments on two benchmarked datasets demonstrate theeffectiveness of our attention mechanism and pointer mixture network on thecode completion task.",Jian Li,2017/11/27,2018/5/14
2012.14631v1,Multi-task Learning based Pre-trained Language Model for Code Completion,http://arxiv.org/abs/2012.14631v1,"Code completion is one of the most useful features in the IntegratedDevelopment Environments (IDEs), which can accelerate software development bysuggesting the next probable token based on the contextual code in real-time.Recent studies have shown that statistical language modeling techniques canimprove the performance of code completion tools through learning fromlarge-scale software repositories. However, these models suffer from two majordrawbacks: a) Existing research uses static embeddings, which map a word to thesame vector regardless of its context. The differences in the meaning of atoken in varying contexts are lost when each token is associated with a singlerepresentation; b) Existing language model based code completion models performpoor on completing identifiers, and the type information of the identifiers isignored in most of these models. To address these challenges, in this paper, wedevelop a multi-task learning based pre-trained language model for codeunderstanding and code generation with a Transformer-based neural architecture.We pre-train it with hybrid objective functions that incorporate both codeunderstanding and code generation tasks. Then we fine-tune the pre-trainedmodel on code completion. During the completion, our model does not directlypredict the next token. Instead, we adopt multi-task learning to predict thetoken and its type jointly and utilize the predicted type to assist the tokenprediction. Experiments results on two real-world datasets demonstrate theeffectiveness of our model when compared with state-of-the-art methods.",Fang Liu,2020/12/29,2020/12/29
2109.15141v1,Predicting Code Review Completion Time in Modern Code Review,http://arxiv.org/abs/2109.15141v1,"Context. Modern Code Review (MCR) is being adopted in both open source andcommercial projects as a common practice. MCR is a widely acknowledged qualityassurance practice that allows early detection of defects as well as poorcoding practices. It also brings several other benefits such as knowledgesharing, team awareness, and collaboration.  Problem. In practice, code reviews can experience significant delays to becompleted due to various socio-technical factors which can affect the projectquality and cost. For a successful review process, peer reviewers shouldperform their review tasks in a timely manner while providing relevant feedbackabout the code change being reviewed. However, there is a lack of tool supportto help developers estimating the time required to complete a code review priorto accepting or declining a review request.  Objective. Our objective is to build and validate an effective approach topredict the code review completion time in the context of MCR and helpdevelopers better manage and prioritize their code review tasks.  Method. We formulate the prediction of the code review completion time as alearning problem. In particular, we propose a framework based on regressionmodels to (i) effectively estimate the code review completion time, and (ii)understand the main factors influencing code review completion time.",Moataz Chouchen,2021/9/30,2021/9/30
2108.01585v2,An Empirical Study on the Usage of Transformer Models for Code Completion,http://arxiv.org/abs/2108.01585v2,"Code completion aims at speeding up code writing by predicting the next codetoken(s) the developer is likely to write. Works in this field focused onimproving the accuracy of the generated predictions, with substantial leapsforward made possible by deep learning (DL) models. However, code completiontechniques are mostly evaluated in the scenario of predicting the next token totype, with few exceptions pushing the boundaries to the prediction of an entirecode statement. Thus, little is known about the performance of state-of-the-artcode completion approaches in more challenging scenarios in which, for example,an entire code block must be generated. We present a large-scale studyexploring the capabilities of state-of-the-art Transformer-based models insupporting code completion at different granularity levels, including singletokens, one or multiple entire statements, up to entire code blocks (e.g., theiterated block of a for loop). We experimented with several variants of tworecently proposed Transformer-based models, namely RoBERTa and the Text-To-TextTransfer Transformer (T5), for the task of code completion. The achievedresults show that Transformer-based models, and in particular the T5, representa viable solution for code completion, with perfect predictions ranging from~29%, obtained when asking the model to guess entire blocks, up to ~69%,reached in the simpler scenario of few tokens masked from the same codestatement.",Matteo Ciniselli,2021/8/3,2021/11/18
2004.05249v1,Sequence Model Design for Code Completion in the Modern IDE,http://arxiv.org/abs/2004.05249v1,"Code completion plays a prominent role in modern integrated developmentenvironments (IDEs). Machine learning has become ubiquitous in analogousnatural language writing and search software, surfacing more relevantautocompletions and search suggestions in fewer keystrokes. Prior research hasreported training high-accuracy, deep neural networks for modeling source code,but little attention has been given to the practical constraints imposed byinteractive developer tools. In particular, neural language models for sourcecode modeling like the one described in Maybe Deep Neural Networks are the BestChoice for Modeling Source Code are framed around code completion, but onlyreport accuracy of next-token prediction. However, in order for a languagemodel (LM) to work well within real-world code completion systems, it must alsoalways make suggestions that produce valid code that typechecks to support codecompletion's role in correctness-checking; return instantaneous results to helpprogrammers code more efficiently in fewer keystrokes; and be small enough tofit comfortably on disk and in memory on developer workstations, sincevirtually all modern IDEs run locally and support offline usage. To meet theseadditional requirements, we propose a novel design for predicting top-k nexttokens that combines static analysis' ability to enumerate all valid keywordsand in-scope identifiers with the ability of a language model to place aprobability distribution over them. Our model mixes character-level inputrepresentation with token output to represent out-of-vocabulary (OOV) tokensmeaningfully and minimize prediction latency. OOV tokens can be predictedthrough detection of local repetition common in software. This design achievesstate-of-art accuracy in source code modeling and fits the constraints imposedby real-world code completion implementations in modern IDEs.",Gareth Ari Aye,2020/4/10,2020/4/10
2106.10158v2,Learning to Complete Code with Sketches,http://arxiv.org/abs/2106.10158v2,"Code completion is usually cast as a language modelling problem, i.e.,continuing an input in a left-to-right fashion. However, in practice, someparts of the completion (e.g., string literals) may be very hard to predict,whereas subsequent parts directly follow from the context. To handle this, weinstead consider the scenario of generating code completions with ""holes""inserted in places where a model is uncertain. We develop Grammformer, aTransformer-based model that guides code generation by the programming languagegrammar, and compare it to a variety of more standard sequence models.  We train the models on code completion for C# and Python given partial codecontext. To evaluate models, we consider both ROUGE as well as a new metricRegexAcc that measures success of generating completions matching long outputswith as few holes as possible. In our experiments, Grammformer generates 10-50%more accurate completions compared to traditional generative models and 37-50%longer sketches compared to sketch-generating baselines trained with similartechniques.",Daya Guo,2021/6/18,2022/1/23
2008.03731v2,Combining Code Embedding with Static Analysis for Function-Call Completion,http://arxiv.org/abs/2008.03731v2,"Code completion is an important feature of integrated developmentenvironments (IDEs). It allows developers to produce code faster, especiallynovice ones who are not fully familiar with APIs and others code. Previousworks on code completion have mainly exploited static type systems ofprogramming languages or code history of the project under development or ofother projects using common APIs. In this work, we present a novel approach forimproving current function-calls completion tools by learning from independentcode repositories, using well-known natural language processing models that canlearn vector representation of source code (code embeddings). Our models arenot trained on historical data of specific projects. Instead, our approachallows to learn high-level concepts and their relationships present amongthousands of projects. As a consequence, the resulting system is able toprovide general suggestions that are not specific to particular projects orAPIs. Additionally, by taking into account the context of the call to complete,our approach suggests function calls relevant to that context. We evaluated ourapproach on a set of open-source projects unseen during the training. Theresults show that the use of the trained model along with a code suggestionplug-in based on static type analysis improves significantly the correctness ofthe completion suggestions.",M. Weyssow,2020/8/9,2020/10/31
2006.11968v3,A sparse code increases the speed and efficiency of neuro-dynamic programming for optimal control tasks with correlated inputs,http://arxiv.org/abs/2006.11968v3,"Sparse codes in neuroscience have been suggested to offer certaincomputational advantages over other neural representations of sensory data. Toexplore this viewpoint, a sparse code is used to represent natural images in anoptimal control task solved with neuro-dynamic programming, and itscomputational properties are investigated. The central finding is that whenfeature inputs to a linear network are correlated, an over-complete sparse codeincreases the memory capacity of the network in an efficient manner beyond thatpossible for any complete code with the same-sized input, and also increasesthe speed of learning the network weights. A complete sparse code is found tomaximise the memory capacity of a linear network by decorrelating its featureinputs to transform the design matrix of the least-squares problem to one offull rank. It also conditions the Hessian matrix of the least-squares problem,thereby increasing the rate of convergence to the optimal network weights.Other types of decorrelating codes would also achieve this. However, anover-complete sparse code is found to be approximately decorrelated, extractinga larger number of approximately decorrelated features from the same-sizedinput, allowing it to efficiently increase memory capacity beyond that possiblefor any complete code: a 2.25 times over-complete sparse code is shown to atleast double memory capacity compared with a complete sparse code using thesame input. This is used in sequential learning to store a potentially largenumber of optimal control tasks in the network, while catastrophic forgettingis avoided using a partitioned representation, yielding a cost-to-go functionapproximator that generalizes over the states in each partition. Sparse codeadvantages over dense codes and local codes are also discussed.",Peter N. Loxley,2020/6/22,2020/11/18
2001.03277v2,Searching a Database of Source Codes Using Contextualized Code Search,http://arxiv.org/abs/2001.03277v2,"Consider the case where a programmer has written some part of a program, buthas left part of the program (such as a method or a function body) incomplete.The goal is to use the context surrounding the missing code to automatically'figure out' which of the codes in the database would be useful to theprogrammer in order to help complete the missing code. The search is'contextualized' in the sense that the search engine should use clues in thepartially-completed code to figure out which database code is most useful. Theuser should not be required to formulate an explicit query. We castcontextualized code search as a learning problem, where the goal is to learn adistribution function computing the likelihood that each database codecompletes the program, and propose a neural model for predicting which databasecode is likely to be most useful. Because it will be prohibitively expensive toapply a neural model to each code in a database of millions or billions ofcodes at search time, one of our key technical concerns is ensuring a speedysearch. We address this by learning a 'reverse encoder' that can be used toreduce the problem of evaluating each database code to computing a convolutionof two normal distributions.",Rohan Mukherjee,2020/1/10,2020/7/26
2203.15580v1,Learning a Structured Latent Space for Unsupervised Point Cloud Completion,http://arxiv.org/abs/2203.15580v1,"Unsupervised point cloud completion aims at estimating the correspondingcomplete point cloud of a partial point cloud in an unpaired manner. It is acrucial but challenging problem since there is no paired partial-completesupervision that can be exploited directly. In this work, we propose a novelframework, which learns a unified and structured latent space that encodingboth partial and complete point clouds. Specifically, we map a series ofrelated partial point clouds into multiple complete shape and occlusion codepairs and fuse the codes to obtain their representations in the unified latentspace. To enforce the learning of such a structured latent space, the proposedmethod adopts a series of constraints including structured rankingregularization, latent code swapping constraint, and distribution supervisionon the related partial point clouds. By establishing such a unified andstructured latent space, better partial-complete geometry consistency and shapecompletion accuracy can be achieved. Extensive experiments show that ourproposed method consistently outperforms state-of-the-art unsupervised methodson both synthetic ShapeNet and real-world KITTI, ScanNet, and Matterport3Ddatasets.",Yingjie Cai,2022/3/29,2022/3/29
2303.04142v1,From Copilot to Pilot: Towards AI Supported Software Development,http://arxiv.org/abs/2303.04142v1,"AI-supported programming has arrived, as shown by the introduction andsuccesses of large language models for code, such as Copilot/Codex(Github/OpenAI) and AlphaCode (DeepMind). Above human average performance onprogramming challenges is now possible. However, software engineering is muchmore than solving programming contests. Moving beyond code completion toAI-supported software engineering will require an AI system that can, amongother things, understand how to avoid code smells, to follow language idioms,and eventually (maybe!) propose rational software designs. In this study, weexplore the current limitations of AI-supported code completion tools likeCopilot and offer a simple taxonomy for understanding the classification ofAI-supported code completion tools in this space. We first perform anexploratory study on Copilot's code suggestions for language idioms and codesmells. Copilot does not follow language idioms and avoid code smells in mostof our test scenarios. We then conduct additional investigation to determinethe current boundaries of AI-supported code completion tools like Copilot byintroducing a taxonomy of software abstraction hierarchies where 'basicprogramming functionality' such as code compilation and syntax checking is atthe least abstract level, software architecture analysis and design are at themost abstract level. We conclude by providing a discussion on challenges forfuture development of AI-supported code completion tools to reach the designlevel of abstraction in our taxonomy.",Rohith Pudari,2023/3/7,2023/3/7
2206.06460v2,MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning,http://arxiv.org/abs/2206.06460v2,"Representation learning of source code is essential for applying machinelearning to software engineering tasks. Learning code representation from amultilingual source code dataset has been shown to be more effective thanlearning from single-language datasets separately, since more training datafrom multilingual dataset improves the model's ability to extractlanguage-agnostic information from source code. However, existing multilingualtraining overlooks the language-specific information which is crucial formodeling source code across different programming languages, while onlyfocusing on learning a unified model with shared parameters among differentlanguages for language-agnostic information modeling. To address this problem,we propose MetaTPTrans, a meta learning approach for multilingual coderepresentation learning. MetaTPTrans generates different parameters for thefeature extractor according to the specific programming language type of theinput code snippet, enabling the model to learn both language-agnostic andlanguage-specific information with dynamic parameters in the feature extractor.We conduct experiments on the code summarization and code completion tasks toverify the effectiveness of our approach. The results demonstrate thesuperiority of our approach with significant improvements on state-of-the-artbaselines.",Weiguo Pian,2022/6/13,2022/12/5
2004.06343v1,Code Completion using Neural Attention and Byte Pair Encoding,http://arxiv.org/abs/2004.06343v1,"In this paper, we aim to do code completion based on implementing a NeuralNetwork from Li et. al.. Our contribution is that we use an encoding that isin-between character and word encoding called Byte Pair Encoding (BPE). We usethis on the source code files treating them as natural text without first goingthrough the abstract syntax tree (AST). We have implemented two models: anattention-enhanced LSTM and a pointer network, where the pointer network wasoriginally introduced to solve out of vocabulary problems. We are interested tosee if BPE can replace the need for the pointer network for code completion.",Youri Arkesteijn,2020/4/14,2020/4/14
1912.00184v2,Complete j-MDP convolutional codes,http://arxiv.org/abs/1912.00184v2,"Maximum distance profile (MDP) convolutional codes have been proven to bevery suitable for transmission over an erasure channel. In addition, thesubclass of complete MDP convolutional codes has the ability to restartdecoding after a burst of erasures. However, there is a lack of constructionsof these codes over fields of small size. In this paper, we introduce thenotion of complete j-MDP convolutional codes, which are a generalization ofcomplete MDP convolutional codes, and describe their decoding properties. Inparticular, we present a decoding algorithm for decoding erasures within agiven time delay T and show that complete T-MDP convolutional codes are optimalfor this algorithm. Moreover, using a computer search with the MAPLE software,we determine the minimal binary and non-binary field size for the existence of(2,1,2) complete j-MDP convolutional codes and provide correspondingconstructions. We give a description of all (2,1,2) complete MDP convolutionalcodes over the smallest possible fields, namely F_13 and F_16 and we also giveconstructions for (2,1,3) complete 4-MDP convolutional codes over F_128obtained by a randomized computer search.",Paulo J. Almeida,2019/11/30,2020/4/26
1810.00015v5,A new approach to the Kasami codes of type 2,http://arxiv.org/abs/1810.00015v5,"The dual of the Kasami code of length $q^2-1$, with $q$ a power of $2$, isconstructed by concatenating a cyclic MDS code of length $q+1$ over $F_q$ witha Simplex code of length $q-1$. This yields a new derivation of the weightdistribution of the Kasami code, a new description of its coset graph, and anew proof that the Kasami code is completely regular. The automorphism groupsof the Kasami code and the related $q$-ary MDS code are determined. New cycliccompletely regular codes over finite fields a power of $2$, generalized Kasamicodes, are constructed; they have coset graphs isomorphic to that of the Kasamicodes. Another wide class of completely regular codes, including additivecodes, as well as unrestricted codes, is obtained by combining cosets of theKasami or generalized Kasami code.",Minjia Shi,2018/9/28,2023/6/26
2204.09877v1,Non-autoregressive Model for Full-line Code Completion,http://arxiv.org/abs/2204.09877v1,"Code completion tools are frequently used by software developers toaccelerate software development by suggesting the following code elements.Completing a sequence of code tokens (e.g., a full line of code) has beenproved more efficient than predicting a single token at a time. To complete thecode sequence, researchers are employing AutoRegressive (AR) decoders togenerate tokens in a left-to-right, token-by-token fashion. Consequently, theprediction of the next token depends on all previously generated tokens, whichleads to high latency in inference. To improve the efficiency and accuracy offull-line code completion, in this paper, we propose a Non-AutoRegressive (NAR)model for code completion boosted by a syntax-aware sampling strategy. Ourexperimental results on two widely used datasets suggest that our modeloutperforms both AR and NAR baselines on full-line code completion, and it isfaster than the AR model with up to 9 times speed-up.",Fang Liu,2022/4/21,2022/4/21
1104.0005v1,On the binary codes with parameters of triply-shortened 1-perfect codes,http://arxiv.org/abs/1104.0005v1,"We study properties of binary codes with parameters close to the parametersof 1-perfect codes. An arbitrary binary $(n=2^m-3, 2^{n-m-1}, 4)$ code $C$,i.e., a code with parameters of a triply-shortened extended Hamming code, is acell of an equitable partition of the $n$-cube into six cells. An arbitrarybinary $(n=2^m-4, 2^{n-m}, 3)$ code $D$, i.e., a code with parameters of atriply-shortened Hamming code, is a cell of an equitable family (but not apartition) from six cells. As a corollary, the codes $C$ and $D$ are completelysemiregular; i.e., the weight distribution of such a code depends only on theminimal and maximal codeword weights and the code parameters. Moreover, if $D$is self-complementary, then it is completely regular. As an intermediateresult, we prove, in terms of distance distributions, a general criterion for apartition of the vertices of a graph (from rather general class of graphs,including the distance-regular graphs) to be equitable. Keywords: 1-perfectcode; triply-shortened 1-perfect code; equitable partition; perfect coloring;weight distribution; distance distribution",Denis Krotov,2011/3/31,2011/3/31
2112.14067v1,The complete weight enumerator of the Reed-Solomon code with dimension two or three,http://arxiv.org/abs/2112.14067v1,"It is well-known that Reed-Solomon codes and extended Reed-Solomon codes aretwo special classes of MDS codes with wide applications in practice. Thecomplete weight enumerators of these codes are very important for determiningthe capability of both error-detection and error-correction. In this paper, forany positive integer $m$ and prime $p$, basing on the character sums, wedetermine the complete weight enumerators of the Reed-Solomon code and theextended Reed-Solomon code with dimension $k$ $(k=2,3)$ over$\mathbb{F}_{p^m}$, explictly, which are generalizations of the correspondingresults in \cite{BK91,K04}.",Canze Zhu,2021/12/28,2021/12/28
2207.04232v3,Construction of MDS self-dual codes from generalized Reed-Solomon codes,http://arxiv.org/abs/2207.04232v3,"MDS codes and self-dual codes are important families of classical codes incoding theory. It is of interest to investigate MDS self-dual codes. Theexistence of MDS self-dual codes over finite field $F_q$ is completely solvedfor $q$ is even. In this paper, for finite field with odd characteristic, weconstruct some new classes of MDS self-dual codes by (extended) generalizedReed-Solomon codes.",Ruhao Wan,2022/7/9,2022/8/27
1909.11503v2,Improve Language Modelling for Code Completion through Statement Level Language Model based on Statement Embedding Generated by BiLSTM,http://arxiv.org/abs/1909.11503v2,"Language models such as RNN, LSTM or other variants have been widely used asgenerative models in natural language processing. In last few years, takingsource code as natural languages, parsing source code into a token sequence andusing a language model such as LSTM to train that sequence are state-of-artmethods to get a generative model for solving the problem of code completion.However, for source code with hundreds of statements, traditional LSTM model orattention-based LSTM model failed to capture the long term dependency of sourcecode. In this paper, we propose a novel statement-level language model (SLM)which uses BiLSTM to generate the embedding for each statement. The standardLSTM is adopted in SLM to iterate and accumulate the embedding of eachstatement in context to help predict next code. The statement level attentionmechanism is also adopted in the model. The proposed model SLM is aimed attoken level code completion. The experiments on inner-project and cross-projectdata sets indicate that the newly proposed statement-level language model withattention mechanism (SLM) outperforms all other state-of-art models in tokenlevel code completion task.",Yixiao Yang,2019/9/25,2019/10/25
2007.01113v2,Entanglement-Assisted Quantum Error Correcting Codes From RS Codes and BCH Codes with Extension Degree 2,http://arxiv.org/abs/2007.01113v2,"Entanglement-assisted quantum error correcting codes (EAQECCs) constructedfrom Reed-Solomon codes and BCH codes are considered in this work. It isprovided a complete and explicit formula for the parameters of EAQECCs comingfrom any Reed-Solomon code, for the Hermitian metric, and from any BCH codewith extension degree $2$ and consecutive cyclotomic cosets, for both theEuclidean and the Hermitian metric. The main task in this work is thecomputation of a completely general formula for $c$, the minimum number ofrequired maximally entangled quantum states.",Carlos Galindo,2020/7/2,2021/4/10
2303.12570v3,RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation,http://arxiv.org/abs/2303.12570v3,"The task of repository-level code completion is to continue writing theunfinished code based on a broader context of the repository. While forautomated code completion tools, it is difficult to utilize the usefulinformation scattered in different files. We propose RepoCoder, a simple,generic, and effective framework to address the challenge. It streamlines therepository-level code completion process by incorporating a similarity-basedretriever and a pre-trained code language model in an iterativeretrieval-generation pipeline. RepoCoder makes effective utilization ofrepository-level information for code completion and has the ability togenerate code at various levels of granularity. Moreover, we propose a newbenchmark RepoEval, which consists of the latest and high-quality real-worldrepositories covering line, API invocation, and function body completionscenarios. Experimental results indicate that RepoCoder significantly improvesthe In-File completion baseline by over 10% in all settings and consistentlyoutperforms the vanilla retrieval-augmented code completion approach.Furthermore, we validate the effectiveness of RepoCoder through comprehensiveanalysis, providing valuable insights for future research. Our source code andbenchmark are publicly available:https://github.com/microsoft/CodeT/tree/main/RepoCoder",Fengji Zhang,2023/3/22,2023/10/20
1905.02482v1,Two classes of linear codes and their generalized Hamming weights,http://arxiv.org/abs/1905.02482v1,"The generalized Hamming weights (GHWs) are fundamental parameters of linearcodes. In this paper, we investigate the generalized Hamming weights of twoclasses of linear codes constructed from defining sets and determine themcompletely employing a number-theoretic approach.",Gaopeng Jian,2019/5/7,2019/5/7
2110.00805v1,Complete b-symbol weight distribution of some irreducible cyclic codes,http://arxiv.org/abs/2110.00805v1,"Recently, $b$-symbol codes are proposed to protect against $b$-symbol errorsin $b$-symbol read channels. It is an interesting subject of study to considerthe complete $b$-symbol weight distribution of cyclic codes since $b$-symbolmetric is a generalization for Hamming metric. The complete $b$-symbol Hammingweight distribution of irreducible codes is known in only a few cases. In thispaper, we give a complete $b$-symbol Hamming weight distribution of a class ofirreducible codes with two nonzero $b$-symbol Hamming weights.",Hongwei Zhu,2021/10/2,2021/10/2
0804.0637v1,A Complete Classification of Ternary Self-Dual Codes of Length 24,http://arxiv.org/abs/0804.0637v1,"Ternary self-dual codes have been classified for lengths up to 20. At length24, a classification of only extremal self-dual codes is known. In this paper,we give a complete classification of ternary self-dual codes of length 24 usingthe classification of 24-dimensional odd unimodular lattices.",Masaaki Harada,2008/4/4,2008/4/4
1104.3727v4,A complete classification of doubly even self-dual codes of length 40,http://arxiv.org/abs/1104.3727v4,"A complete classification of binary doubly even self-dual codes of length 40is given. As a consequence, a classification of binary extremal self-dual codesof length 38 is also given.",Koichi Betsumiya,2011/4/19,2012/11/12
2004.07059v2,Classification of optimal quaternary Hermitian LCD codes of dimension $2$,http://arxiv.org/abs/2004.07059v2,Hermitian linear complementary dual codes are linear codes whose intersectionwith their Hermitian dual code is trivial. The largest minimum weight amongquaternary Hermitian linear complementary dual codes of dimension $2$ is knownfor each length. We give the complete classification of optimal quaternaryHermitian linear complementary dual codes of dimension $2$.,Keita Ishizuka,2020/4/15,2020/4/18
1803.11335v1,On the classification of linear complementary dual codes,http://arxiv.org/abs/1803.11335v1,We give a complete classification of binary linear complementary dual codesof lengths up to $13$ and ternary linear complementary dual codes of lengths upto $10$.,Makoto Araya,2018/3/30,2018/3/30
1208.0393v2,Classification of a family of completely transitive codes,http://arxiv.org/abs/1208.0393v2,"The completely regular codes in Hamming graphs have a high degree ofcombinatorial symmetry and have attracted a lot of interest since theirintroduction in 1973 by Delsarte. This paper studies the subfamily ofcompletely transitive codes, those in which an automorphism group is transitiveon each part of the distance partition. This family is a natural generalisationof the binary completely transitive codes introduced by Sole in 1990. We takethe first step towards a classification of these codes, determining those forwhich the automorphism group is faithful on entries.",Neil I. Gillespie,2012/8/2,2012/10/26
1106.5930v2,An Algorithm for Classification of Binary Self-Dual Codes,http://arxiv.org/abs/1106.5930v2,"An efficient algorithm for classification of binary self-dual codes ispresented. As an application, a complete classification of the self-dual codesof length 38 is given.",Stefka Bouyuklieva,2011/6/29,2012/1/23
1012.5464v2,Classification of self-dual codes of length 36,http://arxiv.org/abs/1012.5464v2,A complete classification of binary self-dual codes of length 36 is given.,Masaaki Harada,2010/12/25,2012/3/22
1106.5960v1,"On the classification of binary self-dual [44,22,8] codes with an automorphism of order 3 or 7",http://arxiv.org/abs/1106.5960v1,"All binary self-dual [44,22,8] codes with an automorphism of order 3 or 7 areclassified. In this way we complete the classification of extremal self-dualcodes of length 44 having an automorphism of odd prime order.",Stefka Bouyuklieva,2011/6/29,2011/6/29
1302.1626v2,On the Classification of Extremal Doubly Even Self-Dual Codes with 2-Transitive Automorphism Group,http://arxiv.org/abs/1302.1626v2,"In this note, we complete the classification of extremal doubly evenself-dual codes with 2-transitive automorphism groups.",Naoki Chigira,2013/2/7,2013/2/19
2302.10556v1,On the classification of completely regular codes with covering radius two and antipodal dual,http://arxiv.org/abs/2302.10556v1,"We classify all linear completely regular codes which have covering radius$\rho = 2$ and whose dual are antipodal. For this, we firstly show severalproperties of such dual codes, which are two-weight codes.",J. Borges,2023/2/21,2023/2/21
math/0702543v1,Group convolutional codes,http://arxiv.org/abs/math/0702543v1,In this note we introduce the concept of group convolutional code. We make acomplete classification of the minimal $S_3$-convolutional codes over the fieldof five elements by means of Jategaonkar's theorems.,S. Estrada,2007/2/19,2007/2/19
1901.05445v2,Deep Holes of Projective Reed-Solomon Codes,http://arxiv.org/abs/1901.05445v2,"Projective Reed-Solomon (PRS) codes are Reed-Solomon codes of the maximumpossible length q+1. The classification of deep holes --received words withmaximum possible error distance-- for PRS codes is an important and difficultproblem. In this paper, we use algebraic methods to explicitly construct threeclasses of deep holes for PRS codes. We show that these three classescompletely classify all deep holes of PRS codes with redundancy at most four.Previously, the deep hole classification was only known for PRS codes withredundancy at most three in work arXiv:1612.05447",Jun Zhang,2019/1/16,2019/9/3
0906.0550v1,On linear completely regular codes with covering radius $=1$. Construction and classification,http://arxiv.org/abs/0906.0550v1,"Completely regular codes with covering radius $\rho=1$ must have minimumdistance $d\leq 3$. For $d=3$, such codes are perfect and their parameters arewell known. In this paper, the cases $d=1$ and $d=2$ are studied and completelycharacterized when the codes are linear. Moreover, it is proven that all thesecodes are completely transitive.",J. Borges J. Rifa V. Zinoviev,2009/6/2,2009/6/2
2311.05428v2,"The classification of orthogonal arrays OA(2048,14,2,7) and some completely regular codes",http://arxiv.org/abs/2311.05428v2,"We describe the classification of orthogonal arrays OA$(2048,14,2,7)$, or,equivalently, completely regular $\{14;2\}$-codes in the $14$-cube ($30848$equivalence classes). In particular, we find that there is exactly onealmost-OA$(2048,14,2,7+1)$, up to equivalence. As derived objects,OA$(1024,13,2,6)$ ($202917$ classes) and completely regular $\{12,2;2,12\}$-and $\{14,12,2;2,12,14\}$-codes in the $13$- and $14$-cubes, respectively, arealso classified.  Keywords: binary orthogonal array, completely regular code, binary 1-perfectcode.",Denis S. Krotov,2023/11/9,2024/1/8
1802.06985v4,Binary linear complementary dual codes,http://arxiv.org/abs/1802.06985v4,"Linear complementary dual codes (or codes with complementary duals) are codeswhose intersections with their dual codes are trivial. We study binary linearcomplementary dual $[n,k]$ codes with the largest minimum weight among allbinary linear complementary dual $[n,k]$ codes. We characterize binary linearcomplementary dual codes with the largest minimum weight for small dimensions.A complete classification of binary linear complementary dual $[n,k]$ codeswith the largest minimum weight is also given for $1 \le k \le n \le 16$.",Masaaki Harada,2018/2/20,2018/5/18
1505.07363v2,An Enumeration of the Equivalence Classes of Self-Dual Matrix Codes,http://arxiv.org/abs/1505.07363v2,"As a result of their applications in network coding, space-time coding, andcoding for criss-cross errors, matrix codes have garnered significantattention; in various contexts, these codes have also been termed rank-metriccodes, space-time codes over finite fields, and array codes. We focus oncharacterizing matrix codes that are both efficient (have high rate) andeffective at error correction (have high minimum rank-distance). It is wellknown that the inherent trade-off between dimension and minimum distance for amatrix code is reversed for its dual code; specifically, if a matrix code hashigh dimension and low minimum distance, then its dual code will have lowdimension and high minimum distance. With an aim towards finding codes with aperfectly balanced trade-off, we study self-dual matrix codes. In this work, wedevelop a framework based on double cosets of the matrix-equivalence maps toprovide a complete classification of the equivalence classes of self-dualmatrix codes, and we employ this method to enumerate the equivalence classes ofthese codes for small parameters.",Katherine Morrison,2015/5/27,2015/7/20
2101.02742v1,Action Word Prediction for Neural Source Code Summarization,http://arxiv.org/abs/2101.02742v1,"Source code summarization is the task of creating short, natural languagedescriptions of source code. Code summarization is the backbone of muchsoftware documentation such as JavaDocs, in which very brief comments such as""adds the customer object"" help programmers quickly understand a snippet ofcode. In recent years, automatic code summarization has become a high valuetarget of research, with approaches based on neural networks making rapidprogress. However, as we will show in this paper, the production of goodsummaries relies on the production of the action word in those summaries: themeaning of the example above would be completely changed if ""removes"" weresubstituted for ""adds."" In this paper, we advocate for a special emphasis onaction word prediction as an important stepping stone problem towards bettercode summarization -- current techniques try to predict the action word alongwith the whole summary, and yet action word prediction on its own is quitedifficult. We show the value of the problem for code summaries, explore theperformance of current baselines, and provide recommendations for futureresearch.",Sakib Haque,2021/1/7,2021/1/7
2108.12738v2,SummerTime: Text Summarization Toolkit for Non-experts,http://arxiv.org/abs/2108.12738v2,"Recent advances in summarization provide models that can generate summariesof higher quality. Such models now exist for a number of summarization tasks,including query-based summarization, dialogue summarization, and multi-documentsummarization. While such models and tasks are rapidly growing in the researchfield, it has also become challenging for non-experts to keep track of them. Tomake summarization methods more accessible to a wider audience, we developSummerTime by rethinking the summarization task from the perspective of an NLPnon-expert. SummerTime is a complete toolkit for text summarization, includingvarious models, datasets and evaluation metrics, for a full spectrum ofsummarization-related tasks. SummerTime integrates with libraries designed forNLP researchers, and enables users with easy-to-use APIs. With SummerTime,users can locate pipeline solutions and search for the best model with theirown data, and visualize the differences, all with a few lines of code. We alsoprovide explanations for models and evaluation metrics to help users understandthe model behaviors and select models that best suit their needs. Our library,along with a notebook demo, is available athttps://github.com/Yale-LILY/SummerTime.",Ansong Ni,2021/8/29,2021/9/10
2108.12987v2,CAST: Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees,http://arxiv.org/abs/2108.12987v2,"Code summarization aims to generate concise natural language descriptions ofsource code, which can help improve program comprehension and maintenance.Recent studies show that syntactic and structural information extracted fromabstract syntax trees (ASTs) is conducive to summary generation. However,existing approaches fail to fully capture the rich information in ASTs becauseof the large size/depth of ASTs. In this paper, we propose a novel model CASTthat hierarchically splits and reconstructs ASTs. First, we hierarchicallysplit a large AST into a set of subtrees and utilize a recursive neural networkto encode the subtrees. Then, we aggregate the embeddings of subtrees byreconstructing the split ASTs to get the representation of the complete AST.Finally, AST representation, together with source code embedding obtained by avanilla code token encoder, is used for code summarization. Extensiveexperiments, including the ablation study and the human evaluation, onbenchmarks have demonstrated the power of CAST. To facilitate reproducibility,our code and data are available at https://anonymous.4open.science/r/CAST/.",Ensheng Shi,2021/8/30,2021/11/30
2309.00584v1,Laminar: A New Serverless Stream-based Framework with Semantic Code Search and Code Completion,http://arxiv.org/abs/2309.00584v1,"This paper introduces Laminar, a novel serverless framework based ondispel4py, a parallel stream-based dataflow library. Laminar efficientlymanages streaming workflows and components through a dedicated registry,offering a seamless serverless experience. Leveraging large lenguage models,Laminar enhances the framework with semantic code search, code summarization,and code completion. This contribution enhances serverless computing bysimplifying the execution of streaming computations, managing data streams moreefficiently, and offering a valuable tool for both researchers andpractitioners.",Zaynab Zahra,2023/9/1,2023/9/1
2310.16853v1,CP-BCS: Binary Code Summarization Guided by Control Flow Graph and Pseudo Code,http://arxiv.org/abs/2310.16853v1,"Automatically generating function summaries for binaries is an extremelyvaluable but challenging task, since it involves translating the executionbehavior and semantics of the low-level language (assembly code) intohuman-readable natural language. However, most current works on understandingassembly code are oriented towards generating function names, which involvenumerous abbreviations that make them still confusing. To bridge this gap, wefocus on generating complete summaries for binary functions, especially forstripped binary (no symbol table and debug information in reality). To fullyexploit the semantics of assembly code, we present a control flow graph andpseudo code guided binary code summarization framework called CP-BCS. CP-BCSutilizes a bidirectional instruction-level control flow graph and pseudo codethat incorporates expert knowledge to learn the comprehensive binary functionexecution behavior and logic semantics. We evaluate CP-BCS on 3 differentbinary optimization levels (O1, O2, and O3) for 3 different computerarchitectures (X86, X64, and ARM). The evaluation results demonstrate CP-BCS issuperior and significantly improves the efficiency of reverse engineering.",Tong Ye,2023/10/24,2023/10/24
2107.02395v1,COSPEX: A Program Comprehension Tool for Novice Programmers,http://arxiv.org/abs/2107.02395v1,"Developers often encounter unfamiliar code during software maintenance whichconsumes a significant amount of time for comprehension, especially for noviceprogrammers. Automated techniques that analyze a source code and present keyinformation to the developers can lead to an effective comprehension of thecode. Researchers have come up with automated code summarization techniquesthat focus on code summarization by generating brief summaries rather thanaiding its comprehension. Existing debuggers represent the execution states ofthe program but they do not show the complete execution at a single point.Studies have revealed that the effort required for program comprehension can bereduced if novice programmers are provided with worked examples. Hence, wepropose COSPEX (Comprehension using Summarization via Program Execution) - anAtom plugin that dynamically extracts key information for every line of codeexecuted and presents it to the developers in the form of an interactiveexample-like dynamic information instance. As a preliminary evaluation, wepresented 14 undergraduates having Python programming experience up to 1 yearwith a code comprehension task in a user survey. We observed that COSPEX helpednovice programmers in program comprehension and improved their understanding ofthe code execution. The source code and tool are available at:https://bit.ly/3utHOBM, and the demo on Youtube is available at:https://bit.ly/2Sp08xQ.",Ashutosh Rajput,2021/7/6,2021/7/6
2306.11832v1,QuOTeS: Query-Oriented Technical Summarization,http://arxiv.org/abs/2306.11832v1,"Abstract. When writing an academic paper, researchers often spendconsiderable time reviewing and summarizing papers to extract relevantcitations and data to compose the Introduction and Related Work sections. Toaddress this problem, we propose QuOTeS, an interactive system designed toretrieve sentences related to a summary of the research from a collection ofpotential references and hence assist in the composition of new papers. QuOTeSintegrates techniques from Query-Focused Extractive Summarization andHigh-Recall Information Retrieval to provide Interactive Query-FocusedSummarization of scientific documents. To measure the performance of oursystem, we carried out a comprehensive user study where participants uploadedpapers related to their research and evaluated the system in terms of itsusability and the quality of the summaries it produces. The results show thatQuOTeS provides a positive user experience and consistently providesquery-focused summaries that are relevant, concise, and complete. We share thecode of our system and the novel Query-Focused Summarization dataset collectedduring our experiments at https://github.com/jarobyte91/quotes.",Juan Ramirez-Orta,2023/6/20,2023/6/20
2207.04285v1,A Closer Look into Transformer-Based Code Intelligence Through Code Transformation: Challenges and Opportunities,http://arxiv.org/abs/2207.04285v1,"Transformer-based models have demonstrated state-of-the-art performance inmany intelligent coding tasks such as code comment generation and codecompletion. Previous studies show that deep learning models are sensitive tothe input variations, but few studies have systematically studied therobustness of Transformer under perturbed input code. In this work, weempirically study the effect of semantic-preserving code transformation on theperformance of Transformer. Specifically, 24 and 27 code transformationstrategies are implemented for two popular programming languages, Java andPython, respectively. For facilitating analysis, the strategies are groupedinto five categories: block transformation, insertion/deletion transformation,grammatical statement transformation, grammatical token transformation, andidentifier transformation. Experiments on three popular code intelligencetasks, including code completion, code summarization and code search,demonstrate insertion/deletion transformation and identifier transformationshow the greatest impact on the performance of Transformer. Our results alsosuggest that Transformer based on abstract syntax trees (ASTs) shows morerobust performance than the model based on only code sequence under most codetransformations. Besides, the design of positional encoding can impact therobustness of Transformer under code transformation. Based on our findings, wedistill some insights about the challenges and opportunities forTransformer-based code intelligence.",Yaoxian Li,2022/7/9,2022/7/9
2109.08780v1,Long-Range Modeling of Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy,http://arxiv.org/abs/2109.08780v1,"Statistical language modeling and translation with transformers have foundmany successful applications in program understanding and generation tasks,setting high benchmarks for tools in modern software development environments.The finite context window of these neural models means, however, that they willbe unable to leverage the entire relevant context of large files and packagesfor any given task. While there are many efforts to extend the context window,we introduce an architecture-independent approach for leveraging the syntactichierarchies of source code for incorporating entire file-level context into afixed-length window. Using concrete syntax trees of each source file we extractsyntactic hierarchies and integrate them into context window by selectivelyremoving from view more specific, less relevant scopes for a given task. Weevaluate this approach on code generation tasks and joint translation ofnatural language and source code in Python programming language, achieving anew state-of-the-art in code completion and summarization for Python in theCodeXGLUE benchmark. We also introduce new CodeXGLUE benchmarks foruser-experience-motivated tasks: code completion with normalized literals,method body completion/code summarization conditioned on file-level context.",Colin B. Clement,2021/9/17,2021/9/17
2202.06840v1,What Do They Capture? -- A Structural Analysis of Pre-Trained Language Models for Source Code,http://arxiv.org/abs/2202.06840v1,"Recently, many pre-trained language models for source code have been proposedto model the context of code and serve as a basis for downstream codeintelligence tasks such as code completion, code search, and codesummarization. These models leverage masked pre-training and Transformer andhave achieved promising results. However, currently there is still littleprogress regarding interpretability of existing pre-trained code models. It isnot clear why these models work and what feature correlations they can capture.In this paper, we conduct a thorough structural analysis aiming to provide aninterpretation of pre-trained language models for source code (e.g., CodeBERT,and GraphCodeBERT) from three distinctive perspectives: (1) attention analysis,(2) probing on the word embedding, and (3) syntax tree induction. Throughcomprehensive analysis, this paper reveals several insightful findings that mayinspire future studies: (1) Attention aligns strongly with the syntax structureof code. (2) Pre-training language models of code can preserve the syntaxstructure of code in the intermediate representations of each Transformerlayer. (3) The pre-trained models of code have the ability of inducing syntaxtrees of code. Theses findings suggest that it may be helpful to incorporatethe syntax structure of code into the process of pre-training for better coderepresentations.",Yao Wan,2022/2/14,2022/2/14
2009.02858v1,Summarization in Semantic Based Service Discovery in Dynamic IoT-Edge Networks,http://arxiv.org/abs/2009.02858v1,"In the last decade, many semantic-based routing protocols had been designedfor peer-to-peer systems. However, they are not suitable for IoT systems,mainly due to their high demands in memory and computing power which are notavailable in many IoT devices. In this paper, we develop a semantic-basedrouting protocol for dynamic IoT systems to facilitate dynamic IoT capabilitydiscovery and composition. Our protocol is a fully decentralized routingprotocol. To reduce the space requirement for routing, each node maintains asummarized routing table. We design an ontology-based summarization algorithmto smartly group similar capabilities in the routing tables and supportadaptive routing table compression. We also design an ontology coding scheme tocode keywords used in the routing tables and query messages. To complete thesummarization scheme, we consider the metrics for choosing the summarizationcandidates in an overflowing routing table. Some of these metrics are novel andare difficult to measure, such as coverage and stability. Our solutionssignificantly reduce the routing table size, ensuring that the routing tablesize can be bounded by the available memory of the IoT devices, whilesupporting efficient IoT capability lookup. Experimental results show that ourapproach can yield significantly lower network traffic and memory requirementfor IoT capability lookup when compared with existing semantic-based routingalgorithms including a centralized solution, a DHT-based approach, a controlledflooding scheme, and a cache-based solution.",Hessam Moeini,2020/9/7,2020/9/7
2307.02503v1,Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review,http://arxiv.org/abs/2307.02503v1,"This paper provides a comprehensive review of the literature concerning theutilization of Natural Language Processing (NLP) techniques, with a particularfocus on transformer-based large language models (LLMs) trained using Big Code,within the domain of AI-assisted programming tasks. LLMs, augmented withsoftware naturalness, have played a crucial role in facilitating AI-assistedprogramming applications, including code generation, code completion, codetranslation, code refinement, code summarization, defect detection, and clonedetection. Notable examples of such applications include the GitHub Copilotpowered by OpenAI's Codex and DeepMind AlphaCode. This paper presents anoverview of the major LLMs and their applications in downstream tasks relatedto AI-assisted programming. Furthermore, it explores the challenges andopportunities associated with incorporating NLP techniques with softwarenaturalness in these applications, with a discussion on extending AI-assistedprogramming capabilities to Apple's Xcode for mobile software development. Thispaper also presents the challenges of and opportunities for incorporating NLPtechniques with software naturalness, empowering developers with advancedcoding assistance and streamlining the software development process.",Man Fai Wong,2023/7/4,2023/7/4
q-bio/0410008v1,Needed for completion of the human genome: hypothesis driven experiments and biologically realistic mathematical models,http://arxiv.org/abs/q-bio/0410008v1,"With the sponsorship of ``Fundacio La Caixa'' we met in Barcelona, November21st and 22nd, to analyze the reasons why, after the completion of the humangenome sequence, the identification all protein coding genes and their variantsremains a distant goal. Here we report on our discussions and summarize some ofthe major challenges that need to be overcome in order to complete the humangene catalog.",Roderic Guigo,2004/10/6,2004/10/6
2009.08366v4,GraphCodeBERT: Pre-training Code Representations with Data Flow,http://arxiv.org/abs/2009.08366v4,"Pre-trained models for programming language have achieved dramatic empiricalimprovements on a variety of code-related tasks such as code search, codecompletion, code summarization, etc. However, existing pre-trained modelsregard a code snippet as a sequence of tokens, while ignoring the inherentstructure of code, which provides crucial code semantics and would enhance thecode understanding process. We present GraphCodeBERT, a pre-trained model forprogramming language that considers the inherent structure of code. Instead oftaking syntactic-level structure of code like abstract syntax tree (AST), weuse data flow in the pre-training stage, which is a semantic-level structure ofcode that encodes the relation of ""where-the-value-comes-from"" betweenvariables. Such a semantic-level structure is neat and does not bring anunnecessarily deep hierarchy of AST, the property of which makes the model moreefficient. We develop GraphCodeBERT based on Transformer. In addition to usingthe task of masked language modeling, we introduce two structure-awarepre-training tasks. One is to predict code structure edges, and the other is toalign representations between source code and code structure. We implement themodel in an efficient way with a graph-guided masked attention function toincorporate the code structure. We evaluate our model on four tasks, includingcode search, clone detection, code translation, and code refinement. Resultsshow that code structure and newly introduced pre-training tasks can improveGraphCodeBERT and achieves state-of-the-art performance on the four downstreamtasks. We further show that the model prefers structure-level attentions overtoken-level attentions in the task of code search.",Daya Guo,2020/9/17,2021/9/13
2401.12554v1,Can Large Language Models Write Parallel Code?,http://arxiv.org/abs/2401.12554v1,"Large Language Models are becoming an increasingly popular tool for softwaredevelopment. Their ability to model and generate source code has beendemonstrated in a variety of contexts, including code completion,summarization, translation, and lookup. However, they often struggle togenerate code for more complex tasks. In this paper, we explore the ability ofstate-of-the-art language models to generate parallel code. We propose abenchmark, PCGBench, consisting of a set of 420 tasks for evaluating theability of language models to generate parallel code, and we evaluate theperformance of several state-of-the-art open- and closed-source language modelson these tasks. We introduce novel metrics for comparing parallel codegeneration performance and use them to explore how well each LLM performs onvarious parallel programming models and computational problem types.",Daniel Nichols,2024/1/23,2024/1/23
2108.07129v2,Autoencoders as Tools for Program Synthesis,http://arxiv.org/abs/2108.07129v2,"Recently there have been many advances in research on language modeling ofsource code. Applications range from code suggestion and completion to codesummarization. However, complete program synthesis of industry-gradeprogramming languages remains an open problem. In this work, we introduce andexperimentally validate a variational autoencoder model for program synthesisof industry-grade programming languages. This model makes use of the inherenttree structure of code and can be used in conjunction with gradient freeoptimization techniques like evolutionary methods to generate programs thatmaximize a given fitness function, for instance, passing a set of test cases. Ademonstration is avaliable at https://tree2tree.app",Sander de Bruin,2021/8/16,2021/9/5
0911.1828v1,Characterizing completely regular codes from an algebraic viewpoint,http://arxiv.org/abs/0911.1828v1,"We first summarize the basic structure of the outer distribution module of acompletely regular code. Then, employing a simple lemma concerning eigenvectorsin association schemes, we propose to study the tightest case, where theindices of the eigenspace that appear in the outer distribution module areequally spaced. In addition to the arithmetic codes of the companion paper,this highly structured class includes other beautiful examples and we proposethe classification of $Q$-polynomial completely regular codes in the Hamminggraphs. A key result is Theorem 3.10 which finds that the $Q$-polynomialcondition is equivalent to the presence of a certain Leonard pair. Thisconnection has impact in two directions. First, the Leonard pairs areclassified and we gain quite a bit of information about the algebraic structureof any code in our class. But also this gives a new setting for the study ofLeonard pairs, one closely related to the classical one where a Leonard pairarises from each thin/dual-thin irreducible module of a Terwilliger algebra ofsome $P$- and $Q$-polynomial association scheme, yet not previously studied. Itis particularly interesting that the Leonard pair associated to some code $C$may belong to one family in the Askey scheme while the distance-regular graphin which the code is found may belong to another.",J. H. Koolen,2009/11/10,2009/11/10
2007.16193v1,SimulEval: An Evaluation Toolkit for Simultaneous Translation,http://arxiv.org/abs/2007.16193v1,"Simultaneous translation on both text and speech focuses on a real-time andlow-latency scenario where the model starts translating before reading thecomplete source input. Evaluating simultaneous translation models is morecomplex than offline models because the latency is another factor to considerin addition to translation quality. The research community, despite its growingfocus on novel modeling approaches to simultaneous translation, currently lacksa universal evaluation procedure. Therefore, we present SimulEval, aneasy-to-use and general evaluation toolkit for both simultaneous text andspeech translation. A server-client scheme is introduced to create asimultaneous translation scenario, where the server sends source input andreceives predictions for evaluation and the client executes customizedpolicies. Given a policy, it automatically performs simultaneous decoding andcollectively reports several popular latency metrics. We also adapt latencymetrics from text simultaneous translation to the speech task. Additionally,SimulEval is equipped with a visualization interface to provide betterunderstanding of the simultaneous decoding process of a system. SimulEval hasalready been extensively used for the IWSLT 2020 shared task on simultaneousspeech translation. Code will be released upon publication.",Xutai Ma,2020/7/31,2020/7/31
1607.01387v2,Algebraic Methods for Quantum Codes on Lattices,http://arxiv.org/abs/1607.01387v2,"This is a note from a series of lectures at Encuentro Colombiano deComputacion Cuantica, Universidad de los Andes, Bogota, Colombia, 2015. Thepurpose is to introduce additive quantum error correcting codes, with emphasison the use of binary representation of Pauli matrices and modules over atranslation group algebra. The topics include symplectic vector spaces,Clifford group, cleaning lemma, an error correcting criterion, entanglementspectrum, implications of the locality of stabilizer group generators, and theclassification of translation-invariant one-dimensional additive codes andtwo-dimensional CSS codes with large code distances. In particular, we describean algorithm to find a Clifford quantum circuit (CNOTs) to transform anytwo-dimensional translation-invariant CSS code on qudits of a prime dimensionwith code distance being the linear system size, into a tensor product offinitely many copies of the qudit toric code and a product state. Thus, thenumber of embedded toric codes is the complete invariant of these CSS codesunder local Clifford circuits.",Jeongwan Haah,2016/7/5,2016/10/17
2306.14580v1,TransERR: Translation-based Knowledge Graph Completion via Efficient Relation Rotation,http://arxiv.org/abs/2306.14580v1,"This paper presents translation-based knowledge graph completion method viaefficient relation rotation (TransERR), a straightforward yet effectivealternative to traditional translation-based knowledge graph completion models.Different from the previous translation-based models, TransERR encodesknowledge graphs in the hypercomplex-valued space, thus enabling it to possessa higher degree of translation freedom in mining latent information between thehead and tail entities. To further minimize the translation distance, TransERRadaptively rotates the head entity and the tail entity with their correspondingunit quaternions, which are learnable in model training. The experiments on 7benchmark datasets validate the effectiveness and the generalization ofTransERR. The results also indicate that TransERR can better encode large-scaledatasets with fewer parameters than the previous translation-based models. Ourcode is available at: \url{https://github.com/dellixx/TransERR}.",Jiang Li,2023/6/26,2023/6/26
2204.14038v1,Phase-free ZX diagrams are CSS codes (...or how to graphically grok the surface code),http://arxiv.org/abs/2204.14038v1,"In this paper, we demonstrate a direct correspondence between phase-free ZXdiagrams, a graphical notation for representing and manipulating a certainclass of linear maps on qubits, and Calderbank-Shor-Steane (CSS) codes, a largefamily of quantum error correcting codes constructed from classical codes,including for example the Steane code, surface codes, and colour codes. Thestabilisers of a CSS code have an especially nice structure arising from a pairof orthogonal $\mathbb F_2$-linear subspaces, or in the case of maximal CSScodes, a single subspace and its orthocomplement. On the other hand, phase-freeZX diagrams can always be efficiently reduced to a normal form given by thebasis elements of an $\mathbb F_2$-linear subspace. Here, we will show thatthese two ways of describing a quantum state by an $\mathbb F_2$-linearsubspace $S$ are in fact the same. Namely, the maximal CSS code generated by$S$ fixes the quantum state whose ZX normal form is also given by $S$.  This insight gives us an immediate translation from stabilisers of a maximalCSS code into a ZX diagram describing its associated state. We show that we canextend this translation to stabilisers and logical operators of any (possiblynon-maximal) CSS code by ""bending wires"". To demonstrate the utility of thistranslation, we give a simple picture of the surface code and a fully graphicalderivation of the action of physical lattice surgery operations on the space oflogical qubits, completing the ZX presentation of lattice surgery initiated byde Beudrap and Horsman.",Aleks Kissinger,2022/4/29,2022/4/29
1912.06840v1,Region and Object based Panoptic Image Synthesis through Conditional GANs,http://arxiv.org/abs/1912.06840v1,"Image-to-image translation is significant to many computer vision and machinelearning tasks such as image synthesis and video synthesis. It has primaryapplications in the graphics editing and animation industries. With thedevelopment of generative adversarial networks, a lot of attention has beendrawn to image-to-image translation tasks. In this paper, we propose andinvestigate a novel task named as panoptic-level image-to-image translation anda naive baseline of solving this task. Panoptic-level image translation extendsthe current image translation task to two separate objectives of semantic styletranslation (adjust the style of objects to that of different domains) andinstance transfiguration (swap between different types of objects). Theproposed task generates an image from a complete and detailed panopticperspective which can enrich the context of real-world vision synthesis. Ourcontribution consists of the proposal of a significant task worth investigatingand a naive baseline of solving it. The proposed baseline consists of themultiple instances sequential translation and semantic-level translation withdomain-invariant content code.",Heng Wang,2019/12/14,2019/12/14
1206.5648v3,C to O-O Translation: Beyond the Easy Stuff,http://arxiv.org/abs/1206.5648v3,"Can we reuse some of the huge code-base developed in C to take advantage ofmodern programming language features such as type safety, object-orientation,and contracts? This paper presents a source-to-source translation of C codeinto Eiffel, a modern object-oriented programming language, and the supportingtool C2Eif. The translation is completely automatic and supports the entire Clanguage (ANSI, as well as many GNU C Compiler extensions, through CIL) as usedin practice, including its usage of native system libraries and inlinedassembly code. Our experiments show that C2Eif can handle C applications andlibraries of significant size (such as vim and libgsl), as well as challengingbenchmarks such as the GCC torture tests. The produced Eiffel code isfunctionally equivalent to the original C code, and takes advantage of some ofEiffel's object-oriented features to produce safe and easy-to-debugtranslations.",Marco Trudel,2012/6/25,2013/9/19
1603.08865v3,Compilation as a Typed EDSL-to-EDSL Transformation,http://arxiv.org/abs/1603.08865v3,"This article is about an implementation and compilation technique that isused in RAW-Feldspar which is a complete rewrite of the Feldspar embeddeddomain-specific language (EDSL) (Axelsson et al. 2010). Feldspar is high-levelfunctional language that generates efficient C code to run on embedded targets.The gist of the technique presented in this post is the following: ratherwriting a back end that converts pure Feldspar expressions directly to C, wetranslate them to a low-level monadic EDSL. From the low-level EDSL, C code isthen generated. This approach has several advantages:  1. The translation is simpler to write than a complete C back end.  2. The translation is between two typed EDSLs, which rules out many potentialerrors.  3. The low-level EDSL is reusable and can be shared between severalhigh-level EDSLs.  Although the article contains a lot of code, most of it is in fact reusable.As mentioned in Discussion, we can write the same implementation in less than50 lines of code using generic libraries that we have developed to supportFeldspar.",Emil Axelsson,2016/3/29,2018/4/19
0908.3579v1,Exceptional error minimization in putative primordial genetic codes,http://arxiv.org/abs/0908.3579v1,"We investigated the error-minimization properties of putative primordialcodes that consisted of 16 supercodons, with the third base being completelyredundant, using a previously derived cost function and the error minimizationpercentage as the measure of a code's robustness to mistranslation. It is shownthat, when the 16-supercodon table is populated with 10 putative primordialamino acids, inferred from the results of abiotic synthesis experiments andother evidence independent of the code evolution, and with minimal assumptionsused to assign the remaining supercodons, the resulting 2-letter codes arenearly optimal in terms of the error minimization level. The results of thecomputational experiments with putative primordial genetic codes that containedonly two meaningful letters in all codons and encoded 10 to 16 amino acidsindicate that such codes are likely to have been nearly optimal with respect tothe minimization of translation errors. This near-optimality could be theoutcome of extensive early selection during the co-evolution of the code withthe primordial, error-prone translation system, or a result of a unique,accidental event. Under this hypothesis, the subsequent expansion of the coderesulted in a decrease of the error minimization level that became sustainableowing to the evolution of a high-fidelity translation system.",Artem S. Novozhilov,2009/8/25,2009/8/25
2307.14352v3,General Image-to-Image Translation with One-Shot Image Guidance,http://arxiv.org/abs/2307.14352v3,"Large-scale text-to-image models pre-trained on massive text-image pairs showexcellent performance in image synthesis recently. However, image can providemore intuitive visual concepts than plain text. People may ask: how can weintegrate the desired visual concept into an existing image, such as ourportrait? Current methods are inadequate in meeting this demand as they lackthe ability to preserve content or translate visual concepts effectively.Inspired by this, we propose a novel framework named visual concept translator(VCT) with the ability to preserve content in the source image and translatethe visual concepts guided by a single reference image. The proposed VCTcontains a content-concept inversion (CCI) process to extract contents andconcepts, and a content-concept fusion (CCF) process to gather the extractedinformation to obtain the target image. Given only one reference image, theproposed VCT can complete a wide range of general image-to-image translationtasks with excellent results. Extensive experiments are conducted to prove thesuperiority and effectiveness of the proposed methods. Codes are available athttps://github.com/CrystalNeuro/visual-concept-translator.",Bin Cheng,2023/7/20,2023/9/20
1812.11193v3,Classification of translation invariant topological Pauli stabilizer codes for prime dimensional qudits on two-dimensional lattices,http://arxiv.org/abs/1812.11193v3,"We prove that on any two-dimensional lattice of qudits of a prime dimension,every translation invariant Pauli stabilizer group with local generators andwith code distance being the linear system size, is decomposed by a localClifford circuit of constant depth into a finite number of copies of the toriccode (abelian discrete gauge theory) stabilizer group. This means that underlocal Clifford circuits the number of toric code copies is the completeinvariant of topological Pauli stabilizer codes. Previously, the sameconclusion was obtained under the assumption of nonchirality for qubit codes orthe Calderbank-Shor-Steane structure for prime qudit codes; we do not assumeany of these.",Jeongwan Haah,2018/12/28,2020/12/16
2212.11135v2,Array-Aware Matching: Taming the Complexity of Large-Scale Simulation Models,http://arxiv.org/abs/2212.11135v2,"Equation-based modelling is a powerful approach to tame the complexity oflarge-scale simulation problems. Equation-based tools automatically translatemodels into imperative languages. When confronted with nowadays' problems,however, well assessed model translation techniques exhibit scalability issues,that are particularly severe when models contain very large arrays. In fact,such models can be made very compact by enclosing equations into loopingconstructs, but reflecting the same compactness into the translated imperativecode is not trivial. In this paper, we face this issue by concentrating on akey step of equations-to-code translation, the equation/variable matching. Wefirst show that an efficient translation of models with (large) arrays needsawareness of their presence, by defining a figure of merit to measure how muchthe looping constructs are preserved along the translation. We then show thatthe said figure of merit allows to define an optimal array-aware matching, andas our main result, that the so stated optimal array-aware matching problem isNP-complete. As an additional result, we propose a heuristic algorithm capableof performing array-aware matching in polynomial time. The proposed algorithmcan be proficiently used by model translator developers in the implementationof efficient tools for large-scale system simulation.",Massimo Fioravanti,2022/11/22,2023/9/6
2310.04951v2,CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation,http://arxiv.org/abs/2310.04951v2,"Recent code translation techniques exploit neural machine translation modelsto translate source code from one programming language to another to satisfyproduction compatibility or to improve efficiency of codebase maintenance. Mostexisting code translation datasets only focus on a single pair of popularprogramming languages. To advance research on code translation and meet diverserequirements of real-world applications, we construct CodeTransOcean, alarge-scale comprehensive benchmark that supports the largest variety ofprogramming languages for code translation. CodeTransOcean consists of threenovel multilingual datasets, namely, MultilingualTrans supporting translationsbetween multiple popular programming languages, NicheTrans for translatingbetween niche programming languages and popular ones, and LLMTrans forevaluating executability of translated code by large language models (LLMs).CodeTransOcean also includes a novel cross-framework dataset, DLTrans, fortranslating deep learning code across different frameworks. We developmultilingual modeling approaches for code translation and demonstrate theirgreat potential in improving the translation quality of both low-resource andhigh-resource language pairs and boosting the training efficiency. We alsopropose a novel evaluation metric Debugging Success Rate@K for program-levelcode translation. Last but not least, we evaluate LLM ChatGPT on our datasetsand investigate its potential for fuzzy execution predictions. We buildbaselines for CodeTransOcean and analyze challenges of code translation forguiding future research. The CodeTransOcean datasets and code are publiclyavailable at https://github.com/WeixiangYAN/CodeTransOcean.",Weixiang Yan,2023/10/8,2023/10/25
2002.11141v1,"Optics-free imaging of complex, non-sparse QR-codes with Deep Neural Networks",http://arxiv.org/abs/2002.11141v1,"We demonstrate optics-free imaging of complex QR-codes using a bare imagesensor and a trained artificial neural network (ANN). The ANN is trained tointerpret the raw sensor data for human visualization. The image sensor isplaced at a specified gap from the QR code. We studied the robustness of ourapproach by experimentally testing the output of the ANNs with systemperturbations of this gap, and the translational and rotational alignments ofthe QR code to the image sensor. Our demonstration opens us the possibility ofusing completely optics-free cameras for application-specific imaging ofcomplex, non-sparse objects.",Evan Scullion,2020/2/25,2020/2/25
2011.04542v1,Learning Autocompletion from Real-World Datasets,http://arxiv.org/abs/2011.04542v1,"Code completion is a popular software development tool integrated into allmajor IDEs. Many neural language models have achieved promising results incompletion suggestion prediction on synthetic benchmarks. However, a recentstudy When Code Completion Fails: a Case Study on Real-World Completionsdemonstrates that these results may not translate to improvements in real-worldperformance. To combat this effect, we train models on real-world codecompletion examples and find that these models outperform models trained oncommitted source code and working version snapshots by 12.8% and 13.8% accuracyrespectively. We observe this improvement across modeling technologies and showthrough A/B testing that it corresponds to a 6.2% increase in programmers'actual autocompletion usage. Furthermore, our study characterizes a largecorpus of logged autocompletion usages to investigate why training onreal-world examples leads to stronger models.",Gareth Ari Aye,2020/11/9,2020/11/9
2305.18201v1,A Critical Evaluation of Evaluations for Long-form Question Answering,http://arxiv.org/abs/2305.18201v1,"Long-form question answering (LFQA) enables answering a wide range ofquestions, but its flexibility poses enormous challenges for evaluation. Weperform the first targeted study of the evaluation of long-form answers,covering both human and automatic evaluation practices. We hire domain expertsin seven areas to provide preference judgments over pairs of answers, alongwith free-form justifications for their choices. We present a careful analysisof experts' evaluation, which focuses on new aspects such as thecomprehensiveness of the answer. Next, we examine automatic text generationmetrics, finding that no existing metrics are predictive of human preferencejudgments. However, some metrics correlate with fine-grained aspects of answers(e.g., coherence). We encourage future work to move away from a single ""overallscore"" of the answer and adopt a multi-faceted evaluation, targeting aspectssuch as factuality and completeness. We publicly release all of our annotationsand code to spur future work into LFQA evaluation.",Fangyuan Xu,2023/5/29,2023/5/29
2305.14221v3,Question Answering as Programming for Solving Time-Sensitive Questions,http://arxiv.org/abs/2305.14221v3,"Question answering plays a pivotal role in human daily life because itinvolves our acquisition of knowledge about the world. However, due to thedynamic and ever-changing nature of real-world facts, the answer can becompletely different when the time constraint in the question changes.Recently, Large Language Models (LLMs) have shown remarkable intelligence inquestion answering, while our experiments reveal that the aforementionedproblems still pose a significant challenge to existing LLMs. This can beattributed to the LLMs' inability to perform rigorous reasoning based onsurface-level text semantics. To overcome this limitation, rather thanrequiring LLMs to directly answer the question, we propose a novel approachwhere we reframe the $\textbf{Q}$uestion $\textbf{A}$nswering task$\textbf{a}$s $\textbf{P}$rogramming ($\textbf{QAaP}$). Concretely, byleveraging modern LLMs' superior capability in understanding both naturallanguage and programming language, we endeavor to harness LLMs to representdiversely expressed text as well-structured code and select the best matchinganswer from multiple candidates through programming. We evaluate our QAaPframework on several time-sensitive question answering datasets and achievedecent improvement, up to $14.5$% over strong baselines. Our codes and data areavailable at https://github.com/TianHongZXY/qaap",Xinyu Zhu,2023/5/23,2023/10/20
2401.03901v1,STAIR: Spatial-Temporal Reasoning with Auditable Intermediate Results for Video Question Answering,http://arxiv.org/abs/2401.03901v1,"Recently we have witnessed the rapid development of video question answeringmodels. However, most models can only handle simple videos in terms of temporalreasoning, and their performance tends to drop when answeringtemporal-reasoning questions on long and informative videos. To tackle thisproblem we propose STAIR, a Spatial-Temporal Reasoning model with AuditableIntermediate Results for video question answering. STAIR is a neural modulenetwork, which contains a program generator to decompose a given question intoa hierarchical combination of several sub-tasks, and a set of lightweightneural modules to complete each of these sub-tasks. Though neural modulenetworks are already widely studied on image-text tasks, applying them tovideos is a non-trivial task, as reasoning on videos requires differentabilities. In this paper, we define a set of basic video-text sub-tasks forvideo question answering and design a set of lightweight modules to completethem. Different from most prior works, modules of STAIR return intermediateoutputs specific to their intentions instead of always returning attentionmaps, which makes it easier to interpret and collaborate with pre-trainedmodels. We also introduce intermediate supervision to make these intermediateoutputs more accurate. We conduct extensive experiments on several videoquestion answering datasets under various settings to show STAIR's performance,explainability, compatibility with pre-trained models, and applicability whenprogram annotations are not available. Code:https://github.com/yellow-binary-tree/STAIR",Yueqian Wang,2024/1/8,2024/1/8
1601.04810v2,Good traceability codes do exist,http://arxiv.org/abs/1601.04810v2,"Traceability codes are combinatorial objects introduced by Chor, Fiat andNaor in 1994 to be used to trace the origin of digital content in traitortracing schemes.  Let $F$ be an alphabet set of size $q$ and $n$ be a positive integer. A$t$-traceability code is a code $\mathscr{C}\subseteq F^n$ which can be used tocatch at least one colluder from a collusion of at most $t$ traitors. It hasbeen shown that $t$-traceability codes do not exist for $q\le t$. When $q>t^2$,$t$-traceability codes with positive code rate can be constructed from errorcorrecting codes with large minimum distance. Therefore, Barg and Kabatianskyasked in 2004 that whether there exist $t$-traceability codes with positivecode rate for $t+1\le q\le t^2$. In 2010, Blackburn, Etzion and Ng gave anaffirmative answer to this question for $q\ge t^2-\lceil t/2\rceil+1$, usingthe probabilistic methods. However, they did not see how their probabilisticmethods can be used to answer this question for the remaining values of $q$.They even suspected that there may be a `Plotkin bound' of traceability codesthat forbids the existence of such codes. In this paper, we give a completeanswer to Barg-Kabatiansky's question (in the affirmative). Surprisingly, ourconstruction is deterministic.",Gennian Ge,2016/1/19,2016/2/26
1205.3878v3,New characterisations of the Nordstrom-Robinson codes,http://arxiv.org/abs/1205.3878v3,"In his doctoral thesis, Snover proved that any binary $(m,256,\delta)$ codeis equivalent to the Nordstrom-Robinson code or the puncturedNordstrom-Robinson code for $(m,\delta)=(16,6)$ or $(15,5)$ respectively. Weprove that these codes are also characterised as \emph{completely regular}binary codes with $(m,\delta)=(16,6)$ or $(15,5)$, and moreover, that they are\emph{completely transitive}. Also, it is known that completely transitivecodes are necessarily completely regular, but whether the converse holds has upto now been an open question. We answer this by proving that certain completelyregular codes are not completely transitive, namely, the (Punctured) Preparatacodes other than the (Punctured) Nordstrom-Robinson code.",Neil I. Gillespie,2012/5/17,2017/2/2
2209.12028v1,Towards Explainable 3D Grounded Visual Question Answering: A New Benchmark and Strong Baseline,http://arxiv.org/abs/2209.12028v1,"Recently, 3D vision-and-language tasks have attracted increasing researchinterest. Compared to other vision-and-language tasks, the 3D visual questionanswering (VQA) task is less exploited and is more susceptible to languagepriors and co-reference ambiguity. Meanwhile, a couple of recently proposed 3DVQA datasets do not well support 3D VQA task due to their limited scale andannotation methods. In this work, we formally define and address a 3D groundedVQA task by collecting a new 3D VQA dataset, referred to as FE-3DGQA, withdiverse and relatively free-form question-answer pairs, as well as dense andcompletely grounded bounding box annotations. To achieve more explainableanswers, we labelled the objects appeared in the complex QA pairs withdifferent semantic types, including answer-grounded objects (both appeared andnot appeared in the questions), and contextual objects for answer-groundedobjects. We also propose a new 3D VQA framework to effectively predict thecompletely visually grounded and explainable answer. Extensive experimentsverify that our newly collected benchmark datasets can be effectively used toevaluate various 3D VQA methods from different aspects and our newly proposedframework also achieves state-of-the-art performance on the new benchmarkdataset. Both the newly collected dataset and our codes will be publiclyavailable at http://github.com/zlccccc/3DGQA.",Lichen Zhao,2022/9/24,2022/9/24
2210.14494v1,CS1QA: A Dataset for Assisting Code-based Question Answering in an Introductory Programming Course,http://arxiv.org/abs/2210.14494v1,"We introduce CS1QA, a dataset for code-based question answering in theprogramming education domain. CS1QA consists of 9,237 question-answer pairsgathered from chat logs in an introductory programming class using Python, and17,698 unannotated chat data with code. Each question is accompanied with thestudent's code, and the portion of the code relevant to answering the question.We carefully design the annotation process to construct CS1QA, and analyze thecollected dataset in detail. The tasks for CS1QA are to predict the questiontype, the relevant code snippet given the question and the code and retrievingan answer from the annotated corpus. Results for the experiments on severalbaseline models are reported and thoroughly analyzed. The tasks for CS1QAchallenge models to understand both the code and natural language. This uniquedataset can be used as a benchmark for source code comprehension and questionanswering in the educational setting.",Changyoon Lee,2022/10/26,2022/10/26
1909.05355v1,Let's Ask Again: Refine Network for Automatic Question Generation,http://arxiv.org/abs/1909.05355v1,"In this work, we focus on the task of Automatic Question Generation (AQG)where given a passage and an answer the task is to generate the correspondingquestion. It is desired that the generated question should be (i) grammaticallycorrect (ii) answerable from the passage and (iii) specific to the givenanswer. An analysis of existing AQG models shows that they produce questionswhich do not adhere to one or more of {the above-mentioned qualities}. Inparticular, the generated questions look like an incomplete draft of thedesired question with a clear scope for refinement. {To alleviate thisshortcoming}, we propose a method which tries to mimic the human process ofgenerating questions by first creating an initial draft and then refining it.More specifically, we propose Refine Network (RefNet) which contains twodecoders. The second decoder uses a dual attention network which pays attentionto both (i) the original passage and (ii) the question (initial draft)generated by the first decoder. In effect, it refines the question generated bythe first decoder, thereby making it more correct and complete. We evaluateRefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and showthat it outperforms existing state-of-the-art methods by 7-16\% on all of thesedatasets. Lastly, we show that we can improve the quality of the second decoderon specific metrics, such as, fluency and answerability by explicitly rewardingrevisions that improve on the corresponding metric during training. The codehas been made publicly available\footnote{https://github.com/PrekshaNema25/RefNet-QG}",Preksha Nema,2019/8/31,2019/8/31
2111.00580v1,Text Classification for Task-based Source Code Related Questions,http://arxiv.org/abs/2111.00580v1,"There is a key demand to automatically generate code for small tasks fordevelopers. Websites such as StackOverflow provide a simplistic way by offeringsolutions in small snippets which provide a complete answer to whatever taskquestion the developer wants to code. Natural Language Processing andparticularly Question-Answering Systems are very helpful in resolving andworking on these tasks. In this paper, we develop a two-fold deep learningmodel: Seq2Seq and a binary classifier that takes in the intent (which is innatural language) and code snippets in Python. We train both the intent and thecode utterances in the Seq2Seq model, where we decided to compare the effect ofthe hidden layer embedding from the encoder for representing the intent andsimilarly, using the decoder's hidden layer embeddings for the code sequence.Then we combine both these embeddings and then train a simple binary neuralnetwork classifier model for predicting if the intent is correctly answered bythe predicted code sequence from the seq2seq model. We find that the hiddenstate layer's embeddings perform slightly better than regular standardembeddings from a constructed vocabulary. We experimented with our tests on theCoNaLa dataset in addition to the StaQC database consisting of simple task-codesnippet-based pairs. We empirically establish that using additional pre-trainedembeddings for code snippets in Python is less context-based in comparison tousing hidden state context vectors from seq2seq models.",Sairamvinay Vijayaraghavan,2021/10/31,2021/10/31
2303.08033v1,Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions about Code,http://arxiv.org/abs/2303.08033v1,"We analyzed effectiveness of three generative pre-trained transformer (GPT)models in answering multiple-choice question (MCQ) assessments, often involvingshort snippets of code, from introductory and intermediate programming coursesat the postsecondary level. This emerging technology stirs countlessdiscussions of its potential uses (e.g., exercise generation, code explanation)as well as misuses in programming education (e.g., cheating). However, thecapabilities of GPT models and their limitations to reason about and/or analyzecode in educational settings have been under-explored. We evaluated severalOpenAI's GPT models on formative and summative MCQ assessments from threePython courses (530 questions). We found that MCQs containing code snippets arenot answered as successfully as those that only contain natural language. Whilequestions requiring to fill-in a blank in the code or completing a naturallanguage statement about the snippet are handled rather successfully, MCQs thatrequire analysis and/or reasoning about the code (e.g., what is true/falseabout the snippet, or what is its output) appear to be the most challenging.These findings can be leveraged by educators to adapt their instructionalpractices and assessments in programming courses, so that GPT becomes avaluable assistant for a learner as opposed to a source of confusion and/orpotential hindrance in the learning process.",Jaromir Savelka,2023/3/9,2023/3/9
2012.08436v2,On the Classification of Binary Completely Transitive Codes with Almost-Simple Top-Group,http://arxiv.org/abs/2012.08436v2,"A code $C$ in the Hamming metric, that is, is a subset of the vertex set$V\varGamma$ of the Hamming graph $\varGamma=H(m,q)$, gives rise to a naturaldistance partition $\{C,C_1,\ldots,C_\rho\}$, where $\rho$ is the coveringradius of $C$. Such a code $C$ is called completely transitive if theautomorphism group $\rm{Aut}(C)$ acts transitively on each of the sets $C$,$C_1$, \ldots, $C_\rho$. A code $C$ is called $2$-neighbour-transitive if$\rho\geq 2$ and $\rm{Aut}(C)$ acts transitively on each of $C$, $C_1$ and$C_2$.  Let $C$ be a completely transitive code in a binary ($q=2$) Hamming graphhaving full automorphism group $\rm{Aut}(C)$ and minimum distance $\delta\geq5$. Then it is known that $\rm{Aut}(C)$ induces a $2$-homogeneous action on thecoordinates of the vertices of the Hamming graph. The main result of this paperclassifies those $C$ for which this induced $2$-homogeneous action is not anaffine, linear or symplectic group. We find that there are $13$ such codes, $4$of which are non-linear codes. Though most of the codes are well-known, weobtain several new results. First, a new non-linear completely transitive codeis constructed, as well as a related non-linear code that is$2$-neighbour-transitive but not completely transitive. Moreover, new proofs ofthe complete transitivity of several codes are given. Additionally, we answerthe question of the existence of distance-regular graphs related to thecompletely transitive codes appearing in our main result.",Robert F. Bailey,2020/12/15,2022/7/31
1611.02694v1,Notes on countably generated complete Boolean algebras,http://arxiv.org/abs/1611.02694v1,"We give a necessary and sufficient condition for an atomless Boolean algebrato be countably generated, and use it to give new proofs of some some knowfacts due to Gaifman-Hales and Solovay and also due to Jech, Kunen and Magidor.We also show that Jensen's coding theorem can be used to provide cardinalpreserving countably generated complete Boolean algebras of arbitrary largecardinality. This answers a question of Jech [5] from 1976.",Mohammad Golshani,2016/11/8,2016/11/8
2309.17050v1,Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models,http://arxiv.org/abs/2309.17050v1,"Many individuals are likely to face a legal dispute at some point in theirlives, but their lack of understanding of how to navigate these complex issuesoften renders them vulnerable. The advancement of natural language processingopens new avenues for bridging this legal literacy gap through the developmentof automated legal aid systems. However, existing legal question answering(LQA) approaches often suffer from a narrow scope, being either confined tospecific legal domains or limited to brief, uninformative responses. In thiswork, we propose an end-to-end methodology designed to generate long-formanswers to any statutory law questions, utilizing a ""retrieve-then-read""pipeline. To support this approach, we introduce and release the Long-formLegal Question Answering (LLeQA) dataset, comprising 1,868 expert-annotatedlegal questions in the French language, complete with detailed answers rootedin pertinent legal provisions. Our experimental results demonstrate promisingperformance on automatic evaluation metrics, but a qualitative analysisuncovers areas for refinement. As one of the only comprehensive,expert-annotated long-form LQA dataset, LLeQA has the potential to not onlyaccelerate research towards resolving a significant real-world issue, but alsoact as a rigorous benchmark for evaluating NLP models in specialized domains.We publicly release our code, data, and models.",Antoine Louis,2023/9/29,2023/9/29
1809.00782v1,Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text,http://arxiv.org/abs/1809.00782v1,"Open Domain Question Answering (QA) is evolving from complex pipelinedsystems to end-to-end deep neural networks. Specialized neural models have beendeveloped for extracting answers from either text alone or Knowledge Bases(KBs) alone. In this paper we look at a more practical setting, namely QA overthe combination of a KB and entity-linked text, which is appropriate when anincomplete KB is available with a large text corpus. Building on recentadvances in graph representation learning we propose a novel model, GRAFT-Net,for extracting answers from a question-specific subgraph containing text and KBentities and relations. We construct a suite of benchmark tasks for thisproblem, varying the difficulty of questions, the amount of training data, andKB completeness. We show that GRAFT-Net is competitive with thestate-of-the-art when tested using either KBs or text alone, and vastlyoutperforms existing methods in the combined setting. Source code is availableat https://github.com/OceanskySun/GraftNet .",Haitian Sun,2018/9/4,2018/9/4
1305.2440v1,"Rate Region of the (4,3,3) Exact-Repair Regenerating Codes",http://arxiv.org/abs/1305.2440v1,"Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),for which a complete characterization of the rate region is provided. Thischaracterization answers in the affirmative the open question whether thereexists a non-vanishing gap between the optimal bandwidth-storage tradeoff ofthe functional-repair regenerating codes (i.e., the cut-set bound) and that ofthe exact-repair regenerating codes. The converse proof relies on the existenceof symmetric optimal solutions. For the achievability, only one non-trivialcorner point of the rate region needs to be addressed, for which an explicitbinary code construction is given.",Chao Tian,2013/5/10,2013/5/10
2212.01218v1,Answer ranking in Community Question Answering: a deep learning approach,http://arxiv.org/abs/2212.01218v1,"Community Question Answering is the field of computational linguistics thatdeals with problems derived from the questions and answers posted to websitessuch as Quora or Stack Overflow. Among some of these problems we find the issueof ranking the multiple answers posted in reply to each question by howinformative they are in the attempt to solve the original question. This worktries to advance the state of the art on answer ranking for community QuestionAnswering by proceeding with a deep learning approach. We started off bycreating a large data set of questions and answers posted to the Stack Overflowwebsite.  We then leveraged the natural language processing capabilities of denseembeddings and LSTM networks to produce a prediction for the accepted answerattribute, and present the answers in a ranked form ordered by how likely theyare to be marked as accepted by the question asker. We also produced a set ofnumerical features to assist with the answer ranking task. These numericalfeatures were either extracted from metadata found in the Stack Overflow postsor derived from the questions and answers texts. We compared the performance ofour deep learning models against a set of forest and boosted trees ensemblemethods and found that our models could not improve the best baseline results.We speculate that this lack of performance improvement versus the baselinemodels may be caused by the large number of out of vocabulary words present inthe programming code snippets found in the questions and answers text. Weconclude that while a deep learning approach may be helpful in answer rankingproblems new methods should be developed to assist with the large number of outof vocabulary words present in the programming code snippets",Lucas Valentin,2022/10/16,2022/10/16
1801.07026v1,Do Mobile Developers Ask on Q&A Sites About Error Codes Thrown by a Cross-Platform App Development Framework? An Empirical Study,http://arxiv.org/abs/1801.07026v1,"During last years development frameworks have emerged to make easier thedevelopment and maintenance of cross-platform mobile applications. Xamarinframework is one of them: it takes as input an app written in C# and producesnative code for Android, iOS and Windows Mobile platforms. When using Xamarin,developers can meet errors, identified with codes, thrown by theframework.Unfortunately, the Xamarin official documentation does not provide acomplete description, solution or workaround for all those codes.In this paper,we analyze two sites of questions and answers related to Xamarin for findingquestions that mention those error codes. We found in both sites that there arequestions written by developers asking about Xamarin errors, and the majorityof them have at least one answer. Our intuition is this discovered informationcould be useful for giving support to Xamarin developers.",Matias Martinez,2018/1/22,2018/1/22
2107.10544v1,An Empirical Study on Code Comment Completion,http://arxiv.org/abs/2107.10544v1,"Code comments play a prominent role in program comprehension activities.However, source code is not always documented and code and comments not alwaysco-evolve. To deal with these issues, researchers have proposed techniques toautomatically generate comments documenting a given code at hand. The mostrecent works in the area applied deep learning (DL) techniques to support sucha task. Despite the achieved advances, the empirical evaluations of theseapproaches show that they are still far from a performance level that wouldmake them valuable for developers. We tackle a simpler and related problem:Code comment completion. Instead of generating a comment for a given code fromscratch, we investigate the extent to which state-of-the-art techniques canhelp developers in writing comments faster. We present a large-scale study inwhich we empirically assess how a simple n-gram model and the recently proposedText-To-Text Transfer Transformer (T5) architecture can perform inautocompleting a code comment the developer is typing. The achieved resultsshow the superiority of the T5 model, despite the n-gram model being acompetitive solution.",Antonio Mastropaolo,2021/7/22,2021/7/22
2203.05132v1,Compilable Neural Code Generation with Compiler Feedback,http://arxiv.org/abs/2203.05132v1,"Automatically generating compilable programs with (or without) naturallanguage descriptions has always been a touchstone problem for computationallinguistics and automated software engineering. Existing deep-learningapproaches model code generation as text generation, either constrained bygrammar structures in decoder, or driven by pre-trained language models onlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few ofthem account for compilability of the generated programs. To improvecompilability of the generated programs, this paper proposes COMPCODER, athree-stage pipeline utilizing compiler feedback for compilable codegeneration, including language model fine-tuning, compilability reinforcement,and compilability discrimination. Comprehensive experiments on two codegeneration tasks demonstrate the effectiveness of our proposed approach,improving the success rate of compilation from 44.18 to 89.18 in codecompletion on average and from 70.3 to 96.2 in text-to-code generation,respectively, when comparing with the state-of-the-art CodeGPT.",Xin Wang,2022/3/10,2022/3/10
2007.12081v2,NITS-Hinglish-SentiMix at SemEval-2020 Task 9: Sentiment Analysis For Code-Mixed Social Media Text Using an Ensemble Model,http://arxiv.org/abs/2007.12081v2,"Sentiment Analysis is the process of deciphering what a sentence emotes andclassifying them as either positive, negative, or neutral. In recent times,India has seen a huge influx in the number of active social media users andthis has led to a plethora of unstructured text data. Since the Indianpopulation is generally fluent in both Hindi and English, they end upgenerating code-mixed Hinglish social media text i.e. the expressions of Hindilanguage, written in the Roman script alongside other English words. Theability to adequately comprehend the notions in these texts is truly necessary.Our team, rns2020 participated in Task 9 at SemEval2020 intending to design asystem to carry out the sentiment analysis of code-mixed social media text.This work proposes a system named NITS-Hinglish-SentiMix to viably complete thesentiment analysis of such code-mixed Hinglish text. The proposed framework hasrecorded an F-Score of 0.617 on the test data.",Subhra Jyoti Baroi,2020/7/23,2020/9/4
2204.09453v1,Event Transition Planning for Open-ended Text Generation,http://arxiv.org/abs/2204.09453v1,"Open-ended text generation tasks, such as dialogue generation and storycompletion, require models to generate a coherent continuation given limitedpreceding context. The open-ended nature of these tasks brings new challengesto the neural auto-regressive text generators nowadays. Despite these neuralmodels are good at producing human-like text, it is difficult for them toarrange causalities and relations between given facts and possible ensuingevents. To bridge this gap, we propose a novel two-stage method whichexplicitly arranges the ensuing events in open-ended text generation. Ourapproach can be understood as a specially-trained coarse-to-fine algorithm,where an event transition planner provides a ""coarse"" plot skeleton and a textgenerator in the second stage refines the skeleton. Experiments on twoopen-ended text generation tasks demonstrate that our proposed methodeffectively improves the quality of the generated text, especially in coherenceand diversity. The code is available at:\url{https://github.com/qtli/EventPlanforTextGen}.",Qintong Li,2022/4/20,2022/4/20
2312.02120v1,Magicoder: Source Code Is All You Need,http://arxiv.org/abs/2312.02120v1,"We introduce Magicoder, a series of fully open-source (code, weights, anddata) Large Language Models (LLMs) for code that significantly closes the gapwith top code models while having no more than 7B parameters. Magicoder modelsare trained on 75K synthetic instruction data using OSS-Instruct, a novelapproach to enlightening LLMs with open-source code snippets to generatehigh-quality instruction data for code. Our main motivation is to mitigate theinherent bias of the synthetic data generated by LLMs by empowering them with awealth of open-source references for the production of more diverse, realistic,and controllable data. The orthogonality of OSS-Instruct and other datageneration methods like Evol-Instruct further enables us to build an enhancedMagicoderS. Both Magicoder and MagicoderS substantially outperformstate-of-the-art code models with similar or even larger sizes on a wide rangeof coding benchmarks, including Python text-to-code generation, multilingualcoding, and data-science program completion. Notably, MagicoderS-CL-7B based onCodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 inpass@1). Overall, OSS-Instruct opens a new direction for low-bias andhigh-quality instruction tuning using abundant open-source references.",Yuxiang Wei,2023/12/4,2023/12/4
2305.00607v1,Boosting Weakly-Supervised Temporal Action Localization with Text Information,http://arxiv.org/abs/2305.00607v1,"Due to the lack of temporal annotation, current Weakly-supervised TemporalAction Localization (WTAL) methods are generally stuck into over-complete orincomplete localization. In this paper, we aim to leverage the text informationto boost WTAL from two aspects, i.e., (a) the discriminative objective toenlarge the inter-class difference, thus reducing the over-complete; (b) thegenerative objective to enhance the intra-class integrity, thus finding morecomplete temporal boundaries. For the discriminative objective, we propose aText-Segment Mining (TSM) mechanism, which constructs a text description basedon the action class label, and regards the text as the query to mine allclass-related segments. Without the temporal annotation of actions, TSMcompares the text query with the entire videos across the dataset to mine thebest matching segments while ignoring irrelevant ones. Due to the sharedsub-actions in different categories of videos, merely applying TSM is toostrict to neglect the semantic-related segments, which results in incompletelocalization. We further introduce a generative objective named Video-textLanguage Completion (VLC), which focuses on all semantic-related segments fromvideos to complete the text sentence. We achieve the state-of-the-artperformance on THUMOS14 and ActivityNet1.3. Surprisingly, we also find ourproposed method can be seamlessly applied to existing methods, and improvetheir performances with a clear margin. The code is available athttps://github.com/lgzlIlIlI/Boosting-WTAL.",Guozhang Li,2023/5/1,2023/5/1
2302.10166v3,Learning Deep Semantics for Test Completion,http://arxiv.org/abs/2302.10166v3,"Writing tests is a time-consuming yet essential task during softwaredevelopment. We propose to leverage recent advances in deep learning for textand code generation to assist developers in writing tests. We formalize thenovel task of test completion to automatically complete the next statement in atest method based on the context of prior statements and the code under test.We develop TeCo -- a deep learning model using code semantics for testcompletion. The key insight underlying TeCo is that predicting the nextstatement in a test method requires reasoning about code execution, which ishard to do with only syntax-level data that existing code completion modelsuse. TeCo extracts and uses six kinds of code semantics data, including theexecution result of prior statements and the execution context of the testmethod. To provide a testbed for this new task, as well as to evaluate TeCo, wecollect a corpus of 130,934 test methods from 1,270 open-source Java projects.Our results show that TeCo achieves an exact-match accuracy of 18, which is 29%higher than the best baseline using syntax-level data only. When measuringfunctional correctness of generated next statement, TeCo can generate runnablecode in 29% of the cases compared to 18% obtained by the best baseline.Moreover, TeCo is significantly better than prior work on test oraclegeneration.",Pengyu Nie,2023/2/20,2023/3/7
2212.03293v2,Diffusion-SDF: Text-to-Shape via Voxelized Diffusion,http://arxiv.org/abs/2212.03293v2,"With the rising industrial attention to 3D virtual modeling technology,generating novel 3D content based on specified conditions (e.g. text) hasbecome a hot issue. In this paper, we propose a new generative 3D modelingframework called Diffusion-SDF for the challenging task of text-to-shapesynthesis. Previous approaches lack flexibility in both 3D data representationand shape generation, thereby failing to generate highly diversified 3D shapesconforming to the given text descriptions. To address this, we propose a SDFautoencoder together with the Voxelized Diffusion model to learn and generaterepresentations for voxelized signed distance fields (SDFs) of 3D shapes.Specifically, we design a novel UinU-Net architecture that implants alocal-focused inner network inside the standard U-Net architecture, whichenables better reconstruction of patch-independent SDF representations. Weextend our approach to further text-to-shape tasks including text-conditionedshape completion and manipulation. Experimental results show that Diffusion-SDFgenerates both higher quality and more diversified 3D shapes that conform wellto given text descriptions when compared to previous approaches. Code isavailable at: https://github.com/ttlmh/Diffusion-SDF",Muheng Li,2022/12/6,2023/5/7
1601.06375v1,Linear code derived from the primage of quadratic function,http://arxiv.org/abs/1601.06375v1,"Linear codes have been an interesting topic in both theory and practice formany years. In this paper, for an odd prime power $q$, we construct some classof linear code over finite field $\mathbb{F}_q$ with defining set be thepreimage of general quadratic form function and determine the explicit completeweight enumerators of the linear codes. Our construction cover all thecorresponding result with quadratic form function and they may haveapplications in cryptography and secret sharing schemes.",Xiaoni Du,2016/1/24,2016/1/24
2111.06470v1,The complete weight enumerator of a subclass of optimal three-weight cyclic codes,http://arxiv.org/abs/2111.06470v1,"A class of optimal three-weight cyclic codes of dimension 3 over any finitefield was presented by Vega [Finite Fields Appl., 42 (2016) 23-38]. Shortlythereafter, Heng and Yue [IEEE Trans. Inf. Theory, 62(8) (2016) 4501-4513]generalized this result by presenting several classes of cyclic codes witheither optimal three weights or a few weights. On the other hand, a class ofoptimal five-weight cyclic codes of dimension 4 over a prime field was recentlypresented by Li, et al. [Adv. Math. Commun., 13(1) (2019) 137-156]. One of thepurposes of this work is to present a more general description for theseoptimal five-weight cyclic codes, which gives place to an enlarged class ofoptimal five-weight cyclic codes of dimension 4 over any finite field. As anapplication of this enlarged class, we present the complete weight enumeratorof a subclass of the optimal three-weight cyclic codes over any finite fieldthat were studied by Vega [Finite Fields Appl., 42 (2016) 23-38]. In addition,we study the dual codes in this enlarged class of optimal five-weight cycliccodes, and show that they are cyclic codes of length $q^2-1$, dimension$q^2-5$, and minimum Hamming distance 4. In fact, through several examples, wesee that those parameters are the best known parameters for linear codes.",Gerardo Vega,2021/11/11,2021/11/11
2303.11989v2,Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models,http://arxiv.org/abs/2303.11989v2,"We present Text2Room, a method for generating room-scale textured 3D meshesfrom a given text prompt as input. To this end, we leverage pre-trained 2Dtext-to-image models to synthesize a sequence of images from different poses.In order to lift these outputs into a consistent 3D scene representation, wecombine monocular depth estimation with a text-conditioned inpainting model.The core idea of our approach is a tailored viewpoint selection such that thecontent of each image can be fused into a seamless, textured 3D mesh. Morespecifically, we propose a continuous alignment strategy that iteratively fusesscene frames with the existing geometry to create a seamless mesh. Unlikeexisting works that focus on generating single objects or zoom-out trajectoriesfrom text, our method generates complete 3D scenes with multiple objects andexplicit 3D geometry. We evaluate our approach using qualitative andquantitative metrics, demonstrating it as the first method to generateroom-scale 3D geometry with compelling textures from only text as input.",Lukas Hllein,2023/3/21,2023/9/10
1811.02356v4,Code-switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation,http://arxiv.org/abs/1811.02356v4,"Code-switching is about dealing with alternative languages in speech or text.It is partially speaker-depend and domain-related, so completely explaining thephenomenon by linguistic rules is challenging. Compared to most monolingualtasks, insufficient data is an issue for code-switching. To mitigate the issuewithout expensive human annotation, we proposed an unsupervised method forcode-switching data augmentation. By utilizing a generative adversarialnetwork, we can generate intra-sentential code-switching sentences frommonolingual sentences. We applied proposed method on two corpora, and theresult shows that the generated code-switching sentences improve theperformance of code-switching language models.",Ching-Ting Chang,2018/11/6,2019/6/19
2301.13816v4,Execution-based Code Generation using Deep Reinforcement Learning,http://arxiv.org/abs/2301.13816v4,"The utilization of programming language (PL) models, pre-trained onlarge-scale code corpora, as a means of automating software engineeringprocesses has demonstrated considerable potential in streamlining various codegeneration tasks such as code completion, code translation, and programsynthesis. However, current approaches mainly rely on supervised fine-tuningobjectives borrowed from text generation, neglecting unique sequence-levelcharacteristics of code, including but not limited to compilability as well assyntactic and functional correctness. To address this limitation, we proposePPOCoder, a new framework for code generation that synergistically combinespre-trained PL models with Proximal Policy Optimization (PPO) which is a widelyused deep reinforcement learning technique. By utilizing non-differentiablefeedback from code execution and structure alignment, PPOCoder seamlesslyintegrates external code-specific knowledge into the model optimizationprocess. It's important to note that PPOCoder is a task-agnostic andmodel-agnostic framework that can be used across different code generationtasks and PLs. Extensive experiments on three code generation tasks demonstratethe effectiveness of our proposed approach compared to SOTA methods, achievingsignificant improvements in compilation success rates and functionalcorrectness across different PLs.",Parshin Shojaee,2023/1/31,2023/7/19
2109.09051v1,On Infinite Families of Narrow-Sense Antiprimitive BCH Codes Admitting 3-Transitive Automorphism Groups and their Consequences,http://arxiv.org/abs/2109.09051v1,"The Bose-Chaudhuri-Hocquenghem (BCH) codes are a well-studied subclass ofcyclic codes that have found numerous applications in error correction andnotably in quantum information processing. A subclass of attractive BCH codesis the narrow-sense BCH codes over the Galois field $\mathrm{GF}(q)$ withlength $q+1$, which are closely related to the action of the projective generallinear group of degree two on the projective line. This paper aims to studysome of the codes within this class and specifically narrow-sense antiprimitiveBCH codes (these codes are also linear complementary duals (LCD) codes thathave interesting practical recent applications in cryptography, among otherbenefits). We shall use tools and combine arguments from algebraic codingtheory, combinatorial designs, and group theory (group actions, representationtheory of finite groups, etc.) to investigate narrow-sense antiprimitive BCHCodes and extend results from the recent literature. Notably, the dimension,the minimum distance of some $q$-ary BCH codes with length $q+1$, and theirduals are determined in this paper. The dual codes of the narrow-senseantiprimitive BCH codes derived in this paper include almost MDS codes.Furthermore, the classification of $\mathrm{PGL} (2, p^m)$-invariant codes over$\mathrm{GF} (p^h)$ is completed.  As an application of this result, the $p$-ranks of all incidence structuresinvariant under the projective general linear group $\mathrm{ PGL }(2, p^m)$are determined.  Furthermore, infinite families of narrow-sense BCH codes admitting a$3$-transitive automorphism group are obtained.  Via these BCH codes, a coding-theory approach to constructing the Wittspherical geometry designs is presented.  The BCH codes proposed in this paper are good candidates for permutationdecoding, as they have a relatively large group of automorphisms.",Qi Liu,2021/9/19,2021/9/19
2309.06267v1,A Complete Proof of an Important Theorem for Variable-to-Variable Length Codes,http://arxiv.org/abs/2309.06267v1,"Variable-to-variable length (VV) codes are a class of lossless source coding.As their name implies, VV codes encode a variable-length sequence of sourcesymbols into a variable-length codeword. This paper will give a complete proofof an important theorem for variable-to-variable length codes.",Wei Yan,2023/9/12,2023/9/12
2108.04434v1,Linear programming bounds for quantum channels acting on quantum error-correcting codes,http://arxiv.org/abs/2108.04434v1,"While quantum weight enumerators establish some of the best upper bounds onthe minimum distance of quantum error-correcting codes, these bounds are notoptimized to quantify the performance of quantum codes under the effect ofarbitrary quantum channels that describe bespoke noise models. Herein, for anyKraus decomposition of any given quantum channel, we introduce correspondingquantum weight enumerators that naturally generalize the Shor-Laflamme quantumweight enumerators. We establish an indirect linear relationship between thesegeneralized quantum weight enumerators by introducing an auxiliary exact weightenumerator that completely quantifies the quantum code's projector, and isindependent of the underlying noise process. By additionally working within theframework of approximate quantum error correction, we establish a generalframework for constructing a linear program that is infeasible wheneverapproximate quantum error correcting codes with corresponding parameters do notexist. Our linear programming framework allows us to establish thenon-existence of certain quantum codes that approximately correct amplitudedamping errors, and obtain non-trivial upper bounds on the maximum dimension ofa broad family of permutation-invariant quantum codes.",Yingkai Ouyang,2021/8/10,2021/8/10
1903.12473v2,Shape Robust Text Detection with Progressive Scale Expansion Network,http://arxiv.org/abs/1903.12473v2,"Scene text detection has witnessed rapid progress especially with the recentdevelopment of convolutional neural networks. However, there still exists twochallenges which prevent the algorithm into industry applications. On the onehand, most of the state-of-art algorithms require quadrangle bounding box whichis in-accurate to locate the texts with arbitrary shape. On the other hand, twotext instances which are close to each other may lead to a false detectionwhich covers both instances. Traditionally, the segmentation-based approach canrelieve the first problem but usually fail to solve the second challenge. Toaddress these two challenges, in this paper, we propose a novel ProgressiveScale Expansion Network (PSENet), which can precisely detect text instanceswith arbitrary shapes. More specifically, PSENet generates the different scaleof kernels for each text instance, and gradually expands the minimal scalekernel to the text instance with the complete shape. Due to the fact that thereare large geometrical margins among the minimal scale kernels, our method iseffective to split the close text instances, making it easier to usesegmentation-based methods to detect arbitrary-shaped text instances. Extensiveexperiments on CTW1500, Total-Text, ICDAR 2015 and ICDAR 2017 MLT validate theeffectiveness of PSENet. Notably, on CTW1500, a dataset full of long curvetexts, PSENet achieves a F-measure of 74.3% at 27 FPS, and our best F-measure(82.2%) outperforms state-of-art algorithms by 6.6%. The code will be releasedin the future.",Wenhai Wang,2019/3/28,2019/7/29
2303.17003v1,Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams,http://arxiv.org/abs/2303.17003v1,"The present study aims to explore the capabilities of Language Models (LMs)in tackling high-stakes multiple-choice tests, represented here by the ExameNacional do Ensino M\'edio (ENEM), a multidisciplinary entrance examinationwidely adopted by Brazilian universities. This exam poses challenging tasks forLMs, since its questions may span into multiple fields of knowledge, requiringunderstanding of information from diverse domains. For instance, a question mayrequire comprehension of both statistics and biology to be solved. This workanalyzed responses generated by GPT-3.5 and GPT-4 models for questionspresented in the 2009-2017 exams, as well as for questions of the 2022 exam,which were made public after the training of the models was completed.Furthermore, different prompt strategies were tested, including the use ofChain-of-Thought (CoT) prompts to generate explanations for answers. On the2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracyof 87%, largely surpassing GPT-3.5 by 11 points. The code and data used onexperiments are available at https://github.com/piresramon/gpt-4-enem.",Desnes Nunes,2023/3/29,2023/3/29
2209.09513v2,Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering,http://arxiv.org/abs/2209.09513v2,"When answering a question, humans utilize the information available acrossdifferent modalities to synthesize a consistent and complete chain of thought(CoT). This process is normally a black box in the case of deep learning modelslike large-scale language models. Recently, science question benchmarks havebeen used to diagnose the multi-hop reasoning ability and interpretability ofan AI system. However, existing datasets fail to provide annotations for theanswers, or are restricted to the textual-only modality, small scales, andlimited domain diversity. To this end, we present Science Question Answering(ScienceQA), a new benchmark that consists of ~21k multimodal multiple choicequestions with a diverse set of science topics and annotations of their answerswith corresponding lectures and explanations. We further design language modelsto learn to generate lectures and explanations as the chain of thought (CoT) tomimic the multi-hop reasoning process when answering ScienceQA questions.ScienceQA demonstrates the utility of CoT in language models, as CoT improvesthe question answering performance by 1.20% in few-shot GPT-3 and 3.99% infine-tuned UnifiedQA. We also explore the upper bound for models to leverageexplanations by feeding those in the input; we observe that it improves thefew-shot performance of GPT-3 by 18.96%. Our analysis further shows thatlanguage models, similar to humans, benefit from explanations to learn fromfewer data and achieve the same performance with just 40% of the data. The dataand code are available at https://scienceqa.github.io.",Pan Lu,2022/9/20,2022/10/17
2311.14109v1,Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training,http://arxiv.org/abs/2311.14109v1,"Multimodal reasoning is a challenging task that requires models to reasonacross multiple modalities to answer questions. Existing approaches have madeprogress by incorporating language and visual modalities into a two-stagereasoning framework, separating rationale generation from answer inference.However, these approaches often fall short due to the inadequate quality of thegenerated rationales. In this work, we delve into the importance of rationalesin model reasoning. We observe that when rationales are completely accurate,the model's accuracy significantly improves, highlighting the need forhigh-quality rationale generation. Motivated by this, we propose MC-CoT, aself-consistency training strategy that generates multiple rationales andanswers, subsequently selecting the most accurate through a voting process.This approach not only enhances the quality of generated rationales but alsoleads to more accurate and robust answers. Through extensive experiments, wedemonstrate that our approach significantly improves model performance acrossvarious benchmarks. Remarkably, we show that even smaller base models, whenequipped with our proposed approach, can achieve results comparable to those oflarger models, illustrating the potential of our approach in harnessing thepower of rationales for improved multimodal reasoning. The code is available athttps://github.com/chengtan9907/mc-cot.",Cheng Tan,2023/11/23,2023/11/23
2310.20256v2,PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection,http://arxiv.org/abs/2310.20256v2,"Recent advances in large language models (LLMs), such as ChatGPT, haveshowcased remarkable zero-shot performance across various NLP tasks. However,the potential of LLMs in personality detection, which involves identifying anindividual's personality from their written texts, remains largely unexplored.Drawing inspiration from Psychological Questionnaires, which are carefullydesigned by psychologists to evaluate individual personality traits through aseries of targeted items, we argue that these items can be regarded as acollection of well-structured chain-of-thought (CoT) processes. Byincorporating these processes, LLMs can enhance their capabilities to make morereasonable inferences on personality from textual input. In light of this, wepropose a novel personality detection method, called PsyCoT, which mimics theway individuals complete psychological questionnaires in a multi-turn dialoguemanner. In particular, we employ a LLM as an AI assistant with a specializationin text analysis. We prompt the assistant to rate individual items at each turnand leverage the historical rating results to derive a conclusive personalitypreference. Our experiments demonstrate that PsyCoT significantly improves theperformance and robustness of GPT-3.5 in personality detection, achieving anaverage F1 score improvement of 4.23/10.63 points on two benchmark datasetscompared to the standard prompting method. Our code is available athttps://github.com/TaoYang225/PsyCoT.",Tao Yang,2023/10/31,2023/11/5
2305.14323v3,ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models,http://arxiv.org/abs/2305.14323v3,"Although large language models (LLMs) have achieved excellent performance ina variety of evaluation benchmarks, they still struggle in complex reasoningtasks which require specific knowledge and multi-hop reasoning. To improve thereasoning abilities, we propose ChatCoT, a tool-augmented chain-of-thoughtreasoning framework for chat-based LLMs (e.g., ChatGPT). In ChatCoT, we modelthe chain-of-thought (CoT) reasoning as multi-turn conversations, to utilizetools in a more natural way through chatting. At each turn, LLMs can eitherinteract with tools or perform the reasoning. Our approach can effectivelyleverage the multi-turn conversation ability of chat-based LLMs, and integratethe thought chain following and tools manipulation in a unified way. Specially,we initialize the early turns of the conversation by the knowledge about tools,tasks, and reasoning format, and propose an iterative tool-augmented reasoningstep to perform step-by-step tool-augmented reasoning. The experiment resultson two complex reasoning datasets (MATH and HotpotQA) have shown theeffectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relativeimprovement over the state-of-the-art baseline. Our code and data are availableat: \url{https://github.com/RUCAIBOX/ChatCoT}.",Zhipeng Chen,2023/5/23,2023/11/6
2304.00776v1,Chain-of-Thought Predictive Control,http://arxiv.org/abs/2304.00776v1,"We study generalizable policy learning from demonstrations for complexlow-level control tasks (e.g., contact-rich object manipulations). We proposean imitation learning method that incorporates the idea of temporal abstractionand the planning capabilities from Hierarchical RL (HRL) in a novel andeffective manner. As a step towards decision foundation models, our design canutilize scalable, albeit highly sub-optimal, demonstrations. Specifically, wefind certain short subsequences of the demos, i.e. the chain-of-thought (CoT),reflect their hierarchical structures by marking the completion of subgoals inthe tasks. Our model learns to dynamically predict the entire CoT as coherentand structured long-term action guidance and consistently outperforms typicaltwo-stage subgoal-conditioned policies. On the other hand, such CoT facilitatesgeneralizable policy learning as they exemplify the decision patterns sharedamong demos (even those with heavy noises and randomness). Our method,Chain-of-Thought Predictive Control (CoTPC), significantly outperforms existingones on challenging low-level manipulation tasks from scalable yet highlysub-optimal demos.",Zhiwei Jia,2023/4/3,2023/4/3
2312.07062v2,ThinkBot: Embodied Instruction Following with Thought Chain Reasoning,http://arxiv.org/abs/2312.07062v2,"Embodied Instruction Following (EIF) requires agents to complete humaninstruction by interacting objects in complicated surrounding environments.Conventional methods directly consider the sparse human instruction to generateaction plans for agents, which usually fail to achieve human goals because ofthe instruction incoherence in action descriptions. On the contrary, we proposeThinkBot that reasons the thought chain in human instruction to recover themissing action descriptions, so that the agent can successfully complete humangoals by following the coherent instruction. Specifically, we first design aninstruction completer based on large language models to recover the missingactions with interacted objects between consecutive human instruction, wherethe perceived surrounding environments and the completed sub-goals areconsidered for instruction completion. Based on the partially observed scenesemantic maps, we present an object localizer to infer the position ofinteracted objects for agents to achieve complex human goals. Extensiveexperiments in the simulated environment show that our ThinkBot outperforms thestate-of-the-art EIF methods by a sizable margin in both success rate andexecution efficiency.",Guanxing Lu,2023/12/12,2023/12/14
1703.05929v1,Completely regular codes by concatenating Hamming codes,http://arxiv.org/abs/1703.05929v1,"We construct new families of completely regular codes by concatenationmethods. By combining parity check matrices of cyclic Hamming codes, we obtainfamilies of completely regular codes. In all cases, we compute the intersectionarray of these codes. We also study when the extension of these codes givescompletely regular codes. Some of these new codes are completely transitive.",J. Borges,2017/3/17,2017/3/17
1902.07628v2,On completely regular and completely transitive codes derived from Hamming codes,http://arxiv.org/abs/1902.07628v2,"Given a parity-check matrix $H_m$ of a $q$-ary Hamming code, we consider apartition of the columns into two subsets. Then, we consider the two codes thathave these submatrices as parity-check matrices. We say that anyone of thesetwo codes is the supplementary code of the other one.  We obtain that if one of these codes is a Hamming code, then thesupplementary code is completely regular and completely transitive. If one ofthe codes is completely regular with covering radius $2$, then thesupplementary code is also completely regular with covering radius at most $2$.Moreover, in this case, either both codes are completely transitive, or bothare not.  With this technique, we obtain infinite families of completely regular andcompletely transitive codes which are quasi-perfect uniformly packed.",J. Borges,2019/2/20,2019/3/6
2210.11184v2,On completely regular codes with minimum eigenvalue in geometric graphs,http://arxiv.org/abs/2210.11184v2,"We prove that any completely regular code with minimum eigenvalue in anygeometric graph G corresponds to a completely regular code in the clique graphof G. Studying the interrelation of these codes, a complete characterization ofthe completely regular codes in the Johnson graphs J(n,w) with covering radiusw-1 and strength 1 is obtained. In particular this result finishes acharacterization of the completely regular codes in the Johnson graphs J(n,3).We also classify the completely regular codes of strength 1 in the Johnsongraphs J(n,4) with only one case for the eigenvalues left open.",I. Yu. Mogilnykh,2022/10/20,2022/12/22
1002.0295v1,On lifting perfect codes,http://arxiv.org/abs/1002.0295v1,"In this paper we consider completely regular codes, obtained from perfect(Hamming) codes by lifting the ground field. More exactly, for a given perfectcode C of length n=(q^m-1)/(q-1) over F_q with a parity check matrix H_m, wedefine a new code C_{(m,r)} of length n over F_{q^r}, r > 1, with this paritycheck matrix H_m. The resulting code C_{(m,r)} is completely regular withcovering radius R = min{r,m}. We compute the intersection numbers of such codesand, finally, we prove that Hamming codes are the only codes that, afterlifting the ground field, result in completely regular codes.",Josep Rif,2010/2/1,2010/2/1
1505.06502v2,The Complete Weight Enumerator of A Class of Linear Codes,http://arxiv.org/abs/1505.06502v2,"Linear codes can be employed to construct authentication codes, which is aninteresting area of cryptography. The parameters of the authentication codesdepend on the complete weight enumerator of the underlying linear codes. Inorder to obtain an authentication code with good parameters, the underlyinglinear code must have proper parameters. The first objective of this paper isto determine the complete weight enumerators of a class of linear codes withtwo weights and three weights. The second is to employ these linear codes toconstruct authentication codes with new parameters.",Can Xiang,2015/5/25,2015/5/26
2009.08603v1,Towards Full-line Code Completion with Neural Language Models,http://arxiv.org/abs/2009.08603v1,"A code completion system suggests future code elements to developers given apartially-complete code snippet. Code completion is one of the most usefulfeatures in Integrated Development Environments (IDEs). Currently, most codecompletion techniques predict a single token at a time. In this paper, we takea further step and discuss the probability of directly completing a whole lineof code instead of a single token. We believe suggesting longer code sequencescan further improve the efficiency of developers. Recently neural languagemodels have been adopted as a preferred approach for code completion, and webelieve these models can still be applied to full-line code completion with afew improvements. We conduct our experiments on two real-world python corporaand evaluate existing neural models based on source code tokens or syntacticalactions. The results show that neural language models can achieve acceptableresults on our tasks, with significant room for improvements.",Wenhan Wang,2020/9/18,2020/9/18
1703.08684v1,On Completely Regular Codes,http://arxiv.org/abs/1703.08684v1,"This work is a survey on completely regular codes. Known properties,relations with other combinatorial structures and constructions are stated. Theexistence problem is also discussed and known results for some particular casesare established. In particular, we present a few new results on completelyregular codes with covering radius 2 and on extended completely regular codes.",J. Borges,2017/3/25,2017/3/25
1901.03149v2,The Complete Hierarchical Locality of the Punctured Simplex Code,http://arxiv.org/abs/1901.03149v2,"This paper presents a new alphabet-dependent bound for codes withhierarchical locality. Then, the complete list of possible localities isderived for a class of codes obtained by deleting specific columns from aSimplex code. This list is used to show that these codes are optimal codes withhierarchical locality.",Matthias Grezet,2019/1/10,2019/7/3
1002.4510v1,On linear $q$-ary completely regular codes with $=2$ and dual antipodal,http://arxiv.org/abs/1002.4510v1,"We characterize all linear $q$-ary completely regular codes with coveringradius $\rho=2$ when the dual codes are antipodal. These completely regularcodes are extensions of linear completely regular codes with covering radius 1,which are all classified. For $\rho=2$, we give a list of all such codes knownto us. This also gives the characterization of two weight linear antipodalcodes.",Joaquim Borges,2010/2/24,2010/2/24
0911.1826v3,Arithmetic completely regular codes,http://arxiv.org/abs/0911.1826v3,"In this paper, we explore completely regular codes in the Hamming graphs andrelated graphs. Experimental evidence suggests that many completely regularcodes have the property that the eigenvalues of the code are in arithmeticprogression. In order to better understand these ""arithmetic completely regularcodes"", we focus on cartesian products of completely regular codes and productsof their corresponding coset graphs in the additive case. Employing earlierresults, we are then able to prove a theorem which nearly classifies thesecodes in the case where the graph admits a completely regular partition intosuch codes (e.g, the cosets of some additive completely regular code).Connections to the theory of distance-regular graphs are explored and severalopen questions are posed.",J. H. Koolen,2009/11/10,2016/2/11
1510.06903v1,Completely regular codes with different parameters and the same distance-regular coset graphs,http://arxiv.org/abs/1510.06903v1,"A known Kronecker construction of completely regular codes has beeninvestigated taking different alphabets in the component codes. This approachis also connected with lifting constructions of completely regular codes. Weobtain several classes of completely regular codes with different parameters,but identical intersection array. Given a prime power $q$ and any two naturalnumbers $a,b$, we construct completely transitive codes over different fieldswith covering radius $\rho=\min\{a,b\}$ and identical intersection array,specifically, one code over $\F_{q^r}$ for each divisor $r$ of $a$ or $b$. As acorollary, for any prime power $q$, we show that distance regular bilinearforms graphs can be obtained as coset graphs from several completely regularcodes with different parameters. Under the same conditions, an explicitconstruction of an infinite family of $q$-ary uniformly packed codes (in thewide sense) with covering radius $\rho$, which are not completely regular, isalso given.",J. Rif,2015/10/23,2015/10/23
quant-ph/0310076v1,Quantum Public-Key Cryptosystem Based on Classical NP-Complete Problem,http://arxiv.org/abs/quant-ph/0310076v1,We present a quantum public-key cryptosystem based on a classical NP-completeproblem related with finding a code word of a given weight in a linear binarycode.,Li Yang,2003/10/12,2003/10/12
2301.03846v1,Practitioners' Expectations on Code Completion,http://arxiv.org/abs/2301.03846v1,"Code completion has become a common practice for programmers during theirdaily programming activities. It aims at automatically predicting the nexttokens or lines that the programmers tend to use. A good code completion toolcan substantially save keystrokes and improve the programming efficiency forprogrammers. Recently, various techniques for code completion have beenproposed for usage in practice. However, it is still unclear what arepractitioners' expectations on code completion and whether existing researchhas met their demands. To fill the gap, we perform an empirical study by firstinterviewing 15 practitioners and then surveying 599 practitioners from 18 ITcompanies about their expectations on code completion. We then compare thepractitioners' demands with current research via conducting a literature reviewof papers on code completion published in premier publication venues from 2012to 2022. Based on the comparison, we highlight the directions desirable forresearchers to invest efforts towards developing code completion techniques formeeting practitioners' expectations.",Chaozheng Wang,2023/1/10,2023/1/10
2205.05638v2,Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning,http://arxiv.org/abs/2205.05638v2,"Few-shot in-context learning (ICL) enables pre-trained language models toperform a previously-unseen task without any gradient-based training by feedinga small number of training examples as part of the input. ICL incurssubstantial computational, memory, and storage costs because it involvesprocessing all of the training examples every time a prediction is made.Parameter-efficient fine-tuning (PEFT) (e.g. adapter modules, prompt tuning,sparse update methods, etc.) offers an alternative paradigm where a small setof parameters are trained to enable a model to perform the new task. In thispaper, we rigorously compare few-shot ICL and PEFT and demonstrate that thelatter offers better accuracy as well as dramatically lower computationalcosts. Along the way, we introduce a new PEFT method called (IA)$^3$ thatscales activations by learned vectors, attaining stronger performance whileonly introducing a relatively tiny amount of new parameters. We also propose asimple recipe based on the T0 model called T-Few that can be applied to newtasks without task-specific tuning or modifications. We validate theeffectiveness of T-Few on completely unseen tasks by applying it to the RAFTbenchmark, attaining super-human performance for the first time andoutperforming the state-of-the-art by 6% absolute. All of the code used in ourexperiments is publicly available.",Haokun Liu,2022/5/11,2022/8/26
2310.00647v2,Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning,http://arxiv.org/abs/2310.00647v2,"Following the success of Large Language Models (LLMs), Large MultimodalModels (LMMs), such as the Flamingo model and its subsequent competitors, havestarted to emerge as natural steps towards generalist agents. However,interacting with recent LMMs reveals major limitations that are hardly capturedby the current evaluation benchmarks. Indeed, task performances (e.g., VQAaccuracy) alone do not provide enough clues to understand their realcapabilities, limitations, and to which extent such models are aligned to humanexpectations. To refine our understanding of those flaws, we deviate from thecurrent evaluation paradigm, and (1) evaluate 10 recent open-source LMMs from3B up to 80B parameter scale, on 5 different axes; hallucinations, abstention,compositionality, explainability and instruction following. Our evaluation onthese axes reveals major flaws in LMMs. While the current go-to solution toalign these models is based on training, such as instruction tuning or RLHF, werather (2) explore the training-free in-context learning (ICL) as a solution,and study how it affects these limitations. Based on our ICL study, (3) we pushICL further and propose new multimodal ICL variants such as; Multitask-ICL,Chain-of-Hindsight-ICL, and Self-Correcting-ICL. Our findings are as follows.(1) Despite their success, LMMs have flaws that remain unsolved with scalingalone. (2) The effect of ICL on LMMs flaws is nuanced; despite itseffectiveness for improved explainability, answer abstention, ICL only slightlyimproves instruction following, does not improve compositional abilities, andactually even amplifies hallucinations. (3) The proposed ICL variants arepromising as post-hoc approaches to efficiently tackle some of those flaws. Thecode is available here: https://github.com/mshukor/EvALign-ICL.",Mustafa Shukor,2023/10/1,2024/1/22
1610.08503v2,Characterizing Intra-cluster light in the Hubble Frontier Fields,http://arxiv.org/abs/1610.08503v2,"We investigate the intra-cluster light (ICL) in the 6 Hubble Frontier Fieldclusters at $0.3<z<0.6$. We employ a new method, which is free from anyfunctional form of the ICL profile, and exploit the unprecedented depth of thisHubble Space Telescope imaging to map the ICL's diffuse light out toclustrocentric radii $R\sim300$kpc ($\mu_{\rm ICL}\sim27$mag arcsec$^{-2}$).From these maps, we construct radial color and stellar mass profiles via SEDfitting and find clear negative color gradients in all systems with increasingdistance from the Brightest Cluster Galaxy (BCG). While this implies older/moremetal rich stellar components in the inner part of the ICL, we find the ICLmostly consists of a $<2$Gyr population, and plausibly originated with $\logM_*/M_\odot<10$ cluster galaxies. Further, we find 10-15% of the ICL's mass atlarge radii ($>150$kpc) lies in a younger/bluer stellar population($\sim1$Gyr), a phenomenon not seen in local samples. We attribute this lightto the higher fraction of starforming/(post-)starburst galaxies in clusters at$z\sim0.5$. Ultimately, we find the ICL's total mass to be $\log M_{\rm *}^{\rmICL}/M_\odot\sim11$-12, constituting 5%-20% of the clusters' total stellarmass, or about a half of the value at $z\sim0$. The above implies distinctformation histories for the ICL and BCGs/other massive cluster galaxies; i.e.the ICL at this epoch is still being constructed rapidly($\sim40M_\odot$yr$^{-1}$), while the BCGs have mostly completed theirevolution. To be consistent with the ICL measurements of local massiveclusters, such as the Virgo, our data suggest mass acquisition mainly fromquiescent cluster galaxies is the principal source of ICL material in thesubsequent $\sim$5 Gyr of cosmic time.",Takahiro Morishita,2016/10/26,2017/8/1
2305.02835v1,Designing Bugs or Doing Another Project: Effects on Secondary Students' Self-Beliefs in Computer Science,http://arxiv.org/abs/2305.02835v1,"Debugging, finding and fixing bugs in code, is a heterogeneous process thatshapes novice learners' self-beliefs and motivation in computing. Our Debuggingby Design intervention (DbD) provocatively puts students in control over bugsby having them collaborate on designing creative buggy projects during anelectronic textiles unit in an introductory computing course. We implementedDbD virtually in eight classrooms with two teachers in public schools withhistorically marginalized populations, using a quasi-experimental design. Datafrom this study included post-activity results from a validated surveyinstrument (N=144). For all students, project completion correlated withincreased computer science creative expression and e-textiles codingself-efficacy. In the comparison classes, project completion correlated withreduced programming anxiety, problem-solving competency beliefs, andprogramming self-concept. In DbD classes, project completion is uniquelycorrelated with increased fascination with design and programming growthmindset. In the discussion, we consider the relative benefits of DbD versusother open-ended projects.",Luis Morales-Navarro,2023/5/4,2023/5/4
2306.15063v2,Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression,http://arxiv.org/abs/2306.15063v2,"Pretrained transformers exhibit the remarkable ability of in-context learning(ICL): they can learn tasks from just a few examples provided in the promptwithout updating any weights. This raises a foundational question: can ICLsolve fundamentally $\textit{new}$ tasks that are very different from thoseseen during pretraining? To probe this question, we examine ICL's performanceon linear regression while varying the diversity of tasks in the pretrainingdataset. We empirically demonstrate a $\textit{task diversity threshold}$ forthe emergence of ICL. Below this threshold, the pretrained transformer cannotsolve unseen regression tasks, instead behaving like a Bayesian estimator withthe $\textit{non-diverse pretraining task distribution}$ as the prior. Beyondthis threshold, the transformer significantly outperforms this estimator; itsbehavior aligns with that of ridge regression, corresponding to a Gaussianprior over $\textit{all tasks}$, including those not seen during pretraining.Thus, when pretrained on data with task diversity greater than the threshold,transformers $\textit{can}$ optimally solve fundamentally new tasks in-context.Importantly, this capability hinges on it deviating from the Bayes optimalestimator with the pretraining distribution as the prior. This study alsoexplores the effect of regularization, model capacity and task structure andunderscores, in a concrete example, the critical role of task diversity,alongside data and model scale, in the emergence of ICL. Code is available athttps://github.com/mansheej/icl-task-diversity.",Allan Ravents,2023/6/26,2023/11/8
1205.4123v2,Estimation and Model Selection for Model-Based Clustering with the Conditional Classification Likelihood,http://arxiv.org/abs/1205.4123v2,"The Integrated Completed Likelihood (ICL) criterion has been proposed byBiernacki et al. (2000) in the model-based clustering framework to select arelevant number of classes and has been used by statisticians in variousapplication areas. A theoretical study of this criterion is proposed. Acontrast related to the clustering objective is introduced: the conditionalclassification likelihood. This yields an estimator and a model selectioncriteria class. The properties of these new procedures are studied and ICL isproved to be an approximation of one of these criteria. We oppose these resultsto the current leading point of view about ICL, that it would not beconsistent. Moreover these results give insights into the class notionunderlying ICL and feed a reflection on the class notion in clustering. Generalresults on penalized minimum contrast criteria and on mixture models arederived, which are interesting in their own right.",Jean-Patrick Baudry,2012/5/18,2012/5/31
2309.16697v1,Inappropriate Benefits and Identification of ChatGPT Misuse in Programming Tests: A Controlled Experiment,http://arxiv.org/abs/2309.16697v1,"While ChatGPT may help students to learn to program, it can be misused to doplagiarism, a breach of academic integrity. Students can ask ChatGPT tocomplete a programming task, generating a solution from other people's workwithout proper acknowledgment of the source(s). To help address this new kindof plagiarism, we performed a controlled experiment measuring the inappropriatebenefits of using ChatGPT in terms of completion time and programmingperformance. We also reported how to manually identify programs aided withChatGPT (via student behavior while using ChatGPT) and student perspective ofChatGPT (via a survey). Seventeen students participated in the experiment. Theywere asked to complete two programming tests. They were divided into two groupsper the test: one group should complete the test without help while the othergroup should complete it with ChatGPT. Our study shows that students withChatGPT complete programming tests two times faster than those without ChatGPT,though their programming performance is comparable. The generated code ishighly efficient and uses complex data structures like lists and dictionaries.Based on the survey results, ChatGPT is recommended to be used as an assistantto complete programming tasks and other general assignments. ChatGPT will bebeneficial as a reference as other search engines do. Logical and criticalthinking are needed to validate the result presented by ChatGPT.",Hapnes Toba,2023/8/11,2023/8/11
2306.10998v1,RepoFusion: Training Code Models to Understand Your Repository,http://arxiv.org/abs/2306.10998v1,"Despite the huge success of Large Language Models (LLMs) in coding assistantslike GitHub Copilot, these models struggle to understand the context present inthe repository (e.g., imports, parent classes, files with similar names, etc.),thereby producing inaccurate code completions. This effect is more pronouncedwhen using these assistants for repositories that the model has not seen duringtraining, such as proprietary software or work-in-progress code projects.Recent work has shown the promise of using context from the repository duringinference. In this work, we extend this idea and propose RepoFusion, aframework to train models to incorporate relevant repository context.Experiments on single-line code completion show that our models trained withrepository context significantly outperform much larger code models asCodeGen-16B-multi ($\sim73\times$ larger) and closely match the performance ofthe $\sim 70\times$ larger StarCoderBase model that was trained with theFill-in-the-Middle objective. We find these results to be a novel andcompelling demonstration of the gains that training with repository context canbring. We carry out extensive ablation studies to investigate the impact ofdesign choices such as context type, number of contexts, context length, andinitialization within our framework. Lastly, we release Stack-Repo, a datasetof 200 Java repositories with permissive licenses and near-deduplicated filesthat are augmented with three types of repository contexts. Additionally, weare making available the code and trained checkpoints for our work. Ourreleased resources can be found at \url{https://huggingface.co/RepoFusion}.",Disha Shrivastava,2023/6/19,2023/6/19
2310.11248v2,CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion,http://arxiv.org/abs/2310.11248v2,"Code completion models have made significant progress in recent years, yetcurrent popular evaluation datasets, such as HumanEval and MBPP, predominantlyfocus on code completion tasks within a single file. This over-simplifiedsetting falls short of representing the real-world software developmentscenario where repositories span multiple files with numerous cross-filedependencies, and accessing and understanding cross-file context is oftenrequired to complete the code correctly.  To fill in this gap, we propose CrossCodeEval, a diverse and multilingualcode completion benchmark that necessitates an in-depth cross-file contextualunderstanding to complete the code accurately. CrossCodeEval is built on adiverse set of real-world, open-sourced, permissively-licensed repositories infour popular programming languages: Python, Java, TypeScript, and C#. To createexamples that strictly require cross-file context for accurate completion, wepropose a straightforward yet efficient static-analysis-based approach topinpoint the use of cross-file context within the current file.  Extensive experiments on state-of-the-art code language models like CodeGenand StarCoder demonstrate that CrossCodeEval is extremely challenging when therelevant cross-file context is absent, and we see clear improvements whenadding these context into the prompt. However, despite such improvements, thepinnacle of performance remains notably unattained even with thehighest-performing model, indicating that CrossCodeEval is also capable ofassessing model's capability in leveraging extensive context to make bettercode completion. Finally, we benchmarked various methods in retrievingcross-file context, and show that CrossCodeEval can also be used to measure thecapability of code retrievers.",Yangruibo Ding,2023/10/17,2023/11/17
1903.00884v2,CodeGRU: Context-aware Deep Learning with Gated Recurrent Unit for Source Code Modeling,http://arxiv.org/abs/1903.00884v2,"Recently deep learning based Natural Language Processing (NLP) models haveshown great potential in the modeling of source code. However, a majorlimitation of these approaches is that they take source code as simple tokensof text and ignore its contextual, syntactical and structural dependencies. Inthis work, we present CodeGRU, a gated recurrent unit based source codelanguage model that is capable of capturing source code's contextual,syntactical and structural dependencies. We introduce a novel approach whichcan capture the source code context by leveraging the source code token types.Further, we adopt a novel approach which can learn variable size context bytaking into account source code's syntax, and structural information. Weevaluate CodeGRU with real-world data set and it shows that CodeGRU outperformsthe state-of-the-art language models and help reduce the vocabulary size up to24.93\%. Unlike previous works, we tested CodeGRU with an independent test setwhich suggests that our methodology does not requisite the source code comesfrom the same domain as training data while providing suggestions. We furtherevaluate CodeGRU with two software engineering applications: source codesuggestion, and source code completion. Our experiment confirms that the sourcecode's contextual information can be vital and can help improve the softwarelanguage models. The extensive evaluation of CodeGRU shows that it outperformsthe state-of-the-art models. The results further suggest that the proposedapproach can help reduce the vocabulary size and is of practical use forsoftware developers.",Yasir Hussain,2019/3/3,2020/7/14
2306.00381v1,Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion,http://arxiv.org/abs/2306.00381v1,"Pretrained code language models have enabled great progress towards programsynthesis. However, common approaches only consider in-file local context andthus miss information and constraints imposed by other parts of the codebaseand its external dependencies. Existing code completion benchmarks also lacksuch context. To resolve these restrictions we curate a new dataset ofpermissively licensed Python packages that includes full projects and theirdependencies and provide tools to extract non-local information with the helpof program analyzers. We then focus on the task of function call argumentcompletion which requires predicting the arguments to function calls. We showthat existing code completion models do not yield good results on ourcompletion task. To better solve this task, we query a program analyzer forinformation relevant to a given function call, and consider ways to provide theanalyzer results to different code completion models during inference andtraining. Our experiments show that providing access to the functionimplementation and function usages greatly improves the argument completionperformance. Our ablation study provides further insights on how differenttypes of information available from the program analyzer and different ways ofincorporating the information affect the model performance.",Hengzhi Pei,2023/6/1,2023/6/1
2202.06689v1,CodeFill: Multi-token Code Completion by Jointly Learning from Structure and Naming Sequences,http://arxiv.org/abs/2202.06689v1,"Code completion is an essential feature of IDEs, yet current autocompletersare restricted to either grammar-based or NLP-based single token completions.Both approaches have significant drawbacks: grammar-based autocompletion isrestricted in dynamically-typed language environments, whereas NLP-basedautocompleters struggle to understand the semantics of the programming languageand the developer's code context.  In this work, we present CodeFill, a language model for autocompletion thatcombines learned structure and naming information. Using a parallel Transformerarchitecture and multi-task learning, CodeFill consumes sequences of sourcecode token names and their equivalent AST token types. Uniquely, CodeFill istrained both for single-token and multi-token (statement) prediction, whichenables it to learn long-range dependencies among grammatical and namingelements. We train CodeFill on two datasets, consisting of 29M and 425M linesof code, respectively. To make the evaluation more realistic, we develop amethod to automatically infer points in the source code at which completionmatters. We compare CodeFill against four baselines and two state-of-the-artmodels, GPT-C and TravTrans+.CodeFill surpasses all baselines in single tokenprediction (MRR: 70.9% vs. 66.2% and 67.8%) and outperforms the state of theart for multi-token prediction (ROUGE-L: 63.7% vs. 52.4% and 59.2%, for n=4tokens). We publicly release our source code and datasets.",Maliheh Izadi,2022/2/14,2022/2/14
1910.06500v2,DeepVS: An Efficient and Generic Approach for Source Code Modeling Usage,http://arxiv.org/abs/1910.06500v2,"The source code suggestions provided by current IDEs are mostly dependent onstatic type learning. These suggestions often end up proposing irrelevantsuggestions for a peculiar context. Recently, deep learning-based approacheshave shown great potential in the modeling of source code for various softwareengineering tasks. However, these techniques lack adequate generalization andresistance to acclimate the use of such models in a real-world softwaredevelopment environment. This letter presents \textit{DeepVS}, an end-to-enddeep neural code completion tool that learns from existing codebases byexploiting the bidirectional Gated Recurrent Unit (BiGRU) neural net. Theproposed tool is capable of providing source code suggestions instantly in anIDE by using pre-trained BiGRU neural net. The evaluation of this work istwo-fold, quantitative and qualitative. Through extensive evaluation on tenreal-world open-source software systems, the proposed method shows significantperformance enhancement and its practicality. Moreover, the results alsosuggest that \textit{DeepVS} tool is capable of suggesting zero-day (unseen)code tokens by learning coding patterns from real-world software systems.",Yasir Hussain,2019/10/15,2020/7/14
1912.00742v1,Pythia: AI-assisted Code Completion System,http://arxiv.org/abs/1912.00742v1,"In this paper, we propose a novel end-to-end approach for AI-assisted codecompletion called Pythia. It generates ranked lists of method and APIrecommendations which can be used by software developers at edit time. Thesystem is currently deployed as part of Intellicode extension in Visual StudioCode IDE. Pythia exploits state-of-the-art large-scale deep learning modelstrained on code contexts extracted from abstract syntax trees. It is designedto work at a high throughput predicting the best matching code completions onthe order of 100 $ms$.  We describe the architecture of the system, perform comparisons tofrequency-based approach and invocation-based Markov Chain language model, anddiscuss challenges serving Pythia models on lightweight client devices.  The offline evaluation results obtained on 2700 Python open source softwareGitHub repositories show a top-5 accuracy of 92\%, surpassing the baselinemodels by 20\% averaged over classes, for both intra and cross-projectsettings.",Alexey Svyatkovskiy,2019/11/29,2019/11/29
2203.13224v2,Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion,http://arxiv.org/abs/2203.13224v2,"Language models (LMs) have recently been shown to generate more factualresponses by employing modularity (Zhou et al., 2021) in combination withretrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs etal. (2021) to include internet search as a module. Our SeeKeR (Searchengine->Knowledge->Response) method thus applies a single LM to three modulartasks in succession: search, generating knowledge, and generating a finalresponse. We show that, when using SeeKeR as a dialogue model, it outperformsthe state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domainknowledge-grounded conversations for the same number of parameters, in terms ofconsistency, knowledge and per-turn engagingness. SeeKeR applied to topicalprompt completions as a standard language model outperforms GPT2 (Radford etal., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality,despite GPT3 being a vastly larger model. Our code and models are made publiclyavailable.",Kurt Shuster,2022/3/24,2022/3/29
2304.09048v2,CodeKGC: Code Language Model for Generative Knowledge Graph Construction,http://arxiv.org/abs/2304.09048v2,"Current generative knowledge graph construction approaches usually fail tocapture structural knowledge by simply flattening natural language intoserialized texts or a specification language. However, large generativelanguage model trained on structured data such as code has demonstratedimpressive capability in understanding natural language for structuralprediction and reasoning tasks. Intuitively, we address the task of generativeknowledge graph construction with code language model: given a code-formatnatural language input, the target is to generate triples which can berepresented as code completion tasks. Specifically, we develop schema-awareprompts that effectively utilize the semantic structure within the knowledgegraph. As code inherently possesses structure, such as class and functiondefinitions, it serves as a useful model for prior semantic structuralknowledge. Furthermore, we employ a rationale-enhanced generation method toboost the performance. Rationales provide intermediate steps, thereby improvingknowledge extraction abilities. Experimental results indicate that the proposedapproach can obtain better performance on benchmark datasets compared withbaselines. Code and datasets are available inhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.",Zhen Bi,2023/4/18,2024/1/18
2209.03320v3,What does a platypus look like? Generating customized prompts for zero-shot image classification,http://arxiv.org/abs/2209.03320v3,"Open-vocabulary models are a promising new paradigm for image classification.Unlike traditional classification models, open-vocabulary models classify amongany arbitrary set of categories specified with natural language duringinference. This natural language, called ""prompts"", typically consists of a setof hand-written templates (e.g., ""a photo of a {}"") which are completed witheach of the category names. This work introduces a simple method to generatehigher accuracy prompts, without relying on any explicit knowledge of the taskdomain and with far fewer hand-constructed sentences. To achieve this, wecombine open-vocabulary models with large language models (LLMs) to createCustomized Prompts via Language models (CuPL, pronounced ""couple""). Inparticular, we leverage the knowledge contained in LLMs in order to generatemany descriptive sentences that contain important discriminatingcharacteristics of the image categories. This allows the model to place agreater importance on these regions in the image when making predictions. Wefind that this straightforward and general approach improves accuracy on arange of zero-shot image classification benchmarks, including over onepercentage point gain on ImageNet. Finally, this simple baseline requires noadditional training and remains completely zero-shot. Code available athttps://github.com/sarahpratt/CuPL.",Sarah Pratt,2022/9/7,2023/12/3
2308.11761v1,KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases,http://arxiv.org/abs/2308.11761v1,"Large language models (LLMs) have demonstrated impressive impact in the fieldof natural language processing, but they still struggle with several issuesregarding, such as completeness, timeliness, faithfulness and adaptability.While recent efforts have focuses on connecting LLMs with external knowledgesources, the integration of knowledge bases (KBs) remains understudied andfaces several challenges. In this paper, we introduce KnowledGPT, acomprehensive framework to bridge LLMs with various knowledge bases,facilitating both the retrieval and storage of knowledge. The retrieval processemploys the program of thought prompting, which generates search language forKBs in code format with pre-defined functions for KB operations. Besidesretrieval, KnowledGPT offers the capability to store knowledge in apersonalized KB, catering to individual user demands. With extensiveexperiments, we show that by integrating LLMs with KBs, KnowledGPT properlyanswers a broader range of questions requiring world knowledge compared withvanilla LLMs, utilizing both knowledge existing in widely-known KBs andextracted into personalized KBs.",Xintao Wang,2023/8/17,2023/8/17
1911.12543v2,How Can We Know What Language Models Know?,http://arxiv.org/abs/1911.12543v2,"Recent work has presented intriguing results examining the knowledgecontained in language models (LM) by having the LM fill in the blanks ofprompts such as ""Obama is a _ by profession"". These prompts are usuallymanually created, and quite possibly sub-optimal; another prompt such as ""Obamaworked as a _"" may result in more accurately predicting the correct profession.Because of this, given an inappropriate prompt, we might fail to retrieve factsthat the LM does know, and thus any given prompt only provides a lower boundestimate of the knowledge contained in an LM. In this paper, we attempt to moreaccurately estimate the knowledge contained in LMs by automatically discoveringbetter prompts to use in this querying process. Specifically, we proposemining-based and paraphrasing-based methods to automatically generatehigh-quality and diverse prompts, as well as ensemble methods to combineanswers from different prompts. Extensive experiments on the LAMA benchmark forextracting relational knowledge from LMs demonstrate that our methods canimprove accuracy from 31.1% to 39.6%, providing a tighter lower bound on whatLMs know. We have released the code and the resulting LM Prompt And QueryArchive (LPAQA) at https://github.com/jzbjyb/LPAQA.",Zhengbao Jiang,2019/11/28,2020/5/3
2311.09601v1,Code Models are Zero-shot Precondition Reasoners,http://arxiv.org/abs/2311.09601v1,"One of the fundamental skills required for an agent acting in an environmentto complete tasks is the ability to understand what actions are plausible atany given point. This work explores a novel use of code representations toreason about action preconditions for sequential decision making tasks. Coderepresentations offer the flexibility to model procedural activities andassociated constraints as well as the ability to execute and verify constraintsatisfaction. Leveraging code representations, we extract action preconditionsfrom demonstration trajectories in a zero-shot manner using pre-trained codemodels. Given these extracted preconditions, we propose a precondition-awareaction sampling strategy that ensures actions predicted by a policy areconsistent with preconditions. We demonstrate that the proposed approachenhances the performance of few-shot policy learning approaches acrosstask-oriented dialog and embodied textworld benchmarks.",Lajanugen Logeswaran,2023/11/16,2023/11/16
cs/0003011v2,Automatic Belief Revision in SNePS,http://arxiv.org/abs/cs/0003011v2,"SNePS is a logic- and network- based knowledge representation, reasoning, andacting system, based on a monotonic, paraconsistent, first-order term logic,with compositional intensional semantics. It has an ATMS-style facility forbelief contraction, and an acting component, including a well-defined syntaxand semantics for primitive and composite acts, as well as for ``rules'' thatallow for acting in support of reasoning and reasoning in support of acting.SNePS has been designed to support natural language competent cognitive agents.  When the current version of SNePS detects an explicit contradiction, itinteracts with the user, providing information that helps the user decide whatto remove from the knowledge base in order to remove the contradiction. Theforthcoming SNePS 2.6 will also do automatic belief contraction if theinformation in the knowledge base warrents it.",Stuart C. Shapiro,2000/3/6,2000/6/16
2203.02167v1,SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models,http://arxiv.org/abs/2203.02167v1,"Knowledge graph completion (KGC) aims to reason over known facts and inferthe missing links. Text-based methods such as KGBERT (Yao et al., 2019) learnentity representations from natural language descriptions, and have thepotential for inductive KGC. However, the performance of text-based methodsstill largely lag behind graph embedding-based methods like TransE (Bordes etal., 2013) and RotatE (Sun et al., 2019b). In this paper, we identify that thekey issue is efficient contrastive learning. To improve the learningefficiency, we introduce three types of negatives: in-batch negatives,pre-batch negatives, and self-negatives which act as a simple form of hardnegatives. Combined with InfoNCE loss, our proposed model SimKGC cansubstantially outperform embedding-based methods on several benchmark datasets.In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19%on WN18RR, +6.8% on the Wikidata5M transductive setting, and +22% on theWikidata5M inductive setting. Thorough analyses are conducted to gain insightsinto each component. Our code is available athttps://github.com/intfloat/SimKGC .",Liang Wang,2022/3/4,2022/3/4
cs/0601088v1,An Algorithm for Constructing All Families of Codes of Arbitrary Requirement in an OCDMA System,http://arxiv.org/abs/cs/0601088v1,A novel code construction algorithm is presented to find all the possiblecode families for code reconfiguration in an OCDMA system. The algorithm isdeveloped through searching all the complete subgraphs of a constructed graph.The proposed algorithm is flexible and practical for constructing opticalorthogonal codes (OOCs) of arbitrary requirement. Simulation results show thatone should choose an appropriate code length in order to obtain sufficientnumber of code families for code reconfiguration with reasonable cost.,Xiang Lu,2006/1/20,2006/1/20
2211.05996v1,Sterile Neutrinos from Dark Matter: A $$ Nightmare?,http://arxiv.org/abs/2211.05996v1,"We provide a comprehensive study of observable spectra from dark matterpair-annihilation or decay into sterile (right-handed) neutrinos. This occurs,for instance, in neutrino portal dark matter models, where a sterile neutrinoacts as the portal between dark matter and the Standard Model sector. Thesubsequent decays of right-handed neutrinos produce detectable Standard Modelparticles, notably photons, positrons, and neutrinos. We study thephenomenology of models where the right-handed neutrino masses are below theGeV scale, as well as models where they are at, or significantly heavier than,the TeV scale. In both instances, and for different reasons, the standardtools, including Monte Carlo simulations, are both inadequate and inaccurate.We present the complete framework to compute the relevant branching ratios forright-handed neutrino decays and the spectra of secondary photons, positrons,and neutrinos for a broad range of dark matter and right-handed neutrinomasses. We discuss the general features of such signals, and compare thespectra to standard signals from dark matter annihilation/decay into bottomquarks. Additionally, we provide open source code1 that can be used to computesuch spectra. The code is available athttps://github.com/LoganAMorrison/blackthorn.",Logan Morrison,2022/11/11,2022/11/11
2309.09826v2,Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding,http://arxiv.org/abs/2309.09826v2,"Auto-completing code enables developers to speed up coding significantly.Recent advances in transformer-based large language model (LLM) technologieshave been applied to code synthesis. However, studies show that many of suchsynthesized codes contain vulnerabilities. We propose a novelvulnerability-constrained decoding approach to reduce the amount of vulnerablecode generated by such models. Using a small dataset of labeled vulnerablelines of code, we fine-tune an LLM to include vulnerability labels whengenerating code, acting as an embedded classifier. Then, during decoding, wedeny the model to generate these labels to avoid generating vulnerable code. Toevaluate the method, we chose to automatically complete Ethereum Blockchainsmart contracts (SCs) as the case study due to the strict requirements of SCsecurity. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuningtook more than one week using ten GPUs. The results showed that our fine-tunedmodel could synthesize SCs with an average BLEU (BiLingual EvaluationUnderstudy) score of 0.557. However, many codes in the auto-completed SCs werevulnerable. Using the code before the vulnerable line of 176 SCs containingdifferent types of vulnerabilities to auto-complete the code, we found thatmore than 70% of the auto-completed codes were insecure. Thus, we furtherfine-tuned the model on other 941 vulnerable SCs containing the same types ofvulnerabilities and applied vulnerability-constrained decoding. The fine-tuningtook only one hour with four GPUs. We then auto-completed the 176 SCs again andfound that our approach could identify 62% of the code to be generated asvulnerable and avoid generating 67% of them, indicating the approach couldefficiently and effectively avoid vulnerabilities in the auto-completed code.",Andr Storhaug,2023/9/18,2023/10/6
cs/0408038v1,The Dynamics of Group Codes: Dual Abelian Group Codes and Systems,http://arxiv.org/abs/cs/0408038v1,"Fundamental results concerning the dynamics of abelian group codes(behaviors) and their duals are developed. Duals of sequence spaces overlocally compact abelian groups may be defined via Pontryagin duality; dualgroup codes are orthogonal subgroups of dual sequence spaces. The dual of acomplete code or system is finite, and the dual of a Laurent code or system is(anti-)Laurent. If C and C^\perp are dual codes, then the state spaces of C actas the character groups of the state spaces of C^\perp. The controllabilityproperties of C are the observability properties of C^\perp. In particular, Cis (strongly) controllable if and only if C^\perp is (strongly) observable, andthe controller memory of C is the observer memory of C^\perp. The controllergranules of C act as the character groups of the observer granules of C^\perp.Examples of minimal observer-form encoder and syndrome-former constructions aregiven. Finally, every observer granule of C is an ""end-around"" controllergranule of C.",G. David Forney Jr.,2004/8/16,2004/8/16
1404.3677v1,Decoding Delay Controlled Reduction of Completion Time in Instantly Decodable Network Coding,http://arxiv.org/abs/1404.3677v1,"For several years, the completion time and the decoding delay problems inInstantly Decodable Network Coding (IDNC) were considered separately and werethought to completely act against each other. Recently, some works aimed tobalance the effects of these two important IDNC metrics but none of themstudied a further optimization of one by controlling the other. In this paper,we study the effect of controlling the decoding delay to reduce the completiontime below its currently best known solution in persistent erasure channels. Wefirst derive the decoding-delay-dependent expressions of the users' and overallcompletion times. Although using such expressions to find the optimal overallcompletion time is NP-hard, we design two novel heuristics that minimizes theprobability of increasing the maximum of these decoding-delay-dependentcompletion time expressions after each transmission through a layered controlof their decoding delays. We, then, extend our study to the limited feedbackscenario. Simulation results show that our new algorithms achieves both a lowermean completion time and mean decoding delay compared to the best knownheuristic for completion time reduction. The gap in performance becomessignificant for harsh erasure scenarios.",Ahmed Douik,2014/4/14,2014/4/14
1705.05564v4,Invariance: a Theoretical Approach for Coding Sets of Words Modulo Literal (Anti)Morphisms,http://arxiv.org/abs/1705.05564v4,"Let $A$ be a finite or countable alphabet and let $\theta$ be literal(anti)morphism onto $A^*$ (by definition, such a correspondence is determinatedby a permutation of the alphabet). This paper deals with sets which areinvariant under $\theta$ ($\theta$-invariant for short).We establish anextension of the famous defect theorem. Moreover, we prove that for theso-called thin $\theta$-invariant codes, maximality and completeness are twoequivalent notions. We prove that a similar property holds in the framework ofsome special families of $\theta$-invariant codes such as prefix (bifix) codes,codes with a finite deciphering delay, uniformly synchronized codes andcircular codes. For a special class of involutive antimorphisms, we prove thatany regular $\theta$-invariant code may be embedded into a complete one.",Jean Nraud,2017/5/16,2017/7/27
1806.10514v1,$2$-Neighbour-Transitive Codes with Small Blocks of Imprimitivity,http://arxiv.org/abs/1806.10514v1,"A code $C$ in the Hamming graph $\varGamma=H(m,q)$ is$2\it{\text{-neighbour-transitive}}$ if ${\rm Aut}(C)$ acts transitively oneach of $C=C_0$, $C_1$ and $C_2$, the first three parts of the distancepartition of $V\varGamma$ with respect to $C$. Previous classifications offamilies of $2$-neighbour-transitive codes leave only those with an affineaction on the alphabet to be investigated. Here, $2$-neighbour-transitive codeswith minimum distance at least $5$ and that contain ""small"" subcodes as blocksof imprimitivity are classified. When considering codes with minimum distanceat least $5$, completely transitive codes are a proper subclass of$2$-neighbour-transitive codes. Thus, as a corollary of the main result,completely transitive codes satisfying the above conditions are alsoclassified.",Neil I. Gillespie,2018/6/27,2018/6/27
1405.5427v1,Characterisation of a family of neighbour transitive codes,http://arxiv.org/abs/1405.5427v1,"We consider codes of length $m$ over an alphabet of size $q$ as subsets ofthe vertex set of the Hamming graph $\Gamma=H(m,q)$. A code for which thereexists an automorphism group $X\leq Aut(\Gamma)$ that acts transitively on thecode and on its set of neighbours is said to be neighbour transitive, and wereintroduced by the authors as a group theoretic analogue to the assumption thatsingle errors are equally likely over a noisy channel. Examples of neighbourtransitive codes include the Hamming codes, various Golay codes, certainHadamard codes, the Nordstrom Robinson codes, certain permutation codes andfrequency permutation arrays, which have connections with powerlinecommunication, and also completely transitive codes, a subfamily of completelyregular codes, which themselves have attracted a lot of interest. It is knownthat for any neighbour transitive code with minimum distance at least 3 thereexists a subgroup of $X$ that has a $2$-transitive action on the alphabet overwhich the code is defined. Therefore, by Burnside's theorem, this action is ofalmost simple or affine type. If the action is of almost simple type, we saythe code is alphabet almost simple neighbour transitive. In this paper wecharacterise a family of neighbour transitive codes, in particular, thealphabet almost simple neighbour transitive codes with minimum distance atleast $3$, and for which the group $X$ has a non-trivial intersection with thebase group of $Aut(\Gamma)$. If $C$ is such a code, we show that, up toequivalence, there exists a subcode $\Delta$ that can be completely described,and that either $C=\Delta$, or $\Delta$ is a neighbour transitive frequencypermutation array and $C$ is the disjoint union of $X$-translates of $\Delta$.  We also prove that any finite group can be identified in a natural way with aneighbour transitive code.",Neil I. Gillespie,2014/5/21,2014/5/21
physics/0509243v1,Characteristic Length Scale of Electric Transport Properties of Genomes,http://arxiv.org/abs/physics/0509243v1,"A tight-binding model together with a novel statistical method are used toinvestigate the relation between the sequence-dependent electric transportproperties and the sequences of protein-coding regions of complete genomes. Acorrelation parameter $\Omega$ is defined to analyze the relation. For someparticular propagation length $w_{max}$, the transport behaviors of the codingand non-coding sequences are very different and the correlation reaches itsmaximal value $\Omega_{max}$. $w_{max}$ and \omax are characteristic values foreach species. The possible reason of the difference between the features oftransport properties in the coding and non-coding regions is the mechanism ofDNA damage repair processes together with the natural selection.",C. T. Shih,2005/9/29,2005/9/29
1905.01567v1,Vector Generation of Quantum Contextual Sets in Even Dimensional Hilbert Spaces,http://arxiv.org/abs/1905.01567v1,"Recently, quantum contextuality has been proved to be the source of quantumcomputation's power. That, together with multiple recent contextualexperiments, prompts improving the methods of generation of contextual sets andfinding their features. The most elaborated contextual sets, which offerblueprints for contextual experiments and computational gates, are theKochen--Specker (KS) sets. In this paper, we show a method of vector generationthat supersedes previous methods. It is implemented by means of algorithms andprograms that generate hypergraphs embodying the Kochen-Specker property andthat are designed to be carried out on supercomputers. We show that vectorcomponent generation of KS hypergraphs exhausts all possible vectors that canbe constructed from chosen vector components, in contrast to previous studiesthat used incomplete lists of vectors and therefore missed a majority ofhypergraphs. Consequently, this unified method is far more efficient forgenerations of KS sets and their implementation in quantum computation andquantum communication. Several new KS classes and their features have beenfound and are elaborated on in the paper. Greechie diagrams are discussed. Adetailed and complete blueprint of a particular 21-11 KS set with a complexcoordinatization is presented in Appendix A, in contrast to the one from thepublished version of this paper where only a few of its states were given.",Mladen Pavicic,2019/5/4,2019/5/4
2304.12269v1,Enriching Source Code with Contextual Data for Code Completion Models: An Empirical Study,http://arxiv.org/abs/2304.12269v1,"Transformer-based pre-trained models have recently achieved great results insolving many software engineering tasks including automatic code completionwhich is a staple in a developer's toolkit. While many have striven to improvethe code-understanding abilities of such models, the opposite -- making thecode easier to understand -- has not been properly investigated. In this study,we aim to answer whether making code easier to understand through usingcontextual data improves the performance of pre-trained code language modelsfor the task of code completion. We consider type annotations and comments astwo common forms of additional contextual information that often helpdevelopers understand code better. For the experiments, we study codecompletion in two granularity levels; token and line completion and take threerecent and large-scale language models for source code: UniXcoder, CodeGPT, andInCoder with five evaluation metrics. Finally, we perform the Wilcoxon SignedRank test to gauge significance and measure the effect size. Contrary to ourexpectations, all models perform better if type annotations are removed (albeitthe effect sizes are small). For comments, we find that the models performbetter in the presence of multi-line comments (again with small effect sizes).Based on our observations, we recommend making proper design choices whentraining, fine-tuning, or simply selecting such models given the intended dataand application. Better evaluations and multi-modal techniques can also befurther investigated to improve the practicality and accuracy ofauto-completions.",Tim van Dam,2023/4/24,2023/4/24
2211.01874v2,Contextual information integration for stance detection via cross-attention,http://arxiv.org/abs/2211.01874v2,"Stance detection deals with identifying an author's stance towards a target.Most existing stance detection models are limited because they do not considerrelevant contextual information which allows for inferring the stancecorrectly. Complementary context can be found in knowledge bases butintegrating the context into pretrained language models is non-trivial due tothe graph structure of standard knowledge bases. To overcome this, we explorean approach to integrate contextual information as text which allows forintegrating contextual information from heterogeneous sources, such asstructured knowledge sources and by prompting large language models. Ourapproach can outperform competitive baselines on a large and diverse stancedetection benchmark in a cross-target setup, i.e. for targets unseen duringtraining. We demonstrate that it is more robust to noisy context and canregularize for unwanted correlations between labels and target-specificvocabulary. Finally, it is independent of the pretrained language model in use.",Tilman Beck,2022/11/3,2023/5/25
2304.06385v5,TransHP: Image Classification with Hierarchical Prompting,http://arxiv.org/abs/2304.06385v5,"This paper explores a hierarchical prompting mechanism for the hierarchicalimage classification (HIC) task. Different from prior HIC methods, ourhierarchical prompting is the first to explicitly inject ancestor-classinformation as a tokenized hint that benefits the descendant-classdiscrimination. We think it well imitates human visual recognition, i.e.,humans may use the ancestor class as a prompt to draw focus on the subtledifferences among descendant classes. We model this prompting mechanism into aTransformer with Hierarchical Prompting (TransHP). TransHP consists of threesteps: 1) learning a set of prompt tokens to represent the coarse (ancestor)classes, 2) on-the-fly predicting the coarse class of the input image at anintermediate block, and 3) injecting the prompt token of the predicted coarseclass into the intermediate feature. Though the parameters of TransHP maintainthe same for all input images, the injected coarse-class prompt conditions(modifies) the subsequent feature extraction and encourages a dynamic focus onrelatively subtle differences among the descendant classes. Extensiveexperiments show that TransHP improves image classification on accuracy (e.g.,improving ViT-B/16 by +2.83% ImageNet classification accuracy), training dataefficiency (e.g., +12.69% improvement under 10% ImageNet training data), andmodel explainability. Moreover, TransHP also performs favorably against priorHIC methods, showing that TransHP well exploits the hierarchical information.The code is available at: https://github.com/WangWenhao0716/TransHP.",Wenhao Wang,2023/4/13,2023/12/20
2310.01469v2,"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples",http://arxiv.org/abs/2310.01469v2,"Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to beknowledgeable and able to adapt to many tasks. However, we still can notcompletely trust their answer, since LLMs suffer fromhallucination--fabricating non-existent facts to cheat users withoutperception. And the reasons for their existence and pervasiveness remainunclear. In this paper, we demonstrate that non-sense prompts composed ofrandom tokens can also elicit the LLMs to respond with hallucinations. Thisphenomenon forces us to revisit that hallucination may be another view ofadversarial examples, and it shares similar features with conventionaladversarial examples as the basic feature of LLMs. Therefore, we formalize anautomatic hallucination triggering method as the hallucination attack in anadversarial way. Finally, we explore basic feature of attacked adversarialprompts and propose a simple yet effective defense strategy. Our code isreleased on GitHub.",Jia-Yu Yao,2023/10/2,2023/10/4
2307.15008v1,A LLM Assisted Exploitation of AI-Guardian,http://arxiv.org/abs/2307.15008v1,"Large language models (LLMs) are now highly capable at a diverse range oftasks. This paper studies whether or not GPT-4, one such LLM, is capable ofassisting researchers in the field of adversarial machine learning. As a casestudy, we evaluate the robustness of AI-Guardian, a recent defense toadversarial examples published at IEEE S&P 2023, a top computer securityconference. We completely break this defense: the proposed scheme does notincrease robustness compared to an undefended baseline.  We write none of the code to attack this model, and instead prompt GPT-4 toimplement all attack algorithms following our instructions and guidance. Thisprocess was surprisingly effective and efficient, with the language model attimes producing code from ambiguous instructions faster than the author of thispaper could have done. We conclude by discussing (1) the warning signs presentin the evaluation that suggested to us AI-Guardian would be broken, and (2) ourexperience with designing attacks and performing novel research using the mostrecent advances in language modeling.",Nicholas Carlini,2023/7/20,2023/7/20
2310.13345v1,An LLM can Fool Itself: A Prompt-Based Adversarial Attack,http://arxiv.org/abs/2310.13345v1,"The wide-ranging applications of large language models (LLMs), especially insafety-critical domains, necessitate the proper evaluation of the LLM'sadversarial robustness. This paper proposes an efficient tool to audit theLLM's adversarial robustness via a prompt-based adversarial attack(PromptAttack). PromptAttack converts adversarial textual attacks into anattack prompt that can cause the victim LLM to output the adversarial sample tofool itself. The attack prompt is composed of three important components: (1)original input (OI) including the original sample and its ground-truth label,(2) attack objective (AO) illustrating a task description of generating a newsample that can fool itself without changing the semantic meaning, and (3)attack guidance (AG) containing the perturbation instructions to guide the LLMon how to complete the task by perturbing the original sample at character,word, and sentence levels, respectively. Besides, we use a fidelity filter toensure that PromptAttack maintains the original semantic meanings of theadversarial examples. Further, we enhance the attack power of PromptAttack byensembling adversarial examples at different perturbation levels. Comprehensiveempirical results using Llama2 and GPT-3.5 validate that PromptAttackconsistently yields a much higher attack success rate compared to AdvGLUE andAdvGLUE++. Interesting findings include that a simple emoji can easily misleadGPT-3.5 to make wrong predictions.",Xilie Xu,2023/10/20,2023/10/20
2203.17274v2,Exploring Visual Prompts for Adapting Large-Scale Models,http://arxiv.org/abs/2203.17274v2,"We investigate the efficacy of visual prompting to adapt large-scale modelsin vision. Following the recent approach from prompt tuning and adversarialreprogramming, we learn a single image perturbation such that a frozen modelprompted with this perturbation performs a new task. Through comprehensiveexperiments, we demonstrate that visual prompting is particularly effective forCLIP and robust to distribution shift, achieving performance competitive withstandard linear probes. We further analyze properties of the downstreamdataset, prompt design, and output transformation in regard to adaptationperformance. The surprising effectiveness of visual prompting provides a newperspective on adapting pre-trained models in vision. Code is available athttp://hjbahng.github.io/visual_prompting .",Hyojin Bahng,2022/3/31,2022/6/3
2310.14158v1,Visual-Attribute Prompt Learning for Progressive Mild Cognitive Impairment Prediction,http://arxiv.org/abs/2310.14158v1,"Deep learning (DL) has been used in the automatic diagnosis of Mild CognitiveImpairment (MCI) and Alzheimer's Disease (AD) with brain imaging data. However,previous methods have not fully exploited the relation between brain image andclinical information that is widely adopted by experts in practice. To exploitthe heterogeneous features from imaging and tabular data simultaneously, wepropose the Visual-Attribute Prompt Learning-based Transformer (VAP-Former), atransformer-based network that efficiently extracts and fuses the multi-modalfeatures with prompt fine-tuning. Furthermore, we propose a Prompt fine-Tuning(PT) scheme to transfer the knowledge from AD prediction task for progressiveMCI (pMCI) diagnosis. In details, we first pre-train the VAP-Former withoutprompts on the AD diagnosis task and then fine-tune the model on the pMCIdetection task with PT, which only needs to optimize a small amount ofparameters while keeping the backbone frozen. Next, we propose a novel globalprompt token for the visual prompts to provide global guidance to themulti-modal representations. Extensive experiments not only show thesuperiority of our method compared with the state-of-the-art methods in pMCIprediction but also demonstrate that the global prompt can make the promptlearning process more effective and stable. Interestingly, the proposed promptlearning model even outperforms the fully fine-tuning baseline on transferringthe knowledge from AD to pMCI.",Luoyao Kang,2023/10/22,2023/10/22
2205.11961v2,ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts,http://arxiv.org/abs/2205.11961v2,"This work introduces a new multi-task, parameter-efficient language model(LM) tuning method that learns to transfer knowledge across different tasks viaa mixture of soft prompts-small prefix embedding vectors pre-trained fordifferent tasks. Our method, called ATTEMPT (ATTEntional Mixtures of PromptTuning), obtains source prompts as encodings of large-scale source tasks into asmall number of parameters and trains an attention module to interpolate thesource prompts and a newly initialized target prompt for every instance in thetarget task. During training, only the target task prompt and the attentionweights, which are shared between tasks in multi-task training, are updated,while the original LM and source prompts are intact. ATTEMPT is highlyparameter-efficient (e.g., updates 2,300 times fewer parameters than fullfine-tuning) while achieving high task performance using knowledge fromhigh-resource tasks. Moreover, it is modular using pre-trained soft prompts,and can flexibly add or remove source prompts for effective knowledge transfer.Our experimental results across 21 diverse NLP datasets show that ATTEMPTsignificantly outperforms prompt tuning and outperforms or matches fullyfine-tuned or other parameter-efficient tuning approaches that use over tentimes more parameters. Finally, ATTEMPT outperforms previous work in few-shotlearning settings.",Akari Asai,2022/5/24,2022/12/1
2209.14500v2,Bidirectional Language Models Are Also Few-shot Learners,http://arxiv.org/abs/2209.14500v2,"Large language models such as GPT-3 (Brown et al., 2020) can performarbitrary tasks without undergoing fine-tuning after being prompted with only afew labeled examples. An arbitrary task can be reformulated as a naturallanguage prompt, and a language model can be asked to generate the completion,indirectly performing the task in a paradigm known as prompt-based learning. Todate, emergent prompt-based learning capabilities have mainly been demonstratedfor unidirectional language models. However, bidirectional language modelspre-trained on denoising objectives such as masked language modeling producestronger learned representations for transfer learning. This motivates thepossibility of prompting bidirectional models, but their pre-trainingobjectives have made them largely incompatible with the existing promptingparadigm. We present SAP (Sequential Autoregressive Prompting), a techniquethat enables the prompting of bidirectional models. Utilizing the machinetranslation task as a case study, we prompt the bidirectional mT5 model (Xue etal., 2021) with SAP and demonstrate its few-shot and zero-shot translationsoutperform the few-shot translations of unidirectional models like GPT-3 andXGLM (Lin et al., 2021), despite mT5's approximately 50% fewer parameters. Wefurther show SAP is effective on question answering and summarization. For thefirst time, our results demonstrate prompt-based learning is an emergentproperty of a broader class of language models, rather than only unidirectionalmodels.",Ajay Patel,2022/9/29,2023/2/6
2310.19424v1,Variational Curriculum Reinforcement Learning for Unsupervised Discovery of Skills,http://arxiv.org/abs/2310.19424v1,"Mutual information-based reinforcement learning (RL) has been proposed as apromising framework for retrieving complex skills autonomously without atask-oriented reward function through mutual information (MI) maximization orvariational empowerment. However, learning complex skills is still challenging,due to the fact that the order of training skills can largely affect sampleefficiency. Inspired by this, we recast variational empowerment as curriculumlearning in goal-conditioned RL with an intrinsic reward function, which wename Variational Curriculum RL (VCRL). From this perspective, we propose anovel approach to unsupervised skill discovery based on information theory,called Value Uncertainty Variational Curriculum (VUVC). We prove that, underregularity conditions, VUVC accelerates the increase of entropy in the visitedstates compared to the uniform curriculum. We validate the effectiveness of ourapproach on complex navigation and robotic manipulation tasks in terms ofsample efficiency and state coverage speed. We also demonstrate that the skillsdiscovered by our method successfully complete a real-world robot navigationtask in a zero-shot setup and that incorporating these skills with a globalplanner further increases the performance.",Seongun Kim,2023/10/30,2023/10/30
1712.05055v2,MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,http://arxiv.org/abs/1712.05055v2,"Recent deep networks are capable of memorizing the entire data even when thelabels are completely random. To overcome the overfitting on corrupted labels,we propose a novel technique of learning another neural network, calledMentorNet, to supervise the training of the base deep networks, namely,StudentNet. During training, MentorNet provides a curriculum (sample weightingscheme) for StudentNet to focus on the sample the label of which is probablycorrect. Unlike the existing curriculum that is usually predefined by humanexperts, MentorNet learns a data-driven curriculum dynamically with StudentNet.Experimental results demonstrate that our approach can significantly improvethe generalization performance of deep networks trained on corrupted trainingdata. Notably, to the best of our knowledge, we achieve the best-publishedresult on WebVision, a large benchmark containing 2.2 million images ofreal-world noisy labels. The code are at https://github.com/google/mentornet",Lu Jiang,2017/12/14,2018/8/13
2103.00147v2,Statistical Measures For Defining Curriculum Scoring Function,http://arxiv.org/abs/2103.00147v2,"Curriculum learning is a training strategy that sorts the training examplesby some measure of their difficulty and gradually exposes them to the learnerto improve the network performance. Motivated by our insights from implicitcurriculum ordering, we first introduce a simple curriculum learning strategythat uses statistical measures such as standard deviation and entropy values toscore the difficulty of data points for real image classification tasks. Weempirically show its improvements in performance with convolutional andfully-connected neural networks on multiple real image datasets. We alsopropose and study the performance of a dynamic curriculum learning algorithm.Our dynamic curriculum algorithm tries to reduce the distance between thenetwork weight and an optimal weight at any training step by greedily samplingexamples with gradients that are directed towards the optimal weight. Further,we use our algorithms to discuss why curriculum learning is helpful.",Vinu Sankar Sadasivan,2021/2/27,2021/7/27
1910.07224v1,Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments,http://arxiv.org/abs/1910.07224v1,"We consider the problem of how a teacher algorithm can enable an unknown DeepReinforcement Learning (DRL) student to become good at a skill over a widerange of diverse environments. To do so, we study how a teacher algorithm canlearn to generate a learning curriculum, whereby it sequentially samplesparameters controlling a stochastic procedural generation of environments.Because it does not initially know the capacities of its student, a keychallenge for the teacher is to discover which environments are easy, difficultor unlearnable, and in what order to propose them to maximize the efficiency oflearning over the learnable ones. To achieve this, this problem is transformedinto a surrogate continuous bandit problem where the teacher samplesenvironments in order to maximize absolute learning progress of its student. Wepresent a new algorithm modeling absolute learning progress with Gaussianmixture models (ALP-GMM). We also adapt existing algorithms and provide acomplete study in the context of DRL. Using parameterized variants of theBipedalWalker environment, we study their efficiency to personalize a learningcurriculum for different learners (embodiments), their robustness to the ratioof learnable/unlearnable environments, and their scalability to non-linear andhigh-dimensional parameter spaces. Videos and code are available athttps://github.com/flowersteam/teachDeepRL.",Rmy Portelas,2019/10/16,2019/10/16
2210.12607v1,Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models,http://arxiv.org/abs/2210.12607v1,"How to usefully encode compositional task structure has long been a corechallenge in AI. Recent work in chain of thought prompting has shown that forvery large neural language models (LMs), explicitly demonstrating theinferential steps involved in a target task may improve performance overend-to-end learning that focuses on the target task alone. However, chain ofthought prompting has significant limitations due to its dependency on hugepretrained LMs. In this work, we present compositional fine-tuning (CFT): anapproach based on explicitly decomposing a target task into component tasks,and then fine-tuning smaller LMs on a curriculum of such component tasks. Weapply CFT to recommendation tasks in two domains, world travel and localdining, as well as a previously studied inferential task (sportsunderstanding). We show that CFT outperforms end-to-end learning even withequal amounts of data, and gets consistently better as more component tasks aremodeled via fine-tuning. Compared with chain of thought prompting, CFT performsat least as well using LMs only 7.4% of the size, and is moreover applicable totask domains for which data are not available during pretraining.",Victor S. Bursztyn,2022/10/23,2022/10/23
2305.18444v2,Continual Task Allocation in Meta-Policy Network via Sparse Prompting,http://arxiv.org/abs/2305.18444v2,"How to train a generalizable meta-policy by continually learning a sequenceof tasks? It is a natural human skill yet challenging to achieve by currentreinforcement learning: the agent is expected to quickly adapt to new tasks(plasticity) meanwhile retaining the common knowledge from previous tasks(stability). We address it by ""Continual Task Allocation via Sparse Prompting(CoTASP)"", which learns over-complete dictionaries to produce sparse masks asprompts extracting a sub-network for each task from a meta-policy network.CoTASP trains a policy for each task by optimizing the prompts and thesub-network weights alternatively. The dictionary is then updated to align theoptimized prompts with tasks' embedding, thereby capturing tasks' semanticcorrelations. Hence, relevant tasks share more neurons in the meta-policynetwork due to similar prompts while cross-task interference causing forgettingis effectively restrained. Given a meta-policy and dictionaries trained onprevious tasks, new task adaptation reduces to highly efficient sparseprompting and sub-network finetuning. In experiments, CoTASP achieves apromising plasticity-stability trade-off without storing or replaying any pasttasks' experiences. It outperforms existing continual and multi-task RL methodson all seen tasks, forgetting reduction, and generalization to unseen tasks.",Yijun Yang,2023/5/29,2023/6/3
2103.00187v2,Multi-agent Reinforcement Learning in OpenSpiel: A Reproduction Report,http://arxiv.org/abs/2103.00187v2,"In this report, we present results reproductions for several core algorithmsimplemented in the OpenSpiel framework for learning in games. The primarycontribution of this work is a validation of OpenSpiel's re-implemented searchand Reinforcement Learning algorithms against the results reported in theirrespective originating works. Additionally, we provide complete documentationof hyperparameters and source code required to reproduce these experimentseasily and exactly.",Michael Walton,2021/2/27,2021/3/2
2301.06845v1,Causal Models with Constraints,http://arxiv.org/abs/2301.06845v1,"Causal models have proven extremely useful in offering formal representationsof causal relationships between a set of variables. Yet in many situations,there are non-causal relationships among variables. For example, we may wantvariables $LDL$, $HDL$, and $TOT$ that represent the level of low-densitylipoprotein cholesterol, the level of lipoprotein high-density lipoproteincholesterol, and total cholesterol level, with the relation $LDL+HDL=TOT$. Thiscannot be done in standard causal models, because we can intervenesimultaneously on all three variables. The goal of this paper is to extendstandard causal models to allow for constraints on settings of variables.Although the extension is relatively straightforward, to make it useful we haveto define a new intervention operation that $disconnects$ a variable from acausal equation. We give examples showing the usefulness of this extension, andprovide a sound and complete axiomatization for causal models with constraints.",Sander Beckers,2023/1/17,2023/1/17
1911.02800v1,A note on totally-omnitonal graphs,http://arxiv.org/abs/1911.02800v1,"Let the edges of the complete graph $K_n$ be coloured red or blue, and let$G$ be a graph with $|V(G)| < n$. Then ot(n,G) is defined to be the minimuminteger, if it exists, such that any such colouring of $K_n$ contains a copy of$G$ with $r$ red edges and $b$ blue edges for any $r,b \geq 0$ with $r+b=e(G)$. If ot(n,G) exists for every sufficiently large $n$, we say that $G$ is\emph{omnitonal}. Omnitonal graphs were introduced by Caro, Hansberg andMontejano [arXiv:1810.12375,2019]. Now let $G_1$, $G_2$ be two copies of $G$with their edges coloured red or blue. If there is a colour-preservingisomorphism from $G_1$ to $G_2$ we say that the 2-colourings of $G$ areequivalent. Now we define tot(n,G) to be the minimum integer, if it exists,such that any such colouring of $K_n$ contains all non-quivalent colourings of$G$ with $r$ red edges and $b$ blue edges for any $r,b \geq 0$ with $r+b=e(G)$. If tot(n, G) exists for every sufficiently large $n$, we say that G is\emph{totally-omnitotal}.  In this note we show that the only totally-omnitonal graphs are stars or starforests namely a forest all of whose components are stars.",Yair Caro,2019/11/7,2019/11/7
1910.08916v1,PT-CoDE: Pre-trained Context-Dependent Encoder for Utterance-level Emotion Recognition,http://arxiv.org/abs/1910.08916v1,"Utterance-level emotion recognition (ULER) is a significant research topicfor understanding human behaviors and developing empathetic chatting machinesin the artificial intelligence area. Unlike traditional text classificationproblem, this task is supported by a limited number of datasets, among whichmost contain inadequate conversations or speeches. Such a data scarcity issuelimits the possibility of training larger and more powerful models for thistask. Witnessing the success of transfer learning in natural language process(NLP), we propose to pre-train a context-dependent encoder (CoDE) for ULER bylearning from unlabeled conversation data. Essentially, CoDE is a hierarchicalarchitecture that contains an utterance encoder and a conversation encoder,making it different from those works that aim to pre-train a universal sentenceencoder. Also, we propose a new pre-training task named ""conversationcompletion"" (CoCo), which attempts to select the correct answer from candidateanswers to fill a masked utterance in a question conversation. The CoCo task iscarried out on pure movie subtitles so that our CoDE can be pre-trained in anunsupervised fashion. Finally, the pre-trained CoDE (PT-CoDE) is fine-tuned forULER and boosts the model performance significantly on five datasets.",Wenxiang Jiao,2019/10/20,2019/10/20
2311.04498v4,"NExT-Chat: An LMM for Chat, Detection and Segmentation",http://arxiv.org/abs/2311.04498v4,"The development of large language models (LLMs) has greatly advanced thefield of multimodal understanding, leading to the emergence of large multimodalmodels (LMMs). In order to enhance the level of visual comprehension, recentstudies have equipped LMMs with region-level understanding capabilities byrepresenting object bounding box coordinates as a series of text sequences(pix2seq). In this paper, we introduce a novel paradigm for object locationmodeling called pix2emb method, where we ask the LMM to output the locationembeddings and then decode them with different decoders. This paradigm allowsus to use different location formats (such as bounding boxes and masks) inmultimodal conversations. Leveraging the proposed pix2emb method, we train anLMM named NExT-Chat and demonstrate its capability of handling multiple taskslike visual grounding, region captioning, and grounded reasoning. Comprehensiveexperiments show the effectiveness of our NExT-Chat on various tasks, e.g.,NExT-Chat (87.7) vs. Shikra (86.9) on POPE-Random, NExT-Chat (68.9) vs. LISA(67.9) on referring expression segmentation task, and NExT-Chat (79.6) vs.Kosmos-2 (62.3) on region caption task. The code and model are released athttps://github.com/NExT-ChatV/NExT-Chat.",Ao Zhang,2023/11/8,2023/12/18
2305.14471v1,CGCE: A Chinese Generative Chat Evaluation Benchmark for General and Financial Domains,http://arxiv.org/abs/2305.14471v1,"Generative chat models, such as ChatGPT and GPT-4, have revolutionizednatural language generation (NLG) by incorporating instructions and humanfeedback to achieve significant performance improvements. However, the lack ofstandardized evaluation benchmarks for chat models, particularly for Chineseand domain-specific models, hinders their assessment and progress. To addressthis gap, we introduce the Chinese Generative Chat Evaluation (CGCE) benchmark,focusing on general and financial domains. The CGCE benchmark encompassesdiverse tasks, including 200 questions in the general domain and 150 specificprofessional questions in the financial domain. Manual scoring evaluatesfactors such as accuracy, coherence, expression clarity, and completeness. TheCGCE benchmark provides researchers with a standardized framework to assess andcompare Chinese generative chat models, fostering advancements in NLG research.",Xuanyu Zhang,2023/5/23,2023/5/23
1210.8400v1,Distributed Quantization Networks,http://arxiv.org/abs/1210.8400v1,"Several key results in distributed source coding offer the intuition thatlittle improvement in compression can be gained from intersensor communicationwhen the information is coded in long blocks. However, when sensors arerestricted to code their observations in small blocks (e.g., 1), intelligentcollaboration between sensors can greatly reduce distortion. For networks wheresensors are allowed to ""chat"" using a side channel that is unobservable at thefusion center, we provide asymptotically-exact characterization of distortionperformance and optimal quantizer design in the high-resolution(low-distortion) regime using a framework called distributed functional scalarquantization (DFSQ). The key result is that chatting can dramatically improveperformance even when intersensor communication is at very low rate, especiallyif the fusion center desires fidelity of a nonlinear computation applied tosource realizations rather than fidelity in representing the sourcesthemselves. We also solve the rate allocation problem when communication linkshave heterogeneous costs and provide a detailed example to demonstrate thetheoretical and practical gains from chatting. This example for maximumcomputation gives insight on the gap between chatting and distributed networks,and how to optimize the intersensor communication.",John Z. Sun,2012/10/31,2012/10/31
2305.06355v2,VideoChat: Chat-Centric Video Understanding,http://arxiv.org/abs/2305.06355v2,"In this paper, we initiate an attempt of developing an end-to-endchat-centric video understanding system, coined as VideoChat. It integratesvideo foundation models and large language models via a learnable neuralinterface, excelling in spatiotemporal reasoning, event localization, andcausal relationship inference. To instructively tune this system, we build avideo-centric instruction dataset, composed of thousands of videos associatedwith detailed descriptions and conversations. This dataset emphasizesspatiotemporal reasoning and captures causal relationships, providing avaluable asset for training our chat-centric video understanding system.Preliminary qualitative experiments demonstrate the potential of our systemacross a broad spectrum of video applications, which could serve as a simpleprototype system for future research on chat-centric video understanding.Access our code and data at https://github.com/OpenGVLab/Ask-Anything",KunChang Li,2023/5/10,2024/1/4
2310.06830v1,Lemur: Harmonizing Natural Language and Code for Language Agents,http://arxiv.org/abs/2310.06830v1,"We introduce Lemur and Lemur-Chat, openly accessible language modelsoptimized for both natural language and coding capabilities to serve as thebackbone of versatile language agents. The evolution from language chat modelsto functional language agents demands that models not only master humaninteraction, reasoning, and planning but also ensure grounding in the relevantenvironments. This calls for a harmonious blend of language and codingcapabilities in the models. Lemur and Lemur-Chat are proposed to address thisnecessity, demonstrating balanced proficiencies in both domains, unlikeexisting open-source models that tend to specialize in either. Throughmeticulous pre-training using a code-intensive corpus and instructionfine-tuning on text and code data, our models achieve state-of-the-art averagedperformance across diverse text and coding benchmarks among open-source models.Comprehensive experiments demonstrate Lemur's superiority over existingopen-source models and its proficiency across various agent tasks involvinghuman communication, tool usage, and interaction under fully- and partially-observable environments. The harmonization between natural and programminglanguages enables Lemur-Chat to significantly narrow the gap with proprietarymodels on agent abilities, providing key insights into developing advancedopen-source agents adept at reasoning, planning, and operating seamlesslyacross environments. https://github.com/OpenLemur/Lemur",Yiheng Xu,2023/10/10,2023/10/10
2310.17680v3,CodeFusion: A Pre-trained Diffusion Model for Code Generation,http://arxiv.org/abs/2310.17680v3,"Imagine a developer who can only change their last line of code, how oftenwould they have to start writing a function from scratch before it is correct?Auto-regressive models for code generation from natural language have a similarlimitation: they do not easily allow reconsidering earlier tokens generated. Weintroduce CodeFusion, a pre-trained diffusion code generation model thataddresses this limitation by iteratively denoising a complete programconditioned on the encoded natural language. We evaluate CodeFusion on the taskof natural language to code generation for Bash, Python, and Microsoft Excelconditional formatting (CF) rules. Experiments show that CodeFusion (75Mparameters) performs on par with state-of-the-art auto-regressive systems(350M-175B parameters) in top-1 accuracy and outperforms them in top-3 andtop-5 accuracy due to its better balance in diversity versus quality.",Mukul Singh,2023/10/26,2023/11/1
2310.04484v2,Ada-Instruct: Adapting Instruction Generators for Complex Reasoning,http://arxiv.org/abs/2310.04484v2,"Generating diverse and sophisticated instructions for downstream tasks byLarge Language Models (LLMs) is pivotal for advancing the effect. Currentapproaches leverage closed-source LLMs, employing in-context prompting forinstruction generation. However, in this paper, we found that in-contextprompting cannot generate complex instructions with length $\ge 100$ for taskslike code completion.  To solve this problem, we introduce Ada-Instruct, an adaptive instructiongenerator developed by fine-tuning open-source LLMs. Our pivotal findingillustrates that fine-tuning open-source LLMs with a mere ten samples generateslong instructions that maintain distributional consistency for complexreasoning tasks. We empirically validated Ada-Instruct's efficacy acrossdifferent applications, including code completion, mathematical reasoning, andcommonsense reasoning. The results underscore Ada-Instruct's superiority,evidencing its improvements over its base models, current self-instructmethods, and other state-of-the-art models.",Wanyun Cui,2023/10/6,2023/10/10
2307.08487v3,Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models,http://arxiv.org/abs/2307.08487v3,"Considerable research efforts have been devoted to ensuring that largelanguage models (LLMs) align with human values and generate safe text. However,an excessive focus on sensitivity to certain topics can compromise the model'srobustness in following instructions, thereby impacting its overall performancein completing tasks. Previous benchmarks for jailbreaking LLMs have primarilyfocused on evaluating the safety of the models without considering theirrobustness. In this paper, we propose a benchmark that assesses both the safetyand robustness of LLMs, emphasizing the need for a balanced approach. Tocomprehensively study text safety and output robustness, we introduce a latentjailbreak prompt dataset, each involving malicious instruction embedding.Specifically, we instruct the model to complete a regular task, such astranslation, with the text to be translated containing malicious instructions.To further analyze safety and robustness, we design a hierarchical annotationframework. We present a systematic analysis of the safety and robustness ofLLMs regarding the position of explicit normal instructions, word replacements(verbs in explicit normal instructions, target groups in maliciousinstructions, cue words for explicit normal instructions), and instructionreplacements (different explicit normal instructions). Our results demonstratethat current LLMs not only prioritize certain instruction verbs but alsoexhibit varying jailbreak rates for different instruction verbs in explicitnormal instructions. Code and data are available athttps://github.com/qiuhuachuan/latent-jailbreak.",Huachuan Qiu,2023/7/17,2023/8/28
2309.07544v2,VerilogEval: Evaluating Large Language Models for Verilog Code Generation,http://arxiv.org/abs/2309.07544v2,"The increasing popularity of large language models (LLMs) has paved the wayfor their application in diverse domains. This paper proposes a benchmarkingframework tailored specifically for evaluating LLM performance in the contextof Verilog code generation for hardware design and verification. We present acomprehensive evaluation dataset consisting of 156 problems from the Veriloginstructional website HDLBits. The evaluation set consists of a diverse set ofVerilog code generation tasks, ranging from simple combinational circuits tocomplex finite state machines. The Verilog code completions can beautomatically tested for functional correctness by comparing the transientsimulation outputs of the generated design with a golden solution. We alsodemonstrate that the Verilog code generation capability of pretrained languagemodels could be improved with supervised fine-tuning by bootstrapping with LLMgenerated synthetic problem-code pairs.",Mingjie Liu,2023/9/14,2023/12/10
2309.00608v3,Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair,http://arxiv.org/abs/2309.00608v3,"During Automated Program Repair (APR), it can be challenging to synthesizecorrect patches for real-world systems in general-purpose programminglanguages. Recent Large Language Models (LLMs) have been shown to be helpful""copilots"" in assisting developers with various coding tasks, and have alsobeen directly applied for patch synthesis. However, most LLMs treat programs assequences of tokens, meaning that they are ignorant of the underlying semanticsconstraints of the target programming language. This results in plenty ofstatically invalid generated patches, impeding the practicality of thetechnique. Therefore, we propose Repilot, a general code generation frameworkto further copilot the AI ""copilots"" (i.e., LLMs) by synthesizing more validpatches during the repair process. Our key insight is that many LLMs produceoutputs autoregressively (i.e., token by token), resembling human writingprograms, which can be significantly boosted and guided through a CompletionEngine. Repilot synergistically synthesizes a candidate patch through theinteraction between an LLM and a Completion Engine, which 1) prunes awayinfeasible tokens suggested by the LLM and 2) proactively completes the tokenbased on the suggestions provided by the Completion Engine. Our evaluation on asubset of the widely-used Defects4j 1.2 and 2.0 datasets shows that Repilotoutperforms state-of-the-art techniques by fixing 27% and 47% more bugs,respectively. Moreover, Repilot produces more valid and correct patches thanthe base LLM with the same budget. While we focus on leveraging Repilot for APRin this work, the overall approach is also generalizable to other codegeneration tasks.",Yuxiang Wei,2023/9/1,2023/11/8
2307.07221v2,"Software Testing with Large Language Models: Survey, Landscape, and Vision",http://arxiv.org/abs/2307.07221v2,"Pre-trained large language models (LLMs) have recently emerged as abreakthrough technology in natural language processing and artificialintelligence, with the ability to handle large-scale datasets and exhibitremarkable performance across a wide range of tasks. Meanwhile, softwaretesting is a crucial undertaking that serves as a cornerstone for ensuring thequality and reliability of software products. As the scope and complexity ofsoftware systems continue to grow, the need for more effective software testingtechniques becomes increasingly urgent, making it an area ripe for innovativeapproaches such as the use of LLMs. This paper provides a comprehensive reviewof the utilization of LLMs in software testing. It analyzes 102 relevantstudies that have used LLMs for software testing, from both the softwaretesting and LLMs perspectives. The paper presents a detailed discussion of thesoftware testing tasks for which LLMs are commonly used, among which test casepreparation and program repair are the most representative. It also analyzesthe commonly used LLMs, the types of prompt engineering that are employed, aswell as the accompanied techniques with these LLMs. It also summarizes the keychallenges and potential opportunities in this direction. This work can serveas a roadmap for future research in this area, highlighting potential avenuesfor exploration, and identifying gaps in our current understanding of the useof LLMs in software testing.",Junjie Wang,2023/7/14,2024/1/5
2310.00710v2,How well does LLM generate security tests?,http://arxiv.org/abs/2310.00710v2,"Developers often build software on top of third-party libraries (Libs) toimprove programmer productivity and software quality. The libraries may containvulnerabilities exploitable by hackers to attack the applications (Apps) builton top of them. People refer to such attacks as supply chain attacks, thedocumented number of which has increased 742% in 2022. People created tools tomitigate such attacks, by scanning the library dependencies of Apps,identifying the usage of vulnerable library versions, and suggesting securealternatives to vulnerable dependencies. However, recent studies show that manydevelopers do not trust the reports by these tools; they ask for code orevidence to demonstrate how library vulnerabilities lead to security exploits,in order to assess vulnerability severity and modification necessity.Unfortunately, manually crafting demos of application-specific attacks ischallenging and time-consuming, and there is insufficient tool support toautomate that procedure.  In this study, we used ChatGPT-4.0 to generate security tests, and todemonstrate how vulnerable library dependencies facilitate the supply chainattacks to given Apps. We explored various prompt styles/templates, and foundthat ChatGPT-4.0 generated tests for all 55 Apps, demonstrating 24 attackssuccessfully. It outperformed two state-of-the-art security test generators --TRANSFER and SIEGE -- by generating a lot more tests and achieving moreexploits. ChatGPT-4.0 worked better when prompts described more on thevulnerabilities, possible exploits, and code context. Our research will shedlight on new research in security test generation. The generated tests willhelp developers create secure by design and secure by default software.",Ying Zhang,2023/10/1,2023/10/3
2307.04346v1,Can Large Language Models Write Good Property-Based Tests?,http://arxiv.org/abs/2307.04346v1,"Property-based testing (PBT), while an established technique in the softwaretesting research community, is still relatively underused in real-worldsoftware. Pain points in writing property-based tests include implementingdiverse random input generators and thinking of meaningful properties to test.Developers, however, are more amenable to writing documentation; plenty oflibrary API documentation is available and can be used as natural languagespecifications for property-based tests. As large language models (LLMs) haverecently shown promise in a variety of coding tasks, we explore the potentialof using LLMs to synthesize property-based tests. We call our approach PBT-GPT,and propose three different strategies of prompting the LLM for PBT. Wecharacterize various failure modes of PBT-GPT and detail an evaluationmethodology for automatically synthesized property-based tests. PBT-GPTachieves promising results in our preliminary studies on sample Python libraryAPIs in $\texttt{numpy}$, $\texttt{networkx}$, and $\texttt{datetime}$.",Vasudev Vikram,2023/7/10,2023/7/10
2312.11513v1,Maatphor: Automated Variant Analysis for Prompt Injection Attacks,http://arxiv.org/abs/2312.11513v1,"Prompt injection has emerged as a serious security threat to large languagemodels (LLMs). At present, the current best-practice for defending againstnewly-discovered prompt injection techniques is to add additional guardrails tothe system (e.g., by updating the system prompt or using classifiers on theinput and/or output of the model.) However, in the same way that variants of apiece of malware are created to evade anti-virus software, variants of a promptinjection can be created to evade the LLM's guardrails. Ideally, when a newprompt injection technique is discovered, candidate defenses should be testednot only against the successful prompt injection, but also against possiblevariants.  In this work, we present, a tool to assist defenders in performing automatedvariant analysis of known prompt injection attacks. This involves solving twomain challenges: (1) automatically generating variants of a given promptaccording, and (2) automatically determining whether a variant was effectivebased only on the output of the model. This tool can also assist in generatingdatasets for jailbreak and prompt injection attacks, thus overcoming thescarcity of data in this domain.  We evaluate Maatphor on three different types of prompt injection tasks.Starting from an ineffective (0%) seed prompt, Maatphor consistently generatesvariants that are at least 60% effective within the first 40 iterations.",Ahmed Salem,2023/12/12,2023/12/12
1805.00336v4,Hyperparameter Optimization for Effort Estimation,http://arxiv.org/abs/1805.00336v4,"Software analytics has been widely used in software engineering for manytasks such as generating effort estimates for software projects. One of the""black arts"" of software analytics is tuning the parameters controlling a datamining algorithm. Such hyperparameter optimization has been widely studied inother software analytics domains (e.g. defect prediction and text mining) but,so far, has not been extensively explored for effort estimation. Accordingly,this paper seeks simple, automatic, effective and fast methods for finding goodtunings for automatic software effort estimation.  We introduce a hyperparameter optimization architecture called OIL (OptimizedInductive Learning). We test OIL on a wide range of hyperparameter optimizersusing data from 945 software projects. After tuning, large improvements ineffort estimation accuracy were observed (measured in terms of standardizedaccuracy).  From those results, we recommend using regression trees (CART) tuned bydifferent evolution combine with default analogy-based estimator. Thisparticular combination of learner and optimizers often achieves in a few hourswhat other optimizers need days to weeks of CPU time to accomplish.  An important part of this analysis is its reproducibility and refutability.All our scripts and data are on-line. It is hoped that this paper will promptand enable much more research on better methods to tune software effortestimators.",Tianpei Xia,2018/4/28,2019/1/31
2304.11686v6,Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting,http://arxiv.org/abs/2304.11686v6,"Automatically detecting software failures is an important task and alongstanding challenge. It requires finding failure-inducing test cases whosetest input can trigger the software's fault, and constructing an automatedoracle to detect the software's incorrect behaviors. Recent advancement oflarge language models (LLMs) motivates us to study how far this challenge canbe addressed by ChatGPT, a state-of-the-art LLM. Unfortunately, our study showsthat ChatGPT has a low probability (28.8%) of finding correct failure-inducingtest cases for buggy programs. A possible reason is that findingfailure-inducing test cases requires analyzing the subtle code differencesbetween a buggy program and its correct version. When these two versions havesimilar syntax, ChatGPT is weak at recognizing subtle code differences. Ourinsight is that ChatGPT's performance can be substantially enhanced whenChatGPT is guided to focus on the subtle code difference. We have aninteresting observation that ChatGPT is effective in inferring the intendedbehaviors of a buggy program. The intended behavior can be leveraged tosynthesize programs, in order to make the subtle code difference between abuggy program and its correct version (i.e., the synthesized program) explicit.Driven by this observation, we propose a novel approach that synergisticallycombines ChatGPT and differential testing to find failure-inducing test cases.We evaluate our approach on Quixbugs (a benchmark of buggy programs), andcompare it with state-of-the-art baselines, including direct use of ChatGPT andPynguin. The experimental result shows that our approach has a much higherprobability (77.8%) of finding correct failure-inducing test cases, 2.7X as thebest baseline.",Tsz-On Li,2023/4/23,2023/9/9
2305.04764v1,ChatUniTest: a ChatGPT-based automated unit test generation tool,http://arxiv.org/abs/2305.04764v1,"Unit testing is a crucial, yet often tedious and time-consuming task. Torelieve developers from this burden, automated unit test generation techniquesare developed. Existing automated unit test generation tools, such asprogram-analysis-based tools like EvoSuite and Randoop, lack programcomprehension, resulting in unit tests with poor readability and limitedassertions. Language-model-based tools, such as AthenaTest and A3Test, havelimitations in the generation of correct unit tests. In this paper, weintroduce ChatUniTest, a ChatGPT-based automated unit test generation tooldeveloped under the Generation-Validation-Repair framework. ChatUniTestgenerates tests by parsing the project, extracting essential information, andcreating an adaptive focal context that includes the focal method and itsdependencies within the pre-defined maximum prompt token limit. The context isincorporated into a prompt and subsequently submitted to ChatGPT. OnceChatGPT's response is received, ChatUniTest proceeds to extract the raw testfrom the response. It then validates the test and employs rule-based repair tofix syntactic and simple compile errors, followed by ChatGPT-based repair toaddress challenging errors. Our rigorous evaluation demonstrates thatChatUniTest outperforms EvoSuite in branch and line coverage, surpassesAthenaTest and A3Test in focal method coverage, and effectively generatesassertions while utilizing mock objects and reflection to achieve testobjectives.",Zhuokui Xie,2023/5/8,2023/5/8
2306.15121v1,Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation,http://arxiv.org/abs/2306.15121v1,"We evaluate AI-assisted generative capabilities on fundamental numericalkernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV,Jacobi Stencil, and CG. We test the generated kernel codes for a variety oflanguage-supported programming models, including (1) C++ (e.g., OpenMP[including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g.,OpenMP [including offload] and OpenACC), (3) Python (e.g., numba, Numba, cuPy,and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, andKernelAbstractions.jl). We use the GitHub Copilot capabilities powered byOpenAI Codex available in Visual Studio Code as of April 2023 to generate avast amount of implementations given simple <kernel> + <programming model> +<optional hints> prompt variants. To quantify and compare the results, wepropose a proficiency metric around the initial 10 suggestions given for eachprompt. Results suggest that the OpenAI Codex outputs for C++ correlate withthe adoption and maturity of programming models. For example, OpenMP and CUDAscore really high, whereas HIP is still lacking. We found that prompts fromeither a targeted language such as Fortran or the more general-purpose Pythoncan benefit from adding code keywords, while Julia prompts perform acceptablywell for its mature programming models (e.g., Threads and CUDA.jl). We expectfor these benchmarks to provide a point of reference for each programmingmodel's community. Overall, understanding the convergence of large languagemodels, AI, and HPC is crucial due to its rapidly evolving nature and how it isredefining human-computer interactions.",William F. Godoy,2023/6/27,2023/6/27
2310.06320v1,Automatic Generation of Test Cases based on Bug Reports: a Feasibility Study with Large Language Models,http://arxiv.org/abs/2310.06320v1,"Software testing is a core discipline in software engineering where a largearray of research results has been produced, notably in the area of automatictest generation. Because existing approaches produce test cases that either canbe qualified as simple (e.g. unit tests) or that require precisespecifications, most testing procedures still rely on test cases written byhumans to form test suites. Such test suites, however, are incomplete: theyonly cover parts of the project or they are produced after the bug is fixed.Yet, several research challenges, such as automatic program repair, andpractitioner processes, build on the assumption that available test suites aresufficient. There is thus a need to break existing barriers in automatic testcase generation. While prior work largely focused on random unit testinginputs, we propose to consider generating test cases that realisticallyrepresent complex user execution scenarios, which reveal buggy behaviour. Suchscenarios are informally described in bug reports, which should therefore beconsidered as natural inputs for specifying bug-triggering test cases. In thiswork, we investigate the feasibility of performing this generation byleveraging large language models (LLMs) and using bug reports as inputs. Ourexperiments include the use of ChatGPT, as an online service, as well asCodeGPT, a code-related pre-trained LLM that was fine-tuned for our task.Overall, we experimentally show that bug reports associated to up to 50% ofDefects4J bugs can prompt ChatGPT to generate an executable test case. We showthat even new bug reports can indeed be used as input for generating executabletest cases. Finally, we report experimental results which confirm thatLLM-generated test cases are immediately useful in software engineering taskssuch as fault localization as well as patch validation in automated programrepair.",Laura Plein,2023/10/10,2023/10/10
2102.06098v1,An Inquisitive Code Editor for Addressing Novice Programmers' Misconceptions of Program Behavior,http://arxiv.org/abs/2102.06098v1,"Novice programmers face numerous barriers while attempting to learn how tocode that may deter them from pursuing a computer science degree or career insoftware development. In this work, we propose a tool concept to address theparticularly challenging barrier of novice programmers holding misconceptionsabout how their code behaves. Specifically, the concept involves an inquisitivecode editor that: (1) identifies misconceptions by periodically prompting thenovice programmer with questions about their program's behavior, (2) correctsthe misconceptions by generating explanations based on the program's actualbehavior, and (3) prevents further misconceptions by inserting test code andutilizing other educational resources. We have implemented portions of theconcept as plugins for the Atom code editor and conducted informal surveys withstudents and instructors. Next steps include deploying the tool prototype tostudents enrolled in introductory programming courses.",Austin Z. Henley,2021/2/11,2021/2/11
2305.14591v3,ALGO: Synthesizing Algorithmic Programs with LLM-Generated Oracle Verifiers,http://arxiv.org/abs/2305.14591v3,"Large language models (LLMs) excel at implementing code from functionalitydescriptions but struggle with algorithmic problems that require not onlyimplementation but also identification of the suitable algorithm. Moreover,LLM-generated programs lack guaranteed correctness and require humanverification. To address these challenges, we propose ALGO, a framework thatsynthesizes Algorithmic programs with LLM-Generated Oracles to guide thegeneration and verify their correctness. ALGO first generates a referenceoracle by prompting an LLM to exhaustively enumerate all the combinations ofrelevant variables. This oracle is then utilized to guide an arbitrary searchstrategy in exploring the algorithm space and to verify the synthesizedalgorithms. Our study shows that the LLM-generated oracles are correct for 88%of the cases. With the oracles as verifiers, ALGO can be integrated with anyexisting code generation model in a model-agnostic manner to enhance itsperformance. Experiments show that when equipped with ALGO, we achieve an 8xbetter one-submission pass rate over the Codex model and a 2.6x betterone-submission pass rate over CodeT, the current state-of-the-art model onCodeContests. We can also get 1.3x better pass rate over the ChatGPT CodeInterpreter on unseen problems. The problem set we used for testing, theprompts we used, the verifier and solution programs, and the test casesgenerated by ALGO are available at https://github.com/zkx06111/ALGO.",Kexun Zhang,2023/5/24,2023/12/8
2310.15991v1,White-box Compiler Fuzzing Empowered by Large Language Models,http://arxiv.org/abs/2310.15991v1,"Compiler correctness is crucial, as miscompilation falsifying the programbehaviors can lead to serious consequences. In the literature, fuzzing has beenextensively studied to uncover compiler defects. However, compiler fuzzingremains challenging: Existing arts focus on black- and grey-box fuzzing, whichgenerates tests without sufficient understanding of internal compilerbehaviors. As such, they often fail to construct programs to exerciseconditions of intricate optimizations. Meanwhile, traditional white-boxtechniques are computationally inapplicable to the giant codebase of compilers.Recent advances demonstrate that Large Language Models (LLMs) excel in codegeneration/understanding tasks and have achieved state-of-the-art performancein black-box fuzzing. Nonetheless, prompting LLMs with compiler source-codeinformation remains a missing piece of research in compiler testing.  To this end, we propose WhiteFox, the first white-box compiler fuzzer usingLLMs with source-code information to test compiler optimization. WhiteFoxadopts a dual-model framework: (i) an analysis LLM examines the low-leveloptimization source code and produces requirements on the high-level testprograms that can trigger the optimization; (ii) a generation LLM produces testprograms based on the summarized requirements. Additionally,optimization-triggering tests are used as feedback to further enhance the testgeneration on the fly. Our evaluation on four popular compilers shows thatWhiteFox can generate high-quality tests to exercise deep optimizationsrequiring intricate conditions, practicing up to 80 more optimizations thanstate-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80confirmed as previously unknown and 51 already fixed. Beyond compiler testing,WhiteFox can also be adapted for white-box fuzzing of other complex, real-worldsoftware systems in general.",Chenyuan Yang,2023/10/24,2023/10/24
2302.09865v2,Can discrete information extraction prompts generalize across language models?,http://arxiv.org/abs/2302.09865v2,"We study whether automatically-induced prompts that effectively extractinformation from a language model can also be used, out-of-the-box, to probeother language models for the same information. After confirming that discreteprompts induced with the AutoPrompt algorithm outperform manual and semi-manualprompts on the slot-filling task, we demonstrate a drop in performance forAutoPrompt prompts learned on a model and tested on another. We introduce a wayto induce prompts by mixing language models at training time that results inprompts that generalize well across models. We conduct an extensive analysis ofthe induced prompts, finding that the more general prompts include a largerproportion of existing English words and have a less order-dependent and moreuniform distribution of information across their component tokens. Our workprovides preliminary evidence that it's possible to generate discrete promptsthat can be induced once and used with a number of different models, and givesinsights on the properties characterizing such prompts.",Nathanal Carraz Rakotonirina,2023/2/20,2023/3/7
2210.01115v2,LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models,http://arxiv.org/abs/2210.01115v2,"Soft prompt learning has recently emerged as one of the methods of choice foradapting V&L models to a downstream task using a few training examples.However, current methods significantly overfit the training data, sufferingfrom large accuracy degradation when tested on unseen classes from the samedomain. To this end, in this paper, we make the following 4 contributions: (1)To alleviate base class overfitting, we propose a novel Language-Aware SoftPrompting (LASP) learning method by means of a text-to-text cross-entropy lossthat maximizes the probability of the learned prompts to be correctlyclassified with respect to pre-defined hand-crafted textual prompts. (2) Toincrease the representation capacity of the prompts, we propose grouped LASPwhere each group of prompts is optimized with respect to a separate subset oftextual prompts. (3) We identify a visual-language misalignment introduced byprompt learning and LASP, and more importantly, propose a re-calibrationmechanism to address it. (4) We show that LASP is inherently amenable toincluding, during training, virtual classes, i.e. class names for which novisual samples are available, further increasing the robustness of the learnedprompts. Through evaluations on 11 datasets, we show that our approach (a)significantly outperforms all prior works on soft prompting, and (b) matchesand surpasses, for the first time, the accuracy on novel classes obtained byhand-crafted prompts and CLIP for 8 out of 11 test datasets. Code will be madeavailable at https://www.adrianbulat.com/lasp",Adrian Bulat,2022/10/3,2023/4/2
2305.00418v3,An Empirical Study of Using Large Language Models for Unit Test Generation,http://arxiv.org/abs/2305.00418v3,"A code generation model generates code by taking a prompt from a codecomment, existing code, or a combination of both. Although code generationmodels (e.g., GitHub Copilot) are increasingly being adopted in practice, it isunclear whether they can successfully be used for unit test generation withoutfine-tuning for a strongly typed language like Java. To fill this gap, weinvestigated how well three models (Codex, GPT-3.5-Turbo, and StarCoder) cangenerate unit tests. We used two benchmarks (HumanEval and Evosuite SF110) toinvestigate the effect of context generation on the unit test generationprocess. We evaluated the models based on compilation rates, test correctness,test coverage, and test smells. We found that the Codex model achieved above80% coverage for the HumanEval dataset, but no model had more than 2% coveragefor the EvoSuite SF110 benchmark. The generated tests also suffered from testsmells, such as Duplicated Asserts and Empty Tests.",Mohammed Latif Siddiq,2023/4/30,2024/1/22
1802.03921v1,"Test Agents: Adaptive, Autonomous and Intelligent Test Cases",http://arxiv.org/abs/1802.03921v1,"Growth of software size, lack of resources to perform regression testing, andfailure to detect bugs faster have seen increased reliance on continuousintegration and test automation. Even with greater hardware and softwareresources dedicated to test automation, software testing is faced with enormouschallenges, resulting in increased dependence on complex mechanisms forautomated test case selection and prioritization as part of a continuousintegration framework. These mechanisms are currently using simple entitiescalled test cases that are concretely realized as executable scripts. Our keyidea is to provide test cases with more reasoning, adaptive behavior andlearning capabilities by using the concepts of intelligent software agents. Werefer to such test cases as test agents. The model that underlie a test agentis capable of flexible and autonomous actions in order to meet overall testingobjectives. Our goal is to increase the decentralization of regression testingby letting test agents to know for themselves when they should be executing,how they should update their purpose, and when they should interact with eachother. In this paper, we envision software test agents that display suchadaptive autonomous behavior. Emerging developments and challenges regardingthe use of test agents are explored-in particular, new research that seeks touse adaptive autonomous agents in software testing.",Eduard Enoiu,2018/2/12,2018/2/12
1505.01367v1,Applying FCA toolbox to Software Testing,http://arxiv.org/abs/1505.01367v1,"Software testing uses wide range of different tools to enhance thecomplicated process of defining quality of the system under test. FormalConcept Analysis (FCA) provides us with algorithms of deriving formal ontologyfrom a set of objects and their attributes. With the use of FCA we canconsiderably improve the efficiency of test case derivation. Moreover, anFCA-based machine learning system supports the analysis of regression testingresults.",Fedor Strok,2015/5/6,2015/5/6
2103.06343v1,Practitioners Testimonials about Software Testing,http://arxiv.org/abs/2103.06343v1,"As software systems are becoming more pervasive, they are also becoming moresusceptible to failures, resulting in potentially lethal combinations. Softwaretesting is critical to preventing software failures but is, arguably, the leastunderstood part of the software life cycle and the toughest to performcorrectly. Adequate research has been carried out in both the process andtechnology dimensions of testing, but not in the human dimensions. This paperattempts to fill in the gap by exploring the human dimension, i.e., trying tounderstand the motivation of software professionals to take up and sustaintesting careers. Towards that end, a survey was conducted in four countries -India, Canada, Cuba, and China - to try to understand how professional softwaretesters perceive and value work-related factors that could influence theirmotivation to take up and sustain testing careers. With a sample of 220software professionals, we observed that very few professionals are keen totake up testing careers. Some aspects of software testing, such as the learningopportunities, appear to be a common motivator across the four countries;whereas the treatment meted out to testers as second-class citizens and thecomplexity of the job appeared to be the most important de-motivators. Thiscomparative study offers useful insights that can help global software industryleaders to come up with an action plan to put the software testing professionunder a new light. That could increase the number of software engineerschoosing testing careers, which would facilitate quality testing.",Pradeep Waychal,2021/3/10,2021/3/10
2008.13114v1,A Novel Multiple Ensemble Learning Models Based on Different Datasets for Software Defect Prediction,http://arxiv.org/abs/2008.13114v1,"Software testing is one of the important ways to ensure the quality ofsoftware. It is found that testing cost more than 50% of overall project cost.Effective and efficient software testing utilizes the minimum resources ofsoftware. Therefore, it is important to construct the procedure which is notonly able to perform the efficient testing but also minimizes the utilizationof project resources. The goal of software testing is to find maximum defectsin the software system. More the defects found in the software ensure moreefficiency is the software testing Different techniques have been proposed todetect the defects in software and to utilize the resources and achieve goodresults. As world is continuously moving toward data driven approach for makingimportant decision. Therefore, in this research paper we performed the machinelearning analysis on the publicly available datasets and tried to achieve themaximum accuracy. The major focus of the paper is to apply different machinelearning techniques on the datasets and find out which technique produceefficient result. Particularly, we proposed an ensemble learning models andperform comparative analysis among KNN, Decision tree, SVM and Na\""ive Bayes ondifferent datasets and it is demonstrated that performance of Ensemble methodis more than other methods in term of accuracy, precision, recall and F1-score.The classification accuracy of ensemble model trained on CM1 is 98.56%,classification accuracy of ensemble model trained on KM2 is 98.18% similarly,the classification accuracy of ensemble learning model trained on PC1 is99.27%. This reveals that Ensemble is more efficient method for making thedefect prediction as compared other techniques.",Ali Nawaz,2020/8/30,2020/8/30
2310.06308v1,Unit Testing Challenges with Automated Marking,http://arxiv.org/abs/2310.06308v1,"Teaching software testing presents difficulties due to its abstract andconceptual nature. The lack of tangible outcomes and limited emphasis onhands-on experience further compound the challenge, often leading todifficulties in comprehension for students. This can result in waningengagement and diminishing motivation over time. In this paper, we introduceonline unit testing challenges with automated marking as a learning tool viathe EdStem platform to enhance students' software testing skills andunderstanding of software testing concepts. Then, we conducted a survey toinvestigate the impact of the unit testing challenges with automated marking onstudent learning. The results from 92 participants showed that our unit testingchallenges have kept students more engaged and motivated, fostering deeperunderstanding and learning, while the automated marking mechanism enhancedstudents' learning progress, helping them to understand their mistakes andmisconceptions quicker than traditional-style human-written manual feedback.Consequently, these results inform educators that the online unit testingchallenges with automated marking improve overall student learning experience,and are an effective pedagogical practice in software testing.",Chakkrit Tantithamthavorn,2023/10/10,2023/10/10
2205.00210v1,Software Testing for Machine Learning,http://arxiv.org/abs/2205.00210v1,"Machine learning has become prevalent across a wide variety of applications.Unfortunately, machine learning has also shown to be susceptible to deception,leading to errors, and even fatal failures. This circumstance calls intoquestion the widespread use of machine learning, especially in safety-criticalapplications, unless we are able to assure its correctness and trustworthinessproperties. Software verification and testing are established technique forassuring such properties, for example by detecting errors. However, softwaretesting challenges for machine learning are vast and profuse - yet critical toaddress. This summary talk discusses the current state-of-the-art of softwaretesting for machine learning. More specifically, it discusses six key challengeareas for software testing of machine learning systems, examines currentapproaches to these challenges and highlights their limitations. The paperprovides a research agenda with elaborated directions for making progresstoward advancing the state-of-the-art on testing of machine learning.",Dusica Marijan,2022/4/30,2022/4/30
1709.03221v1,Fairness Testing: Testing Software for Discrimination,http://arxiv.org/abs/1709.03221v1,"This paper defines software fairness and discrimination and develops atesting-based method for measuring if and how much software discriminates,focusing on causality in discriminatory behavior. Evidence of softwarediscrimination has been found in modern software systems that recommendcriminal sentences, grant access to financial products, and determine who isallowed to participate in promotions. Our approach, Themis, generates efficienttest suites to measure discrimination. Given a schema describing valid systeminputs, Themis generates discrimination tests automatically and does notrequire an oracle. We evaluate Themis on 20 software systems, 12 of which comefrom prior work with explicit focus on avoiding discrimination. We find that(1) Themis is effective at discovering software discrimination, (2)state-of-the-art techniques for removing discrimination from algorithms fail inmany situations, at times discriminating against as much as 98% of an inputsubdomain, (3) Themis optimizations are effective at producing efficient testsuites for measuring discrimination, and (4) Themis is more efficient onsystems that exhibit more discrimination. We thus demonstrate that fairnesstesting is a critical aspect of the software development cycle in domains withpossible discrimination and provide initial tools for measuring softwarediscrimination.",Sainyam Galhotra,2017/9/11,2017/9/11
2202.12139v1,Testing Deep Learning Models: A First Comparative Study of Multiple Testing Techniques,http://arxiv.org/abs/2202.12139v1,"Deep Learning (DL) has revolutionized the capabilities of vision-basedsystems (VBS) in critical applications such as autonomous driving, roboticsurgery, critical infrastructure surveillance, air and maritime trafficcontrol, etc. By analyzing images, voice, videos, or any type of complexsignals, DL has considerably increased the situation awareness of thesesystems. At the same time, while relying more and more on trained DL models,the reliability and robustness of VBS have been challenged and it has becomecrucial to test thoroughly these models to assess their capabilities andpotential errors. To discover faults in DL models, existing software testingmethods have been adapted and refined accordingly. In this article, we providean overview of these software testing methods, namely differential,metamorphic, mutation, and combinatorial testing, as well as adversarialperturbation testing and review some challenges in their deployment forboosting perception systems used in VBS. We also provide a first experimentalcomparative study on a classical benchmark used in VBS and discuss its results.",Mohit Kumar Ahuja,2022/2/24,2022/2/24
2110.06629v1,Detection Software Content Failures Using Dynamic Execution Information,http://arxiv.org/abs/2110.06629v1,"Modern software systems become too complex to be tested and validated.Detecting software partial failures in complex systems at runtime assist tohandle software unintended behaviors, avoiding catastrophic software failuresand improving software runtime availability. These detection techniques aim tofind the manifestation of faults before they finally lead to unavoidablefailures, thus supporting following runtime fault tolerant techniques. Wereview the state of the art articles and find that the content failures accountfor the majority of all kinds of software failures, but its detection methodsare rarely studied. In this work, we propose a novel failure detectionindicator based on the software runtime dynamic execution information forsoftware content failures. The runtime information is recorded during softwareexecution, then transformed to a measure named runtime entropy and finally fedinto machine learning models. The machine learning models are built to classifythe intended and unintended behaviors of the objected software systems. Aseries of controlled experiments on several open source projects are conductedto prove the feasibility of the method. We also evaluate the accuracy ofmachine learning models built in this work.",Shiyi Kong,2021/10/13,2021/10/13
2209.05052v1,Software Resurrection: Discovering Programming Pearls by Showing Modernity to Historical Software,http://arxiv.org/abs/2209.05052v1,"Reading computer program code and documentation written by others is, we aretold, one of the best ways to learn the art of writing intelligible andmaintainable code and documentation. The software resurrection exercise,introduced in this paper, requires a motivated learner to compile and test ahistorical release (e.g. 20 years old) version of a well maintained and widelyadopted open source software on a modern hardware and software platform. Thisexercise concludes by writing a critique based on issues encountered whilecompiling and testing a historical software release on a hardware and softwareplatform that could not have been foreseen at the time of release. The learneris also required to fix the issues as a part of the software resurrectionexercise. The seemingly pointless exercise of resurrecting a historicalsoftware allows motivated learners to experience the pain and joy of softwaremaintenance which is essential for understanding the factors that contribute tointelligibility and maintainability of program code and documentation. Theconcept of software resurrection exercise is illustrated using a version of theSQLite database engine that was released 20 years ago. This illustration showsthat software engineering principles (or programming pearls) emerge when ahistorical software release is adapted to run successfully on a modernplatform. The software resurrection exercise also has the potential to layfoundations for a lifelong willingness to explore and learn from existingprogram code.",Abhishek Dutta,2022/9/12,2022/9/12
2312.12604v1,Studying the Practices of Testing Machine Learning Software in the Wild,http://arxiv.org/abs/2312.12604v1,"Background: We are witnessing an increasing adoption of machine learning(ML), especially deep learning (DL) algorithms in many software systems,including safety-critical systems such as health care systems or autonomousdriving vehicles. Ensuring the software quality of these systems is yet an openchallenge for the research community, mainly due to the inductive nature of MLsoftware systems. Traditionally, software systems were constructed deductively,by writing down the rules that govern the behavior of the system as programcode. However, for ML software, these rules are inferred from training data.Few recent research advances in the quality assurance of ML systems haveadapted different concepts from traditional software testing, such as mutationtesting, to help improve the reliability of ML software systems. However, it isunclear if any of these proposed testing techniques from research are adoptedin practice. There is little empirical evidence about the testing strategies ofML engineers. Aims: To fill this gap, we perform the first fine-grainedempirical study on ML testing practices in the wild, to identify the MLproperties being tested, the followed testing strategies, and theirimplementation throughout the ML workflow. Method: First, we systematicallysummarized the different testing strategies (e.g., Oracle Approximation), thetested ML properties (e.g., Correctness, Bias, and Fairness), and the testingmethods (e.g., Unit test) from the literature. Then, we conducted a study tounderstand the practices of testing ML software. Results: In our findings: 1)we identified four (4) major categories of testing strategy including Grey-box,White-box, Black-box, and Heuristic-based techniques that are used by the MLengineers to find software bugs. 2) We identified 16 ML properties that aretested in the ML workflow.",Moses Openja,2023/12/19,2023/12/19
2108.13837v3,Towards a Common Testing Terminology for Software Engineering and Data Science Experts,http://arxiv.org/abs/2108.13837v3,"Analytical quality assurance, especially testing, is an integral part ofsoftware-intensive system development. With the increased usage of ArtificialIntelligence (AI) and Machine Learning (ML) as part of such systems, thisbecomes more difficult as well-understood software testing approaches cannot beapplied directly to the AI-enabled parts of the system. The required adaptationof classical testing approaches and the development of new concepts for AIwould benefit from a deeper understanding and exchange between AI and softwareengineering experts. We see the different terminologies used in the twocommunities as a major obstacle on this way. As we consider a mutualunderstanding of the testing terminology a key, this paper contributes amapping between the most important concepts from classical software testing andAI testing. In the mapping, we highlight differences in the relevance andnaming of the mapped concepts.",Lisa Jckel,2021/8/31,2021/10/6
2107.07364v1,SilGAN: Generating driving maneuvers for scenario-based software-in-the-loop testing,http://arxiv.org/abs/2107.07364v1,"Automotive software testing continues to rely largely upon expensive fieldtests to ensure quality because alternatives like simulation-based testing arerelatively immature. As a step towards lowering reliance on field tests, wepresent SilGAN, a deep generative model that eases specification, stimulusgeneration, and automation of automotive software-in-the-loop testing. Themodel is trained using data recorded from vehicles in the field. Upon training,the model uses a concise specification for a driving scenario to generaterealistic vehicle state transitions that can occur during such a scenario. Suchauthentic emulation of internal vehicle behavior can be used for rapid,systematic and inexpensive testing of vehicle control software. In addition, bypresenting a targeted method for searching through the information learned bythe model, we show how a test objective like code coverage can be automated.The data driven end-to-end testing pipeline that we present vastly expands thescope and credibility of automotive simulation-based testing. This reduces timeto market while helping maintain required standards of quality.",Dhasarathy Parthasarathy,2021/7/5,2021/7/5
1910.00262v3,Adaptive Metamorphic Testing with Contextual Bandits,http://arxiv.org/abs/1910.00262v3,"Metamorphic Testing is a software testing paradigm which aims at usingnecessary properties of a system-under-test, called metamorphic relations, toeither check its expected outputs, or to generate new test cases. MetamorphicTesting has been successful to test programs for which a full oracle is notavailable or to test programs for which there are uncertainties on expectedoutputs such as learning systems. In this article, we propose AdaptiveMetamorphic Testing as a generalization of a simple yet powerful reinforcementlearning technique, namely contextual bandits, to select one of the multiplemetamorphic relations available for a program. By using contextual bandits,Adaptive Metamorphic Testing learns which metamorphic relations are likely totransform a source test case, such that it has higher chance to discoverfaults. We present experimental results over two major case studies in machinelearning, namely image classification and object detection, and identifyweaknesses and robustness boundaries. Adaptive Metamorphic Testing efficientlyidentifies weaknesses of the tested systems in context of the source test case.",Helge Spieker,2019/10/1,2020/3/13
2105.00741v1,MLCheck- Property-Driven Testing of Machine Learning Models,http://arxiv.org/abs/2105.00741v1,"In recent years, we observe an increasing amount of software with machinelearning components being deployed. This poses the question of qualityassurance for such components: how can we validate whether specifiedrequirements are fulfilled by a machine learned software? Current testing andverification approaches either focus on a single requirement (e.g., fairness)or specialize on a single type of machine learning model (e.g., neuralnetworks). In this paper, we propose property-driven testing of machinelearning models. Our approach MLCheck encompasses (1) a language for propertyspecification, and (2) a technique for systematic test case generation. Thespecification language is comparable to property-based testing languages. Testcase generation employs advanced verification technology for a systematic,property-dependent construction of test suites, without additionaluser-supplied generator functions. We evaluate MLCheck using requirements anddata sets from three different application areas (software discrimination,learning on knowledge graphs and security). Our evaluation shows that despiteits generality MLCheck can even outperform specialised testing approaches whilehaving a comparable runtime.",Arnab Sharma,2021/5/3,2021/5/3
1606.00288v1,A Review of Pair-wise Testing,http://arxiv.org/abs/1606.00288v1,"In software testing, the large size of the input domain makes exhaustivelytesting the inputs a daunting and often impossible task. Pair-wise testing is apopular approach to combinatorial testing problems. This paper reviewsPair-wise testing and its history, strengths, weaknesses, and tools forgenerating test cases.",Jimi Sanchez,2016/6/1,2016/6/1
2002.12543v1,Metamorphic Testing: A New Approach for Generating Next Test Cases,http://arxiv.org/abs/2002.12543v1,"In software testing, a set of test cases is constructed according to somepredefined selection criteria. The software is then examined against these testcases. Three interesting observations have been made on the current artifactsof software testing. Firstly, an error-revealing test case is considered usefulwhile a successful test case which does not reveal software errors is usuallynot further investigated. Whether these successful test cases still containuseful information for revealing software errors has not been properly studied.Secondly, no matter how extensive the testing has been conducted in thedevelopment phase, errors may still exist in the software [5]. These errors, ifleft undetected, may eventually cause damage to the production system. Thestudy of techniques for uncovering software errors in the production phase isseldom addressed in the literature. Thirdly, as indicated by Weyuker in [6],the availability of test oracles is pragmatically unattainable in mostsituations. However, the availability of test oracles is generally assumed inconventional software testing techniques. In this paper, we propose a noveltest case selection technique that derives new test cases from the successfulones. The selection aims at revealing software errors that are possibly leftundetected in successful test cases which may be generated using some existingstrategies. As such, the proposed technique augments the effectiveness ofexisting test selection strategies. The technique also helps uncover softwareerrors in the production phase and can be used in the absence of test oracles.",T. Y. Chen,2020/2/28,2020/2/28
1509.08401v1,Automated Test Case Generation using Petri Nets,http://arxiv.org/abs/1509.08401v1,"Software testing is the process of determining the precision, quality,completeness and security of the software systems. An important step in testingsoftware is the generation of test cases, whose quality plays a vital role indetermining the time for testing and subsequently its cost. In this research,it is shown that both structural and behavioural diagrams can be used torepresent specifications in a single model using High Level Petri Nets (HLPN).This research focuses on automated generation of test models from Petri nets.Moreover, generating consistent formal models (HLPN) from informal models (UML)is the highlight of this research.",Jai Manral,2015/9/28,2015/9/28
1202.4527v1,Study Paper on Test Case generation for GUI Based Testing,http://arxiv.org/abs/1202.4527v1,"With the advent of WWW and outburst in technology and software development,testing the software became a major concern. Due to the importance of thetesting phase in a software development life cycle, testing has been dividedinto graphical user interface (GUI) based testing, logical testing, integrationtesting, etc.GUI Testing has become very important as it provides moresophisticated way to interact with the software. The complexity of testing GUIincreased over time. The testing needs to be performed in a way that itprovides effectiveness, efficiency, increased fault detection rate and goodpath coverage. To cover all use cases and to provide testing for all possible(success/failure) scenarios the length of the test sequence is consideredimportant. Intent of this paper is to study some techniques used for test casegeneration and process for various GUI based software applications.",A. Isabella,2012/2/21,2012/2/21
1206.0373v1,Generation and Optimization of Test cases for Object-Oriented Software Using State Chart Diagram,http://arxiv.org/abs/1206.0373v1,"The process of testing any software system is an enormous task which is timeconsuming and costly. The time and required effort to do sufficient testinggrow, as the size and complexity of the software grows, which may cause overrunof the project budget, delay in the development of software system or some testcases may not be covered. During SDLC (software development life cycle),generally the software testing phase takes around 40-70% of the time and cost.State-based testing is frequently used in software testing. Test datageneration is one of the key issues in software testing. A properly generatedtest suite may not only locate the errors in a software system, but also helpin reducing the high cost associated with software testing. It is often desiredthat test data in the form of test sequences within a test suite can beautomatically generated to achieve required test coverage. This paper proposesan optimization approach to test data generation for the state-based softwaretesting. In this paper, first state transition graph is derived from statechart diagram. Then, all the required information are extracted from the statechart diagram. Then, test cases are generated. Lastly, a set of test cases areminimized by calculating the node coverage for each test case. It is alsodetermined that which test cases are covered by other test cases. The advantageof our test generation technique is that it optimizes test coverage byminimizing time and cost. The proposed test data generation scheme generatestest cases which satisfy transition path coverage criteria, path coveragecriteria and action coverage criteria. A case study on Automatic Ticket Machine(ATM) has been presented to illustrate our approach.",Ranjita Kumari Swain,2012/6/2,2012/6/2
2301.13615v1,Property-Based Mutation Testing,http://arxiv.org/abs/2301.13615v1,"Mutation testing is an established software quality assurance technique forthe assessment of test suites. While it is well-suited to estimate the generalfault-revealing capability of a test suite, it is not practical and informativewhen the software under test must be validated against specific requirements.This is often the case for embedded software, where the software is typicallyvalidated against rigorously-specified safety properties. In such a scenario(i) a mutant is relevant only if it can impact the satisfaction of the testedproperties, and (ii) a mutant is meaningfully-killed with respect to a propertyonly if it causes the violation of that property. To address these limitationsof mutation testing, we introduce property-based mutation testing, a method forassessing the capability of a test suite to exercise the software with respectto a given property. We evaluate our property-based mutation testing frameworkon Simulink models of safety-critical Cyber-Physical Systems (CPS) from theautomotive and avionic domains and demonstrate how property-based mutationtesting is more informative than regular mutation testing. These results opennew perspectives in both mutation testing and test case generation of CPS.",Ezio Bartocci,2023/1/31,2023/1/31
1411.1154v1,A Survey on Software Testing Techniques using Genetic Algorithm,http://arxiv.org/abs/1411.1154v1,"The overall aim of the software industry is to ensure delivery of highquality software to the end user. To ensure high quality software, it isrequired to test software. Testing ensures that software meets userspecifications and requirements. However, the field of software testing has anumber of underlying issues like effective generation of test cases,prioritisation of test cases etc which need to be tackled. These issues demandon effort, time and cost of the testing. Different techniques and methodologieshave been proposed for taking care of these issues. Use of evolutionaryalgorithms for automatic test generation has been an area of interest for manyresearchers. Genetic Algorithm (GA) is one such form of evolutionaryalgorithms. In this research paper, we present a survey of GA approach foraddressing the various issues encountered during software testing.",Chayanika Sharma,2014/11/5,2014/11/5
1106.2686v1,Automated Software Testing Using Metahurestic Technique Based on An Ant Colony Optimization,http://arxiv.org/abs/1106.2686v1,"Software testing is an important and valuable part of the softwaredevelopment life cycle. Due to time, cost and other circumstances, exhaustivetesting is not feasible that's why there is a need to automate the softwaretesting process. Testing effectiveness can be achieved by the State TransitionTesting (STT) which is commonly used in real time, embedded and web-based typeof software systems. Aim of the current paper is to present an algorithm byapplying an ant colony optimization technique, for generation of optimal andminimal test sequences for behavior specification of software. Present paperapproach generates test sequence in order to obtain the complete softwarecoverage. This paper also discusses the comparison between two metaheuristictechniques (Genetic Algorithm and Ant Colony optimization) for transition basedtesting",Praveen Ranjan Srivastava,2011/6/14,2011/6/14
1103.0125v1,Search-based software test data generation using evolutionary computation,http://arxiv.org/abs/1103.0125v1,"Search-based Software Engineering has been utilized for a number of softwareengineering activities. One area where Search-Based Software Engineering hasseen much application is test data generation. Evolutionary testing designatesthe use of metaheuristic search methods for test case generation. The searchspace is the input domain of the test object, with each individual or potentialsolution, being an encoded set of inputs to that test object. The fitnessfunction is tailored to find test data for the type of test that is beingundertaken. Evolutionary Testing (ET) uses optimizing search techniques such asevolutionary algorithms to generate test data. The effectiveness of GA-basedtesting system is compared with a Random testing system. For simple programsboth testing systems work fine, but as the complexity of the program or thecomplexity of input domain grows, GA-based testing system significantlyoutperforms Random testing.",P. Maragathavalli,2011/3/1,2011/3/1
1208.2265v1,Minimal TestCase Generation for Object-Oriented Software with State Charts,http://arxiv.org/abs/1208.2265v1,"Today statecharts are a de facto standard in industry for modeling systembehavior. Test data generation is one of the key issues in software testing.This paper proposes an reduction approach to test data generation for thestate-based software testing. In this paper, first state transition graph isderived from state chart diagram. Then, all the required information areextracted from the state chart diagram. Then, test cases are generated. Lastly,a set of test cases are minimized by calculating the node coverage for eachtest case. It is also determined that which test cases are covered by othertest cases. The advantage of our test generation technique is that it optimizestest coverage by minimizing time and cost. The present test data generationscheme generates test cases which satisfy transition path coverage criteria,path coverage criteria and action coverage criteria. A case study on RailwayTicket Vending Machine (RTVM) has been presented to illustrate our approach.",Ranjita Kumari Swain,2012/8/10,2012/8/10
2310.19204v2,Can ChatGPT advance software testing intelligence? An experience report on metamorphic testing,http://arxiv.org/abs/2310.19204v2,"While ChatGPT is a well-known artificial intelligence chatbot being used toanswer human's questions, one may want to discover its potential in advancingsoftware testing. We examine the capability of ChatGPT in advancing theintelligence of software testing through a case study on metamorphic testing(MT), a state-of-the-art software testing technique. We ask ChatGPT to generatecandidates of metamorphic relations (MRs), which are basically necessaryproperties of the object program and which traditionally require humanintelligence to identify. These MR candidates are then evaluated in terms ofcorrectness by domain experts. We show that ChatGPT can be used to generate newcorrect MRs to test several software systems. Having said that, the majority ofMR candidates are either defined vaguely or incorrect, especially for systemsthat have never been tested with MT. ChatGPT can be used to advance softwaretesting intelligence by proposing MR candidates that can be later adopted forimplementing tests; but human intelligence should still inevitably be involvedto justify and rectify their correctness.",Quang-Hung Luu,2023/10/30,2023/11/23
2101.02817v1,Faster SAT Solving for Software with Repeated Structures (with Case Studies on Software Test Suite Minimization),http://arxiv.org/abs/2101.02817v1,"Theorem provers has been used extensively in software engineering forsoftware testing or verification. However, software is now so large and complexthat additional architecture is needed to guide theorem provers as they try togenerate test suites. The SNAP test suite generator (introduced in this paper)combines the Z3 theorem prover with the following tactic: cluster somecandidate tests, then search for valid tests by proposing small mutations tothe cluster centroids. This technique effectively removes repeated structuresin the tests since many repeated structures can be replaced with one centroid.In practice, SNAP is remarkably effective. For 27 real-world programs with upto half a million variables, SNAP found test suites which were 10 to 750smaller times than those found by the prior state-of-the-art. Also, SNAP ranorders of magnitude faster and (unlike prior work) generated 100% valid tests.",Jianfeng Chen,2021/1/8,2021/1/8
2211.12003v1,Application of property-based testing tools\\ for metamorphic testing,http://arxiv.org/abs/2211.12003v1,"Metamorphic testing (MT) is a general approach for the testing of a specifickind of software systems -- so-called ``non-testable'', where the ``classical''testing approaches are difficult to apply. MT is an effective approach foraddressing the test oracle problem and test case generation problem. The testoracle problem is when it is difficult to determine the correct expected outputof a particular test case or to determine whether the actual outputs agree withthe expected outcomes. The core concept in MT is metamorphic relations (MRs)which provide formal specification of the system under test. One of thechallenges in MT is \emph{effective test generation}. Property-based testing(PBT) is a testing methodology in which test cases are generated according todesired properties of the software. In some sense, MT can be seen as a veryspecific kind of PBT.\\ In this paper, we show how to use PBT tools to automatetest generation and verification of MT. In addition to automation benefit, theproposed method shows how to combine general PBT with MT under the same testingframework.",Nasser Alzahrani,2022/11/22,2022/11/22
1101.2301v1,A Factorial Experiment on Scalability of Search Based Software Testing,http://arxiv.org/abs/1101.2301v1,"Software testing is an expensive process, which is vital in the industry.Construction of the test-data in software testing requires the major cost andto decide which method to use in order to generate the test data is important.This paper discusses the efficiency of search-based algorithms (preferablygenetic algorithm) versus random testing, in soft- ware test-data generation.This study differs from all previous studies due to sample programs (SUTs)which are used. Since we want to in- crease the complexity of SUTs gradually,and the program generation is automatic as well, Grammatical Evolution is usedto guide the program generation. SUTs are generated according to the grammar weprovide, with different levels of complexity. SUTs will first undergo genetical- gorithm and then random testing. Based on the test results, this paperrecommends one method to use for automation of software testing.",Arash Mehrmand,2011/1/12,2011/1/12
1802.07361v1,Fault Detection Effectiveness of Source Test Case Generation Strategies for Metamorphic Testing,http://arxiv.org/abs/1802.07361v1,"Metamorphic testing is a well known approach to tackle the oracle problem insoftware testing. This technique requires the use of source test cases thatserve as seeds for the generation of follow-up test cases. Systematic design oftest cases is crucial for the test quality. Thus, source test case generationstrategy can make a big impact on the fault detection effectiveness ofmetamorphic testing. Most of the previous studies on metamorphic testing haveused either random test data or existing test cases as source test cases. Therehas been limited research done on systematic source test case generation formetamorphic testing. This paper provides a comprehensive evaluation on theimpact of source test case generation techniques on the fault findingeffectiveness of metamorphic testing. We evaluated the effectiveness of linecoverage, branch coverage, weak mutation and random test generation strategiesfor source test case generation. The experiments are conducted with 77 methodsfrom 4 open source code repositories. Our results show that by systematicallycreating source test cases, we can significantly increase the fault findingeffectiveness of metamorphic testing. Further, in this paper we introduce asimple metamorphic testing tool called ""METtester"" that we use to conductmetamorphic testing on these methods.",Prashanta Saha,2018/2/20,2018/2/20
1901.01450v1,Software Testing Process Models Benefits & Drawbacks: a Systematic Literature Review,http://arxiv.org/abs/1901.01450v1,"Context: Software testing plays an essential role in product qualityimprovement. For this reason, several software testing models have beendeveloped to support organizations. However, adoption of testing process modelsinside organizations is still sporadic, with a need for more evidence aboutreported experiences. Aim: Our goal is to identify results gathered from theapplication of software testing models in organizational contexts. We focus oncharacteristics such as the context of use, practices applied in differenttesting process phases, and reported benefits & drawbacks. Method: We performeda Systematic Literature Review (SLR) focused on studies about the applicationof software testing processes, complemented by results from previous reviews.Results: From 35 primary studies and survey-based articles, we collected 17testing models. Although most of the existing models are described asapplicable to general contexts, the evidence obtained from the studies showsthat some models are not suitable for all enterprise sizes, and inadequate forspecific domains. Conclusion: The SLR evidence can serve to compare differentsoftware testing models for applicability inside organizations. Both benefitsand drawbacks, as reported in the surveyed cases, allow getting a better viewof the strengths and weaknesses of each model.",Katarna Hrabovsk,2019/1/5,2019/1/5
1505.04112v1,"How, What and Why to test an ontology",http://arxiv.org/abs/1505.04112v1,"Ontology development relates to software development in that they bothinvolve the production of formal computational knowledge. It is possible,therefore, that some of the techniques used in software engineering could alsobe used for ontologies; for example, in software engineering testing is awell-established process, and part of many different methodologies.  The application of testing to ontologies, therefore, seems attractive. TheKaryotype Ontology is developed using the novel Tawny-OWL library. Thisprovides a fully programmatic environment for ontology development, whichincludes a complete test harness.  In this paper, we describe how we have used this harness to build anextensive series of tests as well as used a commodity continuous integrationsystem to link testing deeply into our development process; this environment,is applicable to any OWL ontology whether written using Tawny-OWL or not.Moreover, we present a novel analysis of our tests, introducing a newclassification of what our different tests are. For each class of test, wedescribe why we use these tests, also by comparison to software tests. Webelieve that this systematic comparison between ontology and softwaredevelopment will help us move to a more agile form of ontology development.",Jennifer D. Warrender,2015/5/15,2015/5/15
1010.5537v2,Using entropy measures for comparison of software traces,http://arxiv.org/abs/1010.5537v2,"The analysis of execution paths (also known as software traces) collectedfrom a given software product can help in a number of areas including softwaretesting, software maintenance and program comprehension. The lack of a scalablematching algorithm operating on detailed execution paths motivates the searchfor an alternative solution.  This paper proposes the use of word entropies for the classification ofsoftware traces. Using a well-studied defective software as an example, weinvestigate the application of both Shannon and extended entropies(Landsberg-Vedral, R\'{e}nyi and Tsallis) to the classification of tracesrelated to various software defects. Our study shows that using entropymeasures for comparisons gives an efficient and scalable method for comparingtraces. The three extended entropies, with parameters chosen to emphasize rareevents, all perform similarly and are superior to the Shannon entropy.",A. V. Miranskyy,2010/10/26,2012/4/25
2211.11409v1,Cost-effective Simulation-based Test Selection in Self-driving Cars Software,http://arxiv.org/abs/2211.11409v1,"Simulation environments are essential for the continuous development ofcomplex cyber-physical systems such as self-driving cars (SDCs). Previousresults on simulation-based testing for SDCs have shown that many automaticallygenerated tests do not strongly contribute to identification of SDC faults,hence do not contribute towards increasing the quality of SDCs. Because runningsuch ""uninformative"" tests generally leads to a waste of computationalresources and a drastic increase in the testing cost of SDCs, testers shouldavoid them. However, identifying ""uninformative"" tests before running themremains an open challenge. Hence, this paper proposes SDCScissor, a frameworkthat leverages Machine Learning (ML) to identify SDC tests that are unlikely todetect faults in the SDC software under test, thus enabling testers to skiptheir execution and drastically increase the cost-effectiveness ofsimulation-based testing of SDCs software. Our evaluation concerning the usageof six ML models on two large datasets characterized by 22'652 tests showedthat SDC-Scissor achieved a classification F1-score up to 96%. Moreover, ourresults show that SDC-Scissor outperformed a randomized baseline in identifyingmore failing tests per time unit.  Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor",Christian Birchler,2022/11/21,2022/11/21
2108.02694v1,Using Metamorphic Relations to Verify and Enhance Artcode Classification,http://arxiv.org/abs/2108.02694v1,"Software testing is often hindered where it is impossible or impractical todetermine the correctness of the behaviour or output of the software under test(SUT), a situation known as the oracle problem. An example of an area facingthe oracle problem is automatic image classification, using machine learning toclassify an input image as one of a set of predefined classes. An approach tosoftware testing that alleviates the oracle problem is metamorphic testing(MT). While traditional software testing examines the correctness of individualtest cases, MT instead examines the relations amongst multiple executions oftest cases and their outputs. These relations are called metamorphic relations(MRs): if an MR is found to be violated, then a fault must exist in the SUT.This paper examines the problem of classifying images containing visuallyhidden markers called Artcodes, and applies MT to verify and enhance thetrained classifiers. This paper further examines two MRs, Separation andOcclusion, and reports on their capability in verifying the imageclassification using one-way analysis of variance (ANOVA) in conjunction withthree other statistical analysis methods: t-test (for unequal variances),Kruskal-Wallis test, and Dunnett's test. In addition to our previously-studiedclassifier, that used Random Forests, we introduce a new classifier that uses asupport vector machine, and present its MR-augmented version. Experimentalevaluations across a number of performance metrics show that the augmentedclassifiers can achieve better performance than non-augmented classifiers. Thispaper also analyses how the enhanced performance is obtained.",Liming Xu,2021/8/5,2021/8/5
2111.04666v1,Machine Learning-based Test Selection for Simulation-based Testing of Self-driving Cars Software,http://arxiv.org/abs/2111.04666v1,"Abstract Simulation platforms facilitate the development of emergingcyber-physical systems (CPS) like self-driving cars (SDC) because they are moreefficient and less dangerous than field operational tests. Despite this,thoroughly testing SDCs in simulated environments remains challenging becauseSDCs must be tested in a sheer amount of long-running test scenarios. Pastresults on software testing optimization have shown that not all the testscontribute equally to establishing confidence in test subjects' quality andreliability, with some \uninformative"" tests that can be skipped (or removed)to reduce testing effort. However, this problem was partially addressed in thecontext of SDC simulation platforms. In this paper, we investigate testselection strategies to increase the cost-effectiveness of simulation-basedtesting in the context of SDCs. We propose an approach called SDC-Scissor (SDCcoSt-effeCtIve teSt SelectOR), which leverages machine learning (ML) strategiesto identify and skip tests that are unlikely to detect faults in SDCs beforeexecuting them. Specifically, SDC-Scissor extract features concerning thecharacteristics of the test scenarios being executed in the simulationenvironment and via ML strategies predict tests that lead to faults beforeexecuting them. Our evaluation shows that SDC-Scissor achieved highclassification accuracy (up to 93.4%) in classifying tests leading to a faultwhich allows improving testing cost-effectiveness: SDC-Scissor was able toreduce (ca. 170%) the time spent in running irrelevant tests as well asidentified 33% more failure triggering tests compared to a randomized baseline.Interestingly, SDC-Scissor does not introduce significant computationaloverhead in the SDCs testing process, which is critical to SDC development inindustrial settings.",Sajad Khatiri,2021/11/8,2021/11/8
1603.04335v1,The landscape of software failure cause models,http://arxiv.org/abs/1603.04335v1,"The software engineering field has a long history of classifying softwarefailure causes. Understanding them is paramount for fault injection, focusingtesting efforts or reliability prediction. Since software fails in manifoldcomplex ways, a broad range of software failure cause models is meanwhilepublished in dependability literature. We present the results of a meta-studythat classifies publications containing a software failure cause model in topicclusters. Our results structure the research field and can help to identifygaps. We applied the systematic mapping methodology for performing a repeatableanalysis.  We identified 156 papers presenting a model of software failure causes. Theirexamination confirms the assumption that a large number of the publicationsdiscusses source code defects only. Models of fault-activating state conditionsand error states are rare. Research seems to be driven mainly by the need forbetter testing methods and code-based quality improvement. Other motivationssuch as online error detection are less frequently given. Mostly, the IEEEdefinitions or orthogonal defect classification is used as base terminology.The majority of use cases comes from web, safety- and security-criticalapplications.",Lena Feinbube,2016/3/14,2016/3/14
1905.11699v4,Automating System Test Case Classification and Prioritization for Use Case-Driven Testing in Product Lines,http://arxiv.org/abs/1905.11699v4,"Product Line Engineering (PLE) is a crucial practice in many softwaredevelopment environments where software systems are complex and developed formultiple customers with varying needs. At the same time, many developmentprocesses are use case-driven and this strongly influences their requirementsengineering and system testing practices. In this paper, we propose, apply, andassess an automated system test case classification and prioritization approachspecifically targeting system testing in the context of use case-drivendevelopment of product families. Our approach provides: (i) automated supportto classify, for a new product in a product family, relevant and valid systemtest cases associated with previous products, and (ii) automated prioritizationof system test cases using multiple risk factors such as fault-proneness ofrequirements and requirements volatility in a product family. Our evaluationwas performed in the context of an industrial product family in the automotivedomain. Results provide empirical evidence that we propose a practical andbeneficial way to classify and prioritize system test cases for industrialproduct lines.",Ines Hajri,2019/5/28,2020/6/17
1704.00537v1,Exploratory Testing: One Size Doesn't Fit All,http://arxiv.org/abs/1704.00537v1,"Exploratory testing (ET) is a powerful and efficient way of testing softwareby integrating design, execution, and analysis of tests during a testingsession. ET is often contrasted with scripted testing, and seen as a choicebetween black and white. We pose that there are different levels of exploratorytesting from fully exploratory to fully scripted and propose a scale for thedegree of exploration for ET. The degree is defined through levels of ET, whichcorrespond to the way test charters are formulated. We have evaluated theclassification through focus groups at four companies and identified factorsthat influence the level of exploratory testing. The results show that theproposed ET levels have distinguishing characteristics and that the levels canbe used as a guide to structure test charters. Our study also indicates thatapplying a combination of ET levels can be beneficial in achieving effectivetesting.",Ahmad Nauman Ghazi,2017/4/3,2017/4/3
2112.13497v1,"Evaluating Software User Feedback Classifiers on Unseen Apps, Datasets, and Metadata",http://arxiv.org/abs/2112.13497v1,"Listening to user's requirements is crucial to building and maintaining highquality software. Online software user feedback has been shown to contain largeamounts of information useful to requirements engineering (RE). Previousstudies have created machine learning classifiers for parsing this feedback fordevelopment insight. While these classifiers report generally good performancewhen evaluated on a test set, questions remain as to how well they extend tounseen data in various forms.  This study evaluates machine learning classifiers performance on feedback fortwo common classification tasks (classifying bug reports and feature requests).Using seven datasets from prior research studies, we investigate theperformance of classifiers when evaluated on feedback from different apps thanthose contained in the training set and when evaluated on completely differentdatasets (coming from different feedback platforms and/or labelled by differentresearchers). We also measure the difference in performance of usingplatform-specific metadata as a feature in classification.  We demonstrate that classification performance is similar on feedback fromunseen apps compared to seen apps in the majority of cases tested. However, theclassifiers do not perform well on unseen datasets. We show that multi-datasettraining or zero shot classification approaches can somewhat mitigate thisperformance decrease. Finally, we find that using metadata as features inclassifying bug reports and feature requests does not lead to a statisticallysignificant improvement in the majority of datasets tested. We discuss theimplications of these results on developing user feedback classification modelsto analyse and extract software requirements.",Peter Devine,2021/12/27,2021/12/27
2203.09604v1,Overview of Test Coverage Criteria for Test Case Generation from Finite State Machines Modelled as Directed Graphs,http://arxiv.org/abs/2203.09604v1,"Test Coverage criteria are an essential concept for test engineers whengenerating the test cases from a System Under Test model. They are routinelyused in test case generation for user interfaces, middleware, and back-endsystem parts for software, electronics, or Internet of Things (IoT) systems.Test Coverage criteria define the number of actions or combinations by which asystem is tested, informally determining a potential ""strength"" of a test set.As no previous study summarized all commonly used test coverage criteria forFinite State Machines and comprehensively discussed them regarding theirsubsumption, equivalence, or non-comparability, this paper provides thisoverview. In this study, 14 most common test coverage criteria and seven oftheir synonyms for Finite State Machines defined via a directed graph aresummarized and compared. The results give researchers and industry testingengineers a helpful overview when setting a software-based or IoT system teststrategy.",Vaclav Rechtberger,2022/3/17,2022/3/17
1811.05005v1,A Fine-Grained Approach for Automated Conversion of JUnit Assertions to English,http://arxiv.org/abs/1811.05005v1,"Converting source or unit test code to English has been shown to improve themaintainability, understandability, and analysis of software and tests. Codesummarizers identify important statements in the source/tests and convert themto easily understood English sentences using static analysis and NLPtechniques. However, current test summarization approaches handle only a subsetof the variation and customization allowed in the JUnit assert API (a criticalcomponent of test cases) which may affect the accuracy of conversions. In thispaper, we present our work towards improving JUnit test summarization with adetailed process for converting a total of 45 unique JUnit assertions toEnglish, including 37 previously-unhandled variations of the assertThat method.This process has also been implemented and released as the AssertConvert tool.Initial evaluations have shown that this tool generates English conversionsthat accurately represent a wide variety of assertion statements which could beused for code summarization or other NLP analyses.",Danielle Gonzalez,2018/11/12,2018/11/12
cs/9902008v1,Managing Object-Oriented Integration and Regression Testing,http://arxiv.org/abs/cs/9902008v1,"Systematic testing of object-oriented software turned out to be much morecomplex than testing conventional software. Especially the highly incrementaland iterative development cycle demands both many more changes and partiallyimplemented resp. re-implemented classes. Much more integration and regressiontesting has to be done to reach stable stages during the development. In thispresentation we propose a diagram capturing all possible dependencies andinteractions in an object-oriented program. Then we give algorithms andcoverage criteria to identify integration resp. regression test strategys andall test cases to be executed after some implementation resp. modificationactivities. Finally, we summarize some practical experiences and heuristics.",Mario Winter,1999/2/5,1999/2/5
2108.12249v1,Developer-Centric Test Amplification The Interplay Between Automatic Generation and Human Exploration,http://arxiv.org/abs/2108.12249v1,"Automatically generating test cases for software has been an active researchtopic for many years. While current tools can generate powerful regression orcrash-reproducing test cases, these are often kept separately from themaintained test suite. In this paper, we leverage the developer's familiaritywith test cases amplified from existing, manually written developer tests.Starting from issues reported by developers in previous studies, we investigatewhat aspects are important to design a developer-centric test amplificationapproach, that provides test cases that are taken over by developers into theirtest suite. We conduct 16 semi-structured interviews with software developerssupported by our prototypical designs of a developer-centric test amplificationapproach and a corresponding test exploration tool. We extend the testamplification tool DSpot, generating test cases that are easier to understand.Our IntelliJ plugin TestCube empowers developers to explore amplified testcases from their familiar environment. From our interviews, we gather 52observations that we summarize into 23 result categories and give two keyrecommendations on how future tool designers can make their tools better suitedfor developer-centric test amplification.",Carolin Brandt,2021/8/27,2021/8/27
1302.1912v1,Testing and Evaluation of Service Oriented Systems,http://arxiv.org/abs/1302.1912v1,"Evaluation of service oriented system has been a challenge, though there arelarge number of evaluation metrics exist but none of them is efficient toevaluate these systems effectively.This paper discusses the different testingtools and evaluation methods available for SOA and summarizes their limitationand support in context of service oriented architectures.",Ashish Seth,2013/2/8,2013/2/8
2208.14885v1,OSC Community Lab: The Integration Test Bed for O-RAN Software Community,http://arxiv.org/abs/2208.14885v1,"O-RAN Software Community (OSC) is an open-source project collaborated byO-RAN Alliance and Linux Foundation, aiming to develop reference softwarecomponents based on 3GPP and O-RAN Alliance specifications. The OSC has twelveprojects. Among them, the Integration and Testing (INT) project is responsiblefor testing the requirements documented in each release for end-to-end and usecase testing. Three OSC Community Laboratories were built to speed up theintegration and interoperability testing among different projects. This papersummarizes the software components developed by OSC projects and the status ofthe three OSC Community Laboratories. The activities of each laboratory, howthe community collaborates, and the challenges we encountered along the waywere elaborated.",Fransiscus Asisi Bimo,2022/8/31,2022/8/31
2106.13891v2,Test Case Selection and Prioritization Using Machine Learning: A Systematic Literature Review,http://arxiv.org/abs/2106.13891v2,"Regression testing is an essential activity to assure that software codechanges do not adversely affect existing functionalities. With the wideadoption of Continuous Integration (CI) in software projects, which increasesthe frequency of running software builds, running all tests can betime-consuming and resource-intensive. To alleviate that problem, Test caseSelection and Prioritization (TSP) techniques have been proposed to improveregression testing by selecting and prioritizing test cases in order to provideearly feedback to developers. In recent years, researchers have relied onMachine Learning (ML) techniques to achieve effective TSP (ML-based TSP). Suchtechniques help combine information about test cases, from partial andimperfect sources, into accurate prediction models. This work conducts asystematic literature review focused on ML-based TSP techniques, aiming toperform an in-depth analysis of the state of the art, thus gaining insightsregarding future avenues of research. To that end, we analyze 29 primarystudies published from 2006 to 2020, which have been identified through asystematic and documented process. This paper addresses five research questionsaddressing variations in ML-based TSP techniques and feature sets for trainingand testing ML models, alternative metrics used for evaluating the techniques,the performance of techniques, and the reproducibility of the publishedstudies. We summarize the results related to our research questions in ahigh-level summary that can be used as a taxonomy for classifying future TSPstudies.",Rongqi Pan,2021/6/25,2021/10/5
2212.13424v1,Towards Benchmarking GUI Compatibility Testing on Mobile Applications,http://arxiv.org/abs/2212.13424v1,"GUI is a bridge connecting user and application. Existing GUI testing taskscan be categorized into two groups: functionality testing and compatibilitytesting. While the functionality testing focuses on detecting applicationruntime bugs, the compatibility testing aims at detecting bugs resulting fromdevice or platform difference. To automate testing procedures and improvetesting efficiency, previous works have proposed dozens of tools. To evaluatethese tools, in functionality testing, researchers have published testingbenchmarks. Comparatively, in compatibility testing, the question of ``Doexisting methods indeed effectively assist test cases replay?'' is not wellanswered. To answer this question and advance the related research in GUIcompatibility testing, we propose a benchmark of GUI compatibility testing. Inour experiments, we compare the replay success rate of existing tools. Based onthe experimental results, we summarize causes which may lead to ineffectivenessin test case replay and propose opportunities for improving thestate-of-the-art.",Jiaming Ye,2022/12/27,2022/12/27
2103.05451v3,The Effects of Continuous Integration on Software Development: a Systematic Literature Review,http://arxiv.org/abs/2103.05451v3,"Context: Continuous integration (CI) is a software engineering technique thatproclaims a set of frequent activities to assure the health of the softwareproduct. Researchers and practitioners mention several benefits related to CI.However, no systematic study surveys state of the art regarding such benefitsor cons. Objective: This study aims to identify and interpret empiricalevidence regarding how CI impacts software development. Method: Through aSystematic Literature Review, we search for studies in six digital libraries.Starting from 479 studies, we select 101 empirical studies that evaluate CI forany software development activity (e.g., testing). We thoroughly read andextract information regarding (i) CI environment, (ii) findings related toeffects of CI, and (iii) the employed methodology. We apply a thematicsynthesis to group and summarize the findings. Results: Existing research hasexplored the positive effects of CI, such as better cooperation, or negativeeffects, such as adding technical and process challenges. From our thematicsynthesis, we identify six themes: development activities, software process,quality assurance, integration patterns, issues & defects, and build patterns.Conclusions: Empirical research in CI has been increasing over recent years. Wefound that much of the existing research reveals that CI brings positiveeffects to the software development phenomena. However, CI may also bringtechnical challenges to software development teams. Despite the overallpositive outlook regarding CI, we still find room for improvements in theexisting empirical research that evaluates the effects of CI.",Eliezio Soares,2021/3/9,2022/1/10
1408.6120v1,The proposal of a novel software testing framework,http://arxiv.org/abs/1408.6120v1,"Software testing is normally used to check the validity of a program. Testoracle performs an important role in software testing. The focus in thisresearch is to perform class level test by introducing a testing framework. Atechnique is developed to generate test oracle for specification-based softwaretesting using Vienna Development Method (VDM++) formal language. A three stagetranslation process, of VDM++ specifications of container classes to C++ testoracle classes, is described in this paper. It is also presented that howderived test oracle is integrated into a proposed functional testing framework.This technique caters object oriented features such as inheritance andaggregation, but concurrency is not considered in this work. Translationissues, limitations and evaluation of the technique are also discussed. Theproposed approach is illustrated with the help of popular triangle problem casestudy.",Munib Ahmad,2014/8/26,2014/8/26
1910.02688v2,Automatic Testing and Improvement of Machine Translation,http://arxiv.org/abs/1910.02688v2,"This paper presents TransRepair, a fully automatic approach for testing andrepairing the consistency of machine translation systems. TransRepair combinesmutation with metamorphic testing to detect inconsistency bugs (without accessto human oracles). It then adopts probability-reference or cross-reference topost-process the translations, in a grey-box or black-box manner, to repair theinconsistencies. Our evaluation on two state-of-the-art translators, GoogleTranslate and Transformer, indicates that TransRepair has a high precision(99%) on generating input pairs with consistent translations. With these tests,using automatic consistency metrics and manual assessment, we find that GoogleTranslate and Transformer have approximately 36% and 40% inconsistency bugs.Black-box repair fixes 28% and 19% bugs on average for Google Translate andTransformer. Grey-box repair fixes 30% bugs on average for Transformer. Manualinspection indicates that the translations repaired by our approach improveconsistency in 87% of cases (degrading it in 2%), and that our repairs havebetter translation acceptability in 27% of the cases (worse in 8%).",Zeyu Sun,2019/10/7,2019/12/25
2401.06765v1,Automated Test Case Repair Using Language Models,http://arxiv.org/abs/2401.06765v1,"Ensuring the quality of software systems through testing is essential, yetmaintaining test cases poses significant challenges and costs. The need forfrequent updates to align with the evolving system under test often entailshigh complexity and cost for maintaining these test cases. Further, unrepairedbroken test cases can degrade test suite quality and disrupt the softwaredevelopment process, wasting developers' time. To address this challenge, wepresent TaRGet (Test Repair GEneraTor), a novel approach leveraging pre-trainedcode language models for automated test case repair. TaRGet treats test repairas a language translation task, employing a two-step process to fine-tune alanguage model based on essential context data characterizing the testbreakage. To evaluate our approach, we introduce TaRBench, a comprehensivebenchmark we developed covering 45,373 broken test repairs across 59open-source projects. Our results demonstrate TaRGet's effectiveness, achievinga 66.1% exact match accuracy. Furthermore, our study examines the effectivenessof TaRGet across different test repair scenarios. We provide a practical guideto predict situations where the generated test repairs might be less reliable.We also explore whether project-specific data is always necessary forfine-tuning and if our approach can be effective on new projects.",Ahmadreza Saboor Yaraghi,2024/1/12,2024/1/12
2110.06773v2,Leveraging Automated Unit Tests for Unsupervised Code Translation,http://arxiv.org/abs/2110.06773v2,"With little to no parallel data available for programming languages,unsupervised methods are well-suited to source code translation. However, themajority of unsupervised machine translation approaches rely onback-translation, a method developed in the context of natural languagetranslation and one that inherently involves training on noisy inputs.Unfortunately, source code is highly sensitive to small changes; a single tokencan result in compilation failures or erroneous programs, unlike naturallanguages where small inaccuracies may not change the meaning of a sentence. Toaddress this issue, we propose to leverage an automated unit-testing system tofilter out invalid translations, thereby creating a fully tested parallelcorpus. We found that fine-tuning an unsupervised model with this filtered dataset significantly reduces the noise in the translations so-generated,comfortably outperforming the state-of-the-art for all language pairs studied.In particular, for Java $\to$ Python and Python $\to$ C++ we outperform thebest previous methods by more than 16% and 24% respectively, reducing the errorrate by more than 35%.",Baptiste Roziere,2021/10/13,2022/2/16
2202.03616v1,Towards Property-Based Tests in Natural Language,http://arxiv.org/abs/2202.03616v1,"We consider a new approach to generate tests from natural language. Ratherthan relying on machine learning or templated extraction from structuredcomments, we propose to apply classic ideas from linguistics to translatenatural-language sentences into executable tests. This paper explores theapplication of combinatory categorial grammars (CCGs) to generatingproperty-based tests. Our prototype is able to generate tests from Englishdescriptions for each example in a textbook chapter on property-based testing.",Colin S. Gordon,2022/2/8,2022/2/8
1906.10742v2,"Machine Learning Testing: Survey, Landscapes and Horizons",http://arxiv.org/abs/1906.10742v2,"This paper provides a comprehensive survey of Machine Learning Testing (MLtesting) research. It covers 144 papers on testing properties (e.g.,correctness, robustness, and fairness), testing components (e.g., the data,learning program, and framework), testing workflow (e.g., test generation andtest evaluation), and application scenarios (e.g., autonomous driving, machinetranslation). The paper also analyses trends concerning datasets, researchtrends, and research focus, concluding with research challenges and promisingresearch directions in ML testing.",Jie M. Zhang,2019/6/19,2019/12/21
2306.06755v3,CoTran: An LLM-based Code Translator using Reinforcement Learning with Feedback from Compiler and Symbolic Execution,http://arxiv.org/abs/2306.06755v3,"In this paper, we present an LLM-based code translation method and anassociated tool called CoTran, that translates whole-programs from onehigh-level programming language to another. Current LLM-based code translationmethods lack a training approach to ensure that the translated code reliablycompiles or bears substantial functional equivalence to the input code. In ourwork, we train an LLM via reinforcement learning, by modifying the fine-tuningprocess to incorporate compiler feedback and symbolic execution (symexec)-basedequivalence testing feedback that checks for functional equivalence between theinput and output programs. The idea is to guide an LLM-in-training, viacompiler and symexec-based testing feedback, by letting it know how far it isfrom producing perfect translations. We report on extensive experimentscomparing CoTran with 14 other code translation tools that includehuman-written transpilers, LLM-based translation tools, and ChatGPT over abenchmark of more than 57,000 Java-Python equivalent pairs, and we show thatCoTran outperforms them on relevant metrics such as compilation accuracy(CompAcc) and functional equivalence accuracy (FEqAcc). For example, our toolachieves 48.68% FEqAcc, 76.98% CompAcc for Python-to-Java translation, whereasthe nearest competing tool (PLBART-base) only gets 38.26% and 75.77% resp.Also, built upon CodeT5, CoTran achieves +11.23%, +14.89% improvement on FEqAccand +4.07%, +8.14% on CompAcc for Java-to-Python and Python-to-Java translationresp.",Prithwish Jana,2023/6/11,2024/1/17
2002.05800v2,On Learning Meaningful Assert Statements for Unit Test Cases,http://arxiv.org/abs/2002.05800v2,"Software testing is an essential part of the software lifecycle and requiresa substantial amount of time and effort. It has been estimated that softwaredevelopers spend close to 50% of their time on testing the code they write. Forthese reasons, a long standing goal within the research community is to(partially) automate software testing. While several techniques and tools havebeen proposed to automatically generate test methods, recent work hascriticized the quality and usefulness of the assert statements they generate.Therefore, we employ a Neural Machine Translation (NMT) based approach calledAtlas(AuTomatic Learning of Assert Statements) to automatically generatemeaningful assert statements for test methods. Given a test method and a focalmethod (i.e.,the main method under test), Atlas can predict a meaningful assertstatement to assess the correctness of the focal method. We applied Atlas tothousands of test methods from GitHub projects and it was able to predict theexact assert statement manually written by developers in 31% of the cases whenonly considering the top-1 predicted assert. When considering the top-5predicted assert statements, Atlas is able to predict exact matches in 50% ofthe cases. These promising results hint to the potential usefulness ofourapproach as (i) a complement to automatic test case generation techniques, and(ii) a code completion support for developers, whocan benefit from therecommended assert statements while writing test code.",Cody Watson,2020/2/13,2020/2/19
2302.01037v2,Sentiment Overflow in the Testing Stack: Analysing Software Testing Posts on Stack Overflow,http://arxiv.org/abs/2302.01037v2,"Software testing is an integral part of modern software engineering practice.Past research has not only underlined its significance, but also revealed itsmulti-faceted nature. The practice of software testing and its adoption isinfluenced by many factors that go beyond tools or technology. This paper setsout to investigate the context of software testing from the practitioners'point of view by mining and analyzing sentimental posts on the widely usedquestion and answer website Stack Overflow. By qualitatively analyzingsentimental expressions of practitioners, which we extract from the StackOverflow dataset using sentiment analysis tools, we discern factors that helpus to better understand the lived experience of software engineers with regardsto software testing. Grounded in the data that we have analyzed, we argue thatsentiments like insecurity, despair and aspiration, have an impact onpractitioners' attitude towards testing. We suggest that they are connected toconcrete factors like the level of complexity of projects in which softwaretesting is practiced.",Mark Swillus,2023/2/2,2023/4/22
2205.07781v1,Social Aspects of Software Testing: Comparative Studies in Asia,http://arxiv.org/abs/2205.07781v1,"This study attempts to understand motivators and de-motivators that influencethe decisions of software students to take up and sustain software testingcareers across three different Asian countries, i.e., China, India, andMalaysia. The re-search question can be framed as How many software studentsacross different Asian geographies are keen to take up testing careers, andwhat are the reasons for their choices? Towards an answer, we developed across-sectional but simple survey-based instrument. In this work, weinvestigated how software students perceived the software testing role. Theresults from China and India revealed that students are not very keen on takingup a software tester career, but the Malaysia students show a more positiveattitude towards software testing. The study also pointed out the importance ofconsidering software testing activities as a set of human-dependent tasks andemphasized the need for further re-search that examines critically individualassessments of software testers about software testing activities. Thisinvestigation can academics involved in software testing courses to understandthe impacting factors on the motivation and de-motivators of their students, aswell as to try convey positive view of testing as challenging and requirescritical thinking and innovative ideas.",Luiz Fernando Capretz,2022/5/16,2022/5/16
2309.01154v1,A Survey on What Developers Think About Testing,http://arxiv.org/abs/2309.01154v1,"Software is infamous for its poor quality and frequent occurrence of bugs.While there is no doubt that thorough testing is an appropriate answer toensure sufficient quality, the poor state of software generally suggests thatdevelopers may not always engage as thoroughly with testing as they should.This observation aligns with the prevailing belief that developers simply donot like writing tests. In order to determine the truth of this belief, weconducted a comprehensive survey with 21 questions aimed at (1) assessingdevelopers' current engagement with testing and (2) identifying factorsinfluencing their inclination toward testing; that is, whether they wouldactually like to test more but are inhibited by their work environment, orwhether they would really prefer to test even less if given the choice. Drawingon 284 responses from professional software developers, we uncover reasons thatpositively and negatively impact developers' motivation to test. Notably,reasons for motivation to write more tests encompass not only a general pursuitof software quality but also personal satisfaction. However, developersnevertheless perceive testing as mundane and tend to prioritize other tasks.One approach emerging from the responses to mitigate these negative factors isby providing better recognition for developers' testing efforts.",Philipp Straubinger,2023/9/3,2023/9/3
1610.02692v1,Open-Ended Visual Question-Answering,http://arxiv.org/abs/1610.02692v1,"This thesis report studies methods to solve Visual Question-Answering (VQA)tasks with a Deep Learning framework. As a preliminary step, we explore LongShort-Term Memory (LSTM) networks used in Natural Language Processing (NLP) totackle Question-Answering (text based). We then modify the previous model toaccept an image as an input in addition to the question. For this purpose, weexplore the VGG-16 and K-CNN convolutional neural networks to extract visualfeatures from the image. These are merged with the word embedding or with asentence embedding of the question to predict the answer. This work wassuccessfully submitted to the Visual Question Answering Challenge 2016, whereit achieved a 53,62% of accuracy in the test dataset. The developed softwarehas followed the best programming practices and Python code style, providing aconsistent baseline in Keras for different configurations.",Issey Masuda,2016/10/9,2016/10/9
2309.02221v1,Improving students' code correctness and test completeness by informal specifications,http://arxiv.org/abs/2309.02221v1,"The quality of software produced by students is often poor. How to teachstudents to develop good quality software has long been a topic in computerscience education and research. We must conclude that we still do not have agood answer to this question. Specifications are necessary to determine thecorrectness of software, to develop error-free software and to write completetests. Several attempts have been made to teach students to writespecifications before writing code. So far, that has not proven to be verysuccessful: Students do not like to write a specification and do not see thebenefits of writing specifications. In this paper we focus on the use ofinformal specifications. Instead of teaching students how to writespecifications, we teach them how to use informal specifications to developcorrect software. The results were surprising: the number of errors in softwareand the completeness of tests both improved considerably and, most importantly,students really appreciate the specifications. We think that if studentsappreciate specification, we have a key to teach them how to specify and toappreciate its value.",Arno Broeders,2023/9/5,2023/9/5
2203.00483v4,A Survey on How Test Flakiness Affects Developers and What Support They Need To Address It,http://arxiv.org/abs/2203.00483v4,"Non-deterministically passing and failing test cases, so-called flaky tests,have recently become a focus area of software engineering research. While thisresearch focus has been met with some enthusiastic endorsement from industry,prior work nevertheless mostly studied flakiness using a code-centric approachby mining software repositories. What data extracted from software repositoriescannot tell us, however, is how developers perceive flakiness: How prevalent istest flakiness in developers' daily routine, how does it affect them, and mostimportantly: What do they want us researchers to do about it? To answer thesequestions, we surveyed 335 professional software developers and testers indifferent domains. The survey respondents confirm that flaky tests are a commonand serious problem, thus reinforcing ongoing research on flaky test detection.Developers are less worried about the computational costs caused by re-runningtests and more about the loss of trust in the test outcomes. Therefore, theywould like to have IDE plugins to detect flaky code as well as bettervisualizations of the problem, particularly dashboards showing test outcomesover time; they also wish for more training and information on flakiness. Theseimportant aspects will require the attention of researchers as well as tooldevelopers.",Martin Gruber,2022/3/1,2022/4/8
2304.12196v1,Can gamification help in software testing education? Findings from an empirical study,http://arxiv.org/abs/2304.12196v1,"Software testing is an essential knowledge area required by industry forsoftware engineers. However, software engineering students often considertesting less appealing than designing or coding. Consequently, it is difficultto engage students to create effective tests. To encourage students, weexplored the use of gamification and investigated whether this technique canhelp to improve the engagement and performance of software testing students. Weconducted a controlled experiment to compare the engagement and performance oftwo groups of students that took an undergraduate software testing course indifferent academic years. The experimental group is formed by 135 students fromthe gamified course whereas the control group is formed by 100 students fromthe non-gamified course. The data collected were statistically analyzed toanswer the research questions of this study. The results show that the studentsthat participated in the gamification experience were more engaged and achieveda better performance. As an additional finding, the analysis of the resultsreveals that a key aspect to succeed is the gamification experience design. Itis important to distribute the motivating stimulus provided by the gamificationthroughout the whole experience to engage students until the end. Given theseresults, we plan to readjust the gamification experience design to increasestudent engagement in the last stage of the experience, as well as to conduct alongitudinal study to evaluate the effects of gamification.",Raquel Blanco,2023/4/24,2023/4/24
2110.11575v1,Methodology for Assessing the State of the Practice for Domain X,http://arxiv.org/abs/2110.11575v1,"To improve software development methods and tools for research software, wefirst need to understand the current state of the practice. Therefore, we havedeveloped a methodology for assessing the state of the software developmentpractices for a given research software domain. For each domain we wish toanswer questions such as: i) What artifacts (documents, code, test cases, etc.)are present? ii) What tools are used? iii) What principles, process andmethodologies are used? iv) What are the pain points for developers? v) Whatactions are used to improve qualities like maintainability and reproducibility?To answer these questions, our methodology prescribes the following steps: i)Identify the domain; ii) Identify a list of candidate software packages; iii)Filter the list to a length of about 30 packages; iv) Gather source code anddocumentation for each package; v) Collect repository related data on eachsoftware package, like number of stars, number of open issues, number of linesof code; vi) Fill in the measurement template (the template consists of 108questions to assess 9 qualities (including the qualities of installability,usability and visibility)); vii) Interview developers (the interview consistsof 20 questions and takes about an hour); viii) Rank the software using theAnalytic Hierarchy Process (AHP); and, ix) Analyze the data to answer thequestions posed above. A domain expert should be engaged throughout theprocess, to ensure that implicit information about the domain is properlyrepresented and to assist with conducting an analysis of the commonalities andvariabilities between the 30 selected packages. Using our methodology,spreadsheet templates and AHP tool, we estimate (based on our experience withusing the process) the time to complete an assessment for a given domain at 173person hours.",Spencer Smith,2021/10/22,2021/10/22
2209.08372v2,CodeQueries: A Dataset of Semantic Queries over Code,http://arxiv.org/abs/2209.08372v2,"Developers often have questions about semantic aspects of code they areworking on, e.g., ""Is there a class whose parent classes declare a conflictingattribute?"". Answering them requires understanding code semantics such asattributes and inheritance relation of classes. An answer to such a questionshould identify code spans constituting the answer (e.g., the declaration ofthe subclass) as well as supporting facts (e.g., the definitions of theconflicting attributes). The existing work on question-answering over code hasconsidered yes/no questions or method-level context. We contribute a labeleddataset, called CodeQueries, of semantic queries over Python code. Compared tothe existing datasets, in CodeQueries, the queries are about code semantics,the context is file level and the answers are code spans. We curate the datasetbased on queries supported by a widely-used static analysis tool, CodeQL, andinclude both positive and negative examples, and queries requiring single-hopand multi-hop reasoning.  To assess the value of our dataset, we evaluate baseline neural approaches.We study a large language model (GPT3.5-Turbo) in zero-shot and few-shotsettings on a subset of CodeQueries. We also evaluate a BERT style model(CuBERT) with fine-tuning. We find that these models achieve limited success onCodeQueries. CodeQueries is thus a challenging dataset to test the ability ofneural models, to understand code semantics, in the extractivequestion-answering setting.",Surya Prakash Sahu,2022/9/17,2023/7/14
1508.03601v1,Is Stack Overflow Overflowing With Questions and Tags,http://arxiv.org/abs/1508.03601v1,"Programming question and answer (Q & A) websites, such as Quora, StackOverflow, and Yahoo! Answer etc. helps us to understand the programmingconcepts easily and quickly in a way that has been tested and applied by manysoftware developers. Stack Overflow is one of the most frequently usedprogramming Q\&A website where the questions and answers posted are presentlyanalyzed manually, which requires a huge amount of time and resource. To savethe effort, we present a topic modeling based technique to analyze the words ofthe original texts to discover the themes that run through them. We alsopropose a method to automate the process of reviewing the quality of questionson Stack Overflow dataset in order to avoid ballooning the stack overflow withinsignificant questions. The proposed method also recommends the appropriatetags for the new post, which averts the creation of unnecessary tags on StackOverflow.",Ranjitha R. K.,2015/8/14,2015/8/14
2309.12732v1,OpenAi's GPT4 as coding assistant,http://arxiv.org/abs/2309.12732v1,"Lately, Large Language Models have been widely used in code generation. GPT4is considered the most potent Large Language Model from Openai. In this paper,we examine GPT3.5 and GPT4 as coding assistants. More specifically, we haveconstructed appropriate tests to check whether the two systems can a) answertypical questions that can arise during the code development, b) producereliable code, and c) contribute to code debugging. The test results areimpressive. The performance of GPT4 is outstanding and signals an increase inthe productivity of programmers and the reorganization of software developmentprocedures based on these new tools.",Lefteris Moussiades,2023/9/22,2023/9/22
1802.07354v1,Quality Assurance of Bioinformatics Software: A Case Study of Testing a Biomedical Text Processing Tool Using Metamorphic Testing,http://arxiv.org/abs/1802.07354v1,"Bioinformatics software plays a very important role in making criticaldecisions within many areas including medicine and health care. However, mostof the research is directed towards developing tools, and little time andeffort is spent on testing the software to assure its quality. In testing, atest oracle is used to determine whether a test is passed or failed duringtesting, and unfortunately, for much of bioinformatics software, the exactexpected outcomes are not well defined. Thus, the main challenge associatedwith conducting systematic testing on bioinformatics software is the oracleproblem.  Metamorphic testing (MT) is a technique used to test programs that face theoracle problem. MT uses metamorphic relations (MRs) to determine whether a testhas passed or failed and specifies how the output should change according to aspecific change made to the input. In this work, we use MT to test LingPipe, atool for processing text using computational linguistics, often used inbioinformatics for bio-entity recognition from biomedical literature.  First, we identify a set of MRs for testing any bio-entity recognitionprogram. Then we develop a set of test cases that can be used to testLingPipe's bio-entity recognition functionality using these MRs. To evaluatethe effectiveness of this testing process, we automatically generate a set offaulty versions of LingPipe. According to our analysis of the experimentalresults, we observe that our MRs can detect the majority of these faultyversions, which shows the utility of this testing technique for qualityassurance of bioinformatics software.",Madhusudan Srinivasan,2018/2/20,2018/2/20
1901.04472v1,EvoMaster: Evolutionary Multi-context Automated System Test Generation,http://arxiv.org/abs/1901.04472v1,"This paper presents EvoMaster, an open-source tool that is able toautomatically generate system level test cases using evolutionary algorithms.Currently, EvoMaster targets RESTful web services running on JVM technology,and has been used to find several faults in existing open-source projects. Wediscuss some of the architectural decisions made for its implementation, andfuture work.",Andrea Arcuri,2019/1/12,2019/1/12
2308.11284v1,LEAP: Efficient and Automated Test Method for NLP Software,http://arxiv.org/abs/2308.11284v1,"The widespread adoption of DNNs in NLP software has highlighted the need forrobustness. Researchers proposed various automatic testing techniques foradversarial test cases. However, existing methods suffer from two limitations:weak error-discovering capabilities, with success rates ranging from 0% to24.6% for BERT-based NLP software, and time inefficiency, taking 177.8s to205.28s per test case, making them challenging for time-constrained scenarios.To address these issues, this paper proposes LEAP, an automated test methodthat uses LEvy flight-based Adaptive Particle swarm optimization integratedwith textual features to generate adversarial test cases. Specifically, weadopt Levy flight for population initialization to increase the diversity ofgenerated test cases. We also design an inertial weight adaptive updateoperator to improve the efficiency of LEAP's global optimization ofhigh-dimensional text examples and a mutation operator based on the greedystrategy to reduce the search time. We conducted a series of experiments tovalidate LEAP's ability to test NLP software and found that the average successrate of LEAP in generating adversarial test cases is 79.1%, which is 6.1%higher than the next best approach (PSOattack). While ensuring high successrates, LEAP significantly reduces time overhead by up to 147.6s compared toother heuristic-based methods. Additionally, the experimental resultsdemonstrate that LEAP can generate more transferable test cases andsignificantly enhance the robustness of DNN-based systems.",Mingxuan Xiao,2023/8/22,2023/8/22
1702.04501v1,Supplementary Material for the Information Sciences Paper: An Experimental Study of Hyper-Heuristic Selection and Acceptance Mechanism for Combinatorial t-way Test Suite Generation,http://arxiv.org/abs/1702.04501v1,"Software testing relates to the process of accessing the functionality of aprogram against some defined specifications. To ensure conformance, testengineers often generate a set of test cases to validate against the userrequirements.  Owing to the growing complexity of software and its increasing diffusion intovarious application domains, it is no longer unusual for a software project tohave testing teams in more than one location or even distributed over manycontinents. Owing to the intertwined dependencies of many software developmentactivities and their geographical and temporal issues, there are potentiallymany overlapping test cases which can cause unwarranted redundancies across theshared modules (i.e. a test for one requirement may be covered by more than onetest).  In this paper, we explore the application of our newly developedhyperheuristic, called Fuzzy Inference Selection (FIS), for addressing testredundancy reduction problem. This paper presents the supplementary results forthe paper : An Experimental Study of Hyper-Heuristic Selection and AcceptanceMechanism for Combinatorial t way Test Suite Generation published inInformation Sciences.",Kamal Z. Zamli,2017/2/15,2017/2/15
2308.09810v1,An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software,http://arxiv.org/abs/2308.09810v1,"The exponential growth of social media platforms has brought about arevolution in communication and content dissemination in human society.Nevertheless, these platforms are being increasingly misused to spread toxiccontent, including hate speech, malicious advertising, and pornography, leadingto severe negative consequences such as harm to teenagers' mental health.Despite tremendous efforts in developing and deploying textual and imagecontent moderation methods, malicious users can evade moderation by embeddingtexts into images, such as screenshots of the text, usually with someinterference. We find that modern content moderation software's performanceagainst such malicious inputs remains underexplored. In this work, we proposeOASIS, a metamorphic testing framework for content moderation software. OASISemploys 21 transform rules summarized from our pilot study on 5,000 real-worldtoxic contents collected from 4 popular social media applications, includingTwitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents,OASIS can generate image test cases, which preserve the toxicity yet are likelyto bypass moderation. In the evaluation, we employ OASIS to test fivecommercial textual content moderation software from famous companies (i.e.,Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud),as well as a state-of-the-art moderation research model. The results show thatOASIS achieves up to 100% error finding rates. Moreover, through retraining themodels with the test cases generated by OASIS, the robustness of the moderationmodel can be improved without performance degradation.",Wenxuan Wang,2023/8/18,2023/8/18
2002.04279v1,Testing of Support Tools for Plagiarism Detection,http://arxiv.org/abs/2002.04279v1,"There is a general belief that software must be able to easily do things thathumans find difficult. Since finding sources for plagiarism in a text is not aneasy task, there is a wide-spread expectation that it must be simple forsoftware to determine if a text is plagiarized or not. Software cannotdetermine plagiarism, but it can work as a support tool for identifying sometext similarity that may constitute plagiarism. But how well do the varioussystems work? This paper reports on a collaborative test of 15 web-basedtext-matching systems that can be used when plagiarism is suspected. It wasconducted by researchers from seven countries using test material in eightdifferent languages, evaluating the effectiveness of the systems onsingle-source and multi-source documents. A usability examination was alsoperformed. The sobering results show that although some systems can indeed helpidentify some plagiarized content, they clearly do not find all plagiarism andat times also identify non-plagiarized material as problematic.",Tom Foltnek,2020/2/11,2020/2/11
1609.08439v2,Model-based Test Generation for Robotic Software: Automata versus Belief-Desire-Intention Agents,http://arxiv.org/abs/1609.08439v2,"Robotic code needs to be verified to ensure its safety and functionalcorrectness, especially when the robot is interacting with people. Testing realcode in simulation is a viable option. However, generating tests that coverrare scenarios, as well as exercising most of the code, is a challengeamplified by the complexity of the interactions between the environment and thesoftware. Model-based test generation methods can automate otherwise manualprocesses and facilitate reaching rare scenarios during testing. In this paper,we compare using Belief-Desire-Intention (BDI) agents as models for testgeneration with more conventional automata-based techniques that exploit modelchecking, in terms of practicality, performance, transferability to differentscenarios, and exploration (`coverage'), through two case studies: acooperative manufacturing task, and a home care scenario. The results highlightthe advantages of using BDI agents for test generation. BDI agents naturallyemulate the agency present in Human-Robot Interactions (HRIs), and are thusmore expressive than automata. The performance of the BDI-based test generationis at least as high, and the achieved coverage is higher or equivalent,compared to test generation based on model checking automata.",Dejanira Araiza-Illan,2016/9/16,2016/12/12
2209.15075v1,What UAE Software Students Think about Software Testing: A Replicated Study,http://arxiv.org/abs/2209.15075v1,"Software testing is vital to improve software quality. However, softwaretester role is stigmatized, partly due to misperception and partly due to thetreatment of the testing process within the software industry. The presentstudy analyses this situation aiming to explore what might inhibit anindividual from taking up a software testing career. In order to investigatethis issue, we surveyed 132 senior students pursuing degrees in informationsystems, information and communication technology, computer science, computerengineering, software engineering, and other closely-related disciplines atthree universities in the United Arab Emirates: two publicly funded and onetop-notch private university. The students were asked to describe the PROs andCONs of taking up a career in software testing and to ponder the likelihoodthat they would take up the career themselves. The study identified 7 main PROsand 9 main CONSs for pursuing a testing career, and indicated that the role ofsoftware tester is perceived as a social role, which may require as many softskills as technical prowess. The results also show that UAE software-relatedstudents have a stronger negative attitude towards software testing compared totheir counterparts in other countries where similar investigations have beencarried out in the past three years.",Luiz Fernando Capretz,2022/9/29,2022/9/29
2310.15657v1,Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model,http://arxiv.org/abs/2310.15657v1,"Mobile applications have become a ubiquitous part of our daily life,providing users with access to various services and utilities. Text input, asan important interaction channel between users and applications, plays animportant role in core functionality such as search queries, authentication,messaging, etc. However, certain special text (e.g., -18 for Font Size) cancause the app to crash, and generating diversified unusual inputs for fullytesting the app is highly demanded. Nevertheless, this is also challenging dueto the combination of explosion dilemma, high context sensitivity, and complexconstraint relations. This paper proposes InputBlaster which leverages the LLMto automatically generate unusual text inputs for mobile app crash detection.It formulates the unusual inputs generation problem as a task of producing aset of test generators, each of which can yield a batch of unusual text inputsunder the same mutation rule. In detail, InputBlaster leverages LLM to producethe test generators together with the mutation rules serving as the reasoningchain, and utilizes the in-context learning schema to demonstrate the LLM withexamples for boosting the performance. InputBlaster is evaluated on 36 textinput widgets with cash bugs involving 31 popular Android apps, and resultsshow that it achieves 78% bug detection rate, with 136% higher than the bestbaseline. Besides, we integrate it with the automated GUI testing tool anddetect 37 unseen crashes in real-world apps from Google Play.",Zhe Liu,2023/10/24,2023/10/24
2111.05003v2,An Empirical Study of Automated Unit Test Generation for Python,http://arxiv.org/abs/2111.05003v2,"Various mature automated test generation tools exist for statically typedprogramming languages such as Java. Automatically generating unit tests fordynamically typed programming languages such as Python, however, issubstantially more difficult due to the dynamic nature of these languages aswell as the lack of type information. Our Pynguin framework provides automatedunit test generation for Python. In this paper, we extend our previous work onPynguin to support more aspects of the Python language, and by studying alarger variety of well-established state of the art test-generation algorithms,namely DynaMOSA, MIO, and MOSA. Furthermore, we improved our Pynguin tool togenerate regression assertions, whose quality we also evaluate. Our experimentsconfirm that evolutionary algorithms can outperform random test generation alsoin the context of Python, and similar to the Java world, DynaMOSA yields thehighest coverage results. However, our results also demonstrate that there arestill fundamental remaining issues, such as inferring type information for codewithout this information, currently limiting the effectiveness of testgeneration for Python.",Stephan Lukasczyk,2021/11/9,2022/7/17
1912.11519v1,A taxonomy of risk-based testing,http://arxiv.org/abs/1912.11519v1,"Software testing has often to be done under severe pressure due to limitedresources and a challenging time schedule facing the demand to assure thefulfillment of the software requirements. In addition, testing should unveilthose software defects that harm the mission-critical functions of thesoftware. Risk-based testing uses risk (re-)assessments to steer all phases ofthe test process in order to optimize testing efforts and limit risks of thesoftware-based system. Due to its importance and high practical relevanceseveral risk-based testing approaches were proposed in academia and industry.This paper presents a taxonomy of risk-based testing providing a framework tounderstand, categorize, assess, and compare risk-based testing approaches tosupport their selection and tailoring for specific purposes. The taxonomy isaligned with the consideration of risks in all phases of the test process andconsists of the top-level classes risk drivers, risk assessment, and risk-basedtest process. The taxonomy of risk-based testing has been developed byanalyzing the work presented in available publications on risk-based testing.Afterwards, it has been applied to the work on risk-based testing presented inthis special section of the International Journal on Software Tools forTechnology Transfer.",Michael Felderer,2019/12/24,2019/12/24
2012.11163v1,MT-Teql: Evaluating and Augmenting Consistency of Text-to-SQL Models with Metamorphic Testing,http://arxiv.org/abs/2012.11163v1,"Text-to-SQL is a task to generate SQL queries from human utterances. However,due to the variation of natural language, two semantically equivalentutterances may appear differently in the lexical level. Likewise, userpreferences (e.g., the choice of normal forms) can lead to dramatic changes intable structures when expressing conceptually identical schemas. Envisioningthe general difficulty for text-to-SQL models to preserve predictionconsistency against linguistic and schema variations, we propose MT-Teql, aMetamorphic Testing-based framework for systematically evaluating andaugmenting the consistency of TExt-to-SQL models. Inspired by the principles ofsoftware metamorphic testing, MT-Teql delivers a model-agnostic framework whichimplements a comprehensive set of metamorphic relations (MRs) to conductsemantics-preserving transformations toward utterances and schemas. ModelInconsistency can be exposed when the original and transformed inputs inducedifferent SQL queries. In addition, we leverage the transformed inputs toretrain models for further model robustness boost. Our experiments show thatour framework exposes thousands of prediction errors from SOTA models andenriches existing datasets by order of magnitude, eliminating over 40%inconsistency errors without compromising standard accuracy.",Pingchuan Ma,2020/12/21,2020/12/21
2307.10573v2,"Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting",http://arxiv.org/abs/2307.10573v2,"Language models can be prompted to reason through problems in a manner thatsignificantly improves performance. However, \textit{why} such promptingimproves performance is unclear. Recent work showed that using logically\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almostas much as logically \textit{valid} CoT prompting, and that editing CoT promptsto replace problem-specific information with abstract information orout-of-distribution information typically doesn't harm performance. Criticshave responded that these findings are based on too few and too easily solvedtasks to draw meaningful conclusions. To resolve this dispute, we test whetherlogically invalid CoT prompts offer the same level of performance gains aslogically valid prompts on the hardest tasks in the BIG-Bench benchmark, termedBIG-Bench Hard (BBH). We find that the logically \textit{invalid} reasoningprompts do indeed achieve similar performance gains on BBH tasks as logicallyvalid reasoning prompts. We also discover that some CoT prompts used byprevious works contain logical errors. This suggests that covariates beyondlogically valid reasoning are responsible for performance improvements.",Rylan Schaeffer,2023/7/20,2023/7/23
2310.17062v1,"An Open, Programmable, Multi-vendor 5G O-RAN Testbed with NVIDIA ARC and OpenAirInterface",http://arxiv.org/abs/2310.17062v1,"The transition of fifth generation (5G) cellular systems to softwarized,programmable, and intelligent networks depends on successfully enabling publicand private 5G deployments that are (i) fully software-driven and (ii) with aperformance at par with that of traditional monolithic systems. This requireshardware acceleration to scale the Physical (PHY) layer performance, end-to-endintegration and testing, and careful planning of the Radio Frequency (RF)environment. In this paper, we describe how the X5G testbed at NortheasternUniversity has addressed these challenges through the first 8-node networkdeployment of the NVIDIA Aerial Research Cloud (ARC), with the Aerial SDK forthe PHY layer, accelerated on Graphics Processing Unit (GPU), and through itsintegration with higher layers from the OpenAirInterface (OAI) open-sourceproject through the Small Cell Forum Functional Application Platform Interface(FAPI). We discuss software integration, the network infrastructure, and adigital twin framework for RF planning. We then profile the performance with upto 4 Commercial Off-the-Shelf (COTS) smartphones for each base station withiPerf and video streaming applications, measuring a cell rate higher than 500Mbps in downlink and 45 Mbps in uplink.",Davide Villa,2023/10/25,2023/10/25
1504.03449v1,Design Tool To Express Failure Detection Protocols,http://arxiv.org/abs/1504.03449v1,"Failure detection protocols---a fundamental building block for craftingfault-tolerant distributed systems---are in many cases described by theirauthors making use of informal pseudo-codes of their conception. Often thesepseudo-codes use syntactical constructs that are not available in COTSprogramming languages such as C or C++. This translates into informaldescriptions that call for ad hoc interpretations and implementations. Beinginformal, these descriptions cannot be tested by their authors, which maytranslate into insufficiently detailed or even faulty specifications. Thispaper tackles this problem introducing a formal syntax for those constructs anda C library that implements them---a tool-set to express and reason aboutfailure detection protocols. The resulting specifications are longer but nonambiguous, and eligible for becoming a standard form.",Vincenzo De Florio,2015/4/14,2015/4/14
2106.14507v1,Design of a user-friendly control system for planetary rovers with CPS feature,http://arxiv.org/abs/2106.14507v1,"In this paper, we present a user-friendly planetary rover's control systemfor low latency surface telerobotic. Thanks to the proposed system, an operatorcan comfortably give commands through the control base station to a rover usingcommercially available off-the-shelf (COTS) joysticks or by command sequencingwith interactive monitoring on the sensed map of the environment. Duringoperations, high situational awareness is made possible thanks to 3D mapvisualization. The map of the environment is built on the on-board computer byprocessing the rover's camera images with a visual Simultaneous Localizationand Mapping (SLAM) algorithm. It is transmitted via Wi-Fi and displayed on thecontrol base station screen in near real-time. The navigation stack takes asinput the visual SLAM data to build a cost map to find the minimum cost path.By interacting with the virtual map, the rover exhibits properties of a CyberPhysical System (CPS) for its self-awareness capabilities. The softwarearchitecture is based on the Robot Operative System (ROS) middleware. Thesystem design and the preliminary field test results are shown in the paper.",Sebastiano Chiodini,2021/6/28,2021/6/28
1306.3882v2,Chaining Test Cases for Reactive System Testing (extended version),http://arxiv.org/abs/1306.3882v2,"Testing of synchronous reactive systems is challenging because long inputsequences are often needed to drive them into a state at which a desiredfeature can be tested. This is particularly problematic in on-target testing,where a system is tested in its real-life application environment and the timerequired for resetting is high. This paper presents an approach to discoveringa test case chain---a single software execution that covers a group of testgoals and minimises overall test execution time. Our technique targets thescenario in which test goals for the requirements are given as safetyproperties. We give conditions for the existence and minimality of a singletest case chain and minimise the number of test chains if a single test chainis infeasible. We report experimental results with a prototype tool for C codegenerated from Simulink models and compare it to state-of-the-art test suitegenerators.",Peter Schrammel,2013/6/14,2013/11/6
2106.09440v2,Archer: Detecting On-Chain-Off-Chain Synchronization Bugs in Decentralized Applications,http://arxiv.org/abs/2106.09440v2,"Since the emergence of Ethereum, blockchain-based decentralized applications(DApps) have become increasingly popular and important. To balance thesecurity, performance, and costs, a DApp typically consists of two layers: anon-chain layer to execute transactions and store crucial data on the blockchainand an off-chain layer to interact with users. A DApp needs to synchronize itsoff-chain layer with the on-chain layer proactively. Otherwise, theinconsistent data in the off-chain layer could mislead users and causeundesirable consequences, e.g., loss of transaction fees. However, transactionssent to the blockchain are not guaranteed to be executed and could even bereversed after execution due to chain reorganization. Such non-determinism inthe transaction execution is unique to blockchain. DApp developers may fail toperform the on-chain-off-chain synchronization accurately due to their lack offamiliarity with the complex transaction lifecycle. In this work, weinvestigate the challenges of synchronizing on-chain and off-chain data inEthereum-based DApps. We present two types of bugs that could result ininconsistencies between the on-chain and off-chain layers. To help detect suchon-chain-off-chain synchronization bugs, we introduce a state transition modelto guide the testing of DApps and propose two effective oracles to facilitatethe automatic identification of bugs. We build the first testing framework,DArcher, to detect on-chain-off-chain synchronization bugs in DApps. We haveevaluated DArcher on 11 popular real-world DApps. DArcher achieves highprecision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection andsignificantly outperforms the baseline methods. It has found 15 real bugs inthe 11 DApps. So far, six of the 15 bugs have been confirmed by the developers,and three have been fixed. These promising results demonstrate the usefulnessof DArcher.",Wuqi Zhang,2021/6/17,2021/9/7
2310.16049v1,MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning,http://arxiv.org/abs/2310.16049v1,"While large language models (LLMs) equipped with techniques likechain-of-thought prompting have demonstrated impressive capabilities, theystill fall short in their ability to reason robustly in complex settings.However, evaluating LLM reasoning is challenging because system capabilitiescontinue to grow while benchmark datasets for tasks like logical deduction haveremained static. We introduce MuSR, a dataset for evaluating language models onmultistep soft reasoning tasks specified in a natural language narrative. Thisdataset has two crucial features. First, it is created through a novelneurosymbolic synthetic-to-natural generation algorithm, enabling theconstruction of complex reasoning instances that challenge GPT-4 (e.g., murdermysteries roughly 1000 words in length) and which can be scaled further as morecapable LLMs are released. Second, our dataset instances are free textnarratives corresponding to real-world domains of reasoning; this makes itsimultaneously much more challenging than other synthetically-craftedbenchmarks while remaining realistic and tractable for human annotators tosolve with high accuracy. We evaluate a range of LLMs and prompting techniqueson this dataset and characterize the gaps that remain for techniques likechain-of-thought to perform robust reasoning.",Zayne Sprague,2023/10/24,2023/10/24
2108.11723v1,Code Coverage and Test Automation: State of the Art,http://arxiv.org/abs/2108.11723v1,"This chapter surveys the state of the art in code coverage from theperspective of test automation. Our aim is to describe and motivate the threemost popular classes of glass box test coverage models, which are: controlflow, logic and data flow coverage. We take a fairly rigorous approach to codecoverage models. Thus, for each class, we will give precise definitions ofspecific examples, some of which are widely known while others deserve to bebetter known by test engineers. Our main goal is to present coverage modelsthat represent the state of the art. These should stimulate thought regardingbest practice, and indicate future directions for test process improvement.",Karl Meinke,2021/8/26,2021/8/26
1701.06146v1,The Influence of Teamwork Quality on Software Team Performance,http://arxiv.org/abs/1701.06146v1,"Traditionally, software quality is thought to depend on sound softwareengineering and development methodologies such as structured programming andagile development. However, high quality software depends just as much on highquality collaboration within the team. Since the success rate of softwaredevelopment projects is low (Wateridge, 1995; The Standish Group, 2009), it isimportant to understand which characteristics of interactions within softwaredevelopment teams significantly influence performance. Hoegl and Gemuenden(2001) reported empirical evidence for the relation between teamwork qualityand software quality, using a six-factor teamwork quality (TWQ) model. Thisarticle extends the work of Hoegl and Gemuenden (2001) with the aim of findingadditional factors that may influence software team performance. We introducethree new TWQ factors: trust, value sharing, and coordination of expertise. Therelationship between TWQ and team performance and the improvement of the modelare tested using data from 252 team members and stakeholders. Results show thatteamwork quality is significantly related to team performance, as rated by bothteam members and stakeholders: TWQ explains 81% of the variance of teamperformance as rated by team members and 61% as rated by stakeholders. Thisstudy shows that trust, shared values, and coordination of expertise areimportant factors for team leaders to consider in order to achieve high qualitysoftware team work.",Emily Weimar,2017/1/22,2017/1/22
1310.4086v1,A Computational Model of Two Cognitive Transitions Underlying Cultural Evolution,http://arxiv.org/abs/1310.4086v1,"We tested the computational feasibility of the proposal that open-endedcultural evolution was made possible by two cognitive transitions: (1) onset ofthe capacity to chain thoughts together, followed by (2) onset of contextualfocus (CF): the capacity to shift between a divergent mode of thought conduciveto 'breaking out of a rut' and a convergent mode of thought conducive to minormodifications. These transitions were simulated in EVOC, an agent-based modelof cultural evolution, in which the fitness of agents' actions increases asagents invent ideas for new actions, and imitate the fittest of theirneighbors' actions. Both mean fitness and diversity of actions across thesociety increased with chaining, and even more so with CF, as hypothesized. CFwas only effective when the fitness function changed, which supports itshypothesized role in generating and refining ideas.",Liane Gabora,2013/10/15,2013/10/15
2205.15982v1,Testing Research Software: A Survey,http://arxiv.org/abs/2205.15982v1,"Background: Research software plays an important role in solving real-lifeproblems, empowering scientific innovations, and handling emergency situations.Therefore, the correctness and trustworthiness of research software are ofabsolute importance. Software testing is an important activity for identifyingproblematic code and helping to produce high-quality software. However, testingof research software is difficult due to the complexity of the underlyingscience, relatively unknown results from scientific algorithms, and the cultureof the research software community. Aims: The goal of this paper is to betterunderstand current testing practices, identify challenges, and providerecommendations on how to improve the testing process for research softwaredevelopment. Method: We surveyed members of the research software developercommunity to collect information regarding their knowledge about and use ofsoftware testing in their projects. Results: We analysed 120 responses andidentified that even though research software developers report they have anaverage level of knowledge about software testing, they still find it difficultdue to the numerous challenges involved. However, there are a number of ways,such as proper training, that can improve the testing process for researchsoftware. Conclusions: Testing can be challenging for any type of software.This difficulty is especially present in the development of research software,where software engineering activities are typically given less attention. Toproduce trustworthy results from research software, there is a need for aculture change so that testing is valued and teams devote appropriate effort towriting and executing tests.",Nasir U. Eisty,2022/5/31,2022/5/31
2311.06201v1,Myths and Facts about a Career in Software Testing: A Comparison between Students' Beliefs and Professionals' Experience,http://arxiv.org/abs/2311.06201v1,"Testing is an indispensable part of software development. However, a careerin software testing is reported to be unpopular among students in computerscience and related areas. This can potentially create a shortage of testers inthe software industry in the future. The question is, whether the perceptionthat undergraduate students have about software testing is accurate and whetherit differs from the experience reported by those who work in testing activitiesin the software development industry. This investigation demonstrates that acareer in software testing is more exciting and rewarding, as reported byprofessionals working in the field, than students may believe. Therefore, inorder to guarantee a workforce focused on software quality, the academy and thesoftware industry need to work together to better inform students aboutsoftware testing and its essential role in software development.",Ronnie de Souza Santos,2023/11/10,2023/11/10
2211.13622v1,The Westermo test results data set,http://arxiv.org/abs/2211.13622v1,"There is a growing body of knowledge in the computer science, softwareengineering, software testing and software test automation disciplines.However, there is a challenge for researchers to evaluate their researchfindings, innovations and tools due to lack of realistic data. This paperpresents the Westermo test results data set, more than one million verdictsfrom testing of embedded systems, from more than five hundred consecutive daysof nightly testing. The data also contains information on code changes in boththe software under test and the test framework used for testing. This data setcan support the research community in particular with respect to the regressiontest selection problem, flaky tests, test results visualization, etc.",Per Erik Strandberg,2022/11/24,2022/11/24
1212.3248v1,A survey of service oriented architecture systems testing,http://arxiv.org/abs/1212.3248v1,"Service oriented architecture (SOA) is one of the latest softwarearchitectures. This architecture is created in direction of the businessrequirements and removed the gap between softwares and businesses. The softwaretesting is the rising cost of activities in development software. SOA hasdifferent specifications and features proportion of the other softwarearchitectures. First this paper reviews SOA testing challenges and existingsolution(s) for those challenges. Then that reports a survey of recent researchto SOA systems testing, that covers both functional and non-functional testing.Those are presented for different levels of functional testing, including unit,integration, and regression testing.",Ebrahim Shamsoddin-Motlagh,2012/12/13,2012/12/13
1804.01954v1,Testing Scientific Software: A Systematic Literature Review,http://arxiv.org/abs/1804.01954v1,"Context: Scientific software plays an important role in critical decisionmaking, for example making weather predictions based on climate models, andcomputation of evidence for research publications. Recently, scientists havehad to retract publications due to errors caused by software faults. Systematictesting can identify such faults in code.  Objective: This study aims to identify specific challenges, proposedsolutions, and unsolved problems faced when testing scientific software.  Method: We conducted a systematic literature survey to identify and analyzerelevant literature. We identified 62 studies that provided relevantinformation about testing scientific software.  Results: We found that challenges faced when testing scientific software fallinto two main categories: (1) testing challenges that occur due tocharacteristics of scientific software such as oracle problems and (2) testingchallenges that occur due to cultural differences between scientists and thesoftware engineering community such as viewing the code and the model that itimplements as inseparable entities. In addition, we identified methods topotentially overcome these challenges and their limitations. Finally wedescribe unsolved challenges and how software engineering researchers andpractitioners can help to overcome them.  Conclusions: Scientific software presents special challenges for testing.Specifically, cultural differences between scientist developers and softwareengineers, along with the characteristics of the scientific software maketesting more difficult. Existing techniques such as code clone detection canhelp to improve the testing process. Software engineers should consider specialchallenges posed by scientific software such as oracle problems when developingtesting techniques.",Upulee Kanewala,2018/4/5,2018/4/5
1912.09881v1,Morphy: A Datamorphic Software Test Automation Tool,http://arxiv.org/abs/1912.09881v1,"This paper presents an automated tool called Morphy for datamorphic testing.It classifies software test artefacts into test entities and test morphisms,which are mappings on testing entities. In addition to datamorphisms,metamorphisms and seed test case makers, Morphy also employs a set of othertest morphisms including test case metrics and filters, test set metrics andfilters, test result analysers and test executers to realise test automation.In particular, basic testing activities can be automated by invoking testmorphisms. Test strategies can be realised as complex combinations of testmorphisms. Test processes can be automated by recording, editing and playingtest scripts that invoke test morphisms and strategies. Three types of teststrategies have been implemented in Morphy: datamorphism combinationstrategies, cluster border exploration strategies and strategies for test setoptimisation via genetic algorithms. This paper focuses on the datamorphismcombination strategies by giving their definitions and implementationalgorithms. The paper also illustrates their uses for testing both traditionalsoftware and AI applications with three case studies.",Hong Zhu,2019/12/20,2019/12/20
2111.08312v1,Automated System-Level Software Testing of Industrial Networked Embedded Systems,http://arxiv.org/abs/2111.08312v1,"Embedded systems are ubiquitous and play critical roles in management systemsfor industry and transport. Software failures in these domains may lead to lossof production or even loss of life, so the software in these systems needs tobe reliable. Software testing is a standard approach for quality assurance ofembedded software, and many software development processes strive for testautomation. Out of the many challenges for successful software test automation,this thesis addresses five: (i) understanding how updated software reaches atest environment, how testing is conducted in the test environment, and howtest results reach the developers that updated the software in the first place;(ii) selecting which test cases to execute in a test suite given constraints onavailable time and test systems; (iii) given that the test cases are run ondifferent configurations of connected devices, selecting which hardware to usefor each test case to be executed; (iv) analyzing test cases that, whenexecuted over time on evolving software, testware or hardware revisions, appearto randomly fail; and (v) making test results information actionable with testresults exploration and visualization. The challenges are tackled in severalways. [Abstract truncated.]",Per Erik Strandberg,2021/11/16,2021/11/16
1008.2647v1,Searching publications on software testing,http://arxiv.org/abs/1008.2647v1,"This note concerns a search for publications in which the pragmatic conceptof a test as conducted in the practice of software testing is formalized, atheory about software testing based on such a formalization is presented or itis demonstrated on the basis of such a theory that there are solid grounds totest software in cases where in principle other forms of analysis could beused. This note reports on the way in which the search has been carried out andthe main outcomes of the search. The message of the note is that thefundamentals of software testing are not yet complete in some respects.",C. A. Middelburg,2010/8/16,2010/8/16
2310.00385v1,Dynamic Demonstrations Controller for In-Context Learning,http://arxiv.org/abs/2310.00385v1,"In-Context Learning (ICL) is a new paradigm for natural language processing(NLP), where a large language model (LLM) observes a small number ofdemonstrations and a test instance as its input, and directly makes predictionswithout updating model parameters. Previous studies have revealed that ICL issensitive to the selection and the ordering of demonstrations. However, thereare few studies regarding the impact of the demonstration number on the ICLperformance within a limited input length of LLM, because it is commonlybelieved that the number of demonstrations is positively correlated with modelperformance. In this paper, we found this conclusion does not always hold true.Through pilot experiments, we discover that increasing the number ofdemonstrations does not necessarily lead to improved performance. Building uponthis insight, we propose a Dynamic Demonstrations Controller (D$^2$Controller),which can improve the ICL performance by adjusting the number of demonstrationsdynamically. The experimental results show that D$^2$Controller yields a 5.4%relative improvement on eight different sizes of LLMs across ten datasets.Moreover, we also extend our method to previous ICL models and achievecompetitive results.",Fei Zhao,2023/9/30,2023/9/30
2311.07556v1,Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference,http://arxiv.org/abs/2311.07556v1,"Recent studies have demonstrated that large language models (LLMs) excel indiverse tasks through in-context learning (ICL) facilitated by task-specificprompts and examples. However, the existing literature shows that ICLencounters performance deterioration when exposed to adversarial inputs.Enhanced performance has been observed when ICL is augmented with naturallanguage explanations (NLEs) (we refer to it as X-ICL). Thus, this workinvestigates whether X-ICL can improve the robustness of LLMs on a suite ofseven adversarial and challenging natural language inference datasets.Moreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT inour case) with few human-generated NLEs to produce further NLEs (we call itChatGPT few-shot), which we show superior to both ChatGPT zero-shot andhuman-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo,LLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shotyields over 6% improvement over ICL. Furthermore, while prompt selectionstrategies were previously shown to significantly improve ICL onin-distribution test sets, we show that these strategies do not match theefficacy of the X-ICL paradigm in robustness-oriented evaluations.",Xuanli He,2023/11/13,2023/11/13
2202.10675v2,The Transition Region between Brightest Cluster Galaxies and Intra-Cluster Light in Galaxy Groups and Clusters,http://arxiv.org/abs/2202.10675v2,"We take advantage of a state-of-art semi analytic model of galaxy formation,and the model presented in \citet{contini21a}, to investigate the massdistribution of Brightest Cluster Galaxies (BCGs) and Intra-Cluster Light (ICL)by addressing two points: (1) the region of transition between a BCG dominateddistribution and an ICL dominated one, and; (2) the relation between the totalBCG+ICL mass and the ICL one alone. We find the transition radius to beindependent of both BCG+ICL and halo masses, with an average of 60$\pm$40 kpc,in good agreement with previous observational measurements, but given the largescatter, it can be considered as a sort of physical separation between the twocomponents only on cluster scale. From the analysis of $M_{ICL}-M_{BCG+ICL}$relation, we build a method able to extract the ICL mass directly from theknowledge of the BCG+ICL one. Given the large scatter on low mass systems, suchmethod under/overpredicts the true value of the ICL in a significant way, up toa factor of three in the worst cases. On the other hand, for $\logM_{BCG+ICL}>12$ or $\log M_{Halo}>14$, the difference between the true valueand the one extracted from the $M_{ICL}-M_{BCG+ICL}$ relation ranges between$\pm$30\%. We therefore suggest this relation as a reliable test forobservational works aiming to isolate the ICL from the BCG, for systems hostedby haloes on cluster scale.",E. Contini,2022/2/22,2022/3/10
2206.14702v1,Interventional Contrastive Learning with Meta Semantic Regularizer,http://arxiv.org/abs/2206.14702v1,"Contrastive learning (CL)-based self-supervised learning models learn visualrepresentations in a pairwise manner. Although the prevailing CL model hasachieved great progress, in this paper, we uncover an ever-overlookedphenomenon: When the CL model is trained with full images, the performancetested in full images is better than that in foreground areas; when the CLmodel is trained with foreground areas, the performance tested in full imagesis worse than that in foreground areas. This observation reveals thatbackgrounds in images may interfere with the model learning semanticinformation and their influence has not been fully eliminated. To tackle thisissue, we build a Structural Causal Model (SCM) to model the background as aconfounder. We propose a backdoor adjustment-based regularization method,namely Interventional Contrastive Learning with Meta Semantic Regularizer(ICL-MSR), to perform causal intervention towards the proposed SCM. ICL-MSR canbe incorporated into any existing CL methods to alleviate backgrounddistractions from representation learning. Theoretically, we prove that ICL-MSRachieves a tighter error bound. Empirically, our experiments on multiplebenchmark datasets demonstrate that ICL-MSR is able to improve the performancesof different state-of-the-art CL methods.",Wenwen Qiang,2022/6/29,2022/6/29
2305.05940v3,Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment,http://arxiv.org/abs/2305.05940v3,"In-context learning (ICL) unfolds as large language models become capable ofinferring test labels conditioned on a few labeled samples without any gradientupdate. ICL-enabled large language models provide a promising step forwardtoward bypassing recurrent annotation costs in a low-resource setting. Yet,only a handful of past studies have explored ICL in a cross-lingual setting, inwhich the need for transferring label-knowledge from a high-resource languageto a low-resource one is immensely crucial. To bridge the gap, we provide thefirst in-depth analysis of ICL for cross-lingual text classification. We findthat the prevalent mode of selecting random input-label pairs to construct theprompt-context is severely limited in the case of cross-lingual ICL, primarilydue to the lack of alignment in the input as well as the output spaces. Tomitigate this, we propose a novel prompt construction strategy -- Cross-lingualIn-context Source-Target Alignment (X-InSTA). With an injected coherence in thesemantics of the input examples and a task-based alignment across the sourceand target languages, X-InSTA is able to outperform random prompt selection bya large margin across three different tasks using 44 different cross-lingualpairs.",Eshaan Tanwar,2023/5/10,2023/6/24
2305.12766v2,Explaining Emergent In-Context Learning as Kernel Regression,http://arxiv.org/abs/2305.12766v2,"Large language models (LLMs) have initiated a paradigm shift in transferlearning. In contrast to the classic pretraining-then-finetuning procedure, inorder to use LLMs for downstream prediction tasks, one only needs to provide afew demonstrations, known as in-context examples, without adding more orupdating existing model parameters. This in-context learning (ICL) capabilityof LLMs is intriguing, and it is not yet fully understood how pretrained LLMsacquire such capabilities. In this paper, we investigate the reason why atransformer-based language model can accomplish in-context learning afterpre-training on a general language corpus by proposing one hypothesis that LLMscan simulate kernel regression with internal representations when faced within-context examples. More concretely, we first prove that Bayesian inference onin-context prompts can be asymptotically understood as kernel regression $\haty = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$ as the number of in-contextdemonstrations grows. Then, we empirically investigate the in-context behaviorsof language models. We find that during ICL, the attention and hidden featuresin LLMs match the behaviors of a kernel regression. Finally, our theoryprovides insights into multiple phenomena observed in the ICL field: whyretrieving demonstrative samples similar to test samples can help, why ICLperformance is sensitive to the output formats, and why ICL accuracy benefitsfrom selecting in-distribution and representative samples.",Chi Han,2023/5/22,2023/10/5
2312.04945v1,The ICL Consistency Test,http://arxiv.org/abs/2312.04945v1,"Just like the previous generation of task-tuned models, large language models(LLMs) that are adapted to tasks via prompt-based methods likein-context-learning (ICL) perform well in some setups but not in others. Thislack of consistency in prompt-based learning hints at a lack of robustgeneralisation. We here introduce the ICL consistency test -- a contribution tothe GenBench collaborative benchmark task (CBT) -- which evaluates howconsistent a model makes predictions across many different setups while usingthe same data. The test is based on different established natural languageinference tasks. We provide preprocessed data constituting 96 different'setups' and a metric that estimates model consistency across these setups. Themetric is provided on a fine-grained level to understand what properties of asetup render predictions unstable and on an aggregated level to compare overallmodel consistency. We conduct an empirical analysis of eight state-of-the-artmodels, and our consistency metric reveals how all tested LLMs lack robustgeneralisation.",Lucas Weber,2023/12/8,2023/12/8
2212.04769v1,Machine Learning-based Test Selection for Simulation-based Testing of Self-driving Cars Software,http://arxiv.org/abs/2212.04769v1,"Simulation platforms facilitate the development of emerging Cyber-PhysicalSystems (CPS) like self-driving cars (SDC) because they are more efficient andless dangerous than field operational test cases. Despite this, thoroughlytesting SDCs in simulated environments remains challenging because SDCs must betested in a sheer amount of long-running test cases. Past results on softwaretesting optimization have shown that not all the test cases contribute equallyto establishing confidence in test subjects' quality and reliability, and theexecution of ""safe and uninformative"" test cases can be skipped to reducetesting effort. However, this problem is only partially addressed in thecontext of SDC simulation platforms. In this paper, we investigate testselection strategies to increase the cost-effectiveness of simulation-basedtesting in the context of SDCs. We propose an approach called SDC-Scissor (SDCcoSt-effeCtIve teSt SelectOR) that leverages Machine Learning (ML) strategiesto identify and skip test cases that are unlikely to detect faults in SDCsbefore executing them.  Our evaluation shows that SDC-Scissor outperforms the baselines. With theLogistic model, we achieve an accuracy of 70%, a precision of 65%, and a recallof 80% in selecting tests leading to a fault and improved testingcost-effectiveness. Specifically, SDC-Scissor avoided the execution of 50% ofunnecessary tests as well as outperformed two baseline strategies.Complementary to existing work, we also integrated SDC-Scissor into the contextof an industrial organization in the automotive domain to demonstrate how itcan be used in industrial settings.",Christian Birchler,2022/12/9,2022/12/9
2203.12776v1,Methods2Test: A dataset of focal methods mapped to test cases,http://arxiv.org/abs/2203.12776v1,"Unit testing is an essential part of the software development process, whichhelps to identify issues with source code in early stages of development andprevent regressions. Machine learning has emerged as viable approach to helpsoftware developers generate automated unit tests. However, generating reliableunit test cases that are semantically correct and capable of catching softwarebugs or unintended behavior via machine learning requires large, metadata-rich,datasets. In this paper we present Methods2Test: A dataset of focal methodsmapped to test cases: a large, supervised dataset of test cases mapped tocorresponding methods under test (i.e., focal methods). This dataset contains780,944 pairs of JUnit tests and focal methods, extracted from a total of91,385 Java open source projects hosted on GitHub with licenses permittingre-distribution. The main challenge behind the creation of the Methods2Test wasto establish a reliable mapping between a test case and the relevant focalmethod. To this aim, we designed a set of heuristics, based on developers' bestpractices in software testing, which identify the likely focal method for agiven test case. To facilitate further analysis, we store a rich set ofmetadata for each method-test pair in JSON-formatted files. Additionally, weextract textual corpus from the dataset at different context levels, which weprovide both in raw and tokenized forms, in order to enable researchers totrain and evaluate machine learning models for Automated Test Generation.Methods2Test is publicly available at:https://github.com/microsoft/methods2test",Michele Tufano,2022/3/23,2022/3/23
2204.10899v1,Comparative Study of Machine Learning Test Case Prioritization for Continuous Integration Testing,http://arxiv.org/abs/2204.10899v1,"There is a growing body of research indicating the potential of machinelearning to tackle complex software testing challenges. One such challengepertains to continuous integration testing, which is highly time-constrained,and generates a large amount of data coming from iterative code commits andtest runs. In such a setting, we can use plentiful test data for trainingmachine learning predictors to identify test cases able to speed up thedetection of regression bugs introduced during code integration. However,different machine learning models can have different fault predictionperformance depending on the context and the parameters of continuousintegration testing, for example variable time budget available for continuousintegration cycles, or the size of test execution history used for learning toprioritize failing test cases. Existing studies on test case prioritizationrarely study both of these factors, which are essential for the continuousintegration practice. In this study we perform a comprehensive comparison ofthe fault prediction performance of machine learning approaches that have shownthe best performance on test case prioritization tasks in the literature. Weevaluate the accuracy of the classifiers in predicting fault-detecting testsfor different values of the continuous integration time budget and withdifferent length of test history used for training the classifiers. Inevaluation, we use real-world industrial datasets from a continuous integrationpractice. The results show that different machine learning models havedifferent performance for different size of test history used for modeltraining and for different time budget available for test case execution. Ourresults imply that machine learning approaches for test prioritization incontinuous integration testing should be carefully configured to achieveoptimal performance.",Dusica Marijan,2022/4/22,2022/4/22
2010.02542v5,Astraea: Grammar-based Fairness Testing,http://arxiv.org/abs/2010.02542v5,"Software often produces biased outputs. In particular, machine learning (ML)based software are known to produce erroneous predictions when processingdiscriminatory inputs. Such unfair program behavior can be caused by societalbias. In the last few years, Amazon, Microsoft and Google have providedsoftware services that produce unfair outputs, mostly due to societal bias(e.g. gender or race). In such events, developers are saddled with the task ofconducting fairness testing. Fairness testing is challenging; developers aretasked with generating discriminatory inputs that reveal and explain biases.  We propose a grammar-based fairness testing approach (called ASTRAEA) whichleverages context-free grammars to generate discriminatory inputs that revealfairness violations in software systems. Using probabilistic grammars, ASTRAEAalso provides fault diagnosis by isolating the cause of observed software bias.ASTRAEA's diagnoses facilitate the improvement of ML fairness.  ASTRAEA was evaluated on 18 software systems that provide three major naturallanguage processing (NLP) services. In our evaluation, ASTRAEA generatedfairness violations with a rate of ~18%. ASTRAEA generated over 573Kdiscriminatory test cases and found over 102K fairness violations. Furthermore,ASTRAEA improves software fairness by ~76%, via model-retraining.",Ezekiel Soremekun,2020/10/6,2022/1/10
2103.00465v1,On Introducing Automatic Test Case Generation in Practice: A Success Story and Lessons Learned,http://arxiv.org/abs/2103.00465v1,"The level and quality of automation dramatically affects software testingactivities, determines costs and effectiveness of the testing process, andlargely impacts on the quality of the final product. While costs and benefitsof automating many testing activities in industrial practice (includingmanaging the quality process, executing large test suites, and managingregression test suites) are well understood and documented, the benefits andobstacles of automatically generating system test suites in industrial practiceare not well reported yet, despite the recent progresses of automated test casegeneration tools. Proprietary tools for automatically generating test cases arebecoming common practice in large software organisations, and commercial toolsare becoming available for some application domains and testing levels.However, generating system test cases in small and medium-size softwarecompanies is still largely a manual, inefficient and ad-hoc activity. Thispaper reports our experience in introducing techniques for automaticallygenerating system test suites in a medium-size company. We describe thetechnical and organisational obstacles that we faced when introducing automatictest case generation in the development process of the company, and present thesolutions that we successfully experienced in that context. In particular, thepaper discusses the problems of automating the generation of test cases byreferring to a customised ERP application that the medium-size companydeveloped for a third party multinational company, and presents ABT2.0, thetest case generator that we developed by tailoring ABT, a researchstate-of-the-art GUI test generator, to their industrial environment. Thispaper presents the new features of ABT2.0, and discusses how these new featuresaddress the issues that we faced.",Matteo Brunetto,2021/2/28,2021/2/28
2206.07877v1,Roadblocks to Attracting Students to Software Testing Careers: Comparisons of Replicated Studies,http://arxiv.org/abs/2206.07877v1,"Context. Recently, a family of studies highlighted the unpopularity ofsoftware testing careers among undergraduate students in software engineeringand computer science courses. The original study and its replications exploredthe perception of students in universities in four countries (Cana-da, China,India, and Malaysia), and indicated that most students do not consider a careerin software testing as an option after graduation. This scenario represents aproblem for the software industry since the lack of skilled testingprofessionals might decrease the quality of software projects and increase thenumber of unsuccessful projects. Goal. The present study aims to replicate, inBrazil, the studies conducted in the other four countries to establishcomparisons and support the development of strategies to improve the visibilityand importance of software testing among undergraduate students across theglobe. Method. We followed the same protocol in the original study to collectdata using a questionnaire and analyzed the answers using descriptivestatistics and qualitative data analysis. Results. Our findings indicatesimilarities among the results obtained in Brazil in comparison to thoseobtained from other countries. We observed that students are not motivated tofollow a testing career in the software industry based on a belief that testingactivities lack challenges and opportunities for continuous learning.Conclusions. In summary, students seem to be interested in learning more aboutsoftware testing. However, the lack of discussions about the theme in softwaredevelopment courses, as well as the limited offer of courses focused onsoftware quality at the university level reduce the visibility of this area,which causes a decrease in the interest in this career.",Rodrigo E. C. Souza,2022/6/16,2022/6/16
2311.11979v1,On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software,http://arxiv.org/abs/2311.11979v1,"Due to the ever-increasing complexity of income tax laws in the UnitedStates, the number of US taxpayers filing their taxes using tax preparationsoftware (henceforth, tax software) continues to increase. According to theU.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filedtheir individual income taxes using tax software. Given the legal consequencesof incorrectly filing taxes for the taxpayer, ensuring the correctness of taxsoftware is of paramount importance. Metamorphic testing has emerged as aleading solution to test and debug legal-critical tax software due to theabsence of correctness requirements and trustworthy datasets. The key ideabehind metamorphic testing is to express the properties of a system in terms ofthe relationship between one input and its slightly metamorphosed twinnedinput. Extracting metamorphic properties from IRS tax publications is a tediousand time-consuming process. As a response, this paper formulates the task ofgenerating metamorphic specifications as a translation task between propertiesextracted from tax documents - expressed in natural language - to a contrastivefirst-order logic form. We perform a systematic analysis on the potential andlimitations of in-context learning with Large Language Models(LLMs) for thistask, and outline a research agenda towards automating the generation ofmetamorphic specifications for tax preparation software.",Dananjay Srinivas,2023/11/20,2023/11/20
2108.11781v2,On the use of test smells for prediction of flaky tests,http://arxiv.org/abs/2108.11781v2,"Regression testing is an important phase to deliver software with quality.However, flaky tests hamper the evaluation of test results and can increasecosts. This is because a flaky test may pass or fail non-deterministically andto identify properly the flakiness of a test requires rerunning the test suitemultiple times. To cope with this challenge, approaches have been proposedbased on prediction models and machine learning. Existing approaches based onthe use of the test case vocabulary may be context-sensitive and prone tooverfitting, presenting low performance when executed in a cross-projectscenario. To overcome these limitations, we investigate the use of test smellsas predictors of flaky tests. We conducted an empirical study to understand iftest smells have good performance as a classifier to predict the flakiness inthe cross-project context, and analyzed the information gain of each testsmell. We also compared the test smell-based approach with the vocabulary-basedone. As a result, we obtained a classifier that had a reasonable performance(Random Forest, 0.83) to predict the flakiness in the testing phase. Thisclassifier presented better performance than vocabulary-based model forcross-project prediction. The Assertion Roulette and Sleepy Test test smelltypes are the ones associated with the best information gain values.",B. H. P. Camara,2021/8/26,2021/9/14
2208.12136v3,A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks,http://arxiv.org/abs/2208.12136v3,"Software testing activities scrutinize the artifacts and the behavior of asoftware product to find possible defects and ensure that the product meets itsexpected requirements. Recently, Deep Reinforcement Learning (DRL) has beensuccessfully employed in complex testing tasks such as game testing, regressiontesting, and test case prioritization to automate the process and providecontinuous adaptation. Practitioners can employ DRL by implementing fromscratch a DRL algorithm or using a DRL framework. DRL frameworks offerwell-maintained implemented state-of-the-art DRL algorithms to facilitate andspeed up the development of DRL applications. Developers have widely used theseframeworks to solve problems in various domains including software testing.However, to the best of our knowledge, there is no study that empiricallyevaluates the effectiveness and performance of implemented algorithms in DRLframeworks. Moreover, some guidelines are lacking from the literature thatwould help practitioners choose one DRL framework over another. In this paper,we empirically investigate the applications of carefully selected DRLalgorithms on two important software testing tasks: test case prioritization inthe context of Continuous Integration (CI) and game testing. For the gametesting task, we conduct experiments on a simple game and use DRL algorithms toexplore the game to detect bugs. Results show that some of the selected DRLframeworks such as Tensorforce outperform recent approaches in the literature.To prioritize test cases, we run experiments on a CI environment where DRLalgorithms from different frameworks are used to rank the test cases. Ourresults show that the performance difference between implemented algorithms insome cases is considerable, motivating further investigation.",Paulina Stevia Nouwou Mindom,2022/8/25,2023/6/29
2310.01719v1,Software Testing and Code Refactoring: A Survey with Practitioners,http://arxiv.org/abs/2310.01719v1,"Nowadays, software testing professionals are commonly required to developcoding skills to work on test automation. One essential skill required fromthose who code is the ability to implement code refactoring, a valued qualityaspect of software development; however, software developers usually encounterobstacles in successfully applying this practice. In this scenario, the presentstudy aims to explore how software testing professionals (e.g., softwaretesters, test engineers, test analysts, and software QAs) deal with coderefactoring to understand the benefits and limitations of this practice in thecontext of software testing. We followed the guidelines to conduct surveys insoftware engineering and applied three sampling techniques, namely conveniencesampling, purposive sampling, and snowballing sampling, to collect data fromtesting professionals. We received answers from 80 individuals reporting theirexperience refactoring the code of automated tests. We concluded that in thecontext of software testing, refactoring offers several benefits, such assupporting the maintenance of automated tests and improving the performance ofthe testing team. However, practitioners might encounter barriers ineffectively implementing this practice, in particular, the lack of interestfrom managers and leaders. Our study raises discussions on the importance ofhaving testing professionals implement refactoring in the code of automatedtests, allowing them to improve their coding abilities.",Danilo Leandro Lima,2023/10/3,2023/10/3
2011.01834v2,Reinforcement Learning for Test Case Prioritization,http://arxiv.org/abs/2011.01834v2,"Continuous Integration (CI) significantly reduces integration problems,speeds up development time, and shortens release time. However, it alsointroduces new challenges for quality assurance activities, includingregression testing, which is the focus of this work. Though various approachesfor test case prioritization have shown to be very promising in the context ofregression testing, specific techniques must be designed to deal with thedynamic nature and timing constraints of CI.  Recently, Reinforcement Learning (RL) has shown great potential in variouschallenging scenarios that require continuous adaptation, such as game playing,real-time ads bidding, and recommender systems. Inspired by this line of workand building on initial efforts in supporting test case prioritization with RLtechniques, we perform here a comprehensive investigation of RL-based test caseprioritization in a CI context. To this end, taking test case prioritization asa ranking problem, we model the sequential interactions between the CIenvironment and a test case prioritization agent as an RL problem, using threealternative ranking models. We then rely on carefully selected and tailoredstate-of-the-art RL techniques to automatically and continuously learn a testcase prioritization strategy, whose objective is to be as close as possible tothe optimal one. Our extensive experimental analysis shows that the best RLsolutions provide a significant accuracy improvement over previous RL-basedwork, with prioritization strategies getting close to being optimal, thuspaving the way for using RL to prioritize test cases in a CI context.",Mojtaba Bagherzadeh,2020/11/3,2021/3/25
2306.02907v1,SelfEvolve: A Code Evolution Framework via Large Language Models,http://arxiv.org/abs/2306.02907v1,"Large language models (LLMs) have already revolutionized code generation,after being pretrained on publicly available code data. However, while variousmethods have been proposed to augment LLMs with retrieved knowledge and enhancethe quality of code generation, the performance of these retrieval-basedmethods is limited by the strength of the retrievers used. In addition, whileLLMs show great emergent ability, they still struggle to produce the correctcode in one turn. To address these challenges, we propose a novel two-steppipeline, called \autoknow, that leverages LLMs as both knowledge providers andself-reflective programmers. Unlike retrieval-based methods, \autoknow~obtainsthe knowledge from input prompts and generates intermediate code based on thegenerated knowledge. After that, \autoknow~asks LLM to act as an expertprogrammer to perform debugging for the generated code. This is achieved byreceiving the error message from the interpreter, without requiring specialtest cases for correctness verification. We evaluate \autoknow~on three codegeneration datasets, including DS-1000 for data science code, HumanEval forsoftware engineering code, and TransCoder for C++-to-Python translation. Ourempirical experiments show that \autoknow~outperforms strong baselines by asignificant margin on all datasets. We also conduct exhaustive analyticalexperiments to validate the effectiveness of the two stages of \autoknow, andfind that both are superior to other prompting-based methods. Furtherscalability analysis demonstrates that \autoknow~can be adapted to other moreadvanced models, such as GPT-4, and bring consistent efficacy improvement.",Shuyang Jiang,2023/6/5,2023/6/5
2302.03848v1,Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based Learning,http://arxiv.org/abs/2302.03848v1,"Prompt-based or in-context learning has achieved high zero-shot performanceon many natural language generation (NLG) tasks. Here we explore theperformance of prompt-based learning for simultaneously controlling thepersonality and the semantic accuracy of an NLG for task-oriented dialogue. Weexperiment with prompt-based learning on the PERSONAGE restaurantrecommendation corpus to generate semantically and stylistically-controlledtext for 5 different Big-5 personality types: agreeable, disagreeable,conscientious, unconscientious, and extravert. We test two different classes ofdiscrete prompts to generate utterances for a particular personality style: (1)prompts that demonstrate generating directly from a meaning representation thatincludes a personality specification; and (2) prompts that rely on firstconverting the meaning representation to a textual pseudo-reference, and thenusing the pseudo-reference in a textual style transfer (TST) prompt. In eachcase, we show that we can vastly improve performance by over-generating outputsand ranking them, testing several ranking functions based on automatic metricsfor semantic accuracy, personality-match, and fluency. We also test whether NLGpersonality demonstrations from the restaurant domain can be used with meaningrepresentations for the video game domain to generate personality stylizedutterances about video games. Our findings show that the TST prompts producesthe highest semantic accuracy (78.46% for restaurants and 87.6% for videogames) and personality accuracy (100% for restaurants and 97% for video games).Our results on transferring personality style to video game utterances aresurprisingly good. To our knowledge, there is no previous work testing theapplication of prompt-based learning to simultaneously controlling both styleand semantic accuracy in NLG.",Angela Ramirez,2023/2/8,2023/2/8
2304.01964v2,"PromptAid: Prompt Exploration, Perturbation, Testing and Iteration using Visual Analytics for Large Language Models",http://arxiv.org/abs/2304.01964v2,"Large Language Models (LLMs) have gained widespread popularity due to theirability to perform ad-hoc Natural Language Processing (NLP) tasks with a simplenatural language prompt. Part of the appeal for LLMs is their approachabilityto the general public, including individuals with no prior technical experiencein NLP techniques. However, natural language prompts can vary significantly interms of their linguistic structure, context, and other semantics. Modifyingone or more of these aspects can result in significant differences in taskperformance. Non-expert users may find it challenging to identify the changesneeded to improve a prompt, especially when they lack domain-specific knowledgeand lack appropriate feedback. To address this challenge, we present PromptAid,a visual analytics system designed to interactively create, refine, and testprompts through exploration, perturbation, testing, and iteration. PromptAiduses multiple, coordinated visualizations which allow users to improve promptsby using the three strategies: keyword perturbations, paraphrasingperturbations, and obtaining the best set of in-context few-shot examples.PromptAid was designed through an iterative prototyping process involving NLPexperts and was evaluated through quantitative and qualitative assessments forLLMs. Our findings indicate that PromptAid helps users to iterate over prompttemplate alterations with less cognitive overhead, generate diverse promptswith help of recommendations, and analyze the performance of the generatedprompts while surpassing existing state-of-the-art prompting interfaces inperformance.",Aditi Mishra,2023/4/4,2023/4/8
2310.15780v1,Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions,http://arxiv.org/abs/2310.15780v1,"Automated Graphical User Interface (GUI) testing plays a crucial role inensuring app quality, especially as mobile applications have become an integralpart of our daily lives. Despite the growing popularity of learning-basedtechniques in automated GUI testing due to their ability to generate human-likeinteractions, they still suffer from several limitations, such as low testingcoverage, inadequate generalization capabilities, and heavy reliance ontraining data. Inspired by the success of Large Language Models (LLMs) likeChatGPT in natural language understanding and question answering, we formulatethe mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLMto chat with the mobile apps by passing the GUI page information to LLM toelicit testing scripts, and executing them to keep passing the app feedback toLLM, iterating the whole process. Within this framework, we have alsointroduced a functionality-aware memory prompting mechanism that equips the LLMwith the ability to retain testing knowledge of the whole process and conductlong-term, functionality-based reasoning to guide exploration. We evaluate iton 93 apps from Google Play and demonstrate that it outperforms the bestbaseline by 32% in activity coverage, and detects 31% more bugs at a fasterrate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 havebeen confirmed and fixed.",Zhe Liu,2023/10/24,2023/10/24
2305.12900v2,Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph,http://arxiv.org/abs/2305.12900v2,"There have been many recent investigations into prompt-based training oftransformer language models for new text genres in low-resource settings. Theprompt-based training approach has been found to be effective in generalizingpre-trained or fine-tuned models for transfer to resource-scarce settings. Thiswork, for the first time, reports results on adopting prompt-based training oftransformers for \textit{scholarly knowledge graph object prediction}. The workis unique in the following two main aspects. 1) It deviates from the otherworks proposing entity and relation extraction pipelines for predicting objectsof a scholarly knowledge graph. 2) While other works have tested the method ontext genera relatively close to the general knowledge domain, we test themethod for a significantly different domain, i.e. scholarly knowledge, in turntesting the linguistic, probabilistic, and factual generalizability of theselarge-scale transformer models. We find that (i) per expectations, transformermodels when tested out-of-the-box underperform on a new domain of data, (ii)prompt-based training of the models achieve performance boosts of up to 40\% ina relaxed evaluation setting, and (iii) testing the models on a starklydifferent domain even with a clever training objective in a low resourcesetting makes evident the domain knowledge capture gap offering anempirically-verified incentive for investing more attention and resources tothe scholarly domain in the context of transformer models.",Jennifer D'Souza,2023/5/22,2023/6/11
1803.09006v2,Combinatorial Modeling and Test Case Generation for Industrial Control Software using ACTS,http://arxiv.org/abs/1803.09006v2,"Combinatorial testing has been suggested as an effective method of creatingtest cases at a lower cost. However, industrially applicable tools for modelingand combinatorial test generation are still scarce. As a direct effect,combinatorial testing has only seen a limited uptake in industry that callsinto question its practical usefulness. This lack of evidence is especiallytroublesome if we consider the use of combinatorial test generation forindustrial safety-critical control software, such as are found in trains,airplanes, and power plants. To study the industrial application ofcombinatorial testing, we evaluated ACTS, a popular tool for combinatorialmodeling and test generation, in terms of applicability and test efficiency onindustrial-sized IEC 61131-3 industrial control software running onProgrammable Logic Controllers (PLC). We assessed ACTS in terms of its directapplicability in combinatorial modeling of IEC 61131-3 industrial software andthe efficiency of ACTS in terms of generation time and test suite size. We used17 industrial control programs provided by Bombardier Transportation Sweden ABand used in a train control management system. Our results show that not allcombinations of algorithms and interaction strengths could generate a testsuite within a realistic cut-off time. The results of the modeling process andthe efficiency evaluation of ACTS are useful for practitioners considering touse combinatorial testing for industrial control software as well as forresearchers trying to improve the use of such combinatorial testing techniques.",Sara Ericsson,2018/3/23,2018/6/11
1906.06144v1,Studies on the Software Testing Profession,http://arxiv.org/abs/1906.06144v1,"This paper attempts to understand motivators and de-motivators that influencethe decisions of software professionals to take up and sustain software testingcareers across four different countries, i.e. Canada, China, Cuba, and India.The research question can be framed as ""How many software professionals acrossdifferent geographies are keen to take up testing careers, and what are thereasons for their choices?"" Towards that, we developed a cross-sectional butsimple survey-based instrument. In this study we investigated how softwaretesters perceived and valued what they do and their environmental settings. Thestudy pointed out the importance of visualizing software testing activities asa set of human-dependent tasks and emphasized the need for research thatexamines critically individual assessments of software testers about softwaretesting activities. This investigation can help global industry leaders tounderstand the impact of work-related factors on the motivation of testingprofessionals, as well as inform and support management and leadership in thiscontext.",Luiz Fernando Capretz,2019/6/12,2019/6/12
1908.01476v1,Testability First!,http://arxiv.org/abs/1908.01476v1,"The pivotal role of testing in high-quality software production has driven asignificant effort in evaluating and assessing testing practices. We explorethe state of testing in a large industrial project over an extended period. Westudy the interplay between bugs in the project and its test cases, andinterview developers and stakeholders to uncover reasons underpinning ourobservations. We realized that testing is not well adopted, and thattestability (ie, ease of testing) is low. We found that developers tended toabandon writing tests when they assessed the effort to be high. Frequentchanges in requirements and pressure to add new features also hindereddevelopers from writing tests. Regardless of the debates on test first orlater, we hypothesize that the underlying reasons for poor test quality arerooted in a lack of attention to testing early in the development of a softwarecomponent, leading to poor testability of the component. However, testabilityis usually overlooked in research that studies the impact of testing practices,and should be explicitly taken into account.",Mohammad Ghafari,2019/8/5,2019/8/5
2005.12570v2,Assessing the maturity of software testing services using CMMI-SVC: An industrial case study,http://arxiv.org/abs/2005.12570v2,"Context: While many companies conduct their software testing activitiesin-house, many other companies outsource their software testing needs to otherfirms who act as software testing service providers. As a result, Testing as aService (TaaS) has emerged as a strong service industry in the last severaldecades. In the context of software testing services, there could be variouschallenges (e.g., during the planning and service delivery phases) and, as aresult, the quality of testing services is not always as expected. Objective:It is important, for both providers and also customers of testing services, toassess the quality and maturity of test services and subsequently improve them.Method: Motivated by a real industrial need in the context of several testingservice providers, to assess the maturity of their software testing services,we chose the existing CMMI for Services maturity model (CMMI-SVC), andconducted a case study using it in the context of two Turkish testing serviceproviders. Results: The case-study results show that maturity appraisal oftesting services using CMMI-SVC was helpful for both companies and their testmanagement teams by enabling them objectively assess the maturity of theirtesting services and also by pinpointing potential improvement areas.Conclusion: We empirically observed that, after some minor customization,CMMI-SVC is indeed a suitable model for maturity appraisal of testing services.",Vahid Garousi,2020/5/26,2020/5/30
2207.01047v1,An Empirical Study of Flaky Tests in JavaScript,http://arxiv.org/abs/2207.01047v1,"Flaky tests (tests with non-deterministic outcomes) can be problematic fortesting efficiency and software reliability. Flaky tests in test suites canalso significantly delay software releases. There have been several studiesthat attempt to quantify the impact of test flakiness in different programminglanguages (e.g., Java and Python) and application domains (e.g., mobile andGUI-based). In this paper, we conduct an empirical study of the state of flakytests in JavaScript. We investigate two aspects of flaky tests in JavaScriptprojects: the main causes of flaky tests in these projects and common fixingstrategies. By analysing 452 commits from large, top-scoring JavaScriptprojects from GitHub, we found that flakiness caused by concurrency-relatedissues (e.g., async wait, race conditions or deadlocks) is the most dominantreason for test flakiness. The other top causes of flaky tests are operatingsystem-specific (e.g., features that work on specific OS or OS versions) andnetwork stability (e.g., internet availability or bad socket management). Interms of how flaky tests are dealt with, the majority of those flaky tests(>80%) are fixed to eliminate flaky behaviour and developers sometimes skip,quarantine or remove flaky tests.",Negar Hashemi,2022/7/3,2022/7/3
1705.09822v2,The risk factors affecting to the software quality failures in Sri Lankan Software industry,http://arxiv.org/abs/1705.09822v2,"Software project failure and cancellation rates increase day by day due totechnical failures, quality failures, lack of end client acceptance etc. andalso the lack of proper management. There are a number of reasons affected bythe software project failures. According to empirical evidence, inadequatetesting resources are one of the major factors that contribute to the poorquality. The main objectives of this study are to study the risk factors thataffect the software quality to provide some recommendation to minimize the riskof poor quality. There are three main factors affecting to software qualitynamely proper testing, test planning and QA team which are directly impacted tothe software quality risks. To conduct this study, I employed an open-endedquestionnaire for collecting qualitative data from responses analyzed themusing thematic approach method. The participants with their experiences agreedonly with requirement clarity and clearly defined acceptance criteria, not withadequate unit testing and finally and also with that not doing regressiontesting force to quality failures. As of data analysis, not having properformal test planning, initial test planning not being realistic, not followingquality risk management, non-proper process and contingency action planningalso lead to the risk of poor project quality. According to the participantsadded that the following factors are also behind the reasons for the lackquality of software. The experienced and skilled employees move out from thecompany as there is not a proper QA process and team members as they do nothave the risk management mentality.",Namadawa Bashini Jeewanthi Gamage,2017/5/27,2017/6/4
2010.13464v3,What It Would Take to Use Mutation Testing in Industry--A Study at Facebook,http://arxiv.org/abs/2010.13464v3,"Traditionally, mutation testing generates an abundance of small deviations ofa program, called mutants. At industrial systems the scale and size ofFacebook's, doing this is infeasible. We should not create mutants that thetest suite would likely fail on or that give no actionable signal todevelopers. To tackle this problem, in this paper, we semi-automatically learnerror-inducing patterns from a corpus of common Java coding errors and fromchanges that caused operational anomalies at Facebook specifically. We combinethe mutations with instrumentation that measures which tests exactly visitedthe mutated piece of code. Results on more than 15,000 generated mutants showthat more than half of the generated mutants survive Facebook's rigorous testsuite of unit, integration, and system tests. Moreover, in a case study with 26developers, all but two found information of automatically detected test holesinteresting in principle. As such, almost half of the 26 would actually act onthe mutant presented to them by adapting an existing or creating a new test.The others did not for a variety of reasons often outside the scope of mutationtesting. It remains a practical challenge how we can include such externalinformation to increase the true actionability rate on mutants.",Moritz Beller,2020/10/26,2021/1/27
2308.07949v1,Fuzzing for CPS Mutation Testing,http://arxiv.org/abs/2308.07949v1,"Mutation testing can help reduce the risks of releasing faulty software. Forsuch reason, it is a desired practice for the development of embedded softwarerunning in safety-critical cyber-physical systems (CPS). Unfortunately,state-of-the-art test data generation techniques for mutation testing of C andC++ software, two typical languages for CPS software, rely on symbolicexecution, whose limitations often prevent its application (e.g., it cannottest black-box components).  We propose a mutation testing approach that leverages fuzz testing, which hasproved effective with C and C++ software. Fuzz testing automatically generatesdiverse test inputs that exercise program branches in a varied number of waysand, therefore, exercise statements in different program states, thusmaximizing the likelihood of killing mutants, our objective.  We performed an empirical assessment of our approach with software componentsused in satellite systems currently in orbit. Our empirical evaluation showsthat mutation testing based on fuzz testing kills a significantly higherproportion of live mutants than symbolic execution (i.e., up to an additional47 percentage points). Further, when symbolic execution cannot be applied, fuzztesting provides significant benefits (i.e., up to 41% mutants killed). Ourstudy is the first one comparing fuzz testing and symbolic execution formutation testing; our results provide guidance towards the development of fuzztesting tools dedicated to mutation testing.",Jaekwon Lee,2023/8/15,2023/8/15
2007.08927v3,Towards a Model of Testers' Cognitive Processes: Software Testing as a Problem Solving Approach,http://arxiv.org/abs/2007.08927v3,"Software testing is a complex, intellectual activity based (at least) onanalysis, reasoning, decision making, abstraction and collaboration performedin a highly demanding environment. Naturally, it uses and allocates multiplecognitive resources in software testers. However, while a cognitive psychologyperspective is increasingly used in the general software engineeringliterature, it has yet to find its place in software testing. To the best ofour knowledge, no theory of software testers' cognitive processes exists. Here,we take the first step towards such a theory by presenting a cognitive model ofsoftware testing based on how problem solving is conceptualized in cognitivepsychology. Our approach is to instantiate a general problem solving processfor the specific problem of creating test cases. We then propose an experimentfor testing our cognitive test design model. The experiment makes use of verbalprotocol analysis to understand the mechanisms by which human testers choose,design, implement and evaluate test cases. An initial evaluation was thenperformed with five software engineering master students as subjects. Theresults support a problem solving-based model of test design for capturingtesters' cognitive processes.",Eduard Enoiu,2020/7/17,2020/12/9
1302.5215v1,Development Of Ontology-Based Intelligent System For Software Testing,http://arxiv.org/abs/1302.5215v1,"Software testing is a prime factor in software industry. Besides knowing theimportance of testing, only limited time is allocated for teaching it. It willbe more efficient if testing is taught simultaneously with programmingfoundations. This integrated learning of testing techniques and programmingallows the programmers to perform in a better way and this leads to theimprovement of the performance of the industry progress. In this paper, atechnique named ontology is introduced, it first defines the various testingprocess in hierarchy and define relationships among them, to share and reusethe knowledge that is captured, secondly metadata is created by naturallanguage processing and finally, the application use ontologies to support testmanagement, it act as knowledge base for multiple environment with theintegrated teaching of programming foundation and testing concepts. Keywords:Meta Data, Ontology, Software Testing, Integration, Programming Foundations.",A. Anandaraj,2013/2/21,2013/2/21
2103.01783v4,How Developers Engineer Test Cases: An Observational Study,http://arxiv.org/abs/2103.01783v4,"One of the main challenges that developers face when testing their systemslies in engineering test cases that are good enough to reveal bugs. And whileour body of knowledge on software testing and automated test case generation isalready quite significant, in practice, developers are still the onesresponsible for engineering test cases manually. Therefore, understanding thedevelopers' thought- and decision-making processes while engineering test casesis a fundamental step in making developers better at testing software. In thispaper, we observe 13 developers thinking-aloud while testing differentreal-world open-source methods, and use these observations to explain howdevelopers engineer test cases. We then challenge and augment our main findingsby surveying 72 software developers on their testing practices. We discuss ourresults from three different angles. First, we propose a general framework thatexplains how developers reason about testing. Second, we propose and describein detail the three different overarching strategies that developers apply whentesting. Third, we compare and relate our observations with the existing bodyof knowledge and propose future studies that would advance our knowledge on thetopic.",Maurcio Aniche,2021/3/1,2021/11/6
1404.6801v1,Nothing is Certain but Doubt and Tests,http://arxiv.org/abs/1404.6801v1,"Effective software safety standards will contribute to confidence, orassurance, in the safety of the systems in which the software is used. It isinfeasible to demonstrate a correlation between standards and accidents, butthere is an alternative view that makes standards ""testable"". Software projectsare subject to uncertainty; good standards reduce uncertainty more than poorones. Similarly assurance or integrity levels in standards should define anuncertainty gradient. The paper proposes an argument -based method of reasoningabout uncertainty that can be used as a basis for conducting experiments(tests) to evaluate standards.",John A. McDermid,2014/4/27,2014/4/27
2303.01302v1,Reasoning-Based Software Testing,http://arxiv.org/abs/2303.01302v1,"With software systems becoming increasingly pervasive and autonomous, ourability to test for their quality is severely challenged. Many systems arecalled to operate in uncertain and highly-changing environment, not rarelyrequired to make intelligent decisions by themselves. This easily results in anintractable state space to explore at testing time. The state-of-the-arttechniques try to keep the pace, e.g., by augmenting the tester's intuitionwith some form of (explicit or implicit) learning from observations to searchthis space efficiently. For instance, they exploit historical data to drive thesearch (e.g., ML-driven testing) or the tests execution data itself (e.g.,adaptive or search-based testing). Despite the indubitable advances, the needfor smartening the search in such a huge space keeps to be pressing.  We introduce Reasoning-Based Software Testing (RBST), a new way of thinkingat the testing problem as a causal reasoning task. Compared to mereintuition-based or state-of-the-art learning-based strategies, we claim thatcausal reasoning more naturally emulates the process that a human would do to''smartly"" search the space. RBST aims to mimic and amplify, with the power ofcomputation, this ability. The conceptual leap can pave the ground to a newtrend of techniques, which can be variously instantiated from the proposedframework, by exploiting the numerous tools for causal discovery and inference.Preliminary results reported in this paper are promising.",Luca Giamattei,2023/3/2,2023/3/2
2105.13798v4,Contextuality degree of quadrics in multi-qubit symplectic polar spaces,http://arxiv.org/abs/2105.13798v4,"Quantum contextuality takes an important place amongst the concepts ofquantum computing that bring an advantage over its classical counterpart. For alarge class of contextuality proofs, aka. observable-based proofs of theKochen-Specker Theorem, we formulate the contextuality property as the absenceof solutions to a linear system and define for a contextual configuration itsdegree of contextuality. Then we explain why subgeometries of binary symplecticpolar spaces are candidates for contextuality proofs. We report the results ofa software that generates these subgeometries, decides their contextuality andcomputes their contextuality degree for some small symplectic polar spaces. Weshow that quadrics in the symplectic polar space $W_n$ are contextual for$n=3,4,5$. The proofs we consider involve more contexts and observables thanthe smallest known proofs. This intermediate size property of those proofs isinteresting for experimental tests, but could also be interesting in quantumgame theory.",Henri de Boutray,2021/5/28,2023/3/20
1804.02533v1,MobiCoMonkey - Context Testing of Android Apps,http://arxiv.org/abs/1804.02533v1,"The functionality of many mobile applications is dependent on variouscontextual, external factors. Depending on unforeseen scenarios, mobile appscan even malfunction or crash. In this paper, we have introduced MobiCoMonkey -automated tool that allows a developer to test app against custom or autogenerated contextual scenarios and help detect possible bugs through theemulator. Moreover, it reports the connection between the bugs and contextualfactors so that the bugs can later be reproduced. It utilizes the tools offeredby Android SDK and logcat to inject events and capture traces of the appexecution.",Amit Seal Ami,2018/4/7,2018/4/7
2309.14519v1,ChatGPT Performance on Standardized Testing Exam -- A Proposed Strategy for Learners,http://arxiv.org/abs/2309.14519v1,"This study explores the problem solving capabilities of ChatGPT and itsprospective applications in standardized test preparation, focusing on the GREquantitative exam. Prior research has shown great potential for the utilizationof ChatGPT for academic purposes in revolutionizing the approach to studyingacross various disciplines. We investigate how ChatGPT performs across variousquestion types in the GRE quantitative domain, and how modifying questionprompts impacts its accuracy. More specifically this study addressed tworesearch questions: 1. How does ChatGPT perform in answering GRE-basedquantitative questions across various content areas? 2. How does the accuracyof ChatGPT vary with modifying the question prompts? The dataset consisting of100 randomly selected GRE quantitative questions was collected from the ETSofficial guide to GRE test preparation. We used quantitative evaluation toanswer our first research question, and t-test to examine the statisticalassociation between prompt modification and ChatGPT's accuracy. Results show astatistical improvement in the ChatGPT's accuracy after applying instructionpriming and contextual prompts to the original questions. ChatGPT showed 84%accuracy with the modified prompts compared to 69% with the original data. Thestudy discusses the areas where ChatGPT struggled with certain questions andhow modifications can be helpful for preparing for standardized tests like GREand provides future directions for prompt modifications.",Umer Farooq,2023/9/25,2023/9/25
2102.09690v2,Calibrate Before Use: Improving Few-Shot Performance of Language Models,http://arxiv.org/abs/2102.09690v2,"GPT-3 can perform numerous tasks when provided a natural language prompt thatcontains a few training examples. We show that this type of few-shot learningcan be unstable: the choice of prompt format, training examples, and even theorder of the training examples can cause accuracy to vary from near chance tonear state-of-the-art. We demonstrate that this instability arises from thebias of language models towards predicting certain answers, e.g., those thatare placed near the end of the prompt or are common in the pre-training data.To mitigate this, we first estimate the model's bias towards each answer byasking for its prediction when given the training prompt and a content-freetest input such as ""N/A"". We then fit calibration parameters that cause theprediction for this input to be uniform across answers. On a diverse set oftasks, this contextual calibration procedure substantially improves GPT-3 andGPT-2's average accuracy (up to 30.0% absolute) and reduces variance acrossdifferent choices of the prompt.",Tony Z. Zhao,2021/2/19,2021/6/10
2312.08282v2,Prompting LLMs with content plans to enhance the summarization of scientific articles,http://arxiv.org/abs/2312.08282v2,"This paper presents novel prompting techniques to improve the performance ofautomatic summarization systems for scientific articles. Scientific articlesummarization is highly challenging due to the length and complexity of thesedocuments. We conceive, implement, and evaluate prompting techniques thatprovide additional contextual information to guide summarization systems.Specifically, we feed summarizers with lists of key terms extracted fromarticles, such as author keywords or automatically generated keywords. Ourtechniques are tested with various summarization models and input texts.Results show performance gains, especially for smaller models summarizingsections separately. This evidences that prompting is a promising approach toovercoming the limitations of less powerful systems. Our findings introduce anew research direction of using prompts to aid smaller models.",Aldan Creo,2023/12/13,2023/12/15
2311.15812v1,C-SAW: Self-Supervised Prompt Learning for Image Generalization in Remote Sensing,http://arxiv.org/abs/2311.15812v1,"We focus on domain and class generalization problems in analyzing opticalremote sensing images, using the large-scale pre-trained vision-language model(VLM), CLIP. While contrastively trained VLMs show impressive zero-shotgeneralization performance, their effectiveness is limited when dealing withdiverse domains during training and testing. Existing prompt learningtechniques overlook the importance of incorporating domain and contentinformation into the prompts, which results in a drop in performance whiledealing with such multi-domain data. To address these challenges, we propose asolution that ensures domain-invariant prompt learning while enhancing theexpressiveness of visual features. We observe that CLIP's vision encoderstruggles to identify contextual image information, particularly when imagepatches are jumbled up. This issue is especially severe in optical remotesensing images, where land-cover classes exhibit well-defined contextualappearances. To this end, we introduce C-SAW, a method that complements CLIPwith a self-supervised loss in the visual space and a novel prompt learningtechnique that emphasizes both visual domain and content-specific features. Wekeep the CLIP backbone frozen and introduce a small set of projectors for boththe CLIP encoders to train C-SAW contrastively. Experimental resultsdemonstrate the superiority of C-SAW across multiple remote sensing benchmarksand different generalization tasks.",Avigyan Bhattacharya,2023/11/27,2023/11/27
1801.05917v1,A Large-Scale Empirical Comparison of Static and Dynamic Test Case Prioritization Techniques,http://arxiv.org/abs/1801.05917v1,"The large body of existing research in Test Case Prioritization (TCP)techniques, can be broadly classified into two categories: dynamic techniques(that rely on run-time execution information) and static techniques (thatoperate directly on source and test code). Absent from this current body ofwork is a comprehensive study aimed at understanding and evaluating the staticapproaches and comparing them to dynamic approaches on a large set of projects.  In this work, we perform the first extensive study aimed at empiricallyevaluating four static TCP techniques comparing them with state-of-researchdynamic TCP techniques at different test-case granularities (e.g., method andclass-level) in terms of effectiveness, efficiency and similarity of faultsdetected. This study was performed on 30 real-word Java programs encompassing431 KLoC. In terms of effectiveness, we find that the static call-graph-basedtechnique outperforms the other static techniques at test-class level, but thetopic-model-based technique performs better at test-method level. In terms ofefficiency, the static call-graph-based technique is also the most efficientwhen compared to other static techniques. When examining the similarity offaults detected for the four static techniques compared to the four dynamicones, we find that on average, the faults uncovered by these two groups oftechniques are quite dissimilar, with the top 10% of test cases agreeing ononly 25% - 30% of detected faults. This prompts further research into theseverity/importance of faults uncovered by these techniques, and into thepotential for combining static and dynamic information for more effectiveapproaches.",Qi Luo,2018/1/18,2018/1/18
2212.04145v2,Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation,http://arxiv.org/abs/2212.04145v2,"Continual Test-Time Adaptation (CTTA) aims to adapt the source model tocontinually changing unlabeled target domains without access to the sourcedata. Existing methods mainly focus on model-based adaptation in aself-training manner, such as predicting pseudo labels for new domain datasets.Since pseudo labels are noisy and unreliable, these methods suffer fromcatastrophic forgetting and error accumulation when dealing with dynamic datadistributions. Motivated by the prompt learning in NLP, in this paper, wepropose to learn an image-level visual domain prompt for target domains whilehaving the source model parameters frozen. During testing, the changing targetdatasets can be adapted to the source model by reformulating the input datawith the learned visual prompts. Specifically, we devise two types of prompts,i.e., domains-specific prompts and domains-agnostic prompts, to extract currentdomain knowledge and maintain the domain-shared knowledge in the continualadaptation. Furthermore, we design a homeostasis-based prompt adaptationstrategy to suppress domain-sensitive parameters in domain-invariant prompts tolearn domain-shared knowledge more effectively. This transition from themodel-dependent paradigm to the model-free one enables us to bypass thecatastrophic forgetting and error accumulation problems. Experiments show thatour proposed method achieves significant performance gains overstate-of-the-art methods on four widely-used benchmarks, including CIFAR-10C,CIFAR-100C, ImageNet-C, and VLCS datasets.",Yulu Gan,2022/12/8,2023/2/11
1905.12195v2,Configuration Testing: Testing Configuration Values as Code and with Code,http://arxiv.org/abs/1905.12195v2,"This paper proposes configuration testing--evaluating configuration values(to be deployed) by exercising the code that uses the values and assessing thecorresponding program behavior. We advocate that configuration values should besystematically tested like software code and that configuration testing shouldbe a key reliability engineering practice for preventing misconfigurations fromproduction deployment.  The essential advantage of configuration testing is to put the configurationvalues (to be deployed) in the context of the target software program undertest. In this way, the dynamic effects of configuration values and the impactof configuration changes can be observed during testing. Configuration testingovercomes the fundamental limitations of de facto approaches to combattingmisconfigurations, namely configuration validation and software testing--theformer is disconnected from code logic and semantics, while the latter canhardly cover all possible configuration values and their combinations. Ourpreliminary results show the effectiveness of configuration testing incapturing real-world misconfigurations.  We present the principles of writing new configuration tests and the promisesof retrofitting existing software tests to be configuration tests. We discussnew adequacy and quality metrics for configuration testing. We also exploreregression testing techniques to enable incremental configuration testingduring continuous integration and deployment in modern software systems.",Tianyin Xu,2019/5/29,2019/7/27
1203.6445v1,Analysis of Test Efficiency during Software Development Process,http://arxiv.org/abs/1203.6445v1,"One of the prerequisites of any organization is an unvarying sustainabilityin the dynamic and competitive industrial environment. Development of highquality software is therefore an inevitable constraint of any softwareindustry. Defect management being one of the highly influencing factors for theproduction of high quality software, it is obligatory for the softwareorganizations to orient them towards effective defect management. Since, thetime of software evolution, testing is deemed a promising technique of defectmanagement in all IT industries. This paper provides an empirical investigationof several projects through a case study comprising of four software companieshaving various production capabilities. The aim of this investigation is toanalyze the efficiency of test team during software development process. Thestudy indicates very low-test efficiency at requirements analysis phase andeven lesser test efficiency at design phase of software development.Subsequently, the study calls for a strong need to improve testing approachesusing techniques such as dynamic testing of design solutions in lieu of statictesting of design document. Dynamic testing techniques enhance the ability ofdetection and elimination of design flaws right at the inception phase andthereby reduce the cost and time of rework. It further improves productivity,quality and sustainability of software industry.",T. R. Gopalakrishnan Nair,2012/3/29,2012/3/29
2310.00867v2,(Dynamic) Prompting might be all you need to repair Compressed LLMs,http://arxiv.org/abs/2310.00867v2,"Large language models (LLMs), while transformative for NLP, come withsignificant computational demands, underlining the need for efficient,training-free compression. Notably, despite the marked improvement intraining-free compression for the largest of LLMs, our tests using LLaMA-7B andOPT-6.7b highlight a significant performance drop in several realisticdownstream tasks. Investigation into the trade-off between resource-intensivepost-compression re-training highlights the prospect of prompt-driven recoveryas a lightweight adaption tool. However, existing studies, confined mainly toperplexity evaluations and simple tasks, fail to offer unequivocal confidencein the scalability and generalizability of prompting. We tackle thisuncertainty in two key ways. First, we uncover the vulnerability of naiveprompts in LLM compression as an over-reliance on a singular prompt per input.In response, we propose inference-time dynamic prompting (IDP), a mechanismthat autonomously chooses from a set of curated prompts based on the context ofeach individual input. Second, we delve into a scientific understanding of why""prompting might be all you need post-LLM compression."" Our findings suggestthat compression does not irretrievably erase LLM model knowledge but displaceit, necessitating a new inference path. IDP effectively redirects this path,enabling the model to tap into its inherent yet displaced knowledge and therebyrecover performance. Empirical tests affirm the value of IDP, demonstrating anaverage performance improvement of 1.24% across nine varied tasks spanningmultiple knowledge domains.",Duc N. M Hoang,2023/10/2,2023/10/14
1509.06948v1,Dynamic concurrent van Emde Boas array,http://arxiv.org/abs/1509.06948v1,"The growing popularity of shared-memory multiprocessor machines has causedsignificant changes in the design of concurrent software. In this approach, theconcurrently running threads communicate and synchronize with each otherthrough data structures in shared memory. Hence, the efficiency of thesestructures is essential for the performance of concurrent applications. Theneed to find new concurrent data structures prompted the author some time agoto propose the cvEB array modeled on the van Emde Boas Tree structure as adynamic set alternative. This paper describes an improved version of thatstructure - the dcvEB array (Dynamic Concurrent van Emde Boas Array). One ofthe improvements involves memory usage optimization. This enhancement requiredthe design of a tree which grows and shrinks at both: the top (root) and thebottom (leaves) level. Another enhancement concerns the successor (andpredecessor) search strategy. The tests performed seem to confirm the highperformance of the dcvEB array. They are especially visible when the range ofkeys is significantly larger than the number of elements in the collection.",Konrad Kuakowski,2015/9/23,2015/9/23
2308.13768v1,Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content,http://arxiv.org/abs/2308.13768v1,"In this paper, we tackle the emerging challenge of unintended harmful contentgeneration in Large Language Models (LLMs) with a novel dual-stage optimisationtechnique using adversarial fine-tuning. Our two-pronged approach employs anadversarial model, fine-tuned to generate potentially harmful prompts, and ajudge model, iteratively optimised to discern these prompts. In thisadversarial cycle, the two models seek to outperform each other in theprompting phase, generating a dataset of rich examples which are then used forfine-tuning. This iterative application of prompting and fine-tuning allowscontinuous refinement and improved performance. The performance of our approachis evaluated through classification accuracy on a dataset consisting ofproblematic prompts not detected by GPT-4, as well as a selection ofcontentious but unproblematic prompts. We show considerable increase inclassification accuracy of the judge model on this challenging dataset as itundergoes the optimisation process. Furthermore, we show that a rudimentarymodel \texttt{ada} can achieve 13\% higher accuracy on the hold-out test setthan GPT-4 after only a few rounds of this process, and that this fine-tuningimproves performance in parallel tasks such as toxic comment identification.",Charles O'Neill,2023/8/26,2023/8/26
2310.09624v2,ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models,http://arxiv.org/abs/2310.09624v2,"As large language models are integrated into society, robustness toward asuite of prompts is increasingly important to maintain reliability in ahigh-variance environment.Robustness evaluations must comprehensivelyencapsulate the various settings in which a user may invoke an intelligentsystem. This paper proposes ASSERT, Automated Safety Scenario Red Teaming,consisting of three methods -- semantically aligned augmentation, targetbootstrapping, and adversarial knowledge injection. For robust safetyevaluation, we apply these methods in the critical domain of AI safety toalgorithmically generate a test suite of prompts covering diverse robustnesssettings -- semantic equivalence, related scenarios, and adversarial. Wepartition our prompts into four safety domains for a fine-grained analysis ofhow the domain affects model performance. Despite dedicated safeguards inexisting state-of-the-art models, we find statistically significant performancedifferences of up to 11% in absolute classification accuracy among semanticallyrelated scenarios and error rates of up to 19% absolute error in zero-shotadversarial settings, raising concerns for users' physical safety.",Alex Mei,2023/10/14,2023/11/11
2103.15350v1,Adversarial Specification Mining,http://arxiv.org/abs/2103.15350v1,"There have been numerous studies on mining temporal specifications fromexecution traces. These approaches learn finite-state automata (FSA) fromexecution traces when running tests. To learn accurate specifications of asoftware system, many tests are required. Existing approaches generalize from alimited number of traces or use simple test generation strategies.Unfortunately, these strategies may not exercise uncommon usage patterns of asoftware system. To address this problem, we propose a new approach,adversarial specification mining, and develop a prototype, DICE (Diversitythrough Counter-Examples). DICE has two components: DICE-Tester and DICE-Miner.After mining Linear Temporal Logic specifications from an input test suite,DICE-Tester adversarially guides test generation, searching for counterexamplesto these specifications to invalidate spurious properties. Thesecounterexamples represent gaps in the diversity of the input test suite. Thisprocess produces execution traces of usage patterns that were unrepresented inthe input test suite. Next, we propose a new specification inference algorithm,DICE-Miner, to infer FSAs using the traces, guided by the temporalspecifications. We find that the inferred specifications are of higher qualitythan those produced by existing state-of-the-art specification miners. Finally,we use the FSAs in a fuzzer for servers of stateful protocols, increasing itscoverage.",Hong Jin Kang,2021/3/29,2021/3/29
2301.12314v1,Progressive Prompts: Continual Learning for Language Models,http://arxiv.org/abs/2301.12314v1,"We introduce Progressive Prompts - a simple and efficient approach forcontinual learning in language models. Our method allows forward transfer andresists catastrophic forgetting, without relying on data replay or a largenumber of task-specific parameters. Progressive Prompts learns a new softprompt for each task and sequentially concatenates it with the previouslylearned prompts, while keeping the base model frozen. Experiments on standardcontinual learning benchmarks show that our approach outperformsstate-of-the-art methods, with an improvement >20% in average test accuracyover the previous best-preforming method on T5 model. We also explore a morechallenging continual learning setup with longer sequences of tasks and showthat Progressive Prompts significantly outperforms prior methods.",Anastasia Razdaibiedina,2023/1/29,2023/1/29
2311.00801v1,GIST: Generated Inputs Sets Transferability in Deep Learning,http://arxiv.org/abs/2311.00801v1,"As the demand for verifiability and testability of neural networks continuesto rise, an increasing number of methods for generating test sets are beingdeveloped. However, each of these techniques tends to emphasize specifictesting aspects and can be quite time-consuming. A straightforward solution tomitigate this issue is to transfer test sets between some benchmarked modelsand a new model under test, based on a desirable property one wishes totransfer. This paper introduces GIST (Generated Inputs Sets Transferability), anovel approach for the efficient transfer of test sets among Deep Learningmodels. Given a property of interest that a user wishes to transfer (e.g.,coverage criterion), GIST enables the selection of good test sets from thepoint of view of this property among available ones from a benchmark. Weempirically evaluate GIST on fault types coverage property with two modalitiesand different test set generation procedures to demonstrate the approach'sfeasibility. Experimental results show that GIST can select an effective testset for the given property to transfer it to the model under test. Our resultssuggest that GIST could be applied to transfer other properties and couldgeneralize to different test sets' generation procedures and modalities",Florian Tambon,2023/11/1,2023/11/1
2307.07507v1,MGit: A Model Versioning and Management System,http://arxiv.org/abs/2307.07507v1,"Models derived from other models are extremely common in machine learning(ML) today. For example, transfer learning is used to create task-specificmodels from ""pre-trained"" models through finetuning. This has led to anecosystem where models are related to each other, sharing structure and ofteneven parameter values. However, it is hard to manage these model derivatives:the storage overhead of storing all derived models quickly becomes onerous,prompting users to get rid of intermediate models that might be useful forfurther analysis. Additionally, undesired behaviors in models are hard to trackdown (e.g., is a bug inherited from an upstream model?). In this paper, wepropose a model versioning and management system called MGit that makes iteasier to store, test, update, and collaborate on model derivatives. MGitintroduces a lineage graph that records provenance and versioning informationbetween models, optimizations to efficiently store model parameters, as well asabstractions over this lineage graph that facilitate relevant testing, updatingand collaboration functionality. MGit is able to reduce the lineage graph'sstorage footprint by up to 7x and automatically update downstream models inresponse to updates to upstream models.",Wei Hao,2023/7/14,2023/7/14
2205.04040v2,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,http://arxiv.org/abs/2205.04040v2,"Question Answering (QA) is a longstanding challenge in natural languageprocessing. Existing QA works mostly focus on specific question types,knowledge domains, or reasoning skills. The specialty in QA research hinderssystems from modeling commonalities between tasks and generalization for widerapplications. To address this issue, we present ProQA, a unified QA paradigmthat solves various tasks through a single model. ProQA takes a unifiedstructural prompt as the bridge and improves the QA-centric ability bystructural prompt-based pre-training. Through a structurally designedprompt-based input schema, ProQA concurrently models the knowledgegeneralization for all QA tasks while keeping the knowledge customization forevery specific QA task. Furthermore, ProQA is pre-trained with structuralprompt-formatted large-scale synthesized corpus, which empowers the model withthe commonly-required QA ability. Experimental results on 11 QA benchmarksdemonstrate that ProQA consistently boosts performance on both full datafine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore,ProQA exhibits strong ability in both continual learning and transfer learningby taking the advantages of the structural prompt.",Wanjun Zhong,2022/5/9,2022/12/9
2312.12478v2,ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval,http://arxiv.org/abs/2312.12478v2,"The goal of Universal Cross-Domain Retrieval (UCDR) is to achieve robustperformance in generalized test scenarios, wherein data may belong to strictlyunknown domains and categories during training. Recently, pre-trained modelswith prompt tuning have shown strong generalization capabilities and attainednoteworthy achievements in various downstream tasks, such as few-shot learningand video-text retrieval. However, applying them directly to UCDR may notsufficiently to handle both domain shift (i.e., adapting to unfamiliar domains)and semantic shift (i.e., transferring to unknown categories). To this end, wepropose Prompting-to-Simulate (ProS), the first method to apply prompt tuningfor UCDR. ProS employs a two-step process to simulate Content-aware DynamicPrompts (CaDP) which can impact models to produce generalized features forUCDR. Concretely, in Prompt Units Learning stage, we introduce two Prompt Unitsto individually capture domain and semantic knowledge in a mask-and-align way.Then, in Context-aware Simulator Learning stage, we train a Content-awarePrompt Simulator under a simulated test scenarios to produce the correspondingCaDP. Extensive experiments conducted on three benchmark datasets show that ourmethod achieves new state-of-the-art performance without bringing excessiveparameters. Our method is publicly available athttps://anonymous.4open.science/r/ProS",Kaipeng Fang,2023/12/19,2024/1/7
2210.10362v3,CPL: Counterfactual Prompt Learning for Vision and Language Models,http://arxiv.org/abs/2210.10362v3,"Prompt tuning is a new few-shot transfer learning technique that only tunesthe learnable prompt for pre-trained vision and language models such as CLIP.However, existing prompt tuning methods tend to learn spurious or entangledrepresentations, which leads to poor generalization to unseen concepts. Towardsnon-spurious and efficient prompt learning from limited examples, this paperpresents a novel \underline{\textbf{C}}ounterfactual\underline{\textbf{P}}rompt \underline{\textbf{L}}earning (CPL) method forvision and language models, which simultaneously employs counterfactualgeneration and contrastive learning in a joint optimization framework.Particularly, CPL constructs counterfactual by identifying minimal non-spuriousfeature change between semantically-similar positive and negative samples thatcauses concept change, and learns more generalizable prompt representation fromboth factual and counterfactual examples via contrastive learning. Extensiveexperiments demonstrate that CPL can obtain superior few-shot performance ondifferent vision and language tasks than previous prompt tuning methods onCLIP. On image classification, we achieve 3.55\% average relative improvementon unseen classes across seven datasets; on image-text retrieval and visualquestion answering, we gain up to 4.09\% and 25.08\% relative improvementsacross three few-shot scenarios on unseen test sets respectively.",Xuehai He,2022/10/19,2022/11/5
1911.01817v3,Whence to Learn? Transferring Knowledge in Configurable Systems using BEETLE,http://arxiv.org/abs/1911.01817v3,"As software systems grow in complexity and the space of possibleconfigurations increases exponentially, finding the near-optimal configurationof a software system becomes challenging. Recent approaches address thischallenge by learning performance models based on a sample set ofconfigurations. However, collecting enough sample configurations can be veryexpensive since each such sample requires configuring, compiling, and executingthe entire system using a complex test suite. When learning on new data is tooexpensive, it is possible to use \textit{Transfer Learning} to ""transfer"" oldlessons to the new context. Traditional transfer learning has a number ofchallenges, specifically, (a) learning from excessive data takes excessivetime, and (b) the performance of the models built via transfer can deteriorateas a result of learning from a poor source. To resolve these problems, wepropose a novel transfer learning framework called BEETLE, which is a""bellwether""-based transfer learner that focuses on identifying and learningfrom the most relevant source from amongst the old data. This paper evaluatesBEETLE with 57 different software configuration problems based on five softwaresystems (a video encoder, an SAT solver, a SQL database, a high-performanceC-compiler, and a streaming data analytics tool). In each of these cases,BEETLE found configurations that are as good as or better than those found byother state-of-the-art transfer learners while requiring only a fraction($\frac{1}{7}$th) of the measurements needed by those other methods. Based onthese results, we say that BEETLE is a new high-water mark in optimallyconfiguring software.",Rahul Krishna,2019/11/1,2020/3/25
2104.02102v1,Automated Performance Testing Based on Active Deep Learning,http://arxiv.org/abs/2104.02102v1,"Generating tests that can reveal performance issues in large and complexsoftware systems within a reasonable amount of time is a challenging task. Onone hand, there are numerous combinations of input data values to explore. Onthe other hand, we have a limited test budget to execute tests. What makes thistask even more difficult is the lack of access to source code and the internaldetails of these systems. In this paper, we present an automated testgeneration method called ACTA for black-box performance testing. ACTA is basedon active learning, which means that it does not require a large set ofhistorical test data to learn about the performance characteristics of thesystem under test. Instead, it dynamically chooses the tests to execute usinguncertainty sampling. ACTA relies on a conditional variant of generativeadversarial networks,and facilitates specifying performance requirements interms of conditions and generating tests that address those conditions.We haveevaluated ACTA on a benchmark web application, and the experimental resultsindicate that this method is comparable with random testing, and two othermachine learning methods,i.e. PerfXRL and DN.",Ali Sedaghatbaf,2021/4/5,2021/4/5
2201.05371v1,"Artificial Intelligence in Software Testing : Impact, Problems, Challenges and Prospect",http://arxiv.org/abs/2201.05371v1,"Artificial Intelligence (AI) is making a significant impact in multiple areaslike medical, military, industrial, domestic, law, arts as AI is capable toperform several roles such as managing smart factories, driving autonomousvehicles, creating accurate weather forecasts, detecting cancer and personalassistants, etc. Software testing is the process of putting the software totest for some abnormal behaviour of the software. Software testing is atedious, laborious and most time-consuming process. Automation tools have beendeveloped that help to automate some activities of the testing process toenhance quality and timely delivery. Over time with the inclusion of continuousintegration and continuous delivery (CI/CD) pipeline, automation tools arebecoming less effective. The testing community is turning to AI to fill the gapas AI is able to check the code for bugs and errors without any humanintervention and in a much faster way than humans. In this study, we aim torecognize the impact of AI technologies on various software testing activitiesor facets in the STLC. Further, the study aims to recognize and explain some ofthe biggest challenges software testers face while applying AI to testing. Thepaper also proposes some key contributions of AI in the future to the domain ofsoftware testing.",Zubair Khaliq,2022/1/14,2022/1/14
2309.01715v1,Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction,http://arxiv.org/abs/2309.01715v1,"Taxonomies represent hierarchical relations between entities, frequentlyapplied in various software modeling and natural language processing (NLP)activities. They are typically subject to a set of structural constraintsrestricting their content. However, manual taxonomy construction can betime-consuming, incomplete, and costly to maintain. Recent studies of largelanguage models (LLMs) have demonstrated that appropriate user inputs (calledprompting) can effectively guide LLMs, such as GPT-3, in diverse NLP taskswithout explicit (re-)training. However, existing approaches for automatedtaxonomy construction typically involve fine-tuning a language model byadjusting model parameters. In this paper, we present a general framework fortaxonomy construction that takes into account structural constraints. Wesubsequently conduct a systematic comparison between the prompting andfine-tuning approaches performed on a hypernym taxonomy and a novel computerscience taxonomy dataset. Our result reveals the following: (1) Even withoutexplicit training on the dataset, the prompting approach outperformsfine-tuning-based approaches. Moreover, the performance gap between promptingand fine-tuning widens when the training dataset is small. However, (2)taxonomies generated by the fine-tuning approach can be easily post-processedto satisfy all the constraints, whereas handling violations of the taxonomiesproduced by the prompting approach can be challenging. These evaluationfindings provide guidance on selecting the appropriate method for taxonomyconstruction and highlight potential enhancements for both approaches.",Boqi Chen,2023/9/4,2023/9/4
2107.07170v2,FLEX: Unifying Evaluation for Few-Shot NLP,http://arxiv.org/abs/2107.07170v2,"Few-shot NLP research is highly active, yet conducted in disjoint researchthreads with evaluation suites that lack challenging-yet-realistic testingsetups and fail to employ careful experimental design. Consequently, thecommunity does not know which techniques perform best or even if theyoutperform simple baselines. In response, we formulate the FLEX Principles, aset of requirements and best practices for unified, rigorous, valid, andcost-sensitive few-shot NLP evaluation. These principles include Sample SizeDesign, a novel approach to benchmark design that optimizes statisticalaccuracy and precision while keeping evaluation costs manageable. Following theprinciples, we release the FLEX benchmark, which includes four few-shottransfer settings, zero-shot evaluation, and a public leaderboard that coversdiverse NLP tasks. In addition, we present UniFew, a prompt-based model forfew-shot learning that unifies pretraining and finetuning prompt formats,eschewing complex machinery of recent prompt-based approaches in adaptingdownstream task formats to language model pretraining objectives. Wedemonstrate that despite simplicity, UniFew achieves results competitive withboth popular meta-learning and prompt-based approaches.",Jonathan Bragg,2021/7/15,2021/11/8
2305.09434v1,Chatting with GPT-3 for Zero-Shot Human-Like Mobile Automated GUI Testing,http://arxiv.org/abs/2305.09434v1,"Mobile apps are indispensable for people's daily life, and automated GUI(Graphical User Interface) testing is widely used for app quality assurance.There is a growing interest in using learning-based techniques for automatedGUI testing which aims at generating human-like actions and interactions.However, the limitations such as low testing coverage, weak generalization, andheavy reliance on training data, make an urgent need for a more effectiveapproach to generate human-like actions to thoroughly test mobile apps.Inspired by the success of the Large Language Model (LLM), e.g., GPT-3 andChatGPT, in natural language understanding and question answering, we formulatethe mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLMto chat with the mobile apps by passing the GUI page information to LLM toelicit testing scripts, and executing them to keep passing the app feedback toLLM, iterating the whole process. Within it, we extract the static context ofthe GUI page and the dynamic context of the iterative testing process, designprompts for inputting this information to LLM, and develop a neural matchingnetwork to decode the LLM's output into actionable steps to execute the app. Weevaluate GPTDroid on 86 apps from Google Play, and its activity coverage is71%, with 32% higher than the best baseline, and can detect 36% more bugs withfaster speed than the best baseline. GPTDroid also detects 48 new bugs on theGoogle Play with 25 of them being confirmed/fixed. We further summarize thecapabilities of GPTDroid behind the superior performance, including semantictext input, compound action, long meaningful test trace, and test caseprioritization.",Zhe Liu,2023/5/16,2023/5/16
2106.06422v1,From Blackboard to the Office: A Look Into How Practitioners Perceive Software Testing Education,http://arxiv.org/abs/2106.06422v1,"The teaching-learning process may require specific pedagogical approaches toestablish a relationship with industry practices. Recently, some studiesinvestigated the educators' perspectives and the undergraduate coursescurriculum to identify potential weaknesses and solutions for the softwaretesting teaching process. However, it is still unclear how the practitionersevaluate the acquisition of knowledge about software testing in undergraduatecourses. This study carried out an expert survey with 68 newly graduatedpractitioners to determine what the industry expects from them and what theylearned in academia. The yielded results indicated that those practitionerslearned at a similar rate as others with a long industry experience. Also, theystudied less than half of the 35 software testing topics collected in thesurvey and took industry-backed extracurricular courses to complement theirlearning. Additionally, our findings point out a set of implications for futureresearch, as the respondents' learning difficulties (e.g., lack of learningsources) and the gap between academic education and industry expectations(e.g., certifications).",Luana Martins,2021/6/11,2021/6/11
2207.04361v1,State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections,http://arxiv.org/abs/2207.04361v1,"Traversing intersections is a challenging problem for autonomous vehicles,especially when the intersections do not have traffic control. Recently deepreinforcement learning has received massive attention due to its success indealing with autonomous driving tasks. In this work, we address the problem oftraversing unsignalized intersections using a novel curriculum for deepreinforcement learning. The proposed curriculum leads to: 1) A faster trainingprocess for the reinforcement learning agent, and 2) Better performancecompared to an agent trained without curriculum. Our main contribution istwo-fold: 1) Presenting a unique curriculum for training deep reinforcementlearning agents, and 2) showing the application of the proposed curriculum forthe unsignalized intersection traversal task. The framework expects processedobservations of the surroundings from the perception system of the autonomousvehicle. We test our method in the CommonRoad motion planning simulator onT-intersections and four-way intersections.",Shivesh Khaitan,2022/7/10,2022/7/10
2308.15116v3,Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators,http://arxiv.org/abs/2308.15116v3,"Molecular dynamics simulations have emerged as a fundamental instrument forstudying biomolecules. At the same time, it is desirable to perform simulationsof a collection of particles under various conditions in which the moleculescan fluctuate. In this paper, we explore and adapt the soft prompt-basedlearning method to molecular dynamics tasks. Our model can remarkablygeneralize to unseen and out-of-distribution scenarios with limited trainingdata. While our work focuses on temperature as a test case, the versatility ofour approach allows for efficient simulation through any continuous dynamicconditions, such as pressure and volumes. Our framework has two stages: 1)Pre-trains with data mixing technique, augments molecular structure data andtemperature prompts, then applies a curriculum learning method by increasingthe ratio of them smoothly. 2) Meta-learning-based fine-tuning frameworkimproves sample-efficiency of fine-tuning process and gives the softprompt-tuning better initialization points. Comprehensive experiments revealthat our framework excels in accuracy for in-domain data and demonstratesstrong generalization capabilities for unseen and out-of-distribution samples.",Jingbang Chen,2023/8/29,2023/10/10
2112.02913v1,Curriculum Meta-Learning for Few-shot Classification,http://arxiv.org/abs/2112.02913v1,"We propose an adaptation of the curriculum training framework, applicable tostate-of-the-art meta learning techniques for few-shot classification.Curriculum-based training popularly attempts to mimic human learning byprogressively increasing the training complexity to enable incremental conceptlearning. As the meta-learner's goal is learning how to learn from as fewsamples as possible, the exact number of those samples (i.e. the size of thesupport set) arises as a natural proxy of a given task's difficulty. We definea simple yet novel curriculum schedule that begins with a larger support sizeand progressively reduces it throughout training to eventually match thedesired shot-size of the test setup. This proposed method boosts the learningefficiency as well as the generalization capability. Our experiments with theMAML algorithm on two few-shot image classification tasks show significantgains with the curriculum training framework. Ablation studies corroborate theindependence of our proposed method from the model architecture as well as themeta-learning hyperparameters",Emmanouil Stergiadis,2021/12/6,2021/12/6
2008.09377v1,Curriculum Learning with Hindsight Experience Replay for Sequential Object Manipulation Tasks,http://arxiv.org/abs/2008.09377v1,"Learning complex tasks from scratch is challenging and often impossible forhumans as well as for artificial agents. A curriculum can be used instead,which decomposes a complex task (target task) into a sequence of source tasks(the curriculum). Each source task is a simplified version of the next sourcetask with increasing complexity. Learning then occurs gradually by training oneach source task while using knowledge from the curriculum's prior sourcetasks. In this study, we present a new algorithm that combines curriculumlearning with Hindsight Experience Replay (HER), to learn sequential objectmanipulation tasks for multiple goals and sparse feedback. The algorithmexploits the recurrent structure inherent in many object manipulation tasks andimplements the entire learning process in the original simulation withoutadjusting it to each source task. We have tested our algorithm on threechallenging throwing tasks and show vast improvements compared to vanilla-HER.",Binyamin Manela,2020/8/21,2020/8/21
2012.11364v1,Reinforcement Learning for Test Case Prioritization,http://arxiv.org/abs/2012.11364v1,"In modern software engineering, Continuous Integration (CI) has become anindispensable step towards systematically managing the life cycles of softwaredevelopment. Large companies struggle with keeping the pipeline updated andoperational, in useful time, due to the large amount of changes and addition offeatures, that build on top of each other and have several developers, workingon different platforms. Associated with such software changes, there is alwaysa strong component of Testing. As teams and projects grow, exhaustive testingquickly becomes inhibitive, becoming adamant to select the most relevant testcases earlier, without compromising software quality. This paper extends recentstudies on applying Reinforcement Learning to optimize testing strategies. Wetest its ability to adapt to new environments, by testing it on novel dataextracted from a financial institution, yielding a Normalized percentage ofFault Detection (NAPFD) of over $0.6$ using the Network Approximator and TestCase Failure Reward. Additionally, we studied the impact of using Decision Tree(DT) Approximator as a model for memory representation, which failed to producesignificant improvements relative to Artificial Neural Networks.",Joo Lousada,2020/12/18,2020/12/18
1811.04122v1,Reinforcement Learning for Automatic Test Case Prioritization and Selection in Continuous Integration,http://arxiv.org/abs/1811.04122v1,"Testing in Continuous Integration (CI) involves test case prioritization,selection, and execution at each cycle. Selecting the most promising test casesto detect bugs is hard if there are uncertainties on the impact of committedcode changes or, if traceability links between code and tests are notavailable. This paper introduces Retecs, a new method for automaticallylearning test case selection and prioritization in CI with the goal to minimizethe round-trip time between code commits and developer feedback on failed testcases. The Retecs method uses reinforcement learning to select and prioritizetest cases according to their duration, previous last execution and failurehistory. In a constantly changing environment, where new test cases are createdand obsolete test cases are deleted, the Retecs method learns to prioritizeerror-prone test cases higher under guidance of a reward function and byobserving previous CI cycles. By applying Retecs on data extracted from threeindustrial case studies, we show for the first time that reinforcement learningenables fruitful automatic adaptive test case selection and prioritization inCI and regression testing.",Helge Spieker,2018/11/9,2018/11/9
1911.05403v2,Reinforcement Learning-Driven Test Generation for Android GUI Applications using Formal Specifications,http://arxiv.org/abs/1911.05403v2,"There have been many studies on automated test generation for mobileGraphical User Interface (GUI) applications. These studies successfullydemonstrate how to detect fatal exceptions and achieve high code and activitycoverage with fully automated test generation engines. However, it is unclearhow many GUI functions these engines manage to test. Furthermore, these enginesimplement only implicit test oracles. We propose Fully Automated ReinforcementLEArning-Driven Specification-Based Test Generator for Android(FARLEAD-Android). FARLEAD-Android accepts a GUI-level formal specification asa Linear-time Temporal Logic (LTL) formula. By dynamically executing theApplication Under Test (AUT), it learns how to generate a test that satisfiesthe LTL formula using Reinforcement Learning (RL). The LTL formula does notjust guide the test generation but also acts as a specified test oracle,enabling the developer to define automated test oracles for a wide variety ofGUI functions by changing the formula. Our evaluation shows thatFARLEAD-Android is more effective and achieves higher performance in generatingtests for specified GUI functions than three known approaches, Random, Monkey,and QBEa. To the best of our knowledge, FARLEAD-Android is the first fullyautomated mobile GUI testing engine that uses formal specifications.",Yavuz Koroglu,2019/11/13,2019/11/27
2310.02368v1,Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation,http://arxiv.org/abs/2310.02368v1,"Software testing is a crucial aspect of software development, and thecreation of high-quality tests that adhere to best practices is essential foreffective maintenance. Recently, Large Language Models (LLMs) have gainedpopularity for code generation, including the automated creation of test cases.However, these LLMs are often trained on vast amounts of publicly availablecode, which may include test cases that do not adhere to best practices and mayeven contain test smells (anti-patterns). To address this issue, we propose anovel technique called Reinforcement Learning from Static Quality Metrics(RLSQM). To begin, we analyze the anti-patterns generated by the LLM and showthat LLMs can generate undesirable test smells. Thus, we train specific rewardmodels for each static quality metric, then utilize Proximal PolicyOptimization (PPO) to train models for optimizing a single quality metric at atime. Furthermore, we amalgamate these rewards into a unified reward modelaimed at capturing different best practices and quality aspects of tests. Bycomparing RL-trained models with those trained using supervised learning, weprovide insights into how reliably utilize RL to improve test generationquality and into the effects of various training strategies. Our experimentalresults demonstrate that the RL-optimized model consistently generatedhigh-quality test cases compared to the base LLM, improving the model by up to21%, and successfully generates nearly 100% syntactically correct code. RLSQMalso outperformed GPT-4 on four out of seven metrics. This represents asignificant step towards enhancing the overall efficiency and reliability ofsoftware testing through Reinforcement Learning and static quality metrics. Ourdata are available at this link: https://figshare.com/s/ded476c8d4c221222849.",Benjamin Steenhoek,2023/10/3,2023/10/3
1908.06900v2,An Autonomous Performance Testing Framework using Self-Adaptive Fuzzy Reinforcement Learning,http://arxiv.org/abs/1908.06900v2,"Test automation brings the potential to reduce costs and human effort, butseveral aspects of software testing remain challenging to automate. One suchexample is automated performance testing to find performance breaking points.Current approaches to tackle automated generation of performance test casesmainly involve using source code or system model analysis or use-case basedtechniques. However, source code and system models might not always beavailable at testing time. On the other hand, if the optimal performancetesting policy for the intended objective in a testing process instead could belearned by the testing system, then test automation without advancedperformance models could be possible. Furthermore, the learned policy couldlater be reused for similar software systems under test, thus leading to highertest efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcementlearning-based performance testing framework. SaFReL learns the optimal policyto generate performance test cases through an initial learning phase, thenreuses it during a transfer learning phase, while keeping the learning runningand updating the policy in the long term. Through multiple experiments on asimulated environment, we demonstrate that our approach generates the targetperformance test cases for different programs more efficiently than a typicaltesting process, and performs adaptively without access to source code andperformance models.",Mahshid Helali Moghadam,2019/8/19,2020/7/30
0903.1889v2,"Test of Universal Rise of Hadronic Total Cross Sections based on pi p, Kp and pbar p,pp Scatterings",http://arxiv.org/abs/0903.1889v2,"Recently there are several evidences of the hadronic total cross sectionsigma(tot) to be proportional to B (log s)2 consistent with the Froissartunitarity bound. The COMPETE collaborations have further assumed sigma(tot) = B(log s/s0)2 + Z to extend its universal rise with the common value of B and s0for all hadronic scatterings to reduce the number of adjustable parameters. Thecoefficient B was suggested to be universal in the arguments of colour glasscondensate (CGC) of QCD in recent years. There has been, however, no rigorousproof yet based only on QCD. We attempt to investigate the value of B for pi+-p, K+- p and pbar p,pp scatterings respectively through the search for thesimultaneous best fit to the experimental sigma(tot) and rho ratios at highenergies. The sigma(tot) at the resonance and intermediate energy regions hasalso been exploited as a duality constraint based on the special form offinite-energy sum rule(FESR). We estimate the values of B, s0 and Zindividually for pi+- p, K+- p and pbar p,pp scatterings without using theuniversality hypothesis. It turs out that the values of B are mutuallyconsistent within one standard deviation. It has to be stressed that we cannotobtain such a definite conclusion without the duality constraint. It is alsointeresting to note that the values of Z for pi p, Kp and pbar(p)papproximately satisfy the ratio 2:2:3 predicted by the quark model. Theobtained value of B for pbar(p)p is Bpp = 0.280 +- 0.015 mb, which predictssigma(tot)(pp) =108.0 +- 1.9mb and rho(pp) =0.131+- 0.0025 at the LHC energys^0.5 =14 TeV.",Muneyuki Ishida,2009/3/11,2009/4/26
2204.11572v2,Upgrade of ASACUSA's Antihydrogen Detector,http://arxiv.org/abs/2204.11572v2,"The goal of the ASACUSA (Atomic Spectroscopy And Collisions Using SlowAntiprotons) CUSP experiment at CERN's Antiproton Decelerator is to measure theground state hyperfine splitting of antihydrogen in order to test whether CPTinvariance is broken.  The ASACUSA hodoscope is a detector consisting of two layers of 32 plasticscintillator bars individually read out by two serially connected silicon photomultipliers (SiPMs) on each end. Two additional layers for position resolutionalong the beam axis were scintillator fibres, which will now be replaced byscintillating tiles placed onto the existing bars and also read out by SiPMs.If the antiproton of antihydrogen annihilates in the center of the hodoscope,particles (mostly pions) are produced and travel through the various layers ofthe detector and produce signals.  The hodoscope was successfully used during the last data taking period atCERN. The necessary time resolution to discriminate between particlestravelling through the detector from outside and particles produced in thecenter of the detector was achieved by the use of waveform digitisers andsoftware constant fraction discrimination. The disadvantage of this readoutscheme was the slow readout speed, which was improved by two orders ofmagnitude. This was done by omitting the digitisers and replacing them withTDCs reading out the digital time-over-threshold (ToT) signal using leadingedge discrimination.",V. Kraxberger,2022/4/25,2022/10/24
1006.4845v2,Neutrino mass constraint with the Sloan Digital Sky Survey power spectrum of luminous red galaxies and perturbation theory,http://arxiv.org/abs/1006.4845v2,"We compare the model power spectrum, computed based on perturbation theory(PT) with the power spectrum of luminous red galaxies (LRG) measured from theSDSSDR7 catalog, assuming a flat, CDM-dominated cosmology. The model includesthe effects of massive neutrinos, nonlinear matter clustering and nonlinear,scale-dependent galaxy bias in a self-consistent manner. We first test theaccuracy of PT-model by comparing the model predictions with the halo powerspectrum in real- and redshift-space measured from simulations without massiveneutrinos. We show that the PT-model with bias parameters being properlyadjusted can fairly well reproduce the simulation results. As a result thebest-fit parameters obtained from the hypothetical parameter fitting recover,within statistical uncertainties, the input cosmological parameters insimulations, including an upper bound on neutrino mass, if the power spectruminformation up to k~0.15h/Mpc is used. However, for the redshift-space powerspectrum, the best-fit cosmological parameters show a sizable bias from theinput values if using the information up to k~0.2h/Mpc, probably due tononlinear redshift distortion effect. Given these tests, we decided, as aconservative choice, to use the LRG power spectrum up to k=0.1h/Mpc in order tominimize possible unknown nonlinearity effects. In combination with the recentresults from Wilkinson Microwave Background Anisotropy Probe (WMAP), we derivea robust upper-bound on the sum of neutrino masses, given as m_nu,tot < 0.81eV(95% C.L.), marginalized over other parameters including nonlinear biasparameters and dark energy equation of state parameter. The neutrino mass limitis improved by a factor of 1.85 compared to the limit from the WMAP5 alone,m_nu,tot < 1.5eV.",Shun Saito,2010/6/24,2011/2/19
1911.02367v1,Randomized Computer Vision Approaches for Pattern Recognition in Timepix and Timepix3 Detectors,http://arxiv.org/abs/1911.02367v1,"Timepix and Timepix3 are hybrid pixel detectors ($256\times 256$ pixels),capable of tracking ionizing particles as isolated clusters of pixels. Toefficiently analyze such clusters at potentially high rates, we introducemultiple randomized pattern recognition algorithms inspired by computer vision.Offering desirable probabilistic bounds on accuracy and complexity, thepresented methods are well-suited for use in real-time applications, and somemay even be modified to tackle trans-dimensional problems. In Timepixdetectors, which do not support data-driven acquisition, they have been shownto correctly separate clusters of overlapping tracks. In Timepix3 detectors,simultaneous acquisition of Time-of-Arrival (ToA) and Time-over-Threshold (ToT)pixel data enables reconstruction of the depth, transitioning from 2D to 3Dpoint clouds. The presented algorithms have been tested on simulated inputs,test beam data from the Heidelberg Ion therapy Center and the Super ProtonSynchrotron and were applied to data acquired in the MoEDAL and ATLASexperiments at CERN.",Petr Mnek,2019/11/6,2019/11/6
2205.15966v1,A Novel Readout Scheme for Muon Tomography Application in Material Identification,http://arxiv.org/abs/2205.15966v1,"This work reports a cost-effective, multi-parameter readout anddata-acquisition system for a muon scattering tomography system based onResistive Plate Chambers (RPCs). Initial test measurements with a prototypeResistive Plate Chamber were performed using a low-cost FPGA coupled to theNINO ASIC for the event selection and handling data. The Time over-Threshold(TOT) property of NINO ASICs has been used to achieve better positioninformation and achieve precise tracking capability. In our test setup, we tryto build an imaging setup using a single RPC and lead block, which covers someareas of RPC. A glass RPC of dimension 30cm x 30cm, filled with a gas mixtureof 95% Freon and 5% Isobutane, equipped with two orthogonal panels of readoutstrips of width 3 cm and pitch 3.2 cm, has been operated.",Subhendu Das,2022/5/31,2022/5/31
hep-ph/0307355v2,pp Elastic Scattering at LHC and Nucleon Structure (Conference Report),http://arxiv.org/abs/hep-ph/0307355v2,"High energy elastic pp differential cross section at LHC at the c.m. energy14 TeV is predicted using the asymptotic behavior of sigma-tot(s) and rho(s),and the measured pbar-p differential cross section at sqrt{s}=546 GeV. Thephenomenological investigation has progressively led to an effective fieldtheory model that describes the nucleon as a chiral bag embedded in aquark-antiquark condensed ground state. The measurement of pp elasticscattering at LHC up to large |t| >~ 10 GeV^2 by the TOTEM group will becrucial to test this structure of the nucleon.",M. M. Islam,2003/7/29,2003/8/15
1106.5082v1,Rise of Kp Total Cross Section and Universality,http://arxiv.org/abs/1106.5082v1,"The increase of the measured hadronic total cross sections at the highestenergies is empirically described by squared log of center-of-mass energy sqrts as sigma(tot)= B (log s)2, consistent with the energy dependence of theFroissart unitarity bound. The coefficient B is argued to have a universalvalue, but this is not proved directly from QCD. In the previous tests of thisuniversality, the p(pbar)p, pi p, and K p forward scatterings were analyzedindependently and found to be consistent with B(pp) = B(pip) = B(Kp), althoughthe determined value of B(Kp) had large uncertainty. In the present work, wehave further analyzed forward Kp scattering to obtain a more exact value ofB(Kp). Making use of continuous moment sum rules(CMSR) we have fully exploitedthe information of low-energy scattering data to predict the high-energybehavior of the amplitude hrough duality. The estimation of B(Kp) is improvedremarkably, and our result strongly supports the universality of B.",Muneyuki Ishida,2011/6/24,2011/6/24
1410.2437v1,S.A.T.E.P. : Synchronous-Asynchronous Tele-education Platform,http://arxiv.org/abs/1410.2437v1,"S.A.T.E.P. means Synchronous Asynchronous Tele education Platform is asoftware application for educational purposes, with a lot of parametrizingfeatures written entirely from scratch. It aims at the training and examinationof computer skills, a platform that can be adjusted to the needs of eachlesson. In the application the trainer and the administrator can define thenumber of the lectures and upload files for each one of them. Furthermore, hecan insert, modify and delete questions which are used for evaluation tests butalso for the trainees examinations. The trainee can read and download the filesof each lesson and also test his knowledge on what he has studied through aseries of questions. A chat module where registered users as well as systemadministrator can discuss and solve questions is also developed.",Lazaros Lazaridis,2014/10/9,2014/10/9
2308.08943v1,Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?,http://arxiv.org/abs/2308.08943v1,"Upon evolving their software, organizations and individual developers have tospend a substantial effort to pay back technical debt, i.e., the fact thatsoftware is released in a shape not as good as it should be, e.g., in terms offunctionality, reliability, or maintainability. This paper empiricallyinvestigates the extent to which technical debt can be automatically paid backby neural-based generative models, and in particular models exploitingdifferent strategies for pre-training and fine-tuning. We start by extracting adateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595open-source projects. SATD refers to technical debt instances documented (e.g.,via code comments) by developers. We use this dataset to experiment with sevendifferent generative deep learning (DL) model configurations. Specifically, wecompare transformers pre-trained and fine-tuned with different combinations oftraining objectives, including the fixing of generic code changes, SATDremovals, and SATD-comment prompt tuning. Also, we investigate theapplicability in this context of a recently-available Large Language Model(LLM)-based chat bot. Results of our study indicate that the automatedrepayment of SATD is a challenging task, with the best model we experimentedwith able to automatically fix ~2% to 8% of test instances, depending on thenumber of attempts it is allowed to make. Given the limited size of thefine-tuning dataset (~5k instances), the model's pre-training plays afundamental role in boosting performance. Also, the ability to remove SATDsteadily drops if the comment documenting the SATD is not provided as input tothe model. Finally, we found general-purpose LLMs to not be a competitiveapproach for addressing SATD.",Antonio Mastropaolo,2023/8/17,2023/8/17
2312.08189v1,GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements,http://arxiv.org/abs/2312.08189v1,"Before implementing a function, programmers are encouraged to write a purposestatement i.e., a short, natural-language explanation of what the functioncomputes. A purpose statement may be ambiguous i.e., it may fail to specify theintended behaviour when two or more inequivalent computations are plausible oncertain inputs. Our paper makes four contributions. First, we propose a novelheuristic that suggests such inputs using Large Language Models (LLMs). Usingthese suggestions, the programmer may choose to clarify the purpose statement(e.g., by providing a functional example that specifies the intended behaviouron such an input). Second, to assess the quality of inputs suggested by ourheuristic, and to facilitate future research, we create an open dataset ofpurpose statements with known ambiguities. Third, we compare our heuristicagainst GitHub Copilot's Chat feature, which can suggest similar inputs whenprompted to generate unit tests. Fourth, we provide an open-sourceimplementation of our heuristic as an extension to Visual Studio Code for thePython programming language, where purpose statements and functional examplesare specified as docstrings and doctests respectively. We believe that thistool will be particularly helpful to novice programmers and instructors.",Mrigank Pawagi,2023/12/13,2023/12/13
2401.09383v1,Synthesizing Hardware-Software Leakage Contracts for RISC-V Open-Source Processors,http://arxiv.org/abs/2401.09383v1,"Microarchitectural attacks compromise security by exploiting software-visibleartifacts of microarchitectural optimizations such as caches and speculativeexecution. Defending against such attacks at the software level requires anappropriate abstraction at the instruction set architecture (ISA) level thatcaptures microarchitectural leakage. Hardware-software leakage contracts haverecently been proposed as such an abstraction. In this paper, we propose asemi-automatic methodology for synthesizing hardware-software leakage contractsfor open-source microarchitectures. For a given ISA, our approach relies onhuman experts to (a) capture the space of possible contracts in the form ofcontract templates and (b) devise a test-case generation strategy to explore amicroarchitecture's potential leakage. For a given implementation of an ISA,these two ingredients are then used to automatically synthesize the mostprecise leakage contract that is satisfied by the microarchitecture. We haveinstantiated this methodology for the RISC-V ISA and applied it to the Ibex andCVA6 open-source processors. Our experiments demonstrate the practicalapplicability of the methodology and uncover subtle and unexpected leaks.",Gideon Mohr,2024/1/17,2024/1/17
2004.08518v1,Improving The Effectiveness of Automatically Generated Test Suites Using Metamorphic Testing,http://arxiv.org/abs/2004.08518v1,"Automated test generation has helped to reduce the cost of software testing.However, developing effective test oracles for these automatically generatedtest inputs is a challenging task. Therefore, most automated test generationtools use trivial oracles that reduce the fault detection effectiveness ofthese automatically generated test cases. In this work, we provide results ofan empirical study showing that utilizing metamorphic relations can increasethe fault detection effectiveness of automatically generated test cases.",Prashanta Saha,2020/4/18,2020/4/18
2308.05549v1,Testing Updated Apps by Adapting Learned Models,http://arxiv.org/abs/2308.05549v1,"Although App updates are frequent and software engineers would like to verifyupdated features only, automated testing techniques verify entire Apps and arethus wasting resources. We present Continuous Adaptation of Learned Models(CALM), an automated App testing approach that efficiently tests App updates byadapting App models learned when automatically testing previous App versions.CALM focuses on functional testing. Since functional correctness can be mainlyverified through the visual inspection of App screens, CALM minimizes thenumber of App screens to be visualized by software testers while maximizing thepercentage of updated methods and instructions exercised. Our empiricalevaluation shows that CALM exercises a significantly higher proportion ofupdated methods and instructions than six state-of-the-art approaches, for thesame maximum number of App screens to be visually inspected. Further, in commonupdate scenarios, where only a small fraction of methods are updated, CALM iseven quicker to outperform all competing approaches in a more significant way.",Chanh-Duc Ngo,2023/8/10,2023/8/10
1201.3929v1,About Instruction Sequence Testing,http://arxiv.org/abs/1201.3929v1,"Software testing is presented as a so-called theme within which differentauthors and groups have defined different subjects each of these subjectshaving a different focus on testing. A uniform concept of software testing isnon-existent and the space of possible coherent perspectives on softwaretesting, each fitting within the theme, is viewed as being spanned by fivedimensions, each dimension representing two opposite views with a variety ofintermediate views in between.  Instruction sequences are used as a simple theoretical conceptualization ofcomputer programs. A theory of instruction sequence testing may serve as amodel for a theory of software testing. Instruction sequences testing isconsidered a new topic for which definitions may be freely contemplated withoutbeing restricted by existing views on software testing.  The problem of developing a theory of instruction sequence testing is posed.A survey is given of motivations and scenarios for developing a theory ofinstruction sequence testing.",J. A. Bergstra,2012/1/18,2012/1/18
2303.04758v1,RANG: Reconstructing reproducible R computational environments,http://arxiv.org/abs/2303.04758v1,"A complete declarative description of the computational environment is oftenmissing when researchers share their materials. Without such description,software obsolescence and missing system components can jeopardizecomputational reproducibility in the future, even when data and computer codeare available. The R package rang is a complete solution for generating thedeclarative description for other researchers to automatically reconstruct thecomputational environment at a specific time point. The reconstruction process,based on Docker, has been tested for R code as old as 2001. The declarativedescription generated by rang satisfies the definition of a reproducibleresearch compendium and can be shared as such. In this contribution, we showhow rang can be used to make otherwise unexecutable code, spanning from fieldssuch as computational social science and bioinformatics, executable again. Wealso provide instructions on how to use rang to construct reproducible andshareable research compendia of current research. The package is currentlyavailable from CRAN (https://cran.r-project.org/web/packages/rang/index.html)and GitHub (https://github.com/chainsawriot/rang).",Chung-hong Chan,2023/3/8,2023/3/8
2310.05136v4,InstructDET: Diversifying Referring Object Detection with Generalized Instructions,http://arxiv.org/abs/2310.05136v4,"We propose InstructDET, a data-centric method for referring object detection(ROD) that localizes target objects based on user instructions. While derivingfrom referring expressions (REC), the instructions we leverage are greatlydiversified to encompass common user intentions related to object detection.For one image, we produce tremendous instructions that refer to every singleobject and different combinations of multiple objects. Each instruction and itscorresponding object bounding boxes (bbxs) constitute one training data pair.In order to encompass common detection expressions, we involve emergingvision-language model (VLM) and large language model (LLM) to generateinstructions guided by text prompts and object bbxs, as the generalizations offoundation models are effective to produce human-like expressions (e.g.,describing object property, category, and relationship). We name ourconstructed dataset as InDET. It contains images, bbxs and generalizedinstructions that are from foundation models. Our InDET is developed fromexisting REC datasets and object detection datasets, with the expandingpotential that any image with object bbxs can be incorporated through using ourInstructDET method. By using our InDET dataset, we show that a conventional RODmodel surpasses existing methods on standard REC datasets and our InDET testset. Our data-centric method InstructDET, with automatic data expansion byleveraging foundation models, directs a promising field that ROD can be greatlydiversified to execute common object detection instructions.",Ronghao Dang,2023/10/8,2023/10/17
1911.00621v3,WEIZZ: Automatic Grey-box Fuzzing for Structured Binary Formats,http://arxiv.org/abs/1911.00621v3,"Fuzzing technologies have evolved at a fast pace in recent years, revealingbugs in programs with ever increasing depth and speed. Applications workingwith complex formats are however more difficult to take on, as inputs need tomeet certain format-specific characteristics to get through the initial parsingstage and reach deeper behaviors of the program. Unlike prior proposals basedon manually written format specifications, in this paper we present a techniqueto automatically generate and mutate inputs for unknown chunk-based binaryformats. We propose a technique to identify dependencies between input bytesand comparison instructions, and later use them to assign tags thatcharacterize the processing logic of the program. Tags become the buildingblock for structure-aware mutations involving chunks and fields of the input.We show that our techniques performs comparably to structure-aware fuzzingproposals that require human assistance. Our prototype implementation WEIZZrevealed 16 unknown bugs in widely used programs.",Andrea Fioraldi,2019/11/2,2020/8/12
2008.12613v5,Type-driven Neural Programming by Example,http://arxiv.org/abs/2008.12613v5,"In this thesis we look into programming by example (PBE), which is aboutfinding a program mapping given inputs to given outputs. PBE has traditionallyseen a split between formal versus neural approaches, where formal approachestypically involve deductive techniques such as SAT solvers and types, while theneural approaches involve training on sample input-outputs with theircorresponding program, typically using sequence-based machine learningtechniques such as LSTMs [41]. As a result of this split, programming types hadyet to be used in neural program synthesis techniques.  We propose a way to incorporate programming types into a neural programsynthesis approach for PBE. We introduce the Typed Neuro-Symbolic ProgramSynthesis (TNSPS) method based on this idea, and test it in the functionalprogramming context to empirically verify type information may help improvegeneralization in neural synthesizers on limited-size datasets.  Our TNSPS model builds upon the existing Neuro-Symbolic Program Synthesis(NSPS), a tree-based neural synthesizer combining info from input-outputexamples plus the current program, by further exposing information on types ofthose input-output examples, of the grammar production rules, as well as of thehole that we wish to expand in the program.  We further explain how we generated a dataset within our domain, which uses alimited subset of Haskell as the synthesis language. Finally we discuss severaltopics of interest that may help take these ideas further. For reproducibility,we release our code publicly.",Kiara Grouwstra,2020/8/28,2020/9/17
2108.01610v1,Towards Substructural Property-Based Testing,http://arxiv.org/abs/2108.01610v1,We propose to extend property-based testing to substructural logics toovercome the current lack of reasoning tools in the field. We take the firststep by implementing a property-based testing system for specifications writtenin the linear logic programming language Lolli. We employ the foundationalproof certificates architecture to model various data generation strategies. Wevalidate our approach by encoding a model of a simple imperative programminglanguage and its compilation and by testing its meta-theory via mutationanalysis.,Marco Mantovani,2021/8/3,2021/8/3
2301.08665v1,MTGP: Combining Metamorphic Testing and Genetic Programming,http://arxiv.org/abs/2301.08665v1,"Genetic programming is an evolutionary approach known for its performance inprogram synthesis. However, it is not yet mature enough for a practical use inreal-world software development, since usually many training cases are requiredto generate programs that generalize to unseen test cases. As in practice, thetraining cases have to be expensively hand-labeled by the user, we need anapproach to check the program behavior with a lower number of training cases.Metamorphic testing needs no labeled input/output examples. Instead, theprogram is executed multiple times, first on a given (randomly generated)input, followed by related inputs to check whether certain user-definedrelations between the observed outputs hold. In this work, we suggest MTGP,which combines metamorphic testing and genetic programming and study itsperformance and the generalizability of the generated programs. Further, weanalyze how the generalizability depends on the number of given labeledtraining cases. We find that using metamorphic testing combined with labeledtraining cases leads to a higher generalization rate than the use of labeledtraining cases alone in almost all studied configurations. Consequently, werecommend researchers to use metamorphic testing in their systems if thelabeling of the training data is expensive.",Dominik Sobania,2023/1/20,2023/1/20
1401.7635v1,Tailored Source Code Transformations to Synthesize Computationally Diverse Program Variants,http://arxiv.org/abs/1401.7635v1,"The predictability of program execution provides attackers a rich source ofknowledge who can exploit it to spy or remotely control the program. Movingtarget defense addresses this issue by constantly switching between manydiverse variants of a program, which reduces the certainty that an attacker canhave about the program execution. The effectiveness of this approach relies onthe availability of a large number of software variants that exhibit differentexecutions. However, current approaches rely on the natural diversity providedby off-the-shelf components, which is very limited. In this paper, we explorethe automatic synthesis of large sets of program variants, called sosies.Sosies provide the same expected functionality as the original program, whileexhibiting different executions. They are said to be computationally diverse.This work addresses two objectives: comparing different transformations forincreasing the likelihood of sosie synthesis (densifying the search space forsosies); demonstrating computation diversity in synthesized sosies. Wesynthesized 30184 sosies in total, for 9 large, real-world, open sourceapplications. For all these programs we identified one type of program analysisthat systematically increases the density of sosies; we measured computationdiversity for sosies of 3 programs and found diversity in method calls or datain more than 40% of sosies. This is a step towards controlled massiveunpredictability of software.",Benoit Baudry,2014/1/29,2014/1/29
1509.00144v3,Automatic Software Diversity in the Light of Test Suites,http://arxiv.org/abs/1509.00144v3,"A few works address the challenge of automating software diversification, andthey all share one core idea: using automated test suites to drivediversification. However, there is is lack of solid understanding of how testsuites, programs and transformations interact one with another in this process.We explore this intricate interplay in the context of a specificdiversification technique called ""sosiefication"". Sosiefication generates sosieprograms, i.e., variants of a program in which some statements are deleted,added or replaced but still pass the test suite of the original program. Ourinvestigation of the influence of test suites on sosiefication exploits thefollowing observation: test suites cover the different regions of programs invery unequal ways. Hence, we hypothesize that sosie synthesis has differentperformances on a statement that is covered by one hundred test case and on astatement that is covered by a single test case. We synthesize 24583 sosies on6 popular open-source Java programs. Our results show that there are twodimensions for diversification. The first one lies in the specification: themore test cases cover a statement, the more difficult it is to synthesizesosies. Yet, to our surprise, we are also able to synthesize sosies on highlytested statements (up to 600 test cases), which indicates an intrinsic propertyof the programs we study. The second dimension is in the code: we manuallyexplore dozens of sosies and characterize new types of forgiving code regionsthat are prone to diversification.",Benoit Baudry,2015/9/1,2018/12/23
2311.04527v1,Extended Paper: API-driven Program Synthesis for Testing Static Typing Implementations,http://arxiv.org/abs/2311.04527v1,"We introduce a novel approach for testing static typing implementations basedon the concept of API-driven program synthesis. The idea is to synthesizetype-intensive but small and well-typed programs by leveraging and combiningapplication programming interfaces (APIs) derived from existing softwarelibraries. Our primary insight is backed up by real-world evidence: asignificant number of compiler typing bugs are caused by small test cases thatemploy APIs from the standard library of the language under test. This isattributed to the inherent complexity of the majority of these APIs, whichoften exercise a wide range of sophisticated type-related features. The maincontribution of our approach is the ability to produce small client programswith increased feature coverage, without bearing the burden of generating thecorresponding well-formed API definitions from scratch. To validate diverseaspects of static typing procedures (i.e., soundness, precision of typeinference), we also enrich our API-driven approach with fault-injection andsemantics-preserving modes, along with their corresponding test oracles.  We evaluate our implemented tool, Thalia on testing the static typingimplementations of the compilers for three popular languages, namely, Scala,Kotlin, and Groovy. Thalia has uncovered 84 typing bugs (77 confirmed and 22fixed), most of which are triggered by test cases featuring APIs that rely onparametric polymorphism, overloading, and higher-order functions. Ourcomparison with state-of-the-art shows that Thalia yields test programs withdistinct characteristics, offering additional and complementary benefits.",Thodoris Sotiropoulos,2023/11/8,2023/11/8
2004.05934v1,Detecting Critical Bugs in SMT Solvers Using Blackbox Mutational Fuzzing,http://arxiv.org/abs/2004.05934v1,"Formal methods use SMT solvers extensively for deciding formulasatisfiability, for instance, in software verification, systematic testgeneration, and program synthesis. However, due to their compleximplementations, solvers may contain critical bugs that lead to unsoundresults. Given the wide applicability of solvers in software reliability,relying on such unsound results may have detrimental consequences. In thispaper, we present STORM, a novel blackbox mutational fuzzing technique fordetecting critical bugs in SMT solvers. We run our fuzzer on seven maturesolvers and find 29 previously unknown critical bugs. STORM is already beingused in testing new features of popular solvers before deployment.",Muhammad Numair Mansur,2020/4/13,2020/4/13
2306.09665v1,State-Of-The-Practice in Quality Assurance in Java-Based Open Source Software Development,http://arxiv.org/abs/2306.09665v1,"To ensure the quality of software systems, software engineers can make use ofa variety of quality assurance approaches, such as software testing, moderncode review, automated static analysis, and build automation. Each of thesequality assurance practices has been studied in depth in isolation, but thereis a clear knowledge gap when it comes to our understanding of how theseapproaches are being used in conjunction or not. In our study, we broadlyinvestigate whether and how these quality assurance approaches are being usedin conjunction in the development of 1,454 popular open source softwareprojects on GitHub. Our study indicates that typically projects do not followall quality assurance practices together with high intensity. In fact, we onlyobserve weak correlation among some quality assurance practices. In general,our study provides a deeper understanding of how existing quality assuranceapproaches are currently being used in Java-based open source softwaredevelopment. Besides, we specifically zoomed in on the more mature projects inour dataset, and generally, we observe that more mature projects are moreintense in their application of the quality assurance practices, with morefocus on their ASAT usage and code reviewing, but no strong change in their CIusage.",Ali Khatami,2023/6/16,2023/6/16
2105.01195v2,Quality Assurance Challenges for Machine Learning Software Applications During Software Development Life Cycle Phases,http://arxiv.org/abs/2105.01195v2,"In the past decades, the revolutionary advances of Machine Learning (ML) haveshown a rapid adoption of ML models into software systems of diverse types.Such Machine Learning Software Applications (MLSAs) are gaining importance inour daily lives. As such, the Quality Assurance (QA) of MLSAs is of paramountimportance. Several research efforts are dedicated to determining the specificchallenges we can face while adopting ML models into software systems. However,we are aware of no research that offered a holistic view of the distribution ofthose ML quality assurance challenges across the various phases of softwaredevelopment life cycles (SDLC). This paper conducts an in-depth literaturereview of a large volume of research papers that focused on the qualityassurance of ML models. We developed a taxonomy of MLSA quality assuranceissues by mapping the various ML adoption challenges across different phases ofSDLC. We provide recommendations and research opportunities to improve SDLCpractices based on the taxonomy. This mapping can help prioritize qualityassurance efforts of MLSAs where the adoption of ML models can be consideredcrucial.",Md Abdullah Al Alamin,2021/5/3,2021/7/8
1512.02708v1,A Case-Based Look at Integrating Social Context into Software Quality,http://arxiv.org/abs/1512.02708v1,"Ensuring high-quality software requires considering the social climate withinwhich the applications will be deployed and used. This can be done by designingquality goals and objectives that are consistent with changing social andethical landscapes. Using principles of technological determinism, this articlepresents three cases that illustrate why it is becoming even more important tointegrate these concerns into software design and quality assurance. With theseexamples in mind, this article explains how to consider technologicaldeterminism in software design and quality assurance practices to achieve thisenhanced sensitivity on a practical level.",Nicole Radziwill,2015/12/9,2015/12/9
1611.01286v1,Integrating a Model of Analytical Quality Assurance into the V-Modell XT,http://arxiv.org/abs/1611.01286v1,"Economic models of quality assurance can be an important tool for decisionmakers in software development projects. They enable to base quality assuranceplanning on economical factors of the product and the used defect-detectiontechniques. A variety of such models has been proposed but many are tooabstract to be used in practice. Furthermore, even the more concrete modelslack an integration with existing software development process models toincrease their applicability. This paper describes an integration of a thoroughstochastic model of the economics of analytical quality assurance with thesystems development process model V-Modell XT. The integration is done in amodular way by providing a new process module - a concept directly available inthe V-Modell XT for extension purposes - related to analytical qualityassurance. In particular, we describe the work products, roles, and activitiesdefined in our new process module and their effects on existing V-Modell XTelements.",Stefan Wagner,2016/11/4,2016/11/4
1408.3253v2,A measurement based software quality framework,http://arxiv.org/abs/1408.3253v2,"In this report we propose a solution to problem of the dependency on theexperience of the software project quality assurance personnel by providing atransparent, objective and measurement based quality framework. The frameworkhelps the quality assurance experts making objective and comparable decisionsin software projects by defining and assessing measurable quality goals andthresholds, directly relating these to an escalation mechanism. First resultsof applying the proposed measurement based software quality framework in a reallife case study are also addressed in this report.",Zdor Dniel Kelemen,2014/8/14,2014/8/17
2308.12825v1,"Requirements Quality Assurance in Industry: Why, What and How?",http://arxiv.org/abs/2308.12825v1,"Context and Motivation: Natural language is the most common form to specifyrequirements in industry. The quality of the specification depends on thecapability of the writer to formulate requirements aimed at differentstakeholders: they are an expression of the customer's needs that are used byanalysts, designers and testers. Given this central role of requirements as amean to communicate intention, assuring their quality is essential to reducemisunderstandings that lead to potential waste. Problem: Quality assurance ofrequirement specifications is largely a manual effort that requires expertiseand domain knowledge. However, this demanding cognitive process is alsocongested by trivial quality issues that should not occur in the first place.Principal ideas: We propose a taxonomy of requirements quality assurancecomplexity that characterizes cognitive load of verifying a quality aspect fromthe human perspective, and automation complexity and accuracy from the machineperspective. Contribution: Once this taxonomy is realized and validated, it canserve as the basis for a decision framework of automated requirements qualityassurance support.",Michael Unterkalmsteiner,2023/8/24,2023/8/24
1611.01287v1,Managing Quality Requirements Using Activity-Based Quality Models,http://arxiv.org/abs/1611.01287v1,Managing requirements on quality aspects is an important issue in thedevelopment of software systems. Difficulties arise from expressing themappropriately what in turn results from the difficulty of the concept ofquality itself. Building and using quality models is an approach to handle thecomplexity of software quality. A novel kind of quality models uses theactivities performed on and with the software as an explicit dimension. Thesequality models are a well-suited basis for managing quality requirements fromelicitation over refinement to assurance. The paper proposes such an approachand shows its applicability in an automotive case study.,Stefan Wagner,2016/11/4,2016/11/4
1202.2506v1,Improvement of Key Problems of Software Testing in Quality Assurance,http://arxiv.org/abs/1202.2506v1,"Quality assurance makes sure the project will be completed based on thepreviously approved specifications, standards and functionality. It is requiredwithout defects and possible problems. It monitors and tries to progress thedevelopment process from the start of the project. Software Quality Assurance(SQA) is the combination of the entire software development process, whichincludes software design, coding, source code control, code review, changemanagement, configuration management and release management. In this paper wedescribe the solution for the key problems of software testing in qualityassurance. The existing software practices have some problems such as testingpractices, attitude of users and culture of organizations. All these treeproblems have some combined problems such as shortcuts in testing, reduction intesting time, poor documentation etc. In this paper we are recommendingstrategies to provide solution of the said problems mentioned above.",Nayyar Iqbal,2012/2/12,2012/2/12
1404.7509v1,On Cloud-Based Engineering of Dependable Systems,http://arxiv.org/abs/1404.7509v1,"The cloud computing paradigm is being adopted by many organizations indifferent application domains as it is cost effective and offers a virtuallyunlimited pool of resources. Engineering critical systems can benefit fromclouds in attaining all dependability means: fault tolerance, fault prevention,fault removal and fault forecasting. Our research aims to investigate thepotential of supporting engineering of dependable software systems with cloudcomputing and proposes an open, extensible, and elastic cloud-based softwareengineering workflow system which represents and executes software processes toimprove collaboration, reliability and quality assurance, and automation insoftware projects.",Sami Alajrami,2014/4/29,2014/4/29
2203.12697v1,What is Software Quality for AI Engineers? Towards a Thinning of the Fog,http://arxiv.org/abs/2203.12697v1,"It is often overseen that AI-enabled systems are also software systems andtherefore rely on software quality assurance (SQA). Thus, the goal of thisstudy is to investigate the software quality assurance strategies adoptedduring the development, integration, and maintenance of AI/ML components andcode. We conducted semi-structured interviews with representatives of tenAustrian SMEs that develop AI-enabled systems. A qualitative analysis of theinterview data identified 12 issues in the development of AI/ML components.Furthermore, we identified when quality issues arise in AI/ML components andhow they are detected. The results of this study should guide future work onsoftware quality assurance processes and techniques for AI/ML components.",Valentina Golendukhina,2022/3/23,2022/3/23
1812.03057v1,Open Problems in Engineering and Quality Assurance of Safety Critical Machine Learning Systems,http://arxiv.org/abs/1812.03057v1,"Fatal accidents are a major issue hindering the wide acceptance ofsafety-critical systems using machine-learning and deep-learning models, suchas automated-driving vehicles. Quality assurance frameworks are required forsuch machine learning systems, but there are no widely accepted and establishedquality-assurance concepts and techniques. At the same time, open problems andthe relevant technical fields are not organized. To establish standard qualityassurance frameworks, it is necessary to visualize and organize these openproblems in an interdisciplinary way, so that the experts from many differenttechnical fields may discuss these problems in depth and develop solutions. Inthe present study, we identify, classify, and explore the open problems inquality assurance of safety-critical machine-learning systems, and theirrelevant corresponding industry and technological trends, usingautomated-driving vehicles as an example. Our results show that addressingthese open problems requires incorporating knowledge from several differenttechnological and industrial fields, including the automobile industry,statistics, software engineering, and machine learning.",Hiroshi Kuwajima,2018/12/7,2018/12/7
2009.05260v1,The AIQ Meta-Testbed: Pragmatically Bridging Academic AI Testing and Industrial Q Needs,http://arxiv.org/abs/2009.05260v1,"AI solutions seem to appear in any and all application domains. As AI becomesmore pervasive, the importance of quality assurance increases. Unfortunately,there is no consensus on what artificial intelligence means and interpretationsrange from simple statistical analysis to sentient humanoid robots. On top ofthat, quality is a notoriously hard concept to pinpoint. What does this meanfor AI quality? In this paper, we share our working definition and a pragmaticapproach to address the corresponding quality assurance with a focus ontesting. Finally, we present our ongoing work on establishing the AIQMeta-Testbed.",Markus Borg,2020/9/11,2020/9/11
1507.06906v1,Exploratory Analysis of Quality Practices in Open Source Domain,http://arxiv.org/abs/1507.06906v1,"Software quality assurance has been a heated topic for several decades, butrelatively few analyses were performed on open source software (OSS). As OSShas become very popular in our daily life, many researchers have been keen onthe quality practices in this area. Although quality management presentsdistinct patterns compared with those in closed-source software development,some widely used OSS products have been implemented. Therefore, qualityassurance of OSS projects has attracted increased research focuses. In thispaper, a survey is conducted to reveal the general quality practices in opensource communities. Exploratory analysis has been carried out to disclose thosequality related activities. The results are compared with those fromclosed-source environments and the distinguished features of the qualityassurance in OSS projects have been confirmed. Moreover, this study suggestspotential directions for OSS developers to follow.",Jie Xu,2015/7/24,2015/7/24
2306.08833v1,Safeguarding Crowdsourcing Surveys from ChatGPT with Prompt Injection,http://arxiv.org/abs/2306.08833v1,"ChatGPT and other large language models (LLMs) have proven useful incrowdsourcing tasks, where they can effectively annotate machine learningtraining data. However, this means that they also have the potential formisuse, specifically to automatically answer surveys. LLMs can potentiallycircumvent quality assurance measures, thereby threatening the integrity ofmethodologies that rely on crowdsourcing surveys. In this paper, we propose amechanism to detect LLM-generated responses to surveys. The mechanism uses""prompt injection"", such as directions that can mislead LLMs into givingpredictable responses. We evaluate our technique against a range of questionscenarios, types, and positions, and find that it can reliably detectLLM-generated responses with more than 93% effectiveness. We also provide anopen-source software to help survey designers use our technique to detect LLMresponses. Our work is a step in ensuring that survey methodologies remainrigorous vis-a-vis LLMs.",Chaofan Wang,2023/6/15,2023/6/15
1507.08888v1,Service Dependability with Continuously Revised Assurance Cases by Multiple Stakeholders: A Case Study,http://arxiv.org/abs/1507.08888v1,"Recently, assurance cases have received much attentions in the field ofsoftware-based computer systems and IT services. However, software very oftenchanges and there are no strong regulations for software. These facts are maintwo challenges to be addressed in software assurance cases. We propose adevelopment method of assurance cases by means of continuous revision at everystage of the system lifecycle, including in-operation and service recovery infailure cases. The quality of dependability arguments are improved by multiplestakeholders who check with each other. This paper reported our experience ofthe proposed method in a case of the ASPEN education service. The case studydemonstrate that the continuos updates create a significant amount of activerisk communications between stakeholders. This gives us a promising perspectivefor the long-term improvement of service dependability with the lifecycleassurance cases.",Kimio Kuramitsu,2015/7/31,2015/7/31
1006.5442v1,Static and Dynamic Quality Assurance by Aspect Oriented Techniques,http://arxiv.org/abs/1006.5442v1,"The overall goal of the described research project was to create applicablequality assurance patterns for Java software systems using the aspect-orientedprogramming language extension AspectJ 5. We tried to develop aspects to checkstatic quality criteria as a variable mutator convention and architecturallayering rules. We successfully developed aspects for automating the followingdynamic quality criteria: Parameterized Exception Chaining, ComfortableDeclaration of Parameterized Exceptions, Not-Null Checking of ReferenceVariables.",Christoph Knabe,2010/6/14,2010/6/14
1812.08836v1,Automatic Quality Assurance and Release (Report from Dagstuhl Seminar 18122),http://arxiv.org/abs/1812.08836v1,"This report documents the program and the outcomes of Dagstuhl Seminar 18122""Automatic Quality Assurance and Release"". The main goal of this seminar was tobridge the knowledge divide on how researchers and industry professionalsreason about and implement DevOps for automatic quality assurance. Through theseminar, we have built up a common understanding of DevOps tools and practices,but we have also identified major academic and educational challenges for thisfield of research.",Bram Adams,2018/12/20,2018/12/20
2104.14056v1,Machine Learning Techniques for Software Quality Assurance: A Survey,http://arxiv.org/abs/2104.14056v1,"Over the last years, machine learning techniques have been applied to moreand more application domains, including software engineering and, especially,software quality assurance. Important application domains have been, e.g.,software defect prediction or test case selection and prioritization. Theability to predict which components in a large software system are most likelyto contain the largest numbers of faults in the next release helps to bettermanage projects, including early estimation of possible release delays, andaffordably guide corrective actions to improve the quality of the software.However, developing robust fault prediction models is a challenging task andmany techniques have been proposed in the literature. Closely related toestimating defect-prone parts of a software system is the question of how toselect and prioritize test cases, and indeed test case prioritization has beenextensively researched as a means for reducing the time taken to discoverregressions in software. In this survey, we discuss various approaches in bothfault prediction and test case prioritization, also explaining how in recentstudies deep learning algorithms for fault prediction help to bridge the gapbetween programs' semantics and fault prediction features. We also reviewrecently proposed machine learning methods for test case prioritization (TCP),and their ability to reduce the cost of regression testing without negativelyaffecting fault detection capabilities.",Safa Omri,2021/4/29,2021/4/29
1512.02707v1,The Ethics of Hacking: Should It Be Taught?,http://arxiv.org/abs/1512.02707v1,"Poor software quality can adversely affect application security by increasingthe potential for a malicious breach of a system. Because computer security andcybersecurity are becoming such relevant topics for practicing softwareengineers, the need for educational opportunities in this area is steadilyincreasing. Universities and colleges have recognized this, and have started tooffer programs in cybersecurity. At face value, these new programs may notappear controversial, but developing their curriculum requires answering acomplex ethical question: Should programs teach hacking to their students? Eventhough there are different types of hackers, media reports of cybersecurityincidents tend to reserve the ""hacker"" label for cyber criminals, whichoverlooks the value in hacking (and, by extension, teaching students to hack).This article examines the full spectrum of hacking behavior, as well asarguments for and against including hacking in education programs, andrecommends that hacking skills be considered an essential component of aneducation and practice in software quality assurance.",Nicole Radziwill,2015/12/9,2015/12/9
1911.11596v1,Distortion and Faults in Machine Learning Software,http://arxiv.org/abs/1911.11596v1,"Machine learning software, deep neural networks (DNN) software in particular,discerns valuable information from a large dataset, a set of data. Outcomes ofsuch DNN programs are dependent on the quality of both learning programs anddatasets. Unfortunately, the quality of datasets is difficult to be defined,because they are just samples. The quality assurance of DNN software isdifficult, because resultant trained machine learning models are unknown priorto its development, and the validation is conducted indirectly in terms ofprediction performance. This paper introduces a hypothesis that faults in thelearning programs manifest themselves as distortions in trained machinelearning models. Relative distortion degrees measured with appropriate observerfunctions may indicate that there are some hidden faults. The proposal isdemonstrated with example cases of the MNIST dataset.",Shin Nakajima,2019/11/25,2019/11/25
2306.06468v1,ScaffML: A Quantum Behavioral Interface Specification Language for Scaffold,http://arxiv.org/abs/2306.06468v1,"Ensuring the correctness of quantum programs is crucial for quantum softwarequality assurance. Although various effective verification methods exist forclassical programs, they cannot be applied to quantum programs due to thefundamental differences in their execution logic, such as quantum superpositionand entanglement. This calls for new methods to verify the correctness ofquantum programs. In this paper, we present a behavioral interfacespecification language (BISL) called ScaffML for the quantum programminglanguage Scaffold. ScaffML allows the specification of pre- and post-conditionsfor Scaffold modules and enables the mixing of assertions with Scaffold code,thereby facilitating debugging and verification of quantum programs. This paperdiscusses the goals and overall approach of ScaffML and describes the basicfeatures of the language through examples. ScaffML provides an easy-to-usespecification language for quantum programmers, supporting static analysis,run-time checking, and formal verification of Scaffold programs. Finally, wepresent several instances to illustrate the workflow and functionalities ofScaffML.",Tiancheng Jin,2023/6/10,2023/6/10
1911.07988v2,Invariant Diffs,http://arxiv.org/abs/1911.07988v2,"Software development is inherently incremental. Nowadays, many softwarecompanies adopt an agile process and a shorter release cycle, where softwareneeds to be delivered faster with quality assurances. On the other hand, themajority of existing program analysis tools still target single versions ofprograms and are slow and inflexible to handle changes. In the popular versioncontrol systems such as git, the program changes are still presented usingsource code diffs. It is hard to understand what program conditions are changedand which source code lines cause them. In this paper, we propose to compute""invariant diffs"" to specify changes. Similar to source diffs that reportcommon code and code churns, we define version invariants to represent programconditions that are common across versions, and invariant churns to show thechanges of program conditions between versions. We designed a staticdemand-driven, path-sensitive analysis to compute and compare invariants formultiple versions of programs using multiversion control flow graphs. We reportinvariant diffs at the matched program points where comparing invariants aremeaningful. Importantly, our analysis correlates source diffs with invariantdiffs to explain what source code changes lead to the property changes. Weimplemented our algorithms in a tool called $H_2$ and performed experiments on104 versions of programs. Our results show that we are able to computeinvariant diffs correctly within reasonable amount of time. The versioninvariants can capture the common properties of program versions evenconstructed by different persons, and the invariant churns can specify thesemantics of changes such as how a patch changed a buggy condition to a correctcondition.",Ashwin Kallingal Joshy,2019/11/18,2020/6/30
1507.06925v1,An Empirical Study on the Procedure to Derive Software Quality Estimation Models,http://arxiv.org/abs/1507.06925v1,"Software quality assurance has been a heated topic for several decades. Iffactors that influence software quality can be identified, they may providemore insight for better software development management. More precise qualityassurance can be achieved by employing resources according to accurate qualityestimation at the early stages of a project. In this paper, a general procedureis proposed to derive software quality estimation models and various techniquesare presented to accomplish the tasks in respective steps. Several statisticaltechniques together with machine learning method are utilized to verify theeffectiveness of software metrics. Moreover, a neuro-fuzzy approach is adoptedto improve the accuracy of the estimation model. This procedure is carried outbased on data from the ISBSG repository to present its empirical value.",Jie Xu,2015/7/24,2015/7/24
1911.04309v1,On the costs and profit of software defect prediction,http://arxiv.org/abs/1911.04309v1,"Defect prediction can be a powerful tool to guide the use of qualityassurance resources. However, while lots of research covered methods for defectprediction as well as methodological aspects of defect prediction research, theactual cost saving potential of defect prediction is still unclear. Within thisarticle, we close this research gap and formulate a cost model for softwaredefect prediction. We derive mathematically provable boundary conditions thatmust be fulfilled by defect prediction models such that there is a positiveprofit when the defect prediction model is used. Our cost model includesaspects like the costs for quality assurance, the costs of post-releasedefects, the possibility that quality assurance fails to reveal predicteddefects, and the relationship between software artifacts and defects. Weinitialize the cost model using different assumptions, perform experiments toshow trends of the behavior of costs on real projects. Our results show thatthe unrealistic assumption that defects only affect a single software artifact,which is a standard practice in the defect prediction literature, leads toinaccurate cost estimations. Moreover, the results indicate that thresholds formachine learning metrics are also not suited to define success criteria forsoftware defect prediction.",Steffen Herbold,2019/11/11,2019/11/11
2312.04917v1,Operationalizing Assurance Cases for Data Scientists: A Showcase of Concepts and Tooling in the Context of Test Data Quality for Machine Learning,http://arxiv.org/abs/2312.04917v1,"Assurance Cases (ACs) are an established approach in safety engineering toargue quality claims in a structured way. In the context of quality assurancefor Machine Learning (ML)-based software components, ACs are also beingdiscussed and appear promising. Tools for operationalizing ACs do exist, yetmainly focus on supporting safety engineers on the system level. However,assuring the quality of an ML component within the system is commonly theresponsibility of data scientists, who are usually less familiar with thesetools. To address this gap, we propose a framework to support theoperationalization of ACs for ML components based on technologies that datascientists use on a daily basis: Python and Jupyter Notebook. Our aim is tomake the process of creating ML-related evidence in ACs more effective. Resultsfrom the application of the framework, documented through notebooks, can beintegrated into existing AC tools. We illustrate the application of theframework on an example excerpt concerned with the quality of the test data.",Lisa Jckel,2023/12/8,2023/12/8
1804.00994v1,A Learning Approach to Enhance Assurances for Real-Time Self-Adaptive Systems,http://arxiv.org/abs/1804.00994v1,"The assurance of real-time properties is prone to context variability.Providing such assurance at design time would require to check all the possiblecontext and system variations or to predict which one will be actually used.Both cases are not viable in practice since there are too many possibilities toforesee. Moreover, the knowledge required to fully provide the assurance forself-adaptive systems is only available at runtime and therefore difficult topredict at early development stages. Despite all the efforts on assurances forself-adaptive systems at design or runtime, there is still a gap on verifyingand validating real-time constraints accounting for context variability. Tofill this gap, we propose a method to provide assurance of self-adaptivesystems, at design- and runtime, with special focus on real-time constraints.We combine off-line requirements elicitation and model checking with on-linedata collection and data mining to guarantee the system's goals, bothfunctional and non-functional, with fine tuning of the adaptation policiestowards the optimization of quality attributes. We experimentally evaluate ourmethod on a simulated prototype of a Body Sensor Network system (BSN)implemented in OpenDaVINCI. The results of the validation are promising andshow that our method is effective in providing evidence that support theprovision of assurance.",Arthur Rodrigues,2018/4/3,2018/4/3
2003.05155v2,Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology,http://arxiv.org/abs/2003.05155v2,"Machine learning is an established and frequently used technique in industryand academia but a standard process model to improve success and efficiency ofmachine learning applications is still missing. Project organizations andmachine learning practitioners have a need for guidance throughout the lifecycle of a machine learning application to meet business expectations. Wetherefore propose a process model for the development of machine learningapplications, that covers six phases from defining the scope to maintaining thedeployed machine learning application. The first phase combines business anddata understanding as data availability oftentimes affects the feasibility ofthe project. The sixth phase covers state-of-the-art approaches for monitoringand maintenance of a machine learning applications, as the risk of modeldegradation in a changing environment is eminent. With each task of theprocess, we propose quality assurance methodology that is suitable to adresschallenges in machine learning development that we identify in form of risks.The methodology is drawn from practical experience and scientific literatureand has proven to be general and stable. The process model expands on CRISP-DM,a data mining process model that enjoys strong industry support but lacks toaddress machine learning specific tasks. Our work proposes an industry andapplication neutral process model tailored for machine learning applicationswith focus on technical tasks for quality assurance.",Stefan Studer,2020/3/11,2021/2/24
2102.06807v1,Learning Software Quality Assurance with Bricks,http://arxiv.org/abs/2102.06807v1,"Software Quality Assurance (SQA) and Software Process Improvement (SPI) aretopics of crucial importance for software engineers; however, teaching them ina lecture room comes with several limitations due to lack of practicalexperience. With that in mind, we created KUALI-Brick, a LEGO(R)-based activitythat brings SQA and SPI concepts together applying them in order tosuccessfully build a LEGO city. This hands-on activity has been carried out ina fourth-year Software Engineering course at the University of Canterbury, withcurrent results showing high levels of fun, increased engagement and animproved learning experience. We present a step-by-step guide to replicate theactivity as well as lessons learned after conducting the activity for threeconsecutive years.",Miguel Ehecatl Morales-Trujillo,2021/2/12,2021/2/12
1810.04538v1,Secure Deep Learning Engineering: A Software Quality Assurance Perspective,http://arxiv.org/abs/1810.04538v1,"Over the past decades, deep learning (DL) systems have achieved tremendoussuccess and gained great popularity in various applications, such asintelligent machines, image processing, speech processing, and medicaldiagnostics. Deep neural networks are the key driving force behind its recentsuccess, but still seem to be a magic black box lacking interpretability andunderstanding. This brings up many open safety and security issues withenormous and urgent demands on rigorous methodologies and engineering practicefor quality enhancement. A plethora of studies have shown that thestate-of-the-art DL systems suffer from defects and vulnerabilities that canlead to severe loss and tragedies, especially when applied to real-worldsafety-critical applications. In this paper, we perform a large-scale study andconstruct a paper repository of 223 relevant works to the quality assurance,security, and interpretation of deep learning. We, from a software qualityassurance perspective, pinpoint challenges and future opportunities towardsuniversal secure deep learning engineering. We hope this work and theaccompanied paper repository can pave the path for the software engineeringcommunity towards addressing the pressing industrial demand of secureintelligent applications.",Lei Ma,2018/10/10,2018/10/10
2208.08982v2,Quality issues in Machine Learning Software Systems,http://arxiv.org/abs/2208.08982v2,"Context: An increasing demand is observed in various domains to employMachine Learning (ML) for solving complex problems. ML models are implementedas software components and deployed in Machine Learning Software Systems(MLSSs). Problem: There is a strong need for ensuring the serving quality ofMLSSs. False or poor decisions of such systems can lead to malfunction of othersystems, significant financial losses, or even threat to human life. Thequality assurance of MLSSs is considered as a challenging task and currently isa hot research topic. Moreover, it is important to cover all various aspects ofthe quality in MLSSs. Objective: This paper aims to investigate thecharacteristics of real quality issues in MLSSs from the viewpoint ofpractitioners. This empirical study aims to identify a catalog of bad-practicesrelated to poor quality in MLSSs. Method: We plan to conduct a set ofinterviews with practitioners/experts, believing that interviews are the bestmethod to retrieve their experience and practices when dealing with qualityissues. We expect that the catalog of issues developed at this step will alsohelp us later to identify the severity, root causes, and possible remedy forquality issues of MLSSs, allowing us to develop efficient quality assurancetools for ML models and MLSSs.",Pierre-Olivier Ct,2022/8/18,2022/8/22
2306.15007v1,Quality Issues in Machine Learning Software Systems,http://arxiv.org/abs/2306.15007v1,"Context: An increasing demand is observed in various domains to employMachine Learning (ML) for solving complex problems. ML models are implementedas software components and deployed in Machine Learning Software Systems(MLSSs). Problem: There is a strong need for ensuring the serving quality ofMLSSs. False or poor decisions of such systems can lead to malfunction of othersystems, significant financial losses, or even threats to human life. Thequality assurance of MLSSs is considered a challenging task and currently is ahot research topic. Objective: This paper aims to investigate thecharacteristics of real quality issues in MLSSs from the viewpoint ofpractitioners. This empirical study aims to identify a catalog of qualityissues in MLSSs. Method: We conduct a set of interviews withpractitioners/experts, to gather insights about their experience and practiceswhen dealing with quality issues. We validate the identified quality issues viaa survey with ML practitioners. Results: Based on the content of 37 interviews,we identified 18 recurring quality issues and 24 strategies to mitigate them.For each identified issue, we describe the causes and consequences according tothe practitioners' experience. Conclusion: We believe the catalog of issuesdeveloped in this study will allow the community to develop efficient qualityassurance tools for ML models and MLSSs. A replication package of our study isavailable on our public GitHub repository.",Pierre-Olivier Ct,2023/6/26,2023/6/26
2205.08029v1,Automatic Error Classification and Root Cause Determination while Replaying Recorded Workload Data at SAP HANA,http://arxiv.org/abs/2205.08029v1,"Capturing customer workloads of database systems to replay these workloadsduring internal testing can be beneficial for software quality assurance.However, we experienced that such replays can produce a large amount of falsepositive alerts that make the results unreliable or time consuming to analyze.Therefore, we design a machine learning based approach that attributes rootcauses to the alerts. This provides several benefits for quality assurance andallows for example to classify whether an alert is true positive or falsepositive. Our approach considerably reduces manual effort and improves theoverall quality assurance for the database system SAP HANA. We discuss theproblem, the design and result of our approach, and we present practicallimitations that may require further research.",Neetha Jambigi,2022/5/16,2022/5/16
1807.00211v2,Advanced Methods for the Optical Quality Assurance of Silicon Sensors,http://arxiv.org/abs/1807.00211v2,"We describe a setup for optical quality assurance of silicon microstripsensors. Pattern recognition algorithms were developed to analyze microscopicscans of the sensors for defects. It is shown that the software has arecognition and classification rate of $>$~90\% for defects like scratches,shorts, broken metal lines etc. We have demonstrated that advanced imageprocessing based on neural network techniques is able to further improve therecognition and defect classification rate.",E. Lavrik,2018/6/30,2018/10/30
2310.05312v1,Quality Assurance of A GPT-based Sentiment Analysis System: Adversarial Review Data Generation and Detection,http://arxiv.org/abs/2310.05312v1,"Large Language Models (LLMs) have been garnering significant attention of AIresearchers, especially following the widespread popularity of ChatGPT.However, due to LLMs' intricate architecture and vast parameters, severalconcerns and challenges regarding their quality assurance require to beaddressed. In this paper, a fine-tuned GPT-based sentiment analysis model isfirst constructed and studied as the reference in AI quality analysis. Then,the quality analysis related to data adequacy is implemented, includingemploying the content-based approach to generate reasonable adversarial reviewcomments as the wrongly-annotated data, and developing surprise adequacy(SA)-based techniques to detect these abnormal data. Experiments based onAmazon.com review data and a fine-tuned GPT model were implemented. Resultswere thoroughly discussed from the perspective of AI quality assurance topresent the quality analysis of an LLM model on generated adversarial textualdata and the effectiveness of using SA on anomaly detection in data qualityassurance.",Tinghui Ouyang,2023/10/9,2023/10/9
2305.04349v1,Documenting Bioinformatics Software Via Reverse Engineering,http://arxiv.org/abs/2305.04349v1,"Documentation is one of the most neglected activities in SoftwareEngineering, although it is an important method of assuring quality andunderstanding. Bioinformatics software is generally written by researchers fromfields other than Computer Science who usually do not provide documentation.Documenting bioinformatics software may ease its adoption in multidisciplinaryteams and expand its impact on the community. In this paper, we highlight howone can document software that is already finished, using reverse engineeringand thinking of the end-user.",Vinicius Soares Silva Marques,2023/5/7,2023/5/7
0910.0493v1,From Requirements to code: an Architecture-centric Approach for producing Quality Systems,http://arxiv.org/abs/0910.0493v1,"When engineering complex and distributed software and hardware systems(increasingly used in many sectors, such as manufacturing, aerospace,transportation, communication, energy, and health-care), quality has become abig issue, since failures can have economics consequences and can also endangerhuman life. Model-based specifications of a component-based system permit toexplicitly model the structure and behaviour of components and theirintegration. In particular Software Architectures (SA) has been advocated as aneffective means to produce quality systems. In this chapter by combiningdifferent technologies and tools for analysis and development, we propose anarchitecture-centric model-driven approach to validate required properties andto generate the system code. Functional requirements are elicited and used foridentifying expected properties the architecture shall express. Thearchitectural compliance to the properties is formally demonstrated, and theproduced architectural model is used to automatically generate the Java code.Suitable transformations assure that the code is conforming to both structuraland behavioural SA constraints. This chapter describes the process anddiscusses how some existing tools and languages can be exploited to support theapproach.",Antonio Bucchiarone,2009/10/2,2009/10/2
2102.05351v1,Quality Assurance for AI-based Systems: Overview and Challenges,http://arxiv.org/abs/2102.05351v1,"The number and importance of AI-based systems in all domains is growing. Withthe pervasive use and the dependence on AI-based systems, the quality of thesesystems becomes essential for their practical usage. However, quality assurancefor AI-based systems is an emerging area that has not been well explored andrequires collaboration between the SE and AI research communities. This paperdiscusses terminology and challenges on quality assurance for AI-based systemsto set a baseline for that purpose. Therefore, we define basic concepts andcharacterize AI-based systems along the three dimensions of artifact type,process, and quality characteristics. Furthermore, we elaborate on the keychallenges of (1) understandability and interpretability of AI models, (2) lackof specifications and defined requirements, (3) need for validation data andtest input generation, (4) defining expected outcomes as test oracles, (5)accuracy and correctness measures, (6) non-functional properties of AI-basedsystems, (7) self-adaptive and self-learning characteristics, and (8) dynamicand frequently changing environments.",Michael Felderer,2021/2/10,2021/2/10
1909.07283v1,Towards Quality Assurance of Software Product Lines with Adversarial Configurations,http://arxiv.org/abs/1909.07283v1,"Software product line (SPL) engineers put a lot of effort to ensure that,through the setting of a large number of possible configuration options,products are acceptable and well-tailored to customers' needs. Unfortunately,options and their mutual interactions create a huge configuration space whichis intractable to exhaustively explore. Instead of testing all products,machine learning techniques are increasingly employed to approximate the set ofacceptable products out of a small training sample of configurations. Machinelearning (ML) techniques can refine a software product line through learnedconstraints and a priori prevent non-acceptable products to be derived. In thispaper, we use adversarial ML techniques to generate adversarial configurationsfooling ML classifiers and pinpoint incorrect classifications of products(videos) derived from an industrial video generator. Our attacks yield (up to)a 100% misclassification rate and a drop in accuracy of 5%. We discuss theimplications these results have on SPL quality assurance.",Paul Temple,2019/9/16,2019/9/16
1910.11007v1,Practical experiences and value of applying software analytics to manage quality,http://arxiv.org/abs/1910.11007v1,"Background: Despite the growth in the use of software analytics platforms inindustry, little empirical evidence is available about the challenges thatpractitioners face and the value that these platforms provide. Aim: The goal ofthis research is to explore the benefits of using a software analytics platformfor practitioners managing quality. Method: In a technology transfer project, asoftware analytics platform was incrementally developed between academic andindustrial partners to address their software quality problems. This paperfocuses on exploring the value provided by this software analytics platform intwo pilot projects. Results: Practitioners emphasized major benefits includingthe improvement of product quality and process performance and an increasedawareness of product readiness. They especially perceived the semi-automatedfunctionality of generating quality requirements by the software analyticsplatform as the benefit with the highest impact and most novel value for them.Conclusions: Practitioners can benefit from modern software analyticsplatforms, especially if they have time to adopt such a platform carefully andintegrate it into their quality assurance activities.",Anna Maria Vollmer,2019/10/24,2019/10/24
2310.13006v1,Software Metadata Classification based on Generative Artificial Intelligence,http://arxiv.org/abs/2310.13006v1,"This paper presents a novel approach to enhance the performance of binarycode comment quality classification models through the application ofGenerative Artificial Intelligence (AI). By leveraging the OpenAI API, adataset comprising 1239 newly generated code-comment pairs, extracted fromvarious GitHub repositories and open-source projects, has been labelled as""Useful"" or ""Not Useful"", and integrated into the existing corpus of 9048 pairsin the C programming language. Employing a cutting-edge Large Language ModelArchitecture, the generated dataset demonstrates notable improvements in modelaccuracy. Specifically, when incorporated into the Support Vector Machine (SVM)model, a 6% increase in precision is observed, rising from 0.79 to 0.85.Additionally, the Artificial Neural Network (ANN) model exhibits a 1.5%increase in recall, climbing from 0.731 to 0.746. This paper sheds light on thepotential of Generative AI in augmenting code comment quality classificationmodels. The results affirm the effectiveness of this methodology, indicatingits applicability in broader contexts within software development and qualityassurance domains. The findings underscore the significance of integratinggenerative techniques to advance the accuracy and efficacy of machine learningmodels in practical software engineering scenarios.",Seetharam Killivalavan,2023/10/14,2023/10/14
2105.04383v1,A framework for the automation of testing computer vision systems,http://arxiv.org/abs/2105.04383v1,"Vision systems, i.e., systems that allow to detect and track objects inimages, have gained substantial importance over the past decades. They are usedin quality assurance applications, e.g., for finding surface defects inproducts during manufacturing, surveillance, but also automated driving,requiring reliable behavior. Interestingly, there is only little work onquality assurance and especially testing of vision systems in general. In thispaper, we contribute to the area of testing vision software, and present aframework for the automated generation of tests for systems based on vision andimage recognition. The framework makes use of existing libraries allowing tomodify original images and to obtain similarities between the original andmodified images. We show how such a framework can be used for testing aparticular industrial application on identifying defects on riblet surfaces andpresent preliminary results from the image classification domain.",Franz Wotawa,2021/5/10,2021/5/10
2002.01759v2,Quality Assurance Technologies of Big Data Applications: A Systematic Literature Review,http://arxiv.org/abs/2002.01759v2,"Big data applications are currently used in many application domains, rangingfrom statistical applications to prediction systems and smart cities. However,the quality of these applications is far from perfect, leading to a largeamount of issues and problems. Consequently, assuring the overall quality forbig data applications plays an increasingly important role. This paper aims atsummarizing and assessing existing quality assurance (QA) technologiesaddressing quality issues in big data applications. We have conducted asystematic literature review (SLR) by searching major scientific databases,resulting in 83 primary and relevant studies on QA technologies for big dataapplications. The SLR results reveal the following main findings: 1) the impactof the big data attributes of volume, velocity, and variety on the quality ofbig data applications; 2) the quality attributes that determine the quality forbig data applications include correctness, performance, availability,scalability, reliability and so on; 3) the existing QA technologies, includinganalysis, specification, model-driven architecture (MDA), verification, faulttolerance, testing, monitoring and fault & failure prediction; 4) existingstrengths and limitations of each kind of QA technology; 5) the existingempirical evidence of each QA technology. This study provides a solidfoundation for research on QA technologies of big data applications. However,many challenges of big data applications regarding quality still remain.",Pengcheng Zhang,2020/2/5,2020/2/6
1708.09492v1,Automatically Generating Commit Messages from Diffs using Neural Machine Translation,http://arxiv.org/abs/1708.09492v1,"Commit messages are a valuable resource in comprehension of softwareevolution, since they provide a record of changes such as feature additions andbug repairs. Unfortunately, programmers often neglect to write good commitmessages. Different techniques have been proposed to help programmers byautomatically writing these messages. These techniques are effective atdescribing what changed, but are often verbose and lack context forunderstanding the rationale behind a change. In contrast, humans write messagesthat are short and summarize the high level rationale. In this paper, we adaptNeural Machine Translation (NMT) to automatically ""translate"" diffs into commitmessages. We trained an NMT algorithm using a corpus of diffs and human-writtencommit messages from the top 1k Github projects. We designed a filter to helpensure that we only trained the algorithm on higher-quality commit messages.Our evaluation uncovered a pattern in which the messages we generate tend to beeither very high or very low quality. Therefore, we created a quality-assurancefilter to detect cases in which we are unable to produce good messages, andreturn a warning instead.",Siyuan Jiang,2017/8/30,2017/8/30
2102.05949v1,DirectDebug: Automated Testing and Debugging of Feature Models,http://arxiv.org/abs/2102.05949v1,"Variability models (e.g., feature models) are a common way for therepresentation of variabilities and commonalities of software artifacts. Suchmodels can be translated to a logical representation and thus allow differentoperations for quality assurance and other types of model property analysis.Specifically, complex and often large-scale feature models can become faulty,i.e., do not represent the expected variability properties of the underlyingsoftware artifact. In this paper, we introduce DirectDebug which is a directdiagnosis approach to the automated testing and debugging of variabilitymodels. The algorithm helps software engineers by supporting an automatedidentification of faulty constraints responsible for an unintended behavior ofa variability model. This approach can significantly decrease development andmaintenance efforts for such models.",Viet-Man Le,2021/2/11,2021/2/11
2210.03427v2,Generating Quizzes to Support Training on Quality Management and Assurance in Space Science and Engineering,http://arxiv.org/abs/2210.03427v2,"Quality management and assurance is key for space agencies to guarantee thesuccess of space missions, which are high-risk and extremely costly. In thispaper, we present a system to generate quizzes, a common resource to evaluatethe effectiveness of training sessions, from documents about quality assuranceprocedures in the Space domain. Our system leverages state of the artauto-regressive models like T5 and BART to generate questions, and a RoBERTamodel to extract answers for such questions, thus verifying their suitability.",Andrs Garca-Silva,2022/10/7,2022/11/4
2002.00748v2,Asking Questions the Human Way: Scalable Question-Answer Generation from Text Corpus,http://arxiv.org/abs/2002.00748v2,"The ability to ask questions is important in both human and machineintelligence. Learning to ask questions helps knowledge acquisition, improvesquestion-answering and machine reading comprehension tasks, and helps a chatbotto keep the conversation flowing with a human. Existing question generationmodels are ineffective at generating a large amount of high-qualityquestion-answer pairs from unstructured text, since given an answer and aninput passage, question generation is inherently a one-to-many mapping. In thispaper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), whichaims at automatically generating high-quality and diverse question-answer pairsfrom unlabeled text corpus at scale by imitating the way a human asksquestions. Our system consists of: i) an information extractor, which samplesfrom the text multiple types of assistive information to guide questiongeneration; ii) neural question generators, which generate diverse andcontrollable questions, leveraging the extracted assistive information; andiii) a neural quality controller, which removes low-quality generated databased on text entailment. We compare our question generation models withexisting approaches and resort to voluntary human evaluation to assess thequality of the generated question-answer pairs. The evaluation results suggestthat our system dramatically outperforms state-of-the-art neural questiongeneration models in terms of the generation quality, while being scalable inthe meantime. With models trained on a relatively smaller amount of data, wecan generate 2.8 million quality-assured question-answer pairs from a millionsentences found in Wikipedia.",Bang Liu,2020/1/27,2020/3/5
1901.10579v1,Aspects of Quality in Internet of Things (IoT) Solutions: A Systematic Mapping Study,http://arxiv.org/abs/1901.10579v1,"Internet of Things (IoT) is an emerging technology that has the promisingpower to change our future. Due to the market pressure, IoT systems may bereleased without sufficient testing. However, it is no longer acceptable torelease IoT systems to the market without assuring the quality. As in the caseof new technologies, the quality assurance process is a challenging task. Thispaper shows the results of the first comprehensive and systematic mapping studyto structure and categories the research evidence in the literature starting in2009 when the early publication of IoT papers for IoT quality assuranceappeared. The conducted research is based on the most recent guidelines on howto perform systematic mapping studies. A set of research questions is definedcarefully regarding the quality aspects of the IoT. Based on these questions, alarge number of evidence and research papers is considered in the study (478papers). We have extracted and analyzed different levels of information fromthose considered papers. Also, we have classified the topics addressed in thosepapers into categories based on the quality aspects. The study results carryout different areas that require more work and investigation in the context ofIoT quality assurance. The results of the study can help in a furtherunderstanding of the research gaps. Moreover, the results show a roadmap forfuture research directions.",Bestoun S. Ahmed,2019/1/22,2019/1/22
2112.05452v1,Improving the Question Answering Quality using Answer Candidate Filtering based on Natural-Language Features,http://arxiv.org/abs/2112.05452v1,"Software with natural-language user interfaces has an ever-increasingimportance. However, the quality of the included Question Answering (QA)functionality is still not sufficient regarding the number of questions thatare answered correctly. In our work, we address the research problem of how theQA quality of a given system can be improved just by evaluating thenatural-language input (i.e., the user's question) and output (i.e., thesystem's answer). Our main contribution is an approach capable of identifyingwrong answers provided by a QA system. Hence, filtering incorrect answers froma list of answer candidates is leading to a highly improved QA quality. Inparticular, our approach has shown its potential while removing in many casesthe majority of incorrect answers, which increases the QA quality significantlyin comparison to the non-filtered output of a system.",Aleksandr Gashkov,2021/12/10,2021/12/10
2007.10851v1,Code2Que: A Tool for Improving Question Titles from Mined Code Snippets in Stack Overflow,http://arxiv.org/abs/2007.10851v1,"Stack Overflow is one of the most popular technical Q&A sites used bysoftware developers. Seeking help from Stack Overflow has become an essentialpart of software developers' daily work for solving programming-relatedquestions. Although the Stack Overflow community has provided quality assuranceguidelines to help users write better questions, we observed that a significantnumber of questions submitted to Stack Overflow are of low quality. In thispaper, we introduce a new web-based tool, Code2Que, which can help developersin writing higher quality questions for a given code snippet. Code2Que consistsof two main stages: offline learning and online recommendation. In the offlinelearning phase, we first collect a set of good quality <code snippet, question>pairs as training samples. We then train our model on these training samplesvia a deep sequence-to-sequence approach, enhanced with an attention mechanism,a copy mechanism and a coverage mechanism. In the online recommendation phase,for a given code snippet, we use the offline trained model to generate questiontitles to assist less experienced developers in writing questions moreeffectively. At the same time, we embed the given code snippet into a vectorand retrieve the related questions with similar problematic code snippets.",Zhipeng Gao,2020/7/19,2020/7/19
1403.4045v1,Goal-oriented Data Visualization with Software Project Control Centers,http://arxiv.org/abs/1403.4045v1,"Many software development organizations still lack support for obtainingintellectual control over their software development processes and fordetermining the performance of their processes and the quality of the producedproducts. Systematic support for detecting and reacting to critical projectstates in order to achieve planned goals is usually missing. One means toinstitutionalize measurement on the basis of explicit models is the developmentand establishment of a so-called Software Project Control Center (SPCC) forsystematic quality assurance and management support. An SPCC is comparable to acontrol room, which is a well known term in the mechanical production domain.Its tasks include collecting, in- terpreting, and visualizing measurement datain order to provide context-, purpose-, and role-oriented information for allstakeholders (e.g., project managers, quality assurance manager, developers)during the execution of a software development project. The article willpresent an overview of SPCC concepts, a concrete instantiation that supportsgoal-oriented data visualization (G-SPCC approach), and experiences frompractical applications.",Jens Heidrich,2014/3/17,2014/3/17
2309.12941v1,Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models,http://arxiv.org/abs/2309.12941v1,"Assurance cases can be used to argue for the safety of products in safetyengineering. In safety-critical areas, the construction of assurance cases isindispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance casesby incorporating formal methods, rendering it possible for automatic reasoningabout assurance cases. We present Trustworthiness Derivation Tree Analyzer(Trusta), a desktop application designed to automatically construct and verifyTDTs. The tool has a built-in Prolog interpreter in its backend, and issupported by the constraint solvers Z3 and MONA. Therefore, it can solveconstraints about logical formulas involving arithmetic, sets, Horn clausesetc. Trusta also utilizes large language models to make the creation andevaluation of assurance cases more convenient. It allows for interactive humanexamination and modification. We evaluated top language models likeChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our testsshowed a 50%-80% similarity between machine-generated and human-created cases.In addition, Trusta can extract formal constraints from text in naturallanguages, facilitating an easier interpretation and validation process. Thisextraction is subject to human review and correction, blending the best ofautomated efficiency with human insight. To our knowledge, this marks the firstintegration of large language models in automatic creating and reasoning aboutassurance cases, bringing a novel approach to a traditional challenge. Throughseveral industrial case studies, Trusta has proven to quickly find some subtleissues that are typically missed in manual inspection, demonstrating itspractical value in enhancing the assurance case development process.",Zezhong Chen,2023/9/22,2023/9/22
1405.4824v1,Measuring Cost of Quality (CoQ) on SDLC Projects is Indispensible for Effective Software Quality Assurance,http://arxiv.org/abs/1405.4824v1,"It is well known fact that was phrased by famous quality scholar P.B. Crosbythat it is always cheaper to do the job right the first time. However, thisstatement must be reconsidered with respect to software development projects,because the concept of quality and associated costs measurements in softwareengineering discipline is not as matured as in manufacturing and other fieldsof the industry. Post delivery defects (i.e. software bugs) are very common andintegral part of software industry. While the process of measuring andclassifying quality cost components is visible, obvious and institutionalizedin manufacturing industry, it is still evolving in software industry. Inaddition to this, the recommendations of British standard BS-6143-2:1990 forclassifying quality-related costs into prevention costs, appraisal costs, andfailure costs have been successfully adopted by many industries, by identifyingthe activities carried out within each of these categories, and measuring thecosts connected with them, software industry has a long-way to go to have thesame level of adoption and institutionalization of cost of quality measurementsand visibility. Cost of Quality for software isn't the price of creating aquality software product or IT-service. It's actually the cost of NOT creatinga quality software product or IT-service. The chronic affliction of majority ofsoftware development projects that are frequently found bleeding with costoverruns, schedule slippage, scope creep and poor quality of deliverables inthe global IT industry, was the trigger for this research work. Lessons learntfrom this study offer valuable prescriptive guidance for small and mediumsoftware businesses, who can benefit from this study by applying the same fortheir quality improvement initiatives using CoQ-metric, to enhance thecapability and maturity of their SDLC-project performance.",Parvez Mahmood Khan,2014/5/19,2014/5/19
1702.07656v1,Does Quality of Requirements Specifications matter? Combined Results of Two Empirical Studies,http://arxiv.org/abs/1702.07656v1,"Background: Requirements Engineering is crucial for project success, and tothis end, many measures for quality assurance of the software requirementsspecification (SRS) have been proposed. Goal: However, we still need anempirical understanding on the extent to which SRS are created and used inpractice, as well as the degree to which the quality of an SRS matters tosubsequent development activities. Method: We studied the relevance of SRS byrelying on survey research and explored the impact of quality defects in SRS byrelying on a controlled experiment. Results: Our results suggest that therelevance of SRS quality depends both on particular project characteristics andwhat is considered as a quality defect; for instance, the domain of safetycritical systems seems to motivate for an intense usage of SRS as a means forcommunication whereas defects hampering the pragmatic quality do not seem to beas relevant as initially thought. Conclusion: Efficient and effective qualityassurance measures must be specific for carefully characterized contexts andcarefully select defect classes.",Jakob Mund,2017/2/24,2017/2/24
2308.16275v1,Quantitative Toolchain Assurance,http://arxiv.org/abs/2308.16275v1,"The software bill of materials (SBOM) concept aims to include moreinformation about a software build such as copyrights, dependencies andsecurity references. But SBOM lacks visibility into the process for building apackage. Efforts such as Supply-chain Levels for Software Artifacts (SLSA) tryto remedy this by focusing on the quality of the build process. But they lackquantitative assessment of that quality. They are purely qualitative. A newform of assurance case and new technique for structuring it, called processreduction, are presented. An assurance case for a toolchain is quantitative andwhen structured as a process reduction can measure the strength of thetoolchain via the strength of the reduction. An example is given for a simpletoolchain.",Dennis Volpano,2023/8/30,2023/8/30
2104.06020v1,Reproducible Builds: Increasing the Integrity of Software Supply Chains,http://arxiv.org/abs/2104.06020v1,"Although it is possible to increase confidence in Free and Open SourceSoftware (FOSS) by reviewing its source code, trusting code is not the same astrusting its executable counterparts. These are typically built and distributedby third-party vendors, with severe security consequences if their supplychains are compromised. In this paper, we present reproducible builds, anapproach that can determine whether generated binaries correspond with theiroriginal source code. We first define the problem, and then provide insightinto the challenges of making real-world software build in a ""reproducible""manner-this is, when every build generates bit-for-bit identical results.Through the experience of the Reproducible Builds project making the DebianLinux distribution reproducible, we also describe the affinity betweenreproducibility and quality assurance (QA).",Chris Lamb,2021/4/13,2021/4/13
2003.11350v1,Quality Assurance of Heterogeneous Applications: The SODALITE Approach,http://arxiv.org/abs/2003.11350v1,"A key focus of the SODALITE project is to assure the quality and performanceof the deployments of applications over heterogeneous Cloud and HPCenvironments. It offers a set of tools to detect and correct errors, smells,and bugs in the deployment models and their provisioning workflows, and aframework to monitor and refactor deployment model instances at runtime. Thispaper presents objectives, designs, early results of the quality assuranceframework and the refactoring framework.",Indika Kumara,2020/3/25,2020/3/25
2203.15414v1,Quality Assurance of Generative Dialog Models in an Evolving Conversational Agent Used for Swedish Language Practice,http://arxiv.org/abs/2203.15414v1,"Due to the migration megatrend, efficient and effective second-languageacquisition is vital. One proposed solution involves AI-enabled conversationalagents for person-centered interactive language practice. We present resultsfrom ongoing action research targeting quality assurance of proprietarygenerative dialog models trained for virtual job interviews. The action teamelicited a set of 38 requirements for which we designed corresponding automatedtest cases for 15 of particular interest to the evolving solution. Our resultsshow that six of the test case designs can detect meaningful differencesbetween candidate models. While quality assurance of natural languageprocessing applications is complex, we provide initial steps toward anautomated framework for machine learning model selection in the context of anevolving conversational agent. Future work will focus on model selection in anMLOps setting.",Markus Borg,2022/3/29,2022/3/29
2312.11889v1,Predicting Line-Level Defects by Capturing Code Contexts with Hierarchical Transformers,http://arxiv.org/abs/2312.11889v1,"Software defects consume 40% of the total budget in software development andcost the global economy billions of dollars every year. Unfortunately, despitethe use of many software quality assurance (SQA) practices in softwaredevelopment (e.g., code review, continuous integration), defects may stillexist in the official release of a software product. Therefore, prioritizingSQA efforts for the vulnerable areas of the codebase is essential to ensure thehigh quality of a software release. Predicting software defects at the linelevel could help prioritize the SQA effort but is a highly challenging taskgiven that only ~3% of lines of a codebase could be defective. Existing workson line-level defect prediction often fall short and cannot fully leverage theline-level defect information. In this paper, we propose Bugsplorer, a noveldeep-learning technique for line-level defect prediction. It leverages ahierarchical structure of transformer models to represent two types of codeelements: code tokens and code lines. Unlike the existing techniques that areoptimized for file-level defect prediction, Bugsplorer is optimized for aline-level defect prediction objective. Our evaluation with five performancemetrics shows that Bugsplorer has a promising capability of predictingdefective lines with 26-72% better accuracy than that of the state-of-the-arttechnique. It can rank the first 20% defective lines within the top 1-3%suspicious lines. Thus, Bugsplorer has the potential to significantly reduceSQA costs by ranking defective lines higher.",Parvez Mahbub,2023/12/19,2023/12/19
1311.3798v1,Integrating Inspection and Test Processes Based on Context-Specific Assumptions,http://arxiv.org/abs/1311.3798v1,"Inspections and testing are two of the most commonly performed softwarequality assurance processes today. Typically, these processes are applied inisolation, which, however, fails to exploit the benefits of systematicallycombining and integrating them. In consequence, tests are not focused based onearly defect detection data. Expected benefits of such process integrationinclude higher defect detection rates or reduced quality assurance effort.Moreover, when conducting testing without any prior information regarding thesystem's quality, it is often unclear how to focus testing. A systematicintegration of inspection and testing processes requires context-specificknowledge about the relationships between inspections and testing. Thisknowledge is typically not available and needs to be empirically identified andvalidated. Often, context-specific assumptions can be seen as a starting pointfor generating such knowledge. Based on the In2Test approach, which usesinspection data to focus testing, we present in this article how knowledgeabout the relationship between inspections and testing can be gained,documented, and evolved in an analytical or empirical manner. In addition, thisarticle gives an overview of related work and highlights future researchdirections.",Frank Elberzhager,2013/11/15,2013/11/15
1701.01941v2,Multi-Objective Software Suite of Two-Dimensional Shape Descriptors for Object-Based Image Analysis,http://arxiv.org/abs/1701.01941v2,"In recent years two sets of planar (2D) shape attributes, provided with anintuitive physical meaning, were proposed to the remote sensing community by,respectively, Nagao & Matsuyama and Shackelford & Davis in their seminal workson the increasingly popular geographic object based image analysis (GEOBIA)paradigm. These two published sets of intuitive geometric features wereselected as initial conditions by the present R&D software project, whosemulti-objective goal was to accomplish: (i) a minimally dependent and maximallyinformative design (knowledge/information representation) of a general purpose,user and application independent dictionary of 2D shape terms provided with aphysical meaning intuitive to understand by human end users and (ii) aneffective (accurate, scale invariant, easy to use) and efficient implementationof 2D shape descriptors. To comply with the Quality Assurance Framework forEarth Observation guidelines, the proposed suite of geometric functions isvalidated by means of a novel quantitative quality assurance policy, centeredon inter feature dependence (causality) assessment. This innovativemultivariate feature validation strategy is alternative to traditional featureselection procedures based on either inductive data learning classificationaccuracy estimation, which is inherently case specific, or cross correlationestimation, because statistical cross correlation does not imply causation. Theproject deliverable is an original general purpose software suite of sevenvalidated off the shelf 2D shape descriptors intuitive to use. Alternative toexisting commercial or open source software libraries of tens of planar shapefunctions whose informativeness remains unknown, it is eligible for use in(GE)OBIA systems in operating mode, expected to mimic human reasoning based ona convergence of evidence approach.",Andrea Baraldi,2017/1/8,2017/2/2
1708.01419v1,DoKnowMe: Towards a Domain Knowledge-driven Methodology for Performance Evaluation,http://arxiv.org/abs/1708.01419v1,"Software engineering considers performance evaluation to be one of the keyportions of software quality assurance. Unfortunately, there seems to be a lackof standard methodologies for performance evaluation even in the scope ofexperimental computer science. Inspired by the concept of ""instantiation"" inobject-oriented programming, we distinguish the generic performance evaluationlogic from the distributed and ad-hoc relevant studies, and develop an abstractevaluation methodology (by analogy of ""class"") we name Domain Knowledge-drivenMethodology (DoKnowMe). By replacing five predefined domain-specific knowledgeartefacts, DoKnowMe could be instantiated into specific methodologies (byanalogy of ""object"") to guide evaluators in performance evaluation of differentsoftware and even computing systems. We also propose a generic validationframework with four indicators (i.e.~usefulness, feasibility, effectiveness andrepeatability), and use it to validate DoKnowMe in the Cloud servicesevaluation domain. Given the positive and promising validation result, we planto integrate more common evaluation strategies to improve DoKnowMe and furtherfocus on the performance evaluation of Cloud autoscaler systems.",Zheng Li,2017/8/4,2017/8/4
1910.07004v1,The NAI Suite -- Drafting and Reasoning over Legal Texts,http://arxiv.org/abs/1910.07004v1,"A prototype for automated reasoning over legal texts, called NAI, ispresented. As an input, NAI accepts formalized logical representations of suchlegal texts that can be created and curated using an integrated annotationinterface. The prototype supports automated reasoning over the given textrepresentation and multiple quality assurance procedures. The pragmatics of theNAI suite as well its feasibility in practical applications is studied on afragment of the Smoking Prohibition (Children in Motor Vehicles) (Scotland) Act2016 of the Scottish Parliament.",Tomer Libal,2019/10/15,2019/10/15
2311.08328v1,A PRISMA-driven systematic mapping study on system assurance weakeners,http://arxiv.org/abs/2311.08328v1,"Context: An assurance case is a structured hierarchy of claims aiming atdemonstrating that a given mission-critical system supports specificrequirements (e.g., safety, security, privacy). The presence of assuranceweakeners (i.e., assurance deficits, logical fallacies) in assurance casesreflects insufficient evidence, knowledge, or gaps in reasoning. Theseweakeners can undermine confidence in assurance arguments, potentiallyhindering the verification of mission-critical system capabilities.  Objectives: As a stepping stone for future research on assurance weakeners,we aim to initiate the first comprehensive systematic mapping study on thissubject. Methods: We followed the well-established PRISMA 2020 and SEGRESSguidelines to conduct our systematic mapping study. We searched for primarystudies in five digital libraries and focused on the 2012-2023 publication yearrange. Our selection criteria focused on studies addressing assurance weakenersat the modeling level, resulting in the inclusion of 39 primary studies in oursystematic review.  Results: Our systematic mapping study reports a taxonomy (map) that providesa uniform categorization of assurance weakeners and approaches proposed tomanage them at the modeling level.  Conclusion: Our study findings suggest that the SACM (Structured AssuranceCase Metamodel) -- a standard specified by the OMG (Object Management Group) --may be the best specification to capture structured arguments and reason abouttheir potential assurance weakeners.",Kimya Khakzad Shahandashti,2023/11/14,2023/11/14
1903.01220v1,An Assurance Framework for Independent Co-assurance of Safety and Security,http://arxiv.org/abs/1903.01220v1,"Integrated safety and security assurance for complex systems is difficult formany technical and socio-technical reasons such as mismatched processes,inadequate information, differing use of language and philosophies, etc.. Manyco-assurance techniques rely on disregarding some of these challenges in orderto present a unified methodology. Even with this simplification, no methodologyhas been widely adopted primarily because this approach is unrealistic when metwith the complexity of real-world system development.  This paper presents an alternate approach by providing a Safety-SecurityAssurance Framework (SSAF) based on a core set of assurance principles. This isdone so that safety and security can be co-assured independently, as opposed tounified co-assurance which has been shown to have significant drawbacks. Thisalso allows for separate processes and expertise from practitioners in eachdomain. With this structure, the focus is shifted from simplified unificationto integration through exchanging the correct information at the right timeusing synchronisation activities.",Nikita Johnson,2019/1/24,2019/1/24
1611.08847v1,Rapid quality assurance with Requirements Smells,http://arxiv.org/abs/1611.08847v1,"Bad requirements quality can cause expensive consequences during the softwaredevelopment lifecycle, especially if iterations are long and feedback comeslate. %-- the faster a problem is found, the cheaper it is to fix. This makesexplicit the need of a lightweight detection mechanism of requirements qualityviolations. We aim at a light-weight static requirements analysis approach thatallows for rapid checks immediately when requirements are written down. Wetransfer the concept of code smells to Requirements Engineering as RequirementsSmells. To evaluate the benefits and limitations, we define RequirementsSmells, realize our concepts for a smell detection in a prototype called Smellaand apply Smella in a series of cases provided by three industrial and auniversity context. The automatic detection yields an average precision of 59%at an average recall of 82% with high variation. The evaluation in practicalenvironments indicates benefits such as an increase of the awareness of qualitydefects. Yet, some smells were not clearly distinguishable. Lightweight smelldetection can uncover many practically relevant requirements defects in areasonably precise way. Although some smells need to be defined more clearly,smell detection provides a helpful means to support quality assurance inRequirements Engineering, for instance, as a supplement to reviews.",H. Femmer,2016/11/27,2016/11/27
1901.05771v2,Time Pressure in Software Engineering: A Systematic Review,http://arxiv.org/abs/1901.05771v2,"Large project overruns and overtime work have been reported in the softwareindustry, resulting in additional expense for companies and personal issues fordevelopers. The present work aims to provide an overview of studies related totime pressure in software engineering; specifically, existing definitions,possible causes, and metrics relevant to time pressure were collected, and amapping of the studies to software processes and approaches was performed.Moreover, we synthesize results of existing quantitative studies on the effectsof time pressure on software development, and offer practical takeaways forpractitioners and researchers, based on empirical evidence. Our search strategyexamined 5,414 sources, found through repository searches and snowballing.Applying inclusion and exclusion criteria resulted in the selection of 102papers, which made relevant contributions related to time pressure in softwareengineering. The majority of high quality studies report increased productivityand decreased quality under time pressure. Frequent categories of studies focuson quality assurance, cost estimation, and process simulation. It appears thattime pressure is usually caused by errors in cost estimation. The effect oftime pressure is most often identified during software quality assurance. Themajority of empirical studies report increased productivity under timepressure, while the most cost estimation and process simulation models assumethat compressing the schedule increases the total needed hours. We also findevidence of the mediating effect of knowledge on the effects of time pressure,and that tight deadlines impact tasks with an algorithmic nature more severely.Future research should better contextualize quantitative studies to account forthe existing conflicting results and to provide an understanding of situationswhen time pressure is either beneficial or harmful.",Miikka Kuutila,2019/1/17,2020/1/9
1604.05389v2,A Model-based Approach for Effective Service Delivery,http://arxiv.org/abs/1604.05389v2,"With the prevalence of X-as-a-Service (e.g., software as a service, platformas a service, infrastructure as a service, etc.) and users' growing demand ongood services, QoS (Quality of Service) assurance is becoming increasinglyimportant to service delivery. Traditional service delivery mainly focuses onfunction or information provisioning, and does not give high priority toquality assurance. In this paper, we tackle the QoS assurance problem in asystematic way, from model to system. We first decompose traditional servicesinto three components - namely software application, data and resource, thendefine models for these three kinds of basic services, and propose a set ofoperations for service publishing and composition. To illustrate our approach,we present a prototype system, the Platform as a Service (PaaS) system, whichis developed in support of our framework and shows how QoS can be ensuredthrough real-time monitoring and dynamic scaling (up or down).",Feng-Lin Li,2016/4/19,2016/5/31
2006.10345v1,Quantifying Assurance in Learning-enabled Systems,http://arxiv.org/abs/2006.10345v1,"Dependability assurance of systems embedding machine learning(ML)components---so called learning-enabled systems (LESs)---is a key step fortheir use in safety-critical applications. In emerging standardization andguidance efforts, there is a growing consensus in the value of using assurancecases for that purpose. This paper develops a quantitative notion of assurancethat an LES is dependable, as a core component of its assurance case, alsoextending our prior work that applied to ML components. Specifically, wecharacterize LES assurance in the form of assurance measures: a probabilisticquantification of confidence that an LES possesses system-level propertiesassociated with functional capabilities and dependability attributes. Weillustrate the utility of assurance measures by application to a real worldautonomous aviation system, also describing their role both in i) guidinghigh-level, runtime risk mitigation decisions and ii) as a core component ofthe associated dynamic assurance case.",Erfan Asaadi,2020/6/18,2020/6/18
